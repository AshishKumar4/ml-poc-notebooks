{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCSGKZcJDnx7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tensorflow.keras.utils import to_categorical  # Only for categorical one hot encoding\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorboard\n",
    "import os\n",
    "import tf_keras as tfk\n",
    "import keras\n",
    "from tensorflow_datasets.core.utils import gcs_utils\n",
    "gcs_utils._is_gcs_disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./logs/\n",
    "MODEL_NAME = 'A01_PROGAN'\n",
    "MODEL_PATH = os.path.join('models', MODEL_NAME)\n",
    "TRAIN_LOGDIR = os.path.join(\"logs\", \"tensorflow\", MODEL_NAME, 'train_data') # Sets up a log directory.\n",
    "# Creates a file writer for the log directory.\n",
    "file_writer = tf.summary.create_file_writer(TRAIN_LOGDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba = tfds.load('celeb_a', split='train', shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "7884836108d74585b2d6c43499be4b00",
      "0320d31ea717465588c394eb4d51e7ef",
      "0587d65448f64931a8b2a7567571a501",
      "56ac596d39214e26976bebd9feb73972",
      "c2771b2e01cc42ae9c72691e40261429",
      "9f334dc705d443d5b99541e467294220",
      "3907d6b9d0944d6aba5bf5d39dd210b1",
      "a8f22d4ccb3b4296970ecc92dd63d8f1",
      "8da5b95687334274bf8b419512f733b8",
      "fc18c429df5446f2928e301253af66df",
      "7c369757827c43c19b2a5e63672a634e",
      "b0600d22ed5948a28bcb5b7ce2c26dcb",
      "6c2bc8cd41a3471ba669e1909e137c33",
      "0eebfcc871b2429fbb7e2be0c30e5dac",
      "8428dd5a5032425489e6181f9849eec2",
      "b22cb14f030f4991816426452c582cd6",
      "bad4648f3d844c08be69d44f1bd2064e",
      "8406068892494f1485665dca6b884c40",
      "a969db852d99484e9f71f284e357e3a5",
      "41c40155b5644a12a43797b6150b5938",
      "4d0955cedfda4f528508280d55f43b00",
      "f4c44c94d37147478e5e059a0f3efb35",
      "305738872c794051adbb8f574dda9fae",
      "d8bf85e3104c45a68c803f5bb943d767",
      "6e06576433db421ba87acd5a96cc058b",
      "a7d7738f3a69421eb0850dad03c62d62",
      "921c132c04a243e9bf3a8ab4aaa0f032",
      "1f96e1060b7f4ad1819d9b1ee5832e76",
      "8b7461e8c5c84bd9b3b0530436cc30b5",
      "09991e0fe8234e4e9904ba454690ab6b",
      "7d3aef57552c47f4978bc0abf0bef07c",
      "6fa6fcdd41e14baf8e5cea8617d0a103",
      "6be34b510cba4fbfad8512bb1f82ac8c"
     ]
    },
    "id": "nE7EZmqONPHN",
    "outputId": "6592b37a-be39-4f4c-ad67-dd5fc5035323"
   },
   "outputs": [],
   "source": [
    "lfw = tfds.load('lfw', split='train', shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lfw), len(celeba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "220*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3eQiTgWLrkAT"
   },
   "outputs": [],
   "source": [
    "def plotImages(imgs):\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "\n",
    "    for i in range(imgs.shape[0]):\n",
    "      plt.subplot(8, 8, i+1)\n",
    "      plt.imshow(tf.cast(imgs[i, :, :, :] * 127.5 + 127.5, tf.uint8))\n",
    "      plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualizeLearningRate(layers.Wrapper):\n",
    "    \"\"\"\n",
    "    Reference from WeightNormalization implementation of TF Addons\n",
    "    EqualizeLearningRate wrapper works for keras CNN and Dense (RNN not tested).\n",
    "    ```python\n",
    "      net = EqualizeLearningRate(\n",
    "          layers.Conv2D(2, 2, activation='relu'),\n",
    "          input_shape=(32, 32, 3),\n",
    "          data_init=True)(x)\n",
    "      net = EqualizeLearningRate(\n",
    "          layers.Conv2D(16, 5, activation='relu'),\n",
    "          data_init=True)(net)\n",
    "      net = EqualizeLearningRate(\n",
    "          layers.Dense(120, activation='relu'),\n",
    "          data_init=True)(net)\n",
    "      net = EqualizeLearningRate(\n",
    "          layers.Dense(n_classes),\n",
    "          data_init=True)(net)\n",
    "    ```\n",
    "    Arguments:\n",
    "      layer: a layer instance.\n",
    "    Raises:\n",
    "      ValueError: If `Layer` does not contain a `kernel` of weights\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, layer, **kwargs):\n",
    "        super(EqualizeLearningRate, self).__init__(layer, **kwargs)\n",
    "        self._track_trackable(layer, name='layer')\n",
    "        self.is_rnn = isinstance(self.layer, layers.RNN)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        \"\"\"Build `Layer`\"\"\"\n",
    "        input_shape = tf.TensorShape(input_shape)\n",
    "        self.input_spec = layers.InputSpec(\n",
    "            shape=[None] + input_shape[1:])\n",
    "\n",
    "        if not self.layer.built:\n",
    "            self.layer.build(input_shape)\n",
    "\n",
    "        kernel_layer = self.layer.cell if self.is_rnn else self.layer\n",
    "\n",
    "        if not hasattr(kernel_layer, 'kernel'):\n",
    "            raise ValueError('`EqualizeLearningRate` must wrap a layer that'\n",
    "                             ' contains a `kernel` for weights')\n",
    "\n",
    "        if self.is_rnn:\n",
    "            kernel = kernel_layer.recurrent_kernel\n",
    "        else:\n",
    "            kernel = kernel_layer.kernel\n",
    "\n",
    "        # He constant\n",
    "        self.fan_in, self.fan_out= self._compute_fans(kernel.shape)\n",
    "        self.he_constant = tf.Variable(1.0 / np.sqrt(self.fan_in), dtype=tf.float32, trainable=False)\n",
    "\n",
    "        self.v = kernel\n",
    "        self.built = True\n",
    "    \n",
    "    def call(self, inputs, training=True):\n",
    "        \"\"\"Call `Layer`\"\"\"\n",
    "        # Multiply the kernel with the he constant.\n",
    "        kernel = self.v #* self.he_constant\n",
    "            \n",
    "        if self.is_rnn:\n",
    "            print(self.is_rnn)\n",
    "            self.layer.cell.recurrent_kernel = kernel\n",
    "            update_kernel = tf.identity(self.layer.cell.recurrent_kernel)\n",
    "        else:\n",
    "            self.layer.kernel = kernel\n",
    "            # update_kernel = tf.identity(self.layer.kernel)\n",
    "\n",
    "        # Ensure we calculate result after updating kernel.\n",
    "        # with tf.control_dependencies([update_kernel]):\n",
    "        outputs = self.layer(inputs)\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tf.TensorShape(\n",
    "            self.layer.compute_output_shape(input_shape).as_list())\n",
    "    \n",
    "    def _compute_fans(self, shape, data_format='channels_last'):\n",
    "        \"\"\"\n",
    "        From Official Keras implementation\n",
    "        Computes the number of input and output units for a weight shape.\n",
    "        # Arguments\n",
    "            shape: Integer shape tuple.\n",
    "            data_format: Image data format to use for convolution kernels.\n",
    "                Note that all kernels in Keras are standardized on the\n",
    "                `channels_last` ordering (even when inputs are set\n",
    "                to `channels_first`).\n",
    "        # Returns\n",
    "            A tuple of scalars, `(fan_in, fan_out)`.\n",
    "        # Raises\n",
    "            ValueError: in case of invalid `data_format` argument.\n",
    "        \"\"\"\n",
    "        if len(shape) == 2:\n",
    "            fan_in = shape[0]\n",
    "            fan_out = shape[1]\n",
    "        elif len(shape) in {3, 4, 5}:\n",
    "            # Assuming convolution kernels (1D, 2D or 3D).\n",
    "            # TH kernel shape: (depth, input_depth, ...)\n",
    "            # TF kernel shape: (..., input_depth, depth)\n",
    "            if data_format == 'channels_first':\n",
    "                receptive_field_size = np.prod(shape[2:])\n",
    "                fan_in = shape[1] * receptive_field_size\n",
    "                fan_out = shape[0] * receptive_field_size\n",
    "            elif data_format == 'channels_last':\n",
    "                receptive_field_size = np.prod(shape[:-2])\n",
    "                fan_in = shape[-2] * receptive_field_size\n",
    "                fan_out = shape[-1] * receptive_field_size\n",
    "            else:\n",
    "                raise ValueError('Invalid data_format: ' + data_format)\n",
    "        else:\n",
    "            # No specific assumptions.\n",
    "            fan_in = np.sqrt(np.prod(shape))\n",
    "            fan_out = np.sqrt(np.prod(shape))\n",
    "        return fan_in, fan_out\n",
    "\n",
    "# pixel-wise feature vector normalization layer\n",
    "class PixelNormalization(layers.Layer):\n",
    "    # initialize the layer\n",
    "    def __init__(self, **kwargs):\n",
    "        super(PixelNormalization, self).__init__(**kwargs)\n",
    " \n",
    "    # perform the operation\n",
    "    def call(self, inputs):\n",
    "        # computing pixel values\n",
    "        values = inputs**2.0\n",
    "        mean_values = K.mean(values, axis=-1, keepdims=True)\n",
    "        mean_values += 1.0e-8\n",
    "        l2 = K.sqrt(mean_values)\n",
    "        normalized = inputs / l2\n",
    "        return normalized\n",
    " \n",
    "    # define the output shape of the layer\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "class PixelNorm(layers.Layer):\n",
    "  def __init__(self, epsilon=1e-8, name=None):\n",
    "    super(PixelNorm, self).__init__(name=name)\n",
    "    self.epsilon = epsilon\n",
    "\n",
    "  def call(self, x):\n",
    "    return x * tf.math.rsqrt(tf.reduce_mean(tf.math.square(x), axis=-1, keepdims=True) + self.epsilon)\n",
    "\n",
    "class FadeAdd(layers.Layer):\n",
    "  def __init__(self, alpha : tf.Variable = None):\n",
    "    super(FadeAdd, self).__init__()\n",
    "    if alpha is None:\n",
    "      self.alpha = tf.Variable(initial_value=0., trainable=False)\n",
    "    else :\n",
    "      self.alpha = alpha\n",
    "\n",
    "  def incrementAlpha(self, step=0.1):\n",
    "    self.alpha.assign(tf.minimum(self.alpha+step, 1.))\n",
    "    # print(\"New Alpha: \", self.alpha)\n",
    "\n",
    "  def call(self, input):\n",
    "    new, old = input\n",
    "    self.alpha.assign(tf.minimum(self.alpha, 1.))\n",
    "    return (new*self.alpha) + (old*(1-self.alpha))\n",
    "\n",
    "class MinibatchStddev(layers.Layer):\n",
    "  def __init__(self, group_size=4, name=None):\n",
    "    super(MinibatchStddev, self).__init__(name=name)\n",
    "    self.group_size = group_size\n",
    "\n",
    "  def call(self, inputs):\n",
    "    group_size = tf.minimum(self.group_size, tf.shape(inputs)[0])\n",
    "    shape = tf.shape(inputs)\n",
    "    minibatch = tf.reshape(inputs, (group_size, -1, shape[1], shape[2], shape[3]))\n",
    "    stddev = tf.sqrt(tf.reduce_mean(tf.square(minibatch - tf.reduce_mean(minibatch, axis=0)), axis=0) + 1e-8)\n",
    "    stddev = tf.reduce_mean(stddev, axis=[1, 2, 3], keepdims=True)\n",
    "    stddev = tf.tile(stddev, [group_size, shape[1], shape[2], 1])\n",
    "    return tf.concat([inputs, stddev], axis=-1)\n",
    "\n",
    "class SelfAttention(layers.Layer):\n",
    "  def __init__(self, channelReduce=1, name=None):\n",
    "    super(SelfAttention, self).__init__(name=name)\n",
    "    self.channelReduce = channelReduce\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {'name': self.name}\n",
    "    base_config = super(SelfAttention, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "  def build(self, input_shape):\n",
    "    self.channels = input_shape[-1]\n",
    "    self.filters_f_g = self.channels // self.channelReduce\n",
    "    self.filters_h = self.channels\n",
    "\n",
    "    kernel_shape_f_g = (1, 1) + (self.channels, self.filters_f_g)\n",
    "    kernel_shape_h = (1, 1) + (self.channels, self.filters_h)\n",
    "\n",
    "    # Create a trainable weight variable for this layer:\n",
    "    self.gamma = self.add_weight(name='gamma', shape=[1], initializer='zeros', trainable=True)\n",
    "    self.kernel_f = self.add_weight(shape=kernel_shape_f_g,\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='kernel_f',\n",
    "                                        trainable=True)\n",
    "    self.kernel_g = self.add_weight(shape=kernel_shape_f_g,\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='kernel_g',\n",
    "                                        trainable=True)\n",
    "    self.kernel_h = self.add_weight(shape=kernel_shape_h,\n",
    "                                        initializer='glorot_uniform',\n",
    "                                        name='kernel_h',\n",
    "                                        trainable=True)\n",
    "\n",
    "    super(SelfAttention, self).build(input_shape)\n",
    "    self.built = True\n",
    "\n",
    "  def call(self, input):\n",
    "    def hw_flatten(x):\n",
    "      inp_shape = tf.shape(x)\n",
    "      # inp_shape = x.shape\n",
    "      shape = [inp_shape[0], inp_shape[1]*inp_shape[2], inp_shape[3]]\n",
    "      return tf.reshape(x, shape=shape)\n",
    "\n",
    "    # input = [NHWC]\n",
    "\n",
    "    f_x =  K.conv2d(input,\n",
    "                     kernel=self.kernel_f,\n",
    "                     strides=(1, 1), padding='same')\n",
    "    g_x =  K.conv2d(input,\n",
    "                     kernel=self.kernel_g,\n",
    "                     strides=(1, 1), padding='same')\n",
    "    h_x =  K.conv2d(input,\n",
    "                     kernel=self.kernel_h,\n",
    "                     strides=(1, 1), padding='same')\n",
    "\n",
    "\n",
    "    f_x_flat = hw_flatten(f_x) # [N(HW)C]\n",
    "    g_x_flat = hw_flatten(g_x) # [N(HW)C]\n",
    "\n",
    "    s = K.batch_dot(g_x_flat, K.permute_dimensions(f_x_flat, (0, 2, 1)))\n",
    "\n",
    "    beta = K.softmax(s, axis=-1)\n",
    "    o = K.batch_dot(beta, hw_flatten(h_x))\n",
    "\n",
    "    o = tf.reshape(o, shape=tf.shape(input))  # [bs, h, w, C]\n",
    "    x = self.gamma * o + input\n",
    "\n",
    "    return x\n",
    "\n",
    "def layer_init_stddev(shape, gain=np.sqrt(2)):\n",
    "  \"\"\"Get the He initialization scaling term.\"\"\"\n",
    "  fan_in = np.prod(shape[:-1])\n",
    "  return gain / np.sqrt(fan_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WCvSyhYbL9z0"
   },
   "outputs": [],
   "source": [
    "fmap_base = 8192\n",
    "fmap_max = 512\n",
    "fmap_decay = 1.\n",
    "def nf(stage): return min(int(fmap_base / (2.0 ** (stage * fmap_decay))), fmap_max)\n",
    "\n",
    "weight_init = tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.02)\n",
    "# weight_init = tf.keras.initializers.HeNormal()\n",
    "const = None # tf.keras.constraints.max_norm(1.0)\n",
    "\n",
    "class FakeLayer(layers.Layer):\n",
    "  def __init__(self, layer, name=None):\n",
    "    super(FakeLayer, self).__init__(name=name)\n",
    "    self.layer = layer\n",
    "    # self.trainable = True\n",
    "\n",
    "  def call(self, input):\n",
    "    return self.layer(input)\n",
    "\n",
    "  def get_config(self):\n",
    "    config = {'name': self.name, 'layer':self.layer}\n",
    "    base_config = super(FakeLayer, self).get_config()\n",
    "    return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def generatorBase():\n",
    "  Normalizer = FakeLayer\n",
    "\n",
    "  resolution = 4\n",
    "  res = int(np.log2(resolution))\n",
    "\n",
    "  inputLayer = layers.Input((512,))\n",
    "  x = inputLayer\n",
    "  x = PixelNorm()(x)\n",
    "  x = Normalizer(layers.Dense(4*4*nf(res-1), kernel_constraint=const, kernel_initializer=weight_init, use_bias=False))(x)\n",
    "  x = layers.LeakyReLU(0.2)(x)\n",
    "  x = layers.Reshape((4, 4, nf(res-1)))(x)\n",
    "  x = PixelNorm()(x)\n",
    "  \n",
    "  x = Normalizer(layers.Conv2D(nf(res-1), kernel_size=(3, 3), padding='same',\n",
    "                                         kernel_constraint=const, kernel_initializer=weight_init, use_bias=False))(x)\n",
    "  x = layers.LeakyReLU(0.2)(x)\n",
    "  x = PixelNorm(name='final_4')(x)\n",
    "\n",
    "  out = Normalizer(layers.Conv2D(3, (1, 1), strides=(1, 1), padding='same',\n",
    "                                           use_bias=False, activation='tanh', kernel_constraint=const,\n",
    "                                           kernel_initializer=weight_init), name='out_4')(x)\n",
    "  print(out.shape)\n",
    "  model = tf.keras.models.Model(inputs=inputLayer, outputs=out)\n",
    "  return model\n",
    "\n",
    "def generatorAddStage(gen, resolution=0, freeze=False, alpha:tf.Variable=None):\n",
    "  print(\"Current Shape: \", gen.output.shape)\n",
    "  Normalizer = FakeLayer\n",
    "\n",
    "  if resolution == 0:\n",
    "    resolution = gen.output.shape[1] * 2\n",
    "\n",
    "  res = int(np.log2(resolution))\n",
    "\n",
    "  if freeze:\n",
    "    print(\"Freezing\")\n",
    "    gen.trainable = False\n",
    "\n",
    "  newDepth = nf(res - 1)\n",
    "  x = gen.get_layer('final_'+str(resolution // 2)).output\n",
    "  print(\"Choosing layer \", x)\n",
    "\n",
    "  print(\"New Depth: \", newDepth)\n",
    "\n",
    "  x = layers.UpSampling2D(size=(2,2), interpolation='bicubic')(x)\n",
    "  # x = layers.Resizing(resolution, resolution, interpolation='nearest')(x)\n",
    "  x = Normalizer(layers.Conv2D(newDepth, (3, 3), strides=(1, 1), padding='same',\n",
    "                                         kernel_constraint=const, kernel_initializer=weight_init, use_bias=False))(x)\n",
    "  x = layers.LeakyReLU(0.2)(x)\n",
    "  x = PixelNorm()(x)\n",
    "\n",
    "  x = Normalizer(layers.Conv2D(newDepth, (3, 3), strides=(1, 1), padding='same',\n",
    "                                         kernel_constraint=const, kernel_initializer=weight_init, use_bias=False))(x)\n",
    "  x = layers.LeakyReLU(0.2)(x)\n",
    "  x = PixelNorm(name='final_'+str(resolution))(x)\n",
    "\n",
    "  out = Normalizer(layers.Conv2D(3, (1, 1), strides=(1, 1), padding='same',\n",
    "                                           activation='tanh', kernel_constraint=const, kernel_initializer=weight_init, use_bias=False), name='out_'+str(resolution))(x)\n",
    "  print(\"New Shape: \", out.shape)\n",
    "\n",
    "  # Add prev output\n",
    "  lastOut = gen.get_layer('out_'+str(resolution // 2)).output\n",
    "  up = layers.UpSampling2D((2,2), interpolation='bicubic')(lastOut)\n",
    "  # up = layers.Resizing(resolution, resolution, interpolation='nearest')(lastOut)\n",
    "\n",
    "  alpha = FadeAdd(alpha)\n",
    "  out = alpha([out, up])\n",
    "\n",
    "  inputLayer = gen.input\n",
    "  model = tf.keras.models.Model(inputs=inputLayer, outputs=out)\n",
    "  return model, alpha\n",
    "\n",
    "def reBaseModel(layers, inpTensor):\n",
    "  layer = inpTensor\n",
    "  # print(\"Rebasing\")\n",
    "  for i in range(len(layers)):\n",
    "    layer = layers[i](layer)\n",
    "  # print(\"Done\")\n",
    "  return layer\n",
    "\n",
    "def descriminatorBase():\n",
    "  Normalizer = layers.SpectralNormalization\n",
    "  resolution = 4\n",
    "  res = int(np.log2(resolution))\n",
    "\n",
    "  inputLayer = layers.Input((4, 4, 3))\n",
    "  # x = layers.GaussianNoise(0.00)(inputLayer)\n",
    "  x = inputLayer\n",
    "\n",
    "  x = MinibatchStddev(name='sup_mbatch_4')(x)\n",
    "  x = Normalizer(layers.Conv2D(nf(res-1), (1, 1), padding='same',\n",
    "                                                  kernel_constraint=const, kernel_initializer=weight_init, use_bias=False), name='sup_conv_4')(x)\n",
    "  x = layers.LeakyReLU(0.2, name='sup_act_4')(x)\n",
    "\n",
    "  baseLayers = []\n",
    "  baseLayers.append(\n",
    "      Normalizer(\n",
    "          layers.Conv2D(nf(res-1), kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
    "                        kernel_constraint=const, kernel_initializer=weight_init, use_bias=False),\n",
    "                        name='depth_4'\n",
    "          )\n",
    "  )\n",
    "  baseLayers.append(layers.LeakyReLU(0.2))\n",
    "\n",
    "  # baseLayers.append(layers.BatchNormalization())\n",
    "  baseLayers.append(layers.Flatten())\n",
    "  baseLayers.append(layers.Dense(1, kernel_constraint=const, kernel_initializer=weight_init, use_bias=False))\n",
    "\n",
    "  encOut = reBaseModel(baseLayers[:-1], x)\n",
    "  desOut = reBaseModel(baseLayers, x)\n",
    "\n",
    "  dis = tf.keras.models.Model(inputs=inputLayer, outputs=desOut)\n",
    "  enc = tf.keras.models.Model(inputs=inputLayer, outputs=encOut)\n",
    "  return dis, enc, baseLayers\n",
    "\n",
    "def descriminatorAddStage(des, enc, baseLayers, resolution=0, freeze=False, alpha:tf.Variable=None):\n",
    "  Normalizer = layers.SpectralNormalization\n",
    "  print(\"Current Shape: \", enc.input.shape)\n",
    "\n",
    "  if freeze:\n",
    "    print(\"Freezing\")\n",
    "    des.trainable = False\n",
    "    enc.trainable = False\n",
    "\n",
    "  print(\"Previous Input layer \", enc.input)\n",
    "\n",
    "  if resolution == 0:\n",
    "    resolution = enc.input.shape[1] * 2\n",
    "\n",
    "  newSize = resolution\n",
    "\n",
    "  res = int(np.log2(resolution))\n",
    "\n",
    "  print(\"New input \", newSize, newSize)\n",
    "\n",
    "  inputLayer = layers.Input((newSize, newSize, 3))\n",
    "  # inp = layers.GaussianNoise(0.00)(inputLayer)\n",
    "  inp = inputLayer\n",
    "\n",
    "  processingLayers = []\n",
    "  processingLayers.append(MinibatchStddev(name='sup_mbatch_'+str(resolution)))\n",
    "  processingLayers.append(Normalizer(layers.Conv2D(nf(res-1), (1, 1), padding='same',\n",
    "                                                                      kernel_constraint=const, kernel_initializer=weight_init, use_bias=False), name='sup_conv_'+str(resolution))\n",
    "  )\n",
    "  processingLayers.append(layers.LeakyReLU(name='sup_act_'+str(resolution), alpha=0.2))\n",
    "\n",
    "  x = reBaseModel(processingLayers, inp)\n",
    "\n",
    "  newLayers = []\n",
    "  newLayers.append(Normalizer(layers.Conv2D(nf(res-1), (3, 3), strides=(1, 1), padding='same',\n",
    "                                                      kernel_constraint=const, kernel_initializer=weight_init, use_bias=False), name='depth_'+str(resolution)))\n",
    "  # newLayers.append(layers.BatchNormalization(momentum=0.8))\n",
    "  newLayers.append(layers.LeakyReLU(0.2))\n",
    "\n",
    "  newLayers.append(Normalizer(layers.Conv2D(nf(res-2), (3, 3), strides=(1, 1), padding='same',\n",
    "                                                      kernel_constraint=const, kernel_initializer=weight_init, use_bias=False), name='depth2_'+str(resolution)))\n",
    "  # newLayers.append(layers.BatchNormalization(momentum=0.8))\n",
    "  newLayers.append(layers.LeakyReLU(0.2))\n",
    "  newLayers.append(layers.AveragePooling2D(2, 2))\n",
    "  # newLayers.append(layers.Resizing(resolution // 2, resolution // 2, interpolation='nearest'))  \n",
    "\n",
    "  newInp = reBaseModel(newLayers, x)\n",
    "  # print(newInp, baseLayers)\n",
    "\n",
    "  small = layers.AveragePooling2D((2, 2))(inp)\n",
    "  # small = layers.Resizing(resolution // 2, resolution // 2, interpolation='nearest')(inp)\n",
    "  sup = des.get_layer('sup_mbatch_'+str(resolution // 2))(small)\n",
    "  sup = des.get_layer('sup_conv_'+str(resolution // 2))(sup)\n",
    "  sup = des.get_layer('sup_act_'+str(resolution // 2))(sup)\n",
    "\n",
    "  print(\"====>\", sup)\n",
    "\n",
    "  print(newInp.shape, sup.shape)\n",
    "  beta = FadeAdd(alpha=alpha)\n",
    "  out = beta([newInp, sup])\n",
    "\n",
    "  print(\"==>\", out)\n",
    "\n",
    "  desOut = reBaseModel(baseLayers, out)\n",
    "  encOut = reBaseModel(baseLayers[:-1], out)\n",
    "\n",
    "  des = tf.keras.models.Model(inputs=inputLayer, outputs=desOut)\n",
    "  enc = tf.keras.models.Model(inputs=inputLayer, outputs=encOut)\n",
    "\n",
    "  baseLayers = newLayers + baseLayers\n",
    "  return des, enc, baseLayers, beta\n",
    "\n",
    "def generateBaseModels():\n",
    "  gen = generatorBase()\n",
    "  des, enc, baseLayers = descriminatorBase()\n",
    "  return gen, des, enc, baseLayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "5qPGQvy-nTws",
    "outputId": "87e0e2bd-42fb-4b7a-c70d-8680797e013f"
   },
   "outputs": [],
   "source": [
    "gen, des, enc, baseLayers = generateBaseModels()\n",
    "print(gen.summary(), des.summary())\n",
    "\n",
    "for i in range(5):\n",
    "  print(\"Adding Stage \", i, \" to generator\")\n",
    "  gen, alpha = generatorAddStage(gen, freeze=False)\n",
    "  print(\"Adding Stage \", i, \" to descriminator\")\n",
    "  des, enc, baseLayers, beta = descriminatorAddStage(des, enc, baseLayers, freeze=False)\n",
    "  print(gen.summary(), des.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gen.summary(), des.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(gen, to_file=\"generator.png\", expand_nested=True, show_shapes=True, show_layer_names=True, dpi=96, show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(des, to_file=\"descriminator.png\", expand_nested=True, show_shapes=True, show_layer_names=True, dpi=96, show_trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lerp(a, b, t):\n",
    "    return a + (b - a) * t\n",
    "\n",
    "def gradientPenalty(des, reals, fakes, batch_size):\n",
    "    \"\"\"Calculates the gradient penalty.\n",
    "\n",
    "    This loss is calculated on an interpolated image\n",
    "    and added to the discriminator loss.\n",
    "    \"\"\"\n",
    "    # Get the interpolated image\n",
    "    mixing_factors = tf.random.uniform([batch_size, 1, 1, 1], 0.0, 1.0, dtype=tf.float32)\n",
    "    mixed_images = lerp(reals, fakes, mixing_factors)\n",
    "\n",
    "    with tf.GradientTape() as gp_tape:\n",
    "        gp_tape.watch(mixed_images)\n",
    "        # 1. Get the discriminator output for this interpolated image.\n",
    "        mixed_output = des(mixed_images, training=True)\n",
    "\n",
    "    # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "    mixed_gradients = gp_tape.gradient(mixed_output, [mixed_images])[0]\n",
    "    # 3. Calculate the norm of the gradients.\n",
    "    mixed_norms = tf.sqrt(tf.reduce_sum(tf.square(mixed_gradients), axis=[1, 2, 3]))\n",
    "    gradient_penalty = tf.reduce_mean((mixed_norms - 1.0) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "def descriminator_WGANGPloss(reals, fakes, des, batch_size, smooth=1, wgan_target=1., wgan_lambda=10., wgan_epsilon=0.001):\n",
    "    real_output = des(reals, training=True)\n",
    "    fake_output = des(fakes, training=True)\n",
    "    loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradient_penalty = gradientPenalty(des, reals, fakes, batch_size)\n",
    "    # gradient_penalty = tf.math.square(mixed_norms - wgan_target)\n",
    "    total_loss = loss + (gradient_penalty * (wgan_lambda / (wgan_target**2))) + wgan_epsilon*real_output\n",
    "    # return tf.reduce_mean(total_loss)\n",
    "    return total_loss, real_output, fake_output\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    # wgan_loss = fake_output - real_output\n",
    "    # return wgan_loss\n",
    "    real_loss = tf.reduce_mean(real_output)\n",
    "    fake_loss = tf.reduce_mean(fake_output)\n",
    "    return fake_loss - real_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    total_loss = -tf.reduce_mean(fake_output)\n",
    "    return total_loss\n",
    "\n",
    "def generator_enc_loss(real, fake):\n",
    "  # return tf.reduce_mean(tf.abs(real - fake))\n",
    "  return tf.abs(real - fake)\n",
    "\n",
    "def generator_hinge_loss(fake_output):\n",
    "  total_loss = -tf.reduce_mean(fake_output)\n",
    "  return total_loss\n",
    "\n",
    "def descriminator_hinge_loss(reals, fakes, des, batch_size, apply_penalty=True, wgan_target=1., penalty_lambda=10):\n",
    "  with tf.GradientTape() as gp_tape:\n",
    "    gp_tape.watch(reals)\n",
    "    real_output = des(reals, training=True)\n",
    "    fake_output = des(fakes, training=True)\n",
    "\n",
    "  real_loss = tf.reduce_mean(tf.nn.relu(1.0 - real_output))\n",
    "  fake_loss = tf.reduce_mean(tf.nn.relu(1.0 + fake_output))\n",
    "  des_loss = real_loss + fake_loss\n",
    "\n",
    "  if apply_penalty:\n",
    "    gradient = gp_tape.gradient(real_output, [reals])[0]\n",
    "    penalty = K.mean(K.sum(tf.math.square(gradient), axis=np.arange(1, len(gradient.shape)))) * penalty_lambda\n",
    "    des_loss += penalty\n",
    "  return des_loss, real_output, fake_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQgQY8nVE4XY"
   },
   "outputs": [],
   "source": [
    "# @tf.function\n",
    "def trainGenEnc(gen, enc, real, batch_size, coeff=1, generator_optimizer=None, enc_optimizer=None):\n",
    "  with tf.GradientTape() as enc_tape, tf.GradientTape() as gen_tape:\n",
    "    real_enc = enc(real, training=True)\n",
    "    enc_fake = gen(real_enc, training=True)\n",
    " \n",
    "  gen_loss = generator_enc_loss(real, enc_fake) * coeff\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
    " \n",
    "  # gradients_of_enc = enc_tape.gradient(gen_loss, enc.trainable_variables)\n",
    "  # enc_optimizer.apply_gradients(zip(gradients_of_enc, enc.trainable_variables))\n",
    "  return gen_loss\n",
    " \n",
    "# @tf.function\n",
    "def trainDes(gen, des, real, batch_size, hinge=False, discriminator_optimizer=None):\n",
    "  with tf.GradientTape() as disc_tape:\n",
    "    noise = tf.random.normal([batch_size, 512])\n",
    " \n",
    "    fake = gen(noise, training=True)\n",
    "    \n",
    "    if hinge:\n",
    "      des_loss, real_output, fake_output = descriminator_hinge_loss(real, fake, des, batch_size)\n",
    "    else:\n",
    "      des_loss, real_output, fake_output = descriminator_WGANGPloss(real, fake, des, batch_size)\n",
    "\n",
    "  gradients_of_discriminator = disc_tape.gradient(des_loss, des.trainable_variables)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, des.trainable_variables))\n",
    "  return des_loss\n",
    " \n",
    "# @tf.function\n",
    "def trainDesGen(gen, des, real, batch_size, hinge=False, generator_optimizer=None, discriminator_optimizer=None):\n",
    "  with tf.GradientTape() as disc_tape, tf.GradientTape() as gen_tape:\n",
    "    noise = tf.random.normal([batch_size, 512])\n",
    "    fake = gen(noise, training=True)\n",
    "    \n",
    "    if hinge:\n",
    "      des_loss, real_output, fake_output = descriminator_hinge_loss(real, fake, des, batch_size)\n",
    "      gen_loss = generator_hinge_loss(fake_output)\n",
    "    else:\n",
    "      des_loss, real_output, fake_output = descriminator_WGANGPloss(real, fake, des, batch_size)\n",
    "      gen_loss = generator_loss(fake_output)\n",
    " \n",
    "  gradients_of_discriminator = disc_tape.gradient(des_loss, des.trainable_variables)\n",
    "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, des.trainable_variables))\n",
    "  \n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
    "  return des_loss, gen_loss\n",
    "\n",
    "# @tf.function\n",
    "def trainGen(gen, des, batch_size, hinge=False, generator_optimizer=None):\n",
    "  with tf.GradientTape() as gen_tape:\n",
    "    noise = tf.random.normal([batch_size, 512])\n",
    " \n",
    "    fake = gen(noise, training=True)\n",
    "    fake_output = des(fake, training=True)\n",
    " \n",
    "    if hinge:\n",
    "      gen_loss = generator_hinge_loss(fake_output)\n",
    "    else:\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "\n",
    "    # print(\"Gen Loss: \", gen_loss, fake_output)\n",
    "  gradients_of_generator = gen_tape.gradient(gen_loss, gen.trainable_variables)\n",
    "  generator_optimizer.apply_gradients(zip(gradients_of_generator, gen.trainable_variables))\n",
    "  return gen_loss\n",
    " \n",
    "def evalGan(gen, des, data, batches, batch_size):\n",
    "  desAcc = 0\n",
    "  genLoss = 0\n",
    "  for i in range(batches):\n",
    "    real = data\n",
    "    fake = gen(tf.random.normal([batch_size, 512]), training=False)\n",
    "\n",
    "    real_output = des(real, training=False)\n",
    "    fake_output = des(fake, training=False)\n",
    "    \n",
    "    output = tf.concat((fake_output, real_output), axis=0)\n",
    "\n",
    "    labels = tf.reshape(tf.concat((tf.zeros_like(fake_output), tf.ones_like(real_output)), axis=0), [-1])\n",
    "    output = tf.reshape(output, [-1])\n",
    "\n",
    "    acc = tf.keras.metrics.binary_accuracy(labels, output, threshold=0.5)\n",
    "    desAcc += acc.numpy()\n",
    "    # print(acc)\n",
    "    genLoss += tf.reduce_sum(generator_loss(fake_output)).numpy() / batch_size\n",
    "  return desAcc / batches, genLoss / batches\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def augmenter(size, alpha=None, method='area'):\n",
    "  if alpha is not None:\n",
    "    @tf.function\n",
    "    def augment(sample):\n",
    "      image = (tf.cast(sample['image'], tf.float32) - 127.5) / 127.5\n",
    "      big = tf.image.resize(image, [size, size], method=method, antialias=True)\n",
    "      small =  tf.image.resize(image, [size//2, size//2], method=method, antialias=True)\n",
    "      small = tf.image.resize(small, [size, size], method='area')\n",
    "      image = (big*alpha.alpha) + (small*(1-alpha.alpha))\n",
    "      image = tf.image.random_flip_left_right(image)\n",
    "      return {'image':image}\n",
    "    return augment\n",
    "  else:\n",
    "    @tf.function\n",
    "    def augment(sample):\n",
    "      image = tf.image.resize(sample['image'], [size, size], method=method, antialias=True)\n",
    "      image = (tf.cast(image, tf.float32) - 127.5) / 127.5\n",
    "      image = tf.image.random_flip_left_right(image)\n",
    "      return {'image':image}\n",
    "    return augment\n",
    "    \n",
    "# @tf.function\n",
    "def trainGan(\n",
    "  genModel, desModel, encModel, desBaseLayers,\n",
    "  data, \n",
    "  name=MODEL_NAME, \n",
    "  modeldir=MODEL_PATH, \n",
    "  trainingConf={\n",
    "    4:{\"epochs\":7, \"batch_size\":64, \"alpha_step\":0.1, \"alpha_delay\":0, \"alpha_multiplier\":1.2}, \n",
    "    8:{\"epochs\":20, \"batch_size\":64, \"alpha_step\":0.07, \"alpha_delay\":0.2, \"alpha_multiplier\":1.2}, \n",
    "    16:{\"epochs\":26, \"batch_size\":64, \"alpha_step\":0.07, \"alpha_delay\":0.2, \"alpha_multiplier\":1.2}, \n",
    "    32:{\"epochs\":32, \"batch_size\":48, \"alpha_step\":0.07, \"alpha_delay\":0.2, \"alpha_multiplier\":1.2}, \n",
    "    64:{\"epochs\":40, \"batch_size\":32, \"alpha_step\":0.07, \"alpha_delay\":0.3, \"alpha_multiplier\":1.2}, \n",
    "    128:{\"epochs\":50, \"batch_size\":32, \"alpha_step\":0.07, \"alpha_delay\":0.3, \"alpha_multiplier\":1.2}, \n",
    "    256:{\"epochs\":55, \"batch_size\":32, \"alpha_step\":0.07, \"alpha_delay\":0.3, \"alpha_multiplier\":1.2}\n",
    "  }, \n",
    "  des_steps=2, \n",
    "  gen_steps=1,\n",
    "):\n",
    "  realData = data\n",
    "  # print(realData.shape)\n",
    "  noise = tf.random.normal([64, 512])\n",
    "  results = []\n",
    "  gen_alpha, des_alpha = None, None\n",
    "  initialCoeff = 1.\n",
    "  scaleSizes = sorted(trainingConf.keys())\n",
    "  \n",
    "  globalIter = tf.Variable(0, dtype=tf.int64)\n",
    "  \n",
    "  # gen, des, enc, baseLayers = genModel, desModel, encModel, desBaseLayers\n",
    "  \n",
    "  modelMap = {\n",
    "    4 : {\"gen\":genModel, \"des\":desModel, \"enc\":encModel, \"gen_alpha\":None, \"des_alpha\":None, \"baseLayers\":desBaseLayers},\n",
    "  }\n",
    "  \n",
    "  for size in scaleSizes[1:]:\n",
    "    print(\"Adding Stage \", size, \" to generator\")\n",
    "    lastModel = modelMap[size // 2]\n",
    "    des, enc, baseLayers, des_alpha = descriminatorAddStage(des=lastModel[\"des\"], enc=lastModel[\"enc\"], baseLayers=lastModel[\"baseLayers\"], freeze=False)\n",
    "    gen, gen_alpha = generatorAddStage(gen=lastModel[\"gen\"], freeze=False)\n",
    "    modelMap[size] = {\"gen\":gen, \"des\":des, \"enc\":enc, \"gen_alpha\":gen_alpha, \"des_alpha\":des_alpha, \"baseLayers\":baseLayers}\n",
    "    \n",
    "  for size in scaleSizes:\n",
    "    conf = trainingConf[size]\n",
    "    epochs = conf['epochs']\n",
    "    batch_size = conf['batch_size']\n",
    "    alphaStep = conf['alpha_step']\n",
    "    alphaDelay = conf['alpha_delay']\n",
    "    alphaMultiplier = conf['alpha_multiplier']\n",
    "    \n",
    "    alphaDelay = int(alphaDelay * epochs)\n",
    "    shouldApplyAlpha = tf.Variable(False, dtype=tf.bool)\n",
    "    alphaStep = tf.Variable(alphaStep, dtype=tf.float32)\n",
    "    \n",
    "    models = modelMap[size]\n",
    "    gen, des, enc, gen_alpha, des_alpha, desBaseLayers = models[\"gen\"], models[\"des\"], models[\"enc\"], models[\"gen_alpha\"], models[\"des_alpha\"], models[\"baseLayers\"]\n",
    "\n",
    "    ideal_batch_size = int((nf(int(np.log2(size)) - 2) / 512) * batch_size)\n",
    "    print(\"Current Batch Size\", batch_size, \"ideal batch size\", ideal_batch_size, \"alpha delay\", alphaDelay)\n",
    "    coeff = initialCoeff\n",
    "    print(\"Input shape: \",des.input.shape, \"Current scale: \", size)\n",
    "    currentData = realData.map(augmenter(size, alpha=None)).shuffle(4096).batch(batch_size, drop_remainder=True).repeat().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    iterData = iter(currentData)\n",
    "    REAL = next(iterData)['image']\n",
    "    \n",
    "    steps = len(realData) // batch_size\n",
    "\n",
    "    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1 = 0, beta_2 = 0.999)\n",
    "    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1 = 0, beta_2 = 0.999)\n",
    "    enc_optimizer = tf.keras.optimizers.Adam(learning_rate=3e-4, beta_1 = 0, beta_2 = 0.999)\n",
    "    def getTrainers():\n",
    "      def _trainDes(real):\n",
    "        return trainDes(gen=gen, des=des, real=real, batch_size=batch_size, discriminator_optimizer=discriminator_optimizer, hinge=False)\n",
    "\n",
    "      def _trainGen():\n",
    "        return trainGen(gen=gen, des=des, batch_size=batch_size, hinge=False, generator_optimizer=generator_optimizer)\n",
    "      \n",
    "      def _trainDesGen(real):\n",
    "        return trainDesGen(gen=gen, des=des, real=real, batch_size=batch_size, \n",
    "                    generator_optimizer=generator_optimizer, discriminator_optimizer=discriminator_optimizer, hinge=True)\n",
    "\n",
    "      def _trainGenEnc(real, coeff):\n",
    "        return trainGenEnc(gen=gen, des=des, real=real, batch_size=batch_size, coeff=coeff,\n",
    "                    discriminator_optimizer=discriminator_optimizer, hinge=False, \n",
    "                    generator_optimizer=generator_optimizer, enc_optimizer=enc_optimizer)\n",
    "\n",
    "      return tf.function(_trainDes), tf.function(_trainGen), tf.function(_trainGenEnc), tf.function(_trainDesGen)\n",
    "\n",
    "    _trainDes, _trainGen, _trainGenEnc, _trainDesGen = getTrainers()\n",
    "    \n",
    "    currentStep = tf.Variable(0, dtype=tf.int64)\n",
    "    \n",
    "    @tf.function\n",
    "    def trainStep(dataIterator): \n",
    "      globalIter.assign_add(1)\n",
    "      for _ in range(des_steps):\n",
    "        batch = next(dataIterator)\n",
    "        real = batch['image']\n",
    "        des_loss = _trainDes(real)\n",
    "        currentStep.assign_add(1)\n",
    "      \n",
    "      for _ in range(gen_steps):\n",
    "        gen_loss = _trainGen()\n",
    "        # gen_loss = trainGen(gen=gen, des=des, batch_size=batch_size, hinge=True, generator_optimizer=generator_optimizer)\n",
    "\n",
    "      # batch = next(dataIterator)\n",
    "      # real = batch['image']\n",
    "      # des_loss, gen_loss = _trainDesGen(real)\n",
    "\n",
    "      if des_alpha != None and gen_alpha != None and shouldApplyAlpha.read_value():\n",
    "        alphaIncr = float(alphaStep.read_value() / float(steps))\n",
    "        # Slow down alpha increment\n",
    "        des_alpha.incrementAlpha(alphaIncr)\n",
    "        gen_alpha.incrementAlpha(alphaIncr)\n",
    "        print(\"Alpha, Beta: \", gen_alpha.alpha, des_alpha.alpha)\n",
    "        \n",
    "      return des_loss, gen_loss\n",
    "    \n",
    "    def trainSteps(dataIterator, steps):\n",
    "      for _ in range(steps):\n",
    "        try:\n",
    "          des_loss, gen_loss = trainStep(dataIterator)\n",
    "          if globalIter % 10 == 0:\n",
    "            # print(\"==>Des Loss: \", des_loss, \"Gen Loss: \", gen_loss)\n",
    "            with file_writer.as_default():\n",
    "                tf.summary.scalar('Generator Loss', gen_loss, step=globalIter)\n",
    "                tf.summary.scalar('Descriminator Loss', des_loss, step=globalIter)\n",
    "          # if currentStep > steps:\n",
    "          #   print(\"Step: \", currentStep)\n",
    "          #   break\n",
    "        except Exception as e:\n",
    "          print(e)\n",
    "          break\n",
    "\n",
    "    fake = gen(noise, training=False)\n",
    "    real = REAL\n",
    "    print(\"Evaluating at the start of epoch:\")\n",
    "    desAcc, genLoss = evalGan(gen, des, real, 10, batch_size)\n",
    "    print(\"Real: \")\n",
    "    plotImages(real)\n",
    "\n",
    "    print(\"Fake: \")\n",
    "    plotImages(fake)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "      print(\"Running epoch \", epoch)\n",
    "      t = time.time()\n",
    "      \n",
    "      shouldApplyAlpha.assign(epoch > alphaDelay)\n",
    "      \n",
    "      trainSteps(iterData, steps)\n",
    "          \n",
    "      alphaStep.assign(alphaStep * alphaMultiplier)\n",
    "      print(\"Alpha step: \", alphaStep.read_value())\n",
    "      coeff *= 0.9\n",
    "      fake = gen(noise, training=False)\n",
    "      real = REAL\n",
    "\n",
    "      print(\"Evaluating:\", time.time() - t)\n",
    "      desAcc, genLoss = evalGan(gen, des, real, 10, batch_size)\n",
    "      results.append({'desAcc':desAcc, 'genLoss':genLoss})\n",
    "      print(\"Epoch \", epoch, \"Descriminator Accuracy \", desAcc, \"Generator Loss \", genLoss, \"of \", epochs, \"Epochs\")\n",
    "      with file_writer.as_default():\n",
    "        tf.summary.scalar('Descriminator Accuracy at Epoch', desAcc, step=epoch)\n",
    "        tf.summary.scalar('Generator Loss at Epoch', genLoss, step=epoch)\n",
    "        # Share images of fake data generated\n",
    "        tf.summary.image('Fake Images', fake, step=epoch)\n",
    "\n",
    "      print(\"Real: \")\n",
    "      plotImages(real)\n",
    "\n",
    "      print(\"Fake: \")\n",
    "      plotImages(fake)\n",
    "\n",
    "      if desAcc > 0.8:\n",
    "        coeff *= 2\n",
    "        coeff = min(coeff, 1.)\n",
    "\n",
    "      if des_alpha != None and gen_alpha != None:\n",
    "        print(\"Final Alpha, Beta: \", gen_alpha.alpha, des_alpha.alpha)\n",
    "\n",
    "      \n",
    "    # _ = input(\"Press Enter to continue\")\n",
    "    gen.save(modeldir + name + '_' + str(size) + '_gen.keras')\n",
    "    des.save(modeldir + name + '_' + str(size)  + '_des.keras')\n",
    "    enc.save(modeldir + name + '_' + str(size)  + '_enc.keras')\n",
    "    # des, enc, baseLayers, des_alpha = descriminatorAddStage(des, enc, baseLayers, freeze=False)\n",
    "    # gen, gen_alpha = generatorAddStage(gen, freeze=False)\n",
    "    epochs *= 1.2\n",
    "    epochs = int(epochs)\n",
    "    initialCoeff *= 0.6\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XyD-7LBrrsZO",
    "outputId": "bf7f8e25-9bbc-4abc-922d-537ef27c8fda"
   },
   "outputs": [],
   "source": [
    "gen, des, enc, baseLayers = generateBaseModels()\n",
    "trainGan(gen, des, enc, baseLayers, data=lfw, des_steps=3, gen_steps=1, name=MODEL_NAME, \n",
    "  trainingConf={\n",
    "    4:{\"epochs\":7, \"batch_size\":64, \"alpha_step\":0.1, \"alpha_delay\":0, \"alpha_multiplier\":1.2}, \n",
    "    8:{\"epochs\":23, \"batch_size\":64, \"alpha_step\":0.015, \"alpha_delay\":0.15, \"alpha_multiplier\":1.15}, \n",
    "    16:{\"epochs\":30, \"batch_size\":64, \"alpha_step\":0.010, \"alpha_delay\":0.15, \"alpha_multiplier\":1.1}, \n",
    "    32:{\"epochs\":30, \"batch_size\":64, \"alpha_step\":0.010, \"alpha_delay\":0.15, \"alpha_multiplier\":1.1}, \n",
    "    64:{\"epochs\":30, \"batch_size\":64, \"alpha_step\":0.01, \"alpha_delay\":0.15, \"alpha_multiplier\":1.1}, \n",
    "    128:{\"epochs\":30, \"batch_size\":64, \"alpha_step\":0.01, \"alpha_delay\":0.15, \"alpha_multiplier\":1.1}, \n",
    "    256:{\"epochs\":30, \"batch_size\":64, \"alpha_step\":0.01, \"alpha_delay\":0.15, \"alpha_multiplier\":1.1}\n",
    "  }, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0320d31ea717465588c394eb4d51e7ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9f334dc705d443d5b99541e467294220",
      "placeholder": "​",
      "style": "IPY_MODEL_3907d6b9d0944d6aba5bf5d39dd210b1",
      "value": "Dl Completed...:   0%"
     }
    },
    "0587d65448f64931a8b2a7567571a501": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a8f22d4ccb3b4296970ecc92dd63d8f1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8da5b95687334274bf8b419512f733b8",
      "value": 0
     }
    },
    "09991e0fe8234e4e9904ba454690ab6b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "0eebfcc871b2429fbb7e2be0c30e5dac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a969db852d99484e9f71f284e357e3a5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_41c40155b5644a12a43797b6150b5938",
      "value": 1
     }
    },
    "1f96e1060b7f4ad1819d9b1ee5832e76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "305738872c794051adbb8f574dda9fae": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d8bf85e3104c45a68c803f5bb943d767",
       "IPY_MODEL_6e06576433db421ba87acd5a96cc058b",
       "IPY_MODEL_a7d7738f3a69421eb0850dad03c62d62"
      ],
      "layout": "IPY_MODEL_921c132c04a243e9bf3a8ab4aaa0f032"
     }
    },
    "3907d6b9d0944d6aba5bf5d39dd210b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "41c40155b5644a12a43797b6150b5938": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "4d0955cedfda4f528508280d55f43b00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56ac596d39214e26976bebd9feb73972": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fc18c429df5446f2928e301253af66df",
      "placeholder": "​",
      "style": "IPY_MODEL_7c369757827c43c19b2a5e63672a634e",
      "value": " 0/1 [03:20&lt;?, ? url/s]"
     }
    },
    "6be34b510cba4fbfad8512bb1f82ac8c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c2bc8cd41a3471ba669e1909e137c33": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bad4648f3d844c08be69d44f1bd2064e",
      "placeholder": "​",
      "style": "IPY_MODEL_8406068892494f1485665dca6b884c40",
      "value": "Dl Size...:  54%"
     }
    },
    "6e06576433db421ba87acd5a96cc058b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_09991e0fe8234e4e9904ba454690ab6b",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7d3aef57552c47f4978bc0abf0bef07c",
      "value": 0
     }
    },
    "6fa6fcdd41e14baf8e5cea8617d0a103": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7884836108d74585b2d6c43499be4b00": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0320d31ea717465588c394eb4d51e7ef",
       "IPY_MODEL_0587d65448f64931a8b2a7567571a501",
       "IPY_MODEL_56ac596d39214e26976bebd9feb73972"
      ],
      "layout": "IPY_MODEL_c2771b2e01cc42ae9c72691e40261429"
     }
    },
    "7c369757827c43c19b2a5e63672a634e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7d3aef57552c47f4978bc0abf0bef07c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8406068892494f1485665dca6b884c40": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8428dd5a5032425489e6181f9849eec2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4d0955cedfda4f528508280d55f43b00",
      "placeholder": "​",
      "style": "IPY_MODEL_f4c44c94d37147478e5e059a0f3efb35",
      "value": " 92/172 [03:20&lt;02:36,  1.96s/ MiB]"
     }
    },
    "8b7461e8c5c84bd9b3b0530436cc30b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8da5b95687334274bf8b419512f733b8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "921c132c04a243e9bf3a8ab4aaa0f032": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f334dc705d443d5b99541e467294220": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a7d7738f3a69421eb0850dad03c62d62": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6fa6fcdd41e14baf8e5cea8617d0a103",
      "placeholder": "​",
      "style": "IPY_MODEL_6be34b510cba4fbfad8512bb1f82ac8c",
      "value": " 0/0 [03:20&lt;?, ? file/s]"
     }
    },
    "a8f22d4ccb3b4296970ecc92dd63d8f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "a969db852d99484e9f71f284e357e3a5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "b0600d22ed5948a28bcb5b7ce2c26dcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6c2bc8cd41a3471ba669e1909e137c33",
       "IPY_MODEL_0eebfcc871b2429fbb7e2be0c30e5dac",
       "IPY_MODEL_8428dd5a5032425489e6181f9849eec2"
      ],
      "layout": "IPY_MODEL_b22cb14f030f4991816426452c582cd6"
     }
    },
    "b22cb14f030f4991816426452c582cd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bad4648f3d844c08be69d44f1bd2064e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2771b2e01cc42ae9c72691e40261429": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d8bf85e3104c45a68c803f5bb943d767": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1f96e1060b7f4ad1819d9b1ee5832e76",
      "placeholder": "​",
      "style": "IPY_MODEL_8b7461e8c5c84bd9b3b0530436cc30b5",
      "value": "Extraction completed...: "
     }
    },
    "f4c44c94d37147478e5e059a0f3efb35": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fc18c429df5446f2928e301253af66df": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
