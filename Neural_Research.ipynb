{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJVKL-Y3a-Ul",
        "outputId": "68801559-67d2-4f95-8e94-ae4c3ae94a2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The dotenv extension is already loaded. To reload it, use:\n",
            "  %reload_ext dotenv\n"
          ]
        }
      ],
      "source": [
        "%load_ext dotenv\n",
        "%dotenv\n",
        "import jax.numpy as jnp\n",
        "import jax\n",
        "import math\n",
        "import sklearn # Only for downloading MNIST Dataset and Accuracy Metrics\n",
        "import sklearn.metrics\n",
        "from keras.utils import to_categorical  # Only for categorical one hot encoding\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo5ppWNtb1lI",
        "outputId": "576c34d1-07e0-428d-b456-09ad5e603f05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((7, 2), (7, 1))"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "xor_x_train = jnp.array([[0, 0], [0, 1], [1, 0], [1, 1], [1, 0], [0, 0], [1, 1]])\n",
        "xor_y_train = jnp.array([[0], [1], [1], [0], [1], [0], [0]])\n",
        "xor_x_train.shape, xor_y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQ0xUhqjby0F",
        "outputId": "7c67e5d3-d008-46e3-adb6-e1e25b0734ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 784)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# (x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "cy_train = jnp.array(to_categorical(y_train))\n",
        "cy_test = jnp.array(to_categorical(y_test))\n",
        "\n",
        "cx_train, cx_test = jnp.array(x_train.reshape(-1, 784)/255.), jnp.array(x_test.reshape(-1, 784)/255.)\n",
        "cx_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import NeuroLab as nl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmj7tTpeSINf"
      },
      "source": [
        "# Neural Network with SGD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MYhVRsYqW-mi"
      },
      "outputs": [],
      "source": [
        "class SGD_Optimizer(nl.Optimizer):\n",
        "    def __init__(self, model, learning_rate, loss, gamma=1, delta=2):\n",
        "        super().__init__(model, loss)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gamma = gamma\n",
        "        self.delta = delta\n",
        "\n",
        "    def train_step(self, x_batch, y_batch):\n",
        "        predictions = self.model.forward(x_batch)\n",
        "        loss_value = self.loss.forward(predictions, y_batch)\n",
        "        grad_loss = self.loss.backward(predictions, y_batch)\n",
        "\n",
        "        for layer in reversed(self.model.get_layers()):\n",
        "            # Back propogate the loss to the layer\n",
        "            grad_loss, deltas = layer.backward(grad_loss)\n",
        "            if deltas != None:\n",
        "                # Simple Stochastic Gradient Decent\n",
        "                delta_weights, delta_biases = deltas\n",
        "                deltas = (delta_weights * self.learning_rate, delta_biases * self.learning_rate)\n",
        "            # Update the weights\n",
        "            layer.update_parameters(deltas)\n",
        "\n",
        "        return loss_value\n",
        "\n",
        "    def on_epoch_end(self, epoch):\n",
        "        # Decay Weight\n",
        "        self.learning_rate *= self.gamma\n",
        "        self.delta *= self.gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "lUaEoghOuoRE",
        "outputId": "03f961ca-ebbc-4866-a29f-c20f2ee3e553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.006026385455412694, test_acc: 0.9328\n",
            "Epoch 1, Loss: 0.003194459505843832, test_acc: 0.9488\n",
            "Epoch 2, Loss: 0.0035828069852161786, test_acc: 0.9579\n",
            "Epoch 3, Loss: 0.002534642267921961, test_acc: 0.9655\n",
            "Epoch 4, Loss: 0.004401777960821992, test_acc: 0.9672\n",
            "Epoch 5, Loss: 0.0027347030422612078, test_acc: 0.9694\n",
            "Epoch 6, Loss: 0.0015456122289155658, test_acc: 0.9696\n",
            "Epoch 7, Loss: 0.0023166172257838994, test_acc: 0.9719\n",
            "Epoch 8, Loss: 0.00196298924717613, test_acc: 0.9726\n",
            "Epoch 9, Loss: 0.0009780029497950715, test_acc: 0.9739\n",
            "Accuracy: 0.9739\n",
            "Confusion Matrix: [[ 972    0    1    1    0    2    0    2    2    0]\n",
            " [   0 1121    2    3    0    1    2    1    5    0]\n",
            " [   5    2  999    6    4    0    2   10    4    0]\n",
            " [   0    0    4  988    1    4    0    7    6    0]\n",
            " [   1    0    4    0  959    0    3    1    3   11]\n",
            " [   3    1    0    8    0  869    7    1    1    2]\n",
            " [   8    3    0    0    3    8  932    0    4    0]\n",
            " [   1    9   15    3    0    0    0  994    4    2]\n",
            " [   2    2    2    5    4    2    2    4  950    1]\n",
            " [   4    5    1   10   14    2    1    8    9  955]]\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       980\n",
            "           1       0.98      0.99      0.98      1135\n",
            "           2       0.97      0.97      0.97      1032\n",
            "           3       0.96      0.98      0.97      1010\n",
            "           4       0.97      0.98      0.98       982\n",
            "           5       0.98      0.97      0.98       892\n",
            "           6       0.98      0.97      0.98       958\n",
            "           7       0.97      0.97      0.97      1028\n",
            "           8       0.96      0.98      0.97       974\n",
            "           9       0.98      0.95      0.96      1009\n",
            "\n",
            "    accuracy                           0.97     10000\n",
            "   macro avg       0.97      0.97      0.97     10000\n",
            "weighted avg       0.97      0.97      0.97     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nl.set_random_key(4)\n",
        "# MNIST\n",
        "layers = [\n",
        "    nl.Dense(784, 128),\n",
        "    nl.ReLU(),\n",
        "    nl.Dense(128, 10),\n",
        "    # Softmax(),\n",
        "    nl.Sigmoid(),\n",
        "]\n",
        "\n",
        "net = nl.NeuralNet(layers)\n",
        "\n",
        "optimizer = SGD_Optimizer(net, learning_rate = 0.01, loss=nl.MeanSquaredError(), delta=0.95, gamma=1)\n",
        "optimizer.fit((cx_train, cy_train), (cx_test, cy_test), epochs=10, batch_size=100, verbose=True)\n",
        "# Infer on cx_test, cy_test\n",
        "predictions = net.predict(cx_test)\n",
        "preds = jnp.array(nl.antiCategorical(predictions))\n",
        "expected = jnp.array(nl.antiCategorical(cy_test))\n",
        "\n",
        "print(f'Accuracy: {sklearn.metrics.accuracy_score(expected, preds)}')\n",
        "print(f'Confusion Matrix: {sklearn.metrics.confusion_matrix(expected, preds)}')\n",
        "print(f'Classification Report: {sklearn.metrics.classification_report(expected, preds)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pARZuRAtDgY0"
      },
      "source": [
        "# Bayesian Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1WhGL1JTfs8"
      },
      "outputs": [],
      "source": [
        "class BayesianDense(Layer):\n",
        "    def __init__(self, n_input, n_output, prior_std=1.0, posterior_std=0.1):\n",
        "        self.n_input = n_input\n",
        "        self.n_output = n_output\n",
        "        self.prior_std = prior_std\n",
        "        self.posterior_std = posterior_std\n",
        "\n",
        "        self.W_mu = jnp.random.normal(0, scale=(1/float(math.sqrt(n_input))), size=(n_input, n_output)).astype(jnp.float64)\n",
        "        self.b_mu = jnp.zeros((1, n_output)).astype(jnp.float64)\n",
        "\n",
        "        self.W_sigma = jnp.full((n_input, n_output), jnp.log(self.posterior_std)).astype(jnp.float64)\n",
        "        self.b_sigma = jnp.full((1, n_output), jnp.log(self.posterior_std)).astype(jnp.float64)\n",
        "        print(\"W_mu\", jnp.mean(self.W_mu),\n",
        "              \"b_mu\", jnp.mean(self.b_mu),\n",
        "              \"W_sigma\", jnp.mean(self.W_sigma), self.W_sigma.shape,\n",
        "              \"b_sigma\", jnp.mean(self.b_sigma), self.b_sigma.shape)\n",
        "\n",
        "    def sample_weights(self):\n",
        "        weights_std = jnp.exp(0.5 * self.W_sigma)\n",
        "        self.W = self.W_mu + weights_std * jnp.random.normal(size=(self.n_input, self.n_output))\n",
        "        biases_std = jnp.exp(0.5 * self.b_sigma)\n",
        "        self.b = self.b_mu + biases_std * jnp.random.normal(size=(1, self.n_output))\n",
        "        # print(\"w\", jnp.mean(self.W), jnp.mean(weights_std), \"b\", jnp.mean(self.b), jnp.mean(biases_std))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.sample_weights()\n",
        "        self.output = jnp.dot(inputs, self.W) + self.b\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, grad_output, learning_rate):\n",
        "        grad_input = jnp.dot(grad_output, self.W.T)\n",
        "\n",
        "        grad_W = jnp.dot(self.inputs.T, grad_output)\n",
        "        grad_b = jnp.mean(grad_output, axis=0, keepdims=True)\n",
        "\n",
        "        grad_W_mu = grad_W / grad_output.shape[0]\n",
        "        grad_b_mu = grad_b / grad_output.shape[0]\n",
        "\n",
        "        grad_W_sigma = ((grad_W ** 2) - 1) / (2 * grad_output.shape[0])\n",
        "        grad_b_sigma = ((grad_b_mu ** 2) - 1) / (2 * grad_output.shape[0])\n",
        "\n",
        "        self.W_mu -= learning_rate * grad_W_mu\n",
        "        self.b_mu -= learning_rate * grad_b_mu\n",
        "\n",
        "        self.W_sigma -= learning_rate * grad_W_sigma\n",
        "        self.b_sigma -= learning_rate * grad_b_sigma\n",
        "\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjRFdyUOThmr",
        "outputId": "2295f52d-1425-46a2-f374-fa04fe11c4e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "W_mu -0.0001789835031751473 b_mu 0.0 W_sigma -2.3025850929940455 (784, 100) b_sigma -2.3025850929940455 (1, 100)\n",
            "W_mu 0.0011180262676438772 b_mu 0.0 W_sigma -2.3025850929940455 (100, 50) b_sigma -2.3025850929940455 (1, 50)\n",
            "W_mu 0.0023444765023452477 b_mu 0.0 W_sigma -2.302585092994045 (50, 10) b_sigma -2.3025850929940455 (1, 10)\n",
            "Epoch 0, Batch 0, Loss: 0.07363589103305021\n",
            "Epoch 1, Batch 0, Loss: 0.03985098104954909\n",
            "Epoch 2, Batch 0, Loss: 0.02593534829055494\n",
            "Epoch 3, Batch 0, Loss: 0.02348652026844813\n",
            "Epoch 4, Batch 0, Loss: 0.019979116766026435\n",
            "Epoch 5, Batch 0, Loss: 0.01774217933964233\n",
            "Epoch 6, Batch 0, Loss: 0.017500500468994637\n",
            "Epoch 7, Batch 0, Loss: 0.01771578663478224\n",
            "Epoch 8, Batch 0, Loss: 0.01647555074216599\n",
            "Epoch 9, Batch 0, Loss: 0.013828134710165842\n",
            "Accuracy: 0.7548\n",
            "Confusion Matrix: [[ 866    0   10    1    1   11    3    2   13   73]\n",
            " [   0 1078    2    4    0    0    4    0   44    3]\n",
            " [  25   15  810   20    9    5   20   13   76   39]\n",
            " [  19    3   36  587    0  197    5   19  126   18]\n",
            " [   0    0    3    0  330    1   18    0   42  588]\n",
            " [  42    2   25   35   11  540   15    7  152   63]\n",
            " [  16    2   33    0   27   26  818    0   15   21]\n",
            " [   8   26   16    0    3    1    0  786   20  168]\n",
            " [   2   11   13   19   13   37   13    5  811   50]\n",
            " [   6    1    3    3   10   15    0   18   31  922]]\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       980\n",
            "           1       0.95      0.95      0.95      1135\n",
            "           2       0.85      0.78      0.82      1032\n",
            "           3       0.88      0.58      0.70      1010\n",
            "           4       0.82      0.34      0.48       982\n",
            "           5       0.65      0.61      0.63       892\n",
            "           6       0.91      0.85      0.88       958\n",
            "           7       0.92      0.76      0.84      1028\n",
            "           8       0.61      0.83      0.70       974\n",
            "           9       0.47      0.91      0.62      1009\n",
            "\n",
            "    accuracy                           0.75     10000\n",
            "   macro avg       0.79      0.75      0.75     10000\n",
            "weighted avg       0.80      0.75      0.75     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "nl.set_random_key(4)\n",
        "# MNIST\n",
        "layers = [\n",
        "    BayesianDense(784, 100),\n",
        "    nl.LeakyReLU(),\n",
        "    BayesianDense(100, 50),\n",
        "    nl.LeakyReLU(),\n",
        "    BayesianDense(50, 10),\n",
        "    nl.Softmax(),\n",
        "]\n",
        "\n",
        "net = nl.NeuralNet(layers, learning_rate = 0.01, loss=nl.MeanSquaredError(), delta=0.95, gamma=1)\n",
        "\n",
        "net.fit(cx_train, cy_train, epochs=10, batch_size=100, verbose=True)\n",
        "# Infer on cx_test, cy_test\n",
        "predictions = net.predict(cx_test, 20)\n",
        "preds = jnp.array(antiCategorical(predictions)).get()\n",
        "expected = jnp.array(antiCategorical(cy_test)).get()\n",
        "\n",
        "\n",
        "print(f'Accuracy: {sklearn.metrics.accuracy_score(expected, preds)}')\n",
        "print(f'Confusion Matrix: {sklearn.metrics.confusion_matrix(expected, preds)}')\n",
        "print(f'Classification Report: {sklearn.metrics.classification_report(expected, preds)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53HGMJspYc4G",
        "outputId": "df2bf8b0-8523-4122-842f-39d7912adca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.6333\n",
            "Confusion Matrix: [[747   0  19   1   0  16  84   1 111   1]\n",
            " [  0 982  22   7   0   0   3  27  94   0]\n",
            " [  4  54 706   5   6   8  41   1 207   0]\n",
            " [  9  37  40 685   2   9   8   2 217   1]\n",
            " [  4  17   6 122 518  34  17   4 243  17]\n",
            " [ 23  31  32  46   6 263  20   4 461   6]\n",
            " [  9   2  15   8   3   6 814   0 101   0]\n",
            " [  2   8  62  19   7  25   5 672 203  25]\n",
            " [  4  11  32   0   2   1  13   1 910   0]\n",
            " [  2   4  21 361   5   5   3 185 387  36]]\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.76      0.84       980\n",
            "           1       0.86      0.87      0.86      1135\n",
            "           2       0.74      0.68      0.71      1032\n",
            "           3       0.55      0.68      0.61      1010\n",
            "           4       0.94      0.53      0.68       982\n",
            "           5       0.72      0.29      0.42       892\n",
            "           6       0.81      0.85      0.83       958\n",
            "           7       0.75      0.65      0.70      1028\n",
            "           8       0.31      0.93      0.47       974\n",
            "           9       0.42      0.04      0.07      1009\n",
            "\n",
            "    accuracy                           0.63     10000\n",
            "   macro avg       0.70      0.63      0.62     10000\n",
            "weighted avg       0.70      0.63      0.62     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "predictions = net.predict(cx_test, 100)\n",
        "preds = jnp.array(antiCategorical(predictions)).get()\n",
        "expected = jnp.array(antiCategorical(cy_test)).get()\n",
        "\n",
        "print(f'Accuracy: {sklearn.metrics.accuracy_score(expected, preds)}')\n",
        "print(f'Confusion Matrix: {sklearn.metrics.confusion_matrix(expected, preds)}')\n",
        "print(f'Classification Report: {sklearn.metrics.classification_report(expected, preds)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TRbfd8TrTdOK"
      },
      "source": [
        "# Simulated Anealing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "OFwMWXcJy7a-"
      },
      "outputs": [],
      "source": [
        "\n",
        "class SimulatedAnnealingOptimizer(nl.Optimizer):\n",
        "    def __init__(self, model, learning_rate, loss):\n",
        "        super().__init__(model, loss)\n",
        "        self.learning_rate = learning_rate\n",
        "        self.best_loss = float(\"inf\")\n",
        "\n",
        "    def forward_with_perturbations(self, x_train, stddev):\n",
        "        perturbations = []\n",
        "        inputs = x_train\n",
        "        for layer in self.model.get_layers():\n",
        "            if isinstance(layer, nl.SimulatedAnnealingLayer):\n",
        "                perturbation = layer.perturb_parameters(stddev)\n",
        "                perturbations.append(perturbation)\n",
        "                inputs = layer.forward_with_perturbations(inputs, perturbation)\n",
        "            else:\n",
        "                inputs = layer.forward(inputs)\n",
        "        return inputs, perturbations\n",
        "\n",
        "    def update_parameters(self, perturbations):\n",
        "      i = 0\n",
        "      for layer in self.model.get_layers():\n",
        "            if isinstance(layer, nl.SimulatedAnnealingLayer):\n",
        "                layer.update_parameters(perturbations[i])\n",
        "                i += 1\n",
        "\n",
        "    def cooling_schedule(self, old_loss, new_loss, current_temp, current_step_size, cooling_rate, step_decay_rate=0.9999):\n",
        "        deltaLoss = new_loss - old_loss\n",
        "        deltaLossScale = deltaLoss / new_loss\n",
        "\n",
        "        if abs(deltaLossScale) > min(1e-4, current_temp):\n",
        "            scalefactor = min(1, current_temp/new_loss)\n",
        "            elastic_rate = 1.0 - scalefactor\n",
        "            elastic_rate = (elastic_rate + scalefactor) / 2\n",
        "            rate = max(cooling_rate, elastic_rate)\n",
        "            new_temp = current_temp * rate\n",
        "            # new_temp = current_temp * cooling_rate\n",
        "            new_step_size = current_step_size * step_decay_rate\n",
        "        else:\n",
        "            new_temp = current_temp / cooling_rate\n",
        "            new_step_size = self.learning_rate\n",
        "            self.learning_rate *= step_decay_rate\n",
        "\n",
        "        return new_temp, new_step_size\n",
        "\n",
        "    def train_step(self, x_batch, y_batch):\n",
        "        for j in range(self.sample_per_batch):\n",
        "            predictions, perturbations = self.forward_with_perturbations(x_batch, self.step_size)\n",
        "            loss = self.loss.forward(predictions, y_batch)\n",
        "            delta_E = (loss - self.best_loss)\n",
        "            energy_cost = jnp.exp(-delta_E / self.current_temp)\n",
        "            acceptance_rate = energy_cost if delta_E > 0 else  1.0\n",
        "            if delta_E < 0 or jax.random.uniform(nl.get_random_key()) <= acceptance_rate:\n",
        "                # Accept proposal\n",
        "                self.update_parameters(perturbations)\n",
        "                self.best_loss = loss\n",
        "                # print(f'Accepted proposal due to temperature {loss} exp: {acceptance_rate}, deltaE {delta_E}')\n",
        "        return self.best_loss\n",
        "\n",
        "    def on_epoch_start(self, epoch):\n",
        "        self.old_loss = self.best_loss\n",
        "\n",
        "    def on_epoch_end(self, epoch):\n",
        "        self.current_temp, self.step_size = self.cooling_schedule(self.old_loss, self.best_loss, self.current_temp, self.step_size, self.cooling_rate, 0.9999)\n",
        "\n",
        "    def on_reporting(self, epoch, loss_value, acc):\n",
        "        print(f'Epoch {epoch}, BestLoss: {loss_value}, Temperature {self.current_temp}, step_size {self.step_size}, test_acc: {acc}')\n",
        "\n",
        "    def on_train_start(self, sample_per_batch=1, initial_temp=1.0, cooling_rate=0.99):\n",
        "        self.current_temp = initial_temp\n",
        "        # self.best_loss = float(\"inf\")\n",
        "        self.step_size = self.learning_rate\n",
        "        self.sample_per_batch = sample_per_batch\n",
        "        self.cooling_rate = cooling_rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "mv5qG3HYd7vO"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, BestLoss: 0.12472543282740714, Temperature 1.0, step_size 0.1, test_acc: 1.0\n",
            "Epoch 1, BestLoss: 0.12504375122918168, Temperature 0.95, step_size 0.09999000000000001, test_acc: 1.0\n",
            "Epoch 2, BestLoss: 0.15363896281138026, Temperature 0.9025, step_size 0.09998000100000001, test_acc: 1.0\n",
            "Epoch 3, BestLoss: 0.13039663762975492, Temperature 0.8573749999999999, step_size 0.09997000299990001, test_acc: 1.0\n",
            "Epoch 4, BestLoss: 0.1471675761057778, Temperature 0.8145062499999999, step_size 0.09996000599960002, test_acc: 1.0\n",
            "Epoch 5, BestLoss: 0.2001160246950294, Temperature 0.7737809374999999, step_size 0.09995000999900006, test_acc: 1.0\n",
            "Epoch 6, BestLoss: 0.19976442404111375, Temperature 0.7350918906249998, step_size 0.09994001499800016, test_acc: 1.0\n",
            "Epoch 7, BestLoss: 0.20820310697963498, Temperature 0.6983372960937497, step_size 0.09993002099650036, test_acc: 1.0\n",
            "Epoch 8, BestLoss: 0.20691650078368626, Temperature 0.6634204312890623, step_size 0.09992002799440071, test_acc: 1.0\n",
            "Epoch 9, BestLoss: 0.20105028821838491, Temperature 0.6302494097246091, step_size 0.09991003599160127, test_acc: 1.0\n",
            "Epoch 10, BestLoss: 0.20354803383070325, Temperature 0.5987369392383786, step_size 0.0999000449880021, test_acc: 1.0\n",
            "Epoch 11, BestLoss: 0.1981431444423134, Temperature 0.5688000922764596, step_size 0.0998900549835033, test_acc: 1.0\n",
            "Epoch 12, BestLoss: 0.20307715251166558, Temperature 0.5403600876626365, step_size 0.09988006597800494, test_acc: 1.0\n",
            "Epoch 13, BestLoss: 0.20972627424248352, Temperature 0.5133420832795047, step_size 0.09987007797140715, test_acc: 1.0\n",
            "Epoch 14, BestLoss: 0.2122836991053939, Temperature 0.48767497911552943, step_size 0.09986009096361001, test_acc: 1.0\n",
            "Epoch 15, BestLoss: 0.2138004572364763, Temperature 0.46329123015975293, step_size 0.09985010495451364, test_acc: 1.0\n",
            "Epoch 16, BestLoss: 0.2140995961413485, Temperature 0.44012666865176525, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 17, BestLoss: 0.21418664275200117, Temperature 0.41812033521917696, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 18, BestLoss: 0.21412393598075055, Temperature 0.3972143184582181, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 19, BestLoss: 0.21417176698327936, Temperature 0.37735360253530714, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 20, BestLoss: 0.2141989013676838, Temperature 0.35848592240854177, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 21, BestLoss: 0.21415825796092233, Temperature 0.34056162628811465, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 22, BestLoss: 0.21386235862827022, Temperature 0.3235335449737089, step_size 0.09978023084607313, test_acc: 1.0\n",
            "Epoch 23, BestLoss: 0.21391131969056132, Temperature 0.30735686772502346, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 24, BestLoss: 0.21414556822428127, Temperature 0.2919890243387723, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 25, BestLoss: 0.2142100681369691, Temperature 0.27738957312183365, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 26, BestLoss: 0.2141689924910692, Temperature 0.263520094465742, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 27, BestLoss: 0.2139414759591172, Temperature 0.25034408974245487, step_size 0.09973035070767541, test_acc: 1.0\n",
            "Epoch 28, BestLoss: 0.2140982788093641, Temperature 0.2378268852553321, step_size 0.09972037767260465, test_acc: 1.0\n",
            "Epoch 29, BestLoss: 0.21412526115290703, Temperature 0.2259355409925655, step_size 0.09971040563483739, test_acc: 1.0\n",
            "Epoch 30, BestLoss: 0.21409432555084365, Temperature 0.2146387639429372, step_size 0.09970043459427391, test_acc: 1.0\n",
            "Epoch 31, BestLoss: 0.21418560593056626, Temperature 0.20390682574579033, step_size 0.09969046455081448, test_acc: 1.0\n",
            "Epoch 32, BestLoss: 0.21415121025909395, Temperature 0.1937114844585008, step_size 0.09968049550435941, test_acc: 1.0\n",
            "Epoch 33, BestLoss: 0.2139008122015907, Temperature 0.18402591023557577, step_size 0.09967052745480898, test_acc: 1.0\n",
            "Epoch 34, BestLoss: 0.21404751374598285, Temperature 0.17482461472379698, step_size 0.0996605604020635, test_acc: 1.0\n",
            "Epoch 35, BestLoss: 0.2135619837714692, Temperature 0.16608338398760714, step_size 0.0996505943460233, test_acc: 1.0\n",
            "Epoch 36, BestLoss: 0.2138721873186885, Temperature 0.15777921478822676, step_size 0.0996406292865887, test_acc: 1.0\n",
            "Epoch 37, BestLoss: 0.21397621720809917, Temperature 0.14989025404881542, step_size 0.09963066522366004, test_acc: 1.0\n",
            "Epoch 38, BestLoss: 0.21372636165906894, Temperature 0.14239574134637464, step_size 0.09962070215713768, test_acc: 1.0\n",
            "Epoch 39, BestLoss: 0.2139832119722767, Temperature 0.1352759542790559, step_size 0.09961074008692197, test_acc: 1.0\n",
            "Epoch 40, BestLoss: 0.21413089372680888, Temperature 0.1285121565651031, step_size 0.09960077901291328, test_acc: 1.0\n",
            "Epoch 41, BestLoss: 0.214166580946923, Temperature 0.12208654873684793, step_size 0.099590818935012, test_acc: 1.0\n",
            "Epoch 42, BestLoss: 0.2141609219674808, Temperature 0.11598222130000553, step_size 0.0995808598531185, test_acc: 1.0\n",
            "Epoch 43, BestLoss: 0.2142223191659525, Temperature 0.12208654873684793, step_size 0.1, test_acc: 1.0\n",
            "Epoch 44, BestLoss: 0.2141377101489169, Temperature 0.11598222130000553, step_size 0.09999000000000001, test_acc: 1.0\n",
            "Epoch 45, BestLoss: 0.21403163396697522, Temperature 0.11018311023500525, step_size 0.09998000100000001, test_acc: 1.0\n",
            "Epoch 46, BestLoss: 0.21378772751532038, Temperature 0.10467395472325498, step_size 0.09997000299990001, test_acc: 1.0\n",
            "Epoch 47, BestLoss: 0.213961894144858, Temperature 0.09944025698709223, step_size 0.09996000599960002, test_acc: 1.0\n",
            "Epoch 48, BestLoss: 0.21387709738829885, Temperature 0.09446824413773762, step_size 0.09995000999900006, test_acc: 1.0\n",
            "Epoch 49, BestLoss: 0.21393399410811606, Temperature 0.08974483193085074, step_size 0.09994001499800016, test_acc: 1.0\n",
            "Epoch 50, BestLoss: 0.21410941296272723, Temperature 0.0852575903343082, step_size 0.09993002099650036, test_acc: 1.0\n",
            "Epoch 51, BestLoss: 0.2140979410801697, Temperature 0.08099471081759278, step_size 0.09992002799440071, test_acc: 1.0\n",
            "Epoch 52, BestLoss: 0.2140489455258381, Temperature 0.0852575903343082, step_size 0.09999000000000001, test_acc: 1.0\n",
            "Epoch 53, BestLoss: 0.21424243976933588, Temperature 0.08099471081759278, step_size 0.09998000100000001, test_acc: 1.0\n",
            "Epoch 54, BestLoss: 0.21423118389904458, Temperature 0.07694497527671314, step_size 0.09997000299990001, test_acc: 1.0\n",
            "Epoch 55, BestLoss: 0.21423505934483789, Temperature 0.08099471081759278, step_size 0.09998000100000001, test_acc: 1.0\n",
            "Epoch 56, BestLoss: 0.21424739642855606, Temperature 0.0852575903343082, step_size 0.09997000299990001, test_acc: 1.0\n",
            "Epoch 57, BestLoss: 0.21423923954414428, Temperature 0.08974483193085074, step_size 0.09996000599960002, test_acc: 1.0\n",
            "Epoch 58, BestLoss: 0.21420652602077683, Temperature 0.09446824413773762, step_size 0.09995000999900006, test_acc: 1.0\n",
            "Epoch 59, BestLoss: 0.21419693938354975, Temperature 0.08974483193085074, step_size 0.09994001499800016, test_acc: 1.0\n",
            "Epoch 60, BestLoss: 0.21416380775250687, Temperature 0.09446824413773762, step_size 0.09994001499800016, test_acc: 1.0\n",
            "Epoch 61, BestLoss: 0.21416915670753375, Temperature 0.08974483193085074, step_size 0.09993002099650036, test_acc: 1.0\n",
            "Epoch 62, BestLoss: 0.2142395807907373, Temperature 0.09446824413773762, step_size 0.09993002099650036, test_acc: 1.0\n",
            "Epoch 63, BestLoss: 0.2142357157097694, Temperature 0.08974483193085074, step_size 0.09992002799440071, test_acc: 1.0\n",
            "Epoch 64, BestLoss: 0.21419338058079052, Temperature 0.09446824413773762, step_size 0.09992002799440071, test_acc: 1.0\n",
            "Epoch 65, BestLoss: 0.21409209155166067, Temperature 0.08974483193085074, step_size 0.09991003599160127, test_acc: 1.0\n",
            "Epoch 66, BestLoss: 0.21402555983529217, Temperature 0.0852575903343082, step_size 0.0999000449880021, test_acc: 1.0\n",
            "Epoch 67, BestLoss: 0.2141685228687027, Temperature 0.08099471081759278, step_size 0.0998900549835033, test_acc: 1.0\n",
            "Epoch 68, BestLoss: 0.21378769288507127, Temperature 0.07694497527671314, step_size 0.09988006597800494, test_acc: 1.0\n",
            "Epoch 69, BestLoss: 0.21241998989191246, Temperature 0.07309772651287748, step_size 0.09987007797140715, test_acc: 1.0\n",
            "Epoch 70, BestLoss: 0.21305552781037948, Temperature 0.0694428401872336, step_size 0.09986009096361001, test_acc: 1.0\n",
            "Epoch 71, BestLoss: 0.2121812391341461, Temperature 0.0659706981778719, step_size 0.09985010495451364, test_acc: 1.0\n",
            "Epoch 72, BestLoss: 0.20905000042197303, Temperature 0.0626721632689783, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 73, BestLoss: 0.20991415475410807, Temperature 0.059538555105529384, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 74, BestLoss: 0.2090498218420742, Temperature 0.05656162735025291, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 75, BestLoss: 0.2047495735299604, Temperature 0.053733545982740265, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 76, BestLoss: 0.20319757502653835, Temperature 0.05104686868360325, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 77, BestLoss: 0.19963754118622598, Temperature 0.04849452524942309, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 78, BestLoss: 0.18358147138585756, Temperature 0.04606979898695193, step_size 0.09978023084607313, test_acc: 1.0\n",
            "Epoch 79, BestLoss: 0.1981495236691977, Temperature 0.04376630903760433, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 80, BestLoss: 0.19993979157830155, Temperature 0.041577993585724116, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 81, BestLoss: 0.1854277617047633, Temperature 0.03949909390643791, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 82, BestLoss: 0.13976085566380908, Temperature 0.03752413921111601, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 83, BestLoss: 0.13770687133839768, Temperature 0.03564793225056021, step_size 0.09973035070767541, test_acc: 1.0\n",
            "Epoch 84, BestLoss: 0.1328791175626475, Temperature 0.0338655356380322, step_size 0.09972037767260465, test_acc: 1.0\n",
            "Epoch 85, BestLoss: 0.13451502861008668, Temperature 0.032172258856130585, step_size 0.09971040563483739, test_acc: 1.0\n",
            "Epoch 86, BestLoss: 0.12933873131931853, Temperature 0.030563645913324056, step_size 0.09970043459427391, test_acc: 1.0\n",
            "Epoch 87, BestLoss: 0.16103307360311142, Temperature 0.029035463617657853, step_size 0.09969046455081448, test_acc: 1.0\n",
            "Epoch 88, BestLoss: 0.13187018160112413, Temperature 0.027583690436774957, step_size 0.09968049550435941, test_acc: 1.0\n",
            "Epoch 89, BestLoss: 0.11327506376130239, Temperature 0.02620450591493621, step_size 0.09967052745480898, test_acc: 1.0\n",
            "Epoch 90, BestLoss: 0.1142534070651469, Temperature 0.0248942806191894, step_size 0.0996605604020635, test_acc: 1.0\n",
            "Epoch 91, BestLoss: 0.1268196401283971, Temperature 0.023649566588229927, step_size 0.0996505943460233, test_acc: 1.0\n",
            "Epoch 92, BestLoss: 0.12472928344947014, Temperature 0.022467088258818428, step_size 0.0996406292865887, test_acc: 1.0\n",
            "Epoch 93, BestLoss: 0.14211980747837955, Temperature 0.021343733845877507, step_size 0.09963066522366004, test_acc: 1.0\n",
            "Epoch 94, BestLoss: 0.14768551737002633, Temperature 0.02027654715358363, step_size 0.09962070215713768, test_acc: 1.0\n",
            "Epoch 95, BestLoss: 0.1480880609181047, Temperature 0.019262719795904448, step_size 0.09961074008692197, test_acc: 1.0\n",
            "Epoch 96, BestLoss: 0.12736289375741147, Temperature 0.018299583806109226, step_size 0.09960077901291328, test_acc: 1.0\n",
            "Epoch 97, BestLoss: 0.11909048123761418, Temperature 0.017384604615803764, step_size 0.099590818935012, test_acc: 1.0\n",
            "Epoch 98, BestLoss: 0.12575569856130764, Temperature 0.016515374385013576, step_size 0.0995808598531185, test_acc: 1.0\n",
            "Epoch 99, BestLoss: 0.1092250293868046, Temperature 0.015689605665762895, step_size 0.0995709017671332, test_acc: 1.0\n",
            "Epoch 100, BestLoss: 0.15112362577721272, Temperature 0.01490512538247475, step_size 0.09956094467695648, test_acc: 1.0\n",
            "Epoch 101, BestLoss: 0.15232952273595013, Temperature 0.014159869113351011, step_size 0.09955098858248879, test_acc: 1.0\n",
            "Epoch 102, BestLoss: 0.1605261280790789, Temperature 0.01345187565768346, step_size 0.09954103348363054, test_acc: 1.0\n",
            "Epoch 103, BestLoss: 0.14207129470614094, Temperature 0.012779281874799287, step_size 0.09953107938028218, test_acc: 1.0\n",
            "Epoch 104, BestLoss: 0.11484200349834342, Temperature 0.012140317781059323, step_size 0.09952112627234415, test_acc: 1.0\n",
            "Epoch 105, BestLoss: 0.08710193414723376, Temperature 0.011533301892006355, step_size 0.09951117415971691, test_acc: 1.0\n",
            "Epoch 106, BestLoss: 0.09021618431290328, Temperature 0.010956636797406038, step_size 0.09950122304230094, test_acc: 1.0\n",
            "Epoch 107, BestLoss: 0.07789129429896335, Temperature 0.010408804957535735, step_size 0.09949127291999671, test_acc: 1.0\n",
            "Epoch 108, BestLoss: 0.10208668192763426, Temperature 0.009888364709658948, step_size 0.0994813237927047, test_acc: 1.0\n",
            "Epoch 109, BestLoss: 0.08264128257109604, Temperature 0.009393946474176, step_size 0.09947137566032543, test_acc: 1.0\n",
            "Epoch 110, BestLoss: 0.09098211584180509, Temperature 0.0089242491504672, step_size 0.0994614285227594, test_acc: 1.0\n",
            "Epoch 111, BestLoss: 0.09635546668896812, Temperature 0.008478036692943839, step_size 0.09945148237990713, test_acc: 1.0\n",
            "Epoch 112, BestLoss: 0.09081008318824793, Temperature 0.008054134858296647, step_size 0.09944153723166914, test_acc: 1.0\n",
            "Epoch 113, BestLoss: 0.07942803296656976, Temperature 0.0076514281153818135, step_size 0.09943159307794597, test_acc: 1.0\n",
            "Epoch 114, BestLoss: 0.09050100259718236, Temperature 0.0072688567096127225, step_size 0.09942164991863818, test_acc: 1.0\n",
            "Epoch 115, BestLoss: 0.06948223005346889, Temperature 0.006905413874132086, step_size 0.09941170775364631, test_acc: 1.0\n",
            "Epoch 116, BestLoss: 0.06806638313182548, Temperature 0.006560143180425482, step_size 0.09940176658287095, test_acc: 1.0\n",
            "Epoch 117, BestLoss: 0.0744407344816167, Temperature 0.0062321360214042075, step_size 0.09939182640621266, test_acc: 1.0\n",
            "Epoch 118, BestLoss: 0.0803698735299851, Temperature 0.005920529220333997, step_size 0.09938188722357204, test_acc: 1.0\n",
            "Epoch 119, BestLoss: 0.07895953427237933, Temperature 0.0056245027593172965, step_size 0.09937194903484968, test_acc: 1.0\n",
            "Epoch 120, BestLoss: 0.0782986996846547, Temperature 0.005343277621351432, step_size 0.0993620118399462, test_acc: 1.0\n",
            "Epoch 121, BestLoss: 0.07321406328199644, Temperature 0.0050761137402838595, step_size 0.09935207563876221, test_acc: 1.0\n",
            "Epoch 122, BestLoss: 0.07569833286361796, Temperature 0.004822308053269666, step_size 0.09934214043119834, test_acc: 1.0\n",
            "Epoch 123, BestLoss: 0.06533578876604744, Temperature 0.004581192650606183, step_size 0.09933220621715522, test_acc: 1.0\n",
            "Epoch 124, BestLoss: 0.06998190405572577, Temperature 0.0043521330180758735, step_size 0.0993222729965335, test_acc: 1.0\n",
            "Epoch 125, BestLoss: 0.0660999094302989, Temperature 0.0041345263671720795, step_size 0.09931234076923384, test_acc: 1.0\n",
            "Epoch 126, BestLoss: 0.06631880737327617, Temperature 0.003927800048813475, step_size 0.09930240953515691, test_acc: 1.0\n",
            "Epoch 127, BestLoss: 0.06472220028773125, Temperature 0.0037314100463728015, step_size 0.0992924792942034, test_acc: 1.0\n",
            "Epoch 128, BestLoss: 0.06701923735309949, Temperature 0.0035448395440541612, step_size 0.09928255004627398, test_acc: 1.0\n",
            "Epoch 129, BestLoss: 0.07444981493906795, Temperature 0.003367597566851453, step_size 0.09927262179126936, test_acc: 1.0\n",
            "Epoch 130, BestLoss: 0.06269894525234175, Temperature 0.00319921768850888, step_size 0.09926269452909023, test_acc: 1.0\n",
            "Epoch 131, BestLoss: 0.06022830946118728, Temperature 0.003039256804083436, step_size 0.09925276825963732, test_acc: 1.0\n",
            "Epoch 132, BestLoss: 0.06144388369329247, Temperature 0.0028872939638792637, step_size 0.09924284298281136, test_acc: 1.0\n",
            "Epoch 133, BestLoss: 0.05855161828613693, Temperature 0.0027429292656853004, step_size 0.09923291869851308, test_acc: 1.0\n",
            "Epoch 134, BestLoss: 0.05828019341955257, Temperature 0.0026057828024010354, step_size 0.09922299540664323, test_acc: 1.0\n",
            "Epoch 135, BestLoss: 0.06655906874350093, Temperature 0.0024754936622809836, step_size 0.09921307310710256, test_acc: 1.0\n",
            "Epoch 136, BestLoss: 0.06580529180937028, Temperature 0.002351718979166934, step_size 0.09920315179979185, test_acc: 1.0\n",
            "Epoch 137, BestLoss: 0.05963931204637009, Temperature 0.0022341330302085875, step_size 0.09919323148461187, test_acc: 1.0\n",
            "Epoch 138, BestLoss: 0.05745116882843575, Temperature 0.002122426378698158, step_size 0.09918331216146341, test_acc: 1.0\n",
            "Epoch 139, BestLoss: 0.05951987024918848, Temperature 0.0020163050597632503, step_size 0.09917339383024726, test_acc: 1.0\n",
            "Epoch 140, BestLoss: 0.05524212809624148, Temperature 0.0019154898067750877, step_size 0.09916347649086424, test_acc: 1.0\n",
            "Epoch 141, BestLoss: 0.054746053768174686, Temperature 0.0018197153164363333, step_size 0.09915356014321515, test_acc: 1.0\n",
            "Epoch 142, BestLoss: 0.05530680420416508, Temperature 0.0017287295506145165, step_size 0.09914364478720084, test_acc: 1.0\n",
            "Epoch 143, BestLoss: 0.05700813421161272, Temperature 0.0016422930730837905, step_size 0.09913373042272211, test_acc: 1.0\n",
            "Epoch 144, BestLoss: 0.06108157814911258, Temperature 0.0015601784194296008, step_size 0.09912381704967983, test_acc: 1.0\n",
            "Epoch 145, BestLoss: 0.059517155538716254, Temperature 0.0014821694984581207, step_size 0.09911390466797487, test_acc: 1.0\n",
            "Epoch 146, BestLoss: 0.05694670991295383, Temperature 0.0014080610235352145, step_size 0.09910399327750807, test_acc: 1.0\n",
            "Epoch 147, BestLoss: 0.05492776621072299, Temperature 0.0013376579723584536, step_size 0.09909408287818032, test_acc: 1.0\n",
            "Epoch 148, BestLoss: 0.05342113329014993, Temperature 0.0012707750737405309, step_size 0.0990841734698925, test_acc: 1.0\n",
            "Epoch 149, BestLoss: 0.05491912841625311, Temperature 0.0012072363200535043, step_size 0.0990742650525455, test_acc: 1.0\n",
            "Epoch 150, BestLoss: 0.0541404451114364, Temperature 0.001146874504050829, step_size 0.09906435762604025, test_acc: 1.0\n",
            "Epoch 151, BestLoss: 0.05196749960808963, Temperature 0.0010895307788482875, step_size 0.09905445119027766, test_acc: 1.0\n",
            "Epoch 152, BestLoss: 0.051319198682040365, Temperature 0.001035054239905873, step_size 0.09904454574515863, test_acc: 1.0\n",
            "Epoch 153, BestLoss: 0.05014545153480254, Temperature 0.0009833015279105794, step_size 0.09903464129058412, test_acc: 1.0\n",
            "Epoch 154, BestLoss: 0.05031843868295192, Temperature 0.0009341364515150504, step_size 0.09902473782645506, test_acc: 1.0\n",
            "Epoch 155, BestLoss: 0.05119618925799464, Temperature 0.0008874296289392978, step_size 0.09901483535267241, test_acc: 1.0\n",
            "Epoch 156, BestLoss: 0.050427851666320245, Temperature 0.0008430581474923328, step_size 0.09900493386913715, test_acc: 1.0\n",
            "Epoch 157, BestLoss: 0.04987122672386276, Temperature 0.0008009052401177162, step_size 0.09899503337575025, test_acc: 1.0\n",
            "Epoch 158, BestLoss: 0.049861673162276375, Temperature 0.0007608599781118304, step_size 0.09898513387241267, test_acc: 1.0\n",
            "Epoch 159, BestLoss: 0.049110948284099495, Temperature 0.0007228169792062388, step_size 0.09897523535902543, test_acc: 1.0\n",
            "Epoch 160, BestLoss: 0.048864738943074346, Temperature 0.0006866761302459269, step_size 0.09896533783548953, test_acc: 1.0\n",
            "Epoch 161, BestLoss: 0.04913434345413338, Temperature 0.0006523423237336305, step_size 0.09895544130170597, test_acc: 1.0\n",
            "Epoch 162, BestLoss: 0.049308037411268664, Temperature 0.0006197252075469489, step_size 0.0989455457575758, test_acc: 1.0\n",
            "Epoch 163, BestLoss: 0.049162142652597385, Temperature 0.0005887389471696014, step_size 0.09893565120300005, test_acc: 1.0\n",
            "Epoch 164, BestLoss: 0.048587976050856886, Temperature 0.0005593019998111214, step_size 0.09892575763787975, test_acc: 1.0\n",
            "Epoch 165, BestLoss: 0.04843593991902484, Temperature 0.0005313368998205653, step_size 0.09891586506211597, test_acc: 1.0\n",
            "Epoch 166, BestLoss: 0.04859138606257035, Temperature 0.0005047700548295369, step_size 0.09890597347560975, test_acc: 1.0\n",
            "Epoch 167, BestLoss: 0.04835488470030638, Temperature 0.00047953155208806006, step_size 0.0988960828782622, test_acc: 1.0\n",
            "Epoch 168, BestLoss: 0.04796215466661339, Temperature 0.000455554974483657, step_size 0.09888619326997437, test_acc: 1.0\n",
            "Epoch 169, BestLoss: 0.04784437664735197, Temperature 0.0004327772257594741, step_size 0.09887630465064738, test_acc: 1.0\n",
            "Epoch 170, BestLoss: 0.04792434842406287, Temperature 0.0004111383644715004, step_size 0.09886641702018231, test_acc: 1.0\n",
            "Epoch 171, BestLoss: 0.04863531229394561, Temperature 0.00039058144624792536, step_size 0.0988565303784803, test_acc: 1.0\n",
            "Epoch 172, BestLoss: 0.04808686330827446, Temperature 0.0003710523739355291, step_size 0.09884664472544245, test_acc: 1.0\n",
            "Epoch 173, BestLoss: 0.048156105523624336, Temperature 0.00035249975523875265, step_size 0.0988367600609699, test_acc: 1.0\n",
            "Epoch 174, BestLoss: 0.04802178619200662, Temperature 0.000334874767476815, step_size 0.0988268763849638, test_acc: 1.0\n",
            "Epoch 175, BestLoss: 0.04796332392046546, Temperature 0.00031813102910297424, step_size 0.09881699369732531, test_acc: 1.0\n",
            "Epoch 176, BestLoss: 0.04789714894776058, Temperature 0.0003022244776478255, step_size 0.09880711199795558, test_acc: 1.0\n",
            "Epoch 177, BestLoss: 0.048506628308155796, Temperature 0.0002871132537654342, step_size 0.09879723128675579, test_acc: 1.0\n",
            "Epoch 178, BestLoss: 0.04800881447425105, Temperature 0.00027275759107716247, step_size 0.09878735156362711, test_acc: 1.0\n",
            "Epoch 179, BestLoss: 0.048104156400778385, Temperature 0.00025911971152330434, step_size 0.09877747282847076, test_acc: 1.0\n",
            "Epoch 180, BestLoss: 0.048369298387221704, Temperature 0.00024616372594713913, step_size 0.0987675950811879, test_acc: 1.0\n",
            "Epoch 181, BestLoss: 0.04806887399776673, Temperature 0.00023385553964978215, step_size 0.09875771832167979, test_acc: 1.0\n",
            "Epoch 182, BestLoss: 0.047760437165265276, Temperature 0.00022216276266729304, step_size 0.09874784254984763, test_acc: 1.0\n",
            "Epoch 183, BestLoss: 0.04792306384189212, Temperature 0.00021105462453392839, step_size 0.09873796776559264, test_acc: 1.0\n",
            "Epoch 184, BestLoss: 0.047829707121072526, Temperature 0.00020050189330723196, step_size 0.09872809396881609, test_acc: 1.0\n",
            "Epoch 185, BestLoss: 0.047718354670142196, Temperature 0.00019047679864187035, step_size 0.09871822115941921, test_acc: 1.0\n",
            "Epoch 186, BestLoss: 0.047907204370274556, Temperature 0.00018095295870977683, step_size 0.09870834933730327, test_acc: 1.0\n",
            "Epoch 187, BestLoss: 0.04775750927341923, Temperature 0.00017190531077428798, step_size 0.09869847850236954, test_acc: 1.0\n",
            "Epoch 188, BestLoss: 0.047761361548412665, Temperature 0.00016331004523557357, step_size 0.09868860865451931, test_acc: 1.0\n",
            "Epoch 189, BestLoss: 0.047759510733471, Temperature 0.00017190531077428798, step_size 0.09991003599160127, test_acc: 1.0\n",
            "Epoch 190, BestLoss: 0.047744712572292305, Temperature 0.00018095295870977683, step_size 0.0999000449880021, test_acc: 1.0\n",
            "Epoch 191, BestLoss: 0.047793444741408626, Temperature 0.00017190531077428798, step_size 0.0998900549835033, test_acc: 1.0\n",
            "Epoch 192, BestLoss: 0.04793457179350441, Temperature 0.00016331004523557357, step_size 0.09988006597800494, test_acc: 1.0\n",
            "Epoch 193, BestLoss: 0.04793133263598216, Temperature 0.00015514454297379488, step_size 0.09987007797140715, test_acc: 1.0\n",
            "Epoch 194, BestLoss: 0.04785871428305969, Temperature 0.00016331004523557357, step_size 0.0998900549835033, test_acc: 1.0\n",
            "Epoch 195, BestLoss: 0.04788588022096985, Temperature 0.00015514454297379488, step_size 0.09988006597800494, test_acc: 1.0\n",
            "Epoch 196, BestLoss: 0.047775643449778055, Temperature 0.00014738731582510513, step_size 0.09987007797140715, test_acc: 1.0\n",
            "Epoch 197, BestLoss: 0.04772395696599595, Temperature 0.00014001795003384986, step_size 0.09986009096361001, test_acc: 1.0\n",
            "Epoch 198, BestLoss: 0.04782271880420205, Temperature 0.00013301705253215737, step_size 0.09985010495451364, test_acc: 1.0\n",
            "Epoch 199, BestLoss: 0.047997071364087436, Temperature 0.0001263661999055495, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 200, BestLoss: 0.04784981275633779, Temperature 0.000120047889910272, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 201, BestLoss: 0.04780569247579716, Temperature 0.0001140454954147584, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 202, BestLoss: 0.047963905290587985, Temperature 0.00010834322064402047, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 203, BestLoss: 0.04779666000725009, Temperature 0.00010292605961181944, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 204, BestLoss: 0.04790036831746737, Temperature 9.777975663122846e-05, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 205, BestLoss: 0.04791098840829356, Temperature 9.289076879966704e-05, step_size 0.09978023084607313, test_acc: 1.0\n",
            "Epoch 206, BestLoss: 0.04785839624681548, Temperature 8.824623035968368e-05, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 207, BestLoss: 0.04791871798306868, Temperature 8.383391884169949e-05, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 208, BestLoss: 0.048006994158913185, Temperature 7.96422228996145e-05, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 209, BestLoss: 0.047926045328327796, Temperature 7.566011175463378e-05, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 210, BestLoss: 0.04782235115923576, Temperature 7.187710616690208e-05, step_size 0.09973035070767541, test_acc: 1.0\n",
            "Epoch 211, BestLoss: 0.04783926358188349, Temperature 6.828325085855697e-05, step_size 0.09972037767260465, test_acc: 1.0\n",
            "Epoch 212, BestLoss: 0.04778731672391802, Temperature 6.486908831562912e-05, step_size 0.09971040563483739, test_acc: 1.0\n",
            "Epoch 213, BestLoss: 0.04781307195716418, Temperature 6.162563389984766e-05, step_size 0.09970043459427391, test_acc: 1.0\n",
            "Epoch 214, BestLoss: 0.04789098795007765, Temperature 5.8544352204855274e-05, step_size 0.09969046455081448, test_acc: 1.0\n",
            "Epoch 215, BestLoss: 0.04783622270559257, Temperature 5.561713459461251e-05, step_size 0.09968049550435941, test_acc: 1.0\n",
            "Epoch 216, BestLoss: 0.04782218955402951, Temperature 5.283627786488188e-05, step_size 0.09967052745480898, test_acc: 1.0\n",
            "Epoch 217, BestLoss: 0.04777223308199681, Temperature 5.019446397163778e-05, step_size 0.0996605604020635, test_acc: 1.0\n",
            "Epoch 218, BestLoss: 0.04774685215228099, Temperature 4.768474077305589e-05, step_size 0.0996505943460233, test_acc: 1.0\n",
            "Epoch 219, BestLoss: 0.04772457439577118, Temperature 4.53005037344031e-05, step_size 0.0996406292865887, test_acc: 1.0\n",
            "Epoch 220, BestLoss: 0.04770845767970559, Temperature 4.303547854768294e-05, step_size 0.09963066522366004, test_acc: 1.0\n",
            "Epoch 221, BestLoss: 0.047712098747434796, Temperature 4.0883704620298796e-05, step_size 0.09962070215713768, test_acc: 1.0\n",
            "Epoch 222, BestLoss: 0.047715874896922236, Temperature 3.883951938928385e-05, step_size 0.09961074008692197, test_acc: 1.0\n",
            "Epoch 223, BestLoss: 0.047698804407226826, Temperature 3.689754341981966e-05, step_size 0.09960077901291328, test_acc: 1.0\n",
            "Epoch 224, BestLoss: 0.047843008829992505, Temperature 3.505266624882867e-05, step_size 0.099590818935012, test_acc: 1.0\n",
            "Epoch 225, BestLoss: 0.047759302284948596, Temperature 3.3300032936387236e-05, step_size 0.0995808598531185, test_acc: 1.0\n",
            "Epoch 226, BestLoss: 0.04779013550129408, Temperature 3.163503128956787e-05, step_size 0.0995709017671332, test_acc: 1.0\n",
            "Epoch 227, BestLoss: 0.04776961694137731, Temperature 3.0053279725089478e-05, step_size 0.09956094467695648, test_acc: 1.0\n",
            "Epoch 228, BestLoss: 0.0477078918518284, Temperature 2.8550615738835003e-05, step_size 0.09955098858248879, test_acc: 1.0\n",
            "Epoch 229, BestLoss: 0.04768010265735536, Temperature 2.7123084951893252e-05, step_size 0.09954103348363054, test_acc: 1.0\n",
            "Epoch 230, BestLoss: 0.047694799747406966, Temperature 2.576693070429859e-05, step_size 0.09953107938028218, test_acc: 1.0\n",
            "Epoch 231, BestLoss: 0.047665357622362105, Temperature 2.447858416908366e-05, step_size 0.09952112627234415, test_acc: 1.0\n",
            "Epoch 232, BestLoss: 0.04766401096023693, Temperature 2.3254654960629475e-05, step_size 0.09951117415971691, test_acc: 1.0\n",
            "Epoch 233, BestLoss: 0.04767575330872987, Temperature 2.2091922212598e-05, step_size 0.09950122304230094, test_acc: 1.0\n",
            "Epoch 234, BestLoss: 0.047689587344399625, Temperature 2.09873261019681e-05, step_size 0.09949127291999671, test_acc: 1.0\n",
            "Epoch 235, BestLoss: 0.047675959135603074, Temperature 1.9937959796869693e-05, step_size 0.0994813237927047, test_acc: 1.0\n",
            "Epoch 236, BestLoss: 0.04766330251915829, Temperature 1.8941061807026206e-05, step_size 0.09947137566032543, test_acc: 1.0\n",
            "Epoch 237, BestLoss: 0.047663450231571994, Temperature 1.7994008716674895e-05, step_size 0.0994614285227594, test_acc: 1.0\n",
            "Epoch 238, BestLoss: 0.04766777729901471, Temperature 1.8941061807026206e-05, step_size 0.09988006597800494, test_acc: 1.0\n",
            "Epoch 239, BestLoss: 0.047650417428209, Temperature 1.7994008716674895e-05, step_size 0.09987007797140715, test_acc: 1.0\n",
            "Epoch 240, BestLoss: 0.047652992990247396, Temperature 1.7094308280841148e-05, step_size 0.09986009096361001, test_acc: 1.0\n",
            "Epoch 241, BestLoss: 0.04764911721151839, Temperature 1.623959286679909e-05, step_size 0.09985010495451364, test_acc: 1.0\n",
            "Epoch 242, BestLoss: 0.047644321211187377, Temperature 1.5427613223459133e-05, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 243, BestLoss: 0.047641692739775664, Temperature 1.4656232562286176e-05, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 244, BestLoss: 0.047646280248018355, Temperature 1.3923420934171866e-05, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 245, BestLoss: 0.04765138329533965, Temperature 1.3227249887463272e-05, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 246, BestLoss: 0.047639600193181, Temperature 1.2565887393090107e-05, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 247, BestLoss: 0.047634923408250415, Temperature 1.19375930234356e-05, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 248, BestLoss: 0.047641893055416516, Temperature 1.134071337226382e-05, step_size 0.09978023084607313, test_acc: 1.0\n",
            "Epoch 249, BestLoss: 0.04764301242655531, Temperature 1.0773677703650629e-05, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 250, BestLoss: 0.04763666729895266, Temperature 1.0234993818468096e-05, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 251, BestLoss: 0.04763767562817987, Temperature 9.72324412754469e-06, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 252, BestLoss: 0.04765037804091689, Temperature 9.237081921167456e-06, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 253, BestLoss: 0.047648238882177486, Temperature 8.775227825109082e-06, step_size 0.09973035070767541, test_acc: 1.0\n",
            "Epoch 254, BestLoss: 0.047659529563452485, Temperature 8.336466433853627e-06, step_size 0.09972037767260465, test_acc: 1.0\n",
            "Epoch 255, BestLoss: 0.04766525273507337, Temperature 7.919643112160946e-06, step_size 0.09971040563483739, test_acc: 1.0\n",
            "Epoch 256, BestLoss: 0.047675659457617904, Temperature 7.523660956552898e-06, step_size 0.09970043459427391, test_acc: 1.0\n",
            "Epoch 257, BestLoss: 0.04767732546547758, Temperature 7.147477908725253e-06, step_size 0.09969046455081448, test_acc: 1.0\n",
            "Epoch 258, BestLoss: 0.04764576419497733, Temperature 6.79010401328899e-06, step_size 0.09968049550435941, test_acc: 1.0\n",
            "Epoch 259, BestLoss: 0.047645493538590676, Temperature 6.45059881262454e-06, step_size 0.09967052745480898, test_acc: 1.0\n",
            "Epoch 260, BestLoss: 0.047634950757752925, Temperature 6.79010401328899e-06, step_size 0.09987007797140715, test_acc: 1.0\n",
            "Epoch 261, BestLoss: 0.04763725669380848, Temperature 6.45059881262454e-06, step_size 0.09986009096361001, test_acc: 1.0\n",
            "Epoch 262, BestLoss: 0.04764062344732337, Temperature 6.128068871993313e-06, step_size 0.09985010495451364, test_acc: 1.0\n",
            "Epoch 263, BestLoss: 0.04764062344732337, Temperature 5.821665428393647e-06, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 264, BestLoss: 0.04764865467962399, Temperature 6.128068871993312e-06, step_size 0.09986009096361001, test_acc: 1.0\n",
            "Epoch 265, BestLoss: 0.047635829700973006, Temperature 5.821665428393647e-06, step_size 0.09985010495451364, test_acc: 1.0\n",
            "Epoch 266, BestLoss: 0.047632578260312926, Temperature 5.530582156973964e-06, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 267, BestLoss: 0.04763447037792593, Temperature 5.254053049125266e-06, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 268, BestLoss: 0.04763345485165214, Temperature 4.991350396669002e-06, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 269, BestLoss: 0.04763345485165214, Temperature 4.741782876835552e-06, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 270, BestLoss: 0.047639394704827316, Temperature 4.991350396669002e-06, step_size 0.09985010495451364, test_acc: 1.0\n",
            "Epoch 271, BestLoss: 0.047635258979440716, Temperature 4.741782876835552e-06, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 272, BestLoss: 0.0476355675584139, Temperature 4.504693732993774e-06, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 273, BestLoss: 0.04763006202135933, Temperature 4.279459046344085e-06, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 274, BestLoss: 0.047633041633811414, Temperature 4.065486094026881e-06, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 275, BestLoss: 0.04763679403053276, Temperature 3.862211789325536e-06, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 276, BestLoss: 0.04763087709511158, Temperature 3.6691011998592594e-06, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 277, BestLoss: 0.047630645651686954, Temperature 3.485646139866296e-06, step_size 0.09978023084607313, test_acc: 1.0\n",
            "Epoch 278, BestLoss: 0.047632825952113156, Temperature 3.3113638328729812e-06, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 279, BestLoss: 0.047632825952113156, Temperature 3.145795641229332e-06, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 280, BestLoss: 0.04763112919042631, Temperature 3.3113638328729812e-06, step_size 0.09984011994401819, test_acc: 1.0\n",
            "Epoch 281, BestLoss: 0.04763082054948295, Temperature 3.145795641229332e-06, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 282, BestLoss: 0.047631428065399835, Temperature 2.988505859167865e-06, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 283, BestLoss: 0.047631428065399835, Temperature 2.8390805662094717e-06, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 284, BestLoss: 0.04763097098980246, Temperature 2.988505859167865e-06, step_size 0.09983013593202379, test_acc: 1.0\n",
            "Epoch 285, BestLoss: 0.04763022057499531, Temperature 2.8390805662094717e-06, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 286, BestLoss: 0.04763073331327736, Temperature 2.697126537898998e-06, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 287, BestLoss: 0.04763421459197084, Temperature 2.562270211004048e-06, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 288, BestLoss: 0.047633720180704844, Temperature 2.4341567004538453e-06, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 289, BestLoss: 0.04763493835468433, Temperature 2.312448865431153e-06, step_size 0.09978023084607313, test_acc: 1.0\n",
            "Epoch 290, BestLoss: 0.047634635548191674, Temperature 2.196826422159595e-06, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 291, BestLoss: 0.047632872359164545, Temperature 2.0869851010516154e-06, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 292, BestLoss: 0.04763193736745151, Temperature 1.9826358459990345e-06, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 293, BestLoss: 0.04763193736745151, Temperature 1.8835040536990826e-06, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 294, BestLoss: 0.04763490455436211, Temperature 1.9826358459990345e-06, step_size 0.09982015291843059, test_acc: 1.0\n",
            "Epoch 295, BestLoss: 0.04763560609486351, Temperature 1.8835040536990826e-06, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 296, BestLoss: 0.04763560609486351, Temperature 1.7893288510141284e-06, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 297, BestLoss: 0.04763560609486351, Temperature 1.8835040536990826e-06, step_size 0.09981017090313875, test_acc: 1.0\n",
            "Epoch 298, BestLoss: 0.04763264927131714, Temperature 1.9826358459990345e-06, step_size 0.09980018988604844, test_acc: 1.0\n",
            "Epoch 299, BestLoss: 0.04763264927131714, Temperature 1.8835040536990826e-06, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 300, BestLoss: 0.04763264927131714, Temperature 1.9826358459990345e-06, step_size 0.09979020986705983, test_acc: 1.0\n",
            "Epoch 301, BestLoss: 0.04763050576279743, Temperature 2.0869851010516154e-06, step_size 0.09978023084607313, test_acc: 1.0\n",
            "Epoch 302, BestLoss: 0.047631653407574054, Temperature 1.9826358459990345e-06, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 303, BestLoss: 0.04763270363300804, Temperature 1.8835040536990826e-06, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 304, BestLoss: 0.047631047783605426, Temperature 1.7893288510141284e-06, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 305, BestLoss: 0.047631047783605426, Temperature 1.699862408463422e-06, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 306, BestLoss: 0.047631323198479875, Temperature 1.7893288510141284e-06, step_size 0.09977025282298851, test_acc: 1.0\n",
            "Epoch 307, BestLoss: 0.047631323198479875, Temperature 1.699862408463422e-06, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 308, BestLoss: 0.04762983695428175, Temperature 1.7893288510141284e-06, step_size 0.09976027579770622, test_acc: 1.0\n",
            "Epoch 309, BestLoss: 0.04762983695428175, Temperature 1.699862408463422e-06, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 310, BestLoss: 0.04762951677877134, Temperature 1.7893288510141284e-06, step_size 0.09975029977012645, test_acc: 1.0\n",
            "Epoch 311, BestLoss: 0.04762951677877134, Temperature 1.699862408463422e-06, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 312, BestLoss: 0.04762951677877134, Temperature 1.7893288510141284e-06, step_size 0.09974032474014943, test_acc: 1.0\n",
            "Epoch 313, BestLoss: 0.04762951677877134, Temperature 1.8835040536990826e-06, step_size 0.09973035070767541, test_acc: 1.0\n",
            "Epoch 314, BestLoss: 0.04762951677877134, Temperature 1.9826358459990345e-06, step_size 0.09972037767260465, test_acc: 1.0\n",
            "Epoch 315, BestLoss: 0.04762951677877134, Temperature 2.0869851010516154e-06, step_size 0.09971040563483739, test_acc: 1.0\n",
            "Epoch 316, BestLoss: 0.04762737979591521, Temperature 2.196826422159595e-06, step_size 0.09970043459427391, test_acc: 1.0\n",
            "Epoch 317, BestLoss: 0.04762737979591521, Temperature 2.0869851010516154e-06, step_size 0.09969046455081448, test_acc: 1.0\n",
            "Epoch 318, BestLoss: 0.04762760592424302, Temperature 2.196826422159595e-06, step_size 0.09969046455081448, test_acc: 1.0\n",
            "Epoch 319, BestLoss: 0.04762760592424302, Temperature 2.0869851010516154e-06, step_size 0.09968049550435941, test_acc: 1.0\n",
            "Epoch 320, BestLoss: 0.04762790573688064, Temperature 2.196826422159595e-06, step_size 0.09968049550435941, test_acc: 1.0\n",
            "Epoch 321, BestLoss: 0.04762729685504611, Temperature 2.0869851010516154e-06, step_size 0.09967052745480898, test_acc: 1.0\n",
            "Epoch 322, BestLoss: 0.047626823535747806, Temperature 1.9826358459990345e-06, step_size 0.0996605604020635, test_acc: 1.0\n",
            "Epoch 323, BestLoss: 0.04762881867429309, Temperature 1.8835040536990826e-06, step_size 0.0996505943460233, test_acc: 1.0\n",
            "Epoch 324, BestLoss: 0.047628934191638224, Temperature 1.7893288510141284e-06, step_size 0.0996406292865887, test_acc: 1.0\n",
            "Epoch 325, BestLoss: 0.04763154709633142, Temperature 1.699862408463422e-06, step_size 0.09963066522366004, test_acc: 1.0\n",
            "Epoch 326, BestLoss: 0.04763064588532752, Temperature 1.6148692880402508e-06, step_size 0.09962070215713768, test_acc: 1.0\n",
            "Epoch 327, BestLoss: 0.04763064588532752, Temperature 1.534125823638238e-06, step_size 0.09961074008692197, test_acc: 1.0\n",
            "Epoch 328, BestLoss: 0.04763064588532752, Temperature 1.6148692880402508e-06, step_size 0.09967052745480898, test_acc: 1.0\n",
            "Epoch 329, BestLoss: 0.04763064962104796, Temperature 1.699862408463422e-06, step_size 0.0996605604020635, test_acc: 1.0\n",
            "Epoch 330, BestLoss: 0.04763101225173527, Temperature 1.7893288510141284e-06, step_size 0.0996505943460233, test_acc: 1.0\n",
            "Epoch 331, BestLoss: 0.047632731044454577, Temperature 1.699862408463422e-06, step_size 0.0996406292865887, test_acc: 1.0\n",
            "Epoch 332, BestLoss: 0.047632731044454577, Temperature 1.6148692880402508e-06, step_size 0.09963066522366004, test_acc: 1.0\n",
            "Epoch 333, BestLoss: 0.047632731044454577, Temperature 1.699862408463422e-06, step_size 0.0996406292865887, test_acc: 1.0\n",
            "Epoch 334, BestLoss: 0.047632731044454577, Temperature 1.7893288510141284e-06, step_size 0.09963066522366004, test_acc: 1.0\n",
            "Epoch 335, BestLoss: 0.047632731044454577, Temperature 1.8835040536990826e-06, step_size 0.09962070215713768, test_acc: 1.0\n",
            "Epoch 336, BestLoss: 0.04763156349237711, Temperature 1.9826358459990345e-06, step_size 0.09961074008692197, test_acc: 1.0\n",
            "Epoch 337, BestLoss: 0.047629874122421034, Temperature 1.8835040536990826e-06, step_size 0.09960077901291328, test_acc: 1.0\n",
            "Epoch 338, BestLoss: 0.047629874122421034, Temperature 1.7893288510141284e-06, step_size 0.099590818935012, test_acc: 1.0\n",
            "Epoch 339, BestLoss: 0.04763072487115462, Temperature 1.8835040536990826e-06, step_size 0.09960077901291328, test_acc: 1.0\n",
            "Epoch 340, BestLoss: 0.04763287673727563, Temperature 1.7893288510141284e-06, step_size 0.099590818935012, test_acc: 1.0\n",
            "Epoch 341, BestLoss: 0.04763448882819579, Temperature 1.699862408463422e-06, step_size 0.0995808598531185, test_acc: 1.0\n",
            "Epoch 342, BestLoss: 0.0476275267277483, Temperature 1.6148692880402508e-06, step_size 0.0995709017671332, test_acc: 1.0\n",
            "Epoch 343, BestLoss: 0.04762642567521717, Temperature 1.534125823638238e-06, step_size 0.09956094467695648, test_acc: 1.0\n",
            "Epoch 344, BestLoss: 0.047625964792519966, Temperature 1.457419532456326e-06, step_size 0.09955098858248879, test_acc: 1.0\n",
            "Epoch 345, BestLoss: 0.04762575822853139, Temperature 1.3845485558335097e-06, step_size 0.09954103348363054, test_acc: 1.0\n",
            "Epoch 346, BestLoss: 0.04762552236923069, Temperature 1.3153211280418342e-06, step_size 0.09953107938028218, test_acc: 1.0\n",
            "Epoch 347, BestLoss: 0.047626282225370256, Temperature 1.2495550716397424e-06, step_size 0.09952112627234415, test_acc: 1.0\n",
            "Epoch 348, BestLoss: 0.047626282225370256, Temperature 1.1870773180577553e-06, step_size 0.09951117415971691, test_acc: 1.0\n",
            "Epoch 349, BestLoss: 0.047626282225370256, Temperature 1.2495550716397424e-06, step_size 0.099590818935012, test_acc: 1.0\n",
            "Epoch 350, BestLoss: 0.04762730007750213, Temperature 1.3153211280418342e-06, step_size 0.0995808598531185, test_acc: 1.0\n",
            "Epoch 351, BestLoss: 0.04762609429460225, Temperature 1.2495550716397424e-06, step_size 0.0995709017671332, test_acc: 1.0\n",
            "Epoch 352, BestLoss: 0.047627352534148806, Temperature 1.1870773180577553e-06, step_size 0.09956094467695648, test_acc: 1.0\n",
            "Epoch 353, BestLoss: 0.047627352534148806, Temperature 1.1277234521548674e-06, step_size 0.09955098858248879, test_acc: 1.0\n",
            "Epoch 354, BestLoss: 0.047627352534148806, Temperature 1.1870773180577553e-06, step_size 0.0995709017671332, test_acc: 1.0\n",
            "Epoch 355, BestLoss: 0.047627352534148806, Temperature 1.2495550716397424e-06, step_size 0.09956094467695648, test_acc: 1.0\n",
            "Epoch 356, BestLoss: 0.04762724595215943, Temperature 1.3153211280418342e-06, step_size 0.09955098858248879, test_acc: 1.0\n",
            "Epoch 357, BestLoss: 0.047629907729766274, Temperature 1.2495550716397424e-06, step_size 0.09954103348363054, test_acc: 1.0\n",
            "Epoch 358, BestLoss: 0.04762795466324318, Temperature 1.1870773180577553e-06, step_size 0.09953107938028218, test_acc: 1.0\n",
            "Epoch 359, BestLoss: 0.04762755535081055, Temperature 1.1277234521548674e-06, step_size 0.09952112627234415, test_acc: 1.0\n",
            "Epoch 360, BestLoss: 0.04762755535081055, Temperature 1.071337279547124e-06, step_size 0.09951117415971691, test_acc: 1.0\n",
            "Epoch 361, BestLoss: 0.04762755535081055, Temperature 1.1277234521548674e-06, step_size 0.09954103348363054, test_acc: 1.0\n",
            "Epoch 362, BestLoss: 0.04762755535081055, Temperature 1.1870773180577553e-06, step_size 0.09953107938028218, test_acc: 1.0\n",
            "Epoch 363, BestLoss: 0.04762944914669911, Temperature 1.2495550716397424e-06, step_size 0.09952112627234415, test_acc: 1.0\n",
            "Epoch 364, BestLoss: 0.047629375309703764, Temperature 1.1870773180577553e-06, step_size 0.09951117415971691, test_acc: 1.0\n",
            "Epoch 365, BestLoss: 0.047629375309703764, Temperature 1.1277234521548674e-06, step_size 0.09950122304230094, test_acc: 1.0\n",
            "Epoch 366, BestLoss: 0.047629375309703764, Temperature 1.1870773180577553e-06, step_size 0.09951117415971691, test_acc: 1.0\n",
            "Epoch 367, BestLoss: 0.04762619346926052, Temperature 1.2495550716397424e-06, step_size 0.09950122304230094, test_acc: 1.0\n",
            "Epoch 368, BestLoss: 0.04762619346926052, Temperature 1.1870773180577553e-06, step_size 0.09949127291999671, test_acc: 1.0\n",
            "Epoch 369, BestLoss: 0.04762843324348633, Temperature 1.2495550716397424e-06, step_size 0.09949127291999671, test_acc: 1.0\n",
            "Epoch 370, BestLoss: 0.04762843324348633, Temperature 1.1870773180577553e-06, step_size 0.0994813237927047, test_acc: 1.0\n",
            "Epoch 371, BestLoss: 0.04762748469915532, Temperature 1.2495550716397424e-06, step_size 0.0994813237927047, test_acc: 1.0\n",
            "Epoch 372, BestLoss: 0.04762748469915532, Temperature 1.1870773180577553e-06, step_size 0.09947137566032543, test_acc: 1.0\n",
            "Epoch 373, BestLoss: 0.04762748469915532, Temperature 1.2495550716397424e-06, step_size 0.09947137566032543, test_acc: 1.0\n",
            "Epoch 374, BestLoss: 0.047627595131639874, Temperature 1.3153211280418342e-06, step_size 0.0994614285227594, test_acc: 1.0\n",
            "Epoch 375, BestLoss: 0.047627591087071784, Temperature 1.2495550716397424e-06, step_size 0.09945148237990713, test_acc: 1.0\n",
            "Epoch 376, BestLoss: 0.047627591087071784, Temperature 1.3153211280418342e-06, step_size 0.09945148237990713, test_acc: 1.0\n",
            "Epoch 377, BestLoss: 0.04762938593049802, Temperature 1.3845485558335097e-06, step_size 0.09944153723166914, test_acc: 1.0\n",
            "Epoch 378, BestLoss: 0.04762914601950809, Temperature 1.3153211280418342e-06, step_size 0.09943159307794597, test_acc: 1.0\n",
            "Epoch 379, BestLoss: 0.04762858756282093, Temperature 1.2495550716397424e-06, step_size 0.09942164991863818, test_acc: 1.0\n",
            "Epoch 380, BestLoss: 0.047628554471125774, Temperature 1.1870773180577553e-06, step_size 0.09941170775364631, test_acc: 1.0\n",
            "Epoch 381, BestLoss: 0.047628554471125774, Temperature 1.2495550716397424e-06, step_size 0.09943159307794597, test_acc: 1.0\n",
            "Epoch 382, BestLoss: 0.047628554471125774, Temperature 1.3153211280418342e-06, step_size 0.09942164991863818, test_acc: 1.0\n",
            "Epoch 383, BestLoss: 0.047628554471125774, Temperature 1.3845485558335097e-06, step_size 0.09941170775364631, test_acc: 1.0\n",
            "Epoch 384, BestLoss: 0.04762927935632475, Temperature 1.457419532456326e-06, step_size 0.09940176658287095, test_acc: 1.0\n",
            "Epoch 385, BestLoss: 0.04762927935632475, Temperature 1.3845485558335097e-06, step_size 0.09939182640621266, test_acc: 1.0\n",
            "Epoch 386, BestLoss: 0.04762847649690509, Temperature 1.457419532456326e-06, step_size 0.09939182640621266, test_acc: 1.0\n",
            "Epoch 387, BestLoss: 0.04762950145857178, Temperature 1.3845485558335097e-06, step_size 0.09938188722357204, test_acc: 1.0\n",
            "Epoch 388, BestLoss: 0.04762851767819587, Temperature 1.3153211280418342e-06, step_size 0.09937194903484968, test_acc: 1.0\n",
            "Epoch 389, BestLoss: 0.04762851767819587, Temperature 1.2495550716397424e-06, step_size 0.0993620118399462, test_acc: 1.0\n",
            "Epoch 390, BestLoss: 0.04762915023979837, Temperature 1.3153211280418342e-06, step_size 0.09938188722357204, test_acc: 1.0\n",
            "Epoch 391, BestLoss: 0.04762906854225438, Temperature 1.2495550716397424e-06, step_size 0.09937194903484968, test_acc: 1.0\n",
            "Epoch 392, BestLoss: 0.04762884490614933, Temperature 1.1870773180577553e-06, step_size 0.0993620118399462, test_acc: 1.0\n",
            "Epoch 393, BestLoss: 0.047628910127594085, Temperature 1.1277234521548674e-06, step_size 0.09935207563876221, test_acc: 1.0\n",
            "Epoch 394, BestLoss: 0.047628910127594085, Temperature 1.071337279547124e-06, step_size 0.09934214043119834, test_acc: 1.0\n",
            "Epoch 395, BestLoss: 0.047628910127594085, Temperature 1.1277234521548674e-06, step_size 0.09937194903484968, test_acc: 1.0\n",
            "Epoch 396, BestLoss: 0.047628070444361306, Temperature 1.1870773180577553e-06, step_size 0.0993620118399462, test_acc: 1.0\n",
            "Epoch 397, BestLoss: 0.04763132861159983, Temperature 1.1277234521548674e-06, step_size 0.09935207563876221, test_acc: 1.0\n",
            "Epoch 398, BestLoss: 0.04762818001568094, Temperature 1.071337279547124e-06, step_size 0.09934214043119834, test_acc: 1.0\n",
            "Epoch 399, BestLoss: 0.04762818001568094, Temperature 1.0177704155697677e-06, step_size 0.09933220621715522, test_acc: 1.0\n",
            "Epoch 400, BestLoss: 0.047628477575588024, Temperature 1.0713372795471238e-06, step_size 0.09935207563876221, test_acc: 1.0\n",
            "Epoch 401, BestLoss: 0.04762904355637658, Temperature 1.0177704155697677e-06, step_size 0.09934214043119834, test_acc: 1.0\n",
            "Epoch 402, BestLoss: 0.047628545888493315, Temperature 9.668818947912793e-07, step_size 0.09933220621715522, test_acc: 1.0\n",
            "Epoch 403, BestLoss: 0.04763013628777852, Temperature 9.185378000517153e-07, step_size 0.0993222729965335, test_acc: 1.0\n",
            "Epoch 404, BestLoss: 0.04762814498998341, Temperature 8.726109100491295e-07, step_size 0.09931234076923384, test_acc: 1.0\n",
            "Epoch 405, BestLoss: 0.04762814498998341, Temperature 8.28980364546673e-07, step_size 0.09930240953515691, test_acc: 1.0\n",
            "Epoch 406, BestLoss: 0.04762765382150983, Temperature 8.726109100491295e-07, step_size 0.09934214043119834, test_acc: 1.0\n",
            "Epoch 407, BestLoss: 0.04762765382150983, Temperature 8.28980364546673e-07, step_size 0.09933220621715522, test_acc: 1.0\n",
            "Epoch 408, BestLoss: 0.04762765382150983, Temperature 8.726109100491295e-07, step_size 0.09933220621715522, test_acc: 1.0\n",
            "Epoch 409, BestLoss: 0.04762621394907424, Temperature 9.185378000517153e-07, step_size 0.0993222729965335, test_acc: 1.0\n",
            "Epoch 410, BestLoss: 0.04762480529713166, Temperature 8.726109100491295e-07, step_size 0.09931234076923384, test_acc: 1.0\n",
            "Epoch 411, BestLoss: 0.04762480529713166, Temperature 8.28980364546673e-07, step_size 0.09930240953515691, test_acc: 1.0\n",
            "Epoch 412, BestLoss: 0.04762594758133258, Temperature 8.726109100491295e-07, step_size 0.09931234076923384, test_acc: 1.0\n",
            "Epoch 413, BestLoss: 0.047624410276517884, Temperature 8.28980364546673e-07, step_size 0.09930240953515691, test_acc: 1.0\n",
            "Epoch 414, BestLoss: 0.047624410276517884, Temperature 7.875313463193393e-07, step_size 0.0992924792942034, test_acc: 1.0\n",
            "Epoch 415, BestLoss: 0.047624410276517884, Temperature 8.28980364546673e-07, step_size 0.09930240953515691, test_acc: 1.0\n",
            "Epoch 416, BestLoss: 0.047624410276517884, Temperature 8.726109100491295e-07, step_size 0.0992924792942034, test_acc: 1.0\n",
            "Epoch 417, BestLoss: 0.04762293301378691, Temperature 9.185378000517153e-07, step_size 0.09928255004627398, test_acc: 1.0\n",
            "Epoch 418, BestLoss: 0.04762293301378691, Temperature 8.726109100491295e-07, step_size 0.09927262179126936, test_acc: 1.0\n",
            "Epoch 419, BestLoss: 0.047623356245333294, Temperature 9.185378000517153e-07, step_size 0.09927262179126936, test_acc: 1.0\n",
            "Epoch 420, BestLoss: 0.04762271121621575, Temperature 8.726109100491295e-07, step_size 0.09926269452909023, test_acc: 1.0\n",
            "Epoch 421, BestLoss: 0.047622502581472444, Temperature 8.28980364546673e-07, step_size 0.09925276825963732, test_acc: 1.0\n",
            "Epoch 422, BestLoss: 0.047622502581472444, Temperature 7.875313463193393e-07, step_size 0.09924284298281136, test_acc: 1.0\n",
            "Epoch 423, BestLoss: 0.047622470046969304, Temperature 8.28980364546673e-07, step_size 0.09926269452909023, test_acc: 1.0\n",
            "Epoch 424, BestLoss: 0.047622470046969304, Temperature 8.726109100491295e-07, step_size 0.09925276825963732, test_acc: 1.0\n",
            "Epoch 425, BestLoss: 0.047622470046969304, Temperature 9.185378000517153e-07, step_size 0.09924284298281136, test_acc: 1.0\n",
            "Epoch 426, BestLoss: 0.047622984481928955, Temperature 9.668818947912793e-07, step_size 0.09923291869851308, test_acc: 1.0\n",
            "Epoch 427, BestLoss: 0.047622984481928955, Temperature 9.185378000517153e-07, step_size 0.09922299540664323, test_acc: 1.0\n",
            "Epoch 428, BestLoss: 0.047622984481928955, Temperature 9.668818947912793e-07, step_size 0.09922299540664323, test_acc: 1.0\n",
            "Epoch 429, BestLoss: 0.047622984481928955, Temperature 1.0177704155697677e-06, step_size 0.09921307310710256, test_acc: 1.0\n",
            "Epoch 430, BestLoss: 0.04762251115477012, Temperature 1.0713372795471238e-06, step_size 0.09920315179979185, test_acc: 1.0\n",
            "Epoch 431, BestLoss: 0.04762251115477012, Temperature 1.0177704155697677e-06, step_size 0.09919323148461187, test_acc: 1.0\n",
            "Epoch 432, BestLoss: 0.04762251115477012, Temperature 1.0713372795471238e-06, step_size 0.09919323148461187, test_acc: 1.0\n",
            "Epoch 433, BestLoss: 0.047622385164044684, Temperature 1.1277234521548672e-06, step_size 0.09918331216146341, test_acc: 1.0\n",
            "Epoch 434, BestLoss: 0.047622385164044684, Temperature 1.0713372795471238e-06, step_size 0.09917339383024726, test_acc: 1.0\n",
            "Epoch 435, BestLoss: 0.047622385164044684, Temperature 1.1277234521548672e-06, step_size 0.09917339383024726, test_acc: 1.0\n",
            "Epoch 436, BestLoss: 0.047622513715701184, Temperature 1.187077318057755e-06, step_size 0.09916347649086424, test_acc: 1.0\n",
            "Epoch 437, BestLoss: 0.047622184559288024, Temperature 1.1277234521548672e-06, step_size 0.09915356014321515, test_acc: 1.0\n",
            "Epoch 438, BestLoss: 0.04762215776244358, Temperature 1.0713372795471238e-06, step_size 0.09914364478720084, test_acc: 1.0\n",
            "Epoch 439, BestLoss: 0.04762181554082065, Temperature 1.1277234521548672e-06, step_size 0.09915356014321515, test_acc: 1.0\n",
            "Epoch 440, BestLoss: 0.04762214197602216, Temperature 1.0713372795471238e-06, step_size 0.09914364478720084, test_acc: 1.0\n",
            "Epoch 441, BestLoss: 0.04762214197602216, Temperature 1.0177704155697677e-06, step_size 0.09913373042272211, test_acc: 1.0\n",
            "Epoch 442, BestLoss: 0.04762222149520729, Temperature 1.0713372795471238e-06, step_size 0.09914364478720084, test_acc: 1.0\n",
            "Epoch 443, BestLoss: 0.04762160598537903, Temperature 1.0177704155697677e-06, step_size 0.09913373042272211, test_acc: 1.0\n",
            "Epoch 444, BestLoss: 0.04762175685590923, Temperature 9.668818947912793e-07, step_size 0.09912381704967983, test_acc: 1.0\n",
            "Epoch 445, BestLoss: 0.047621629345291745, Temperature 9.185378000517153e-07, step_size 0.09911390466797487, test_acc: 1.0\n",
            "Epoch 446, BestLoss: 0.047621629345291745, Temperature 8.726109100491295e-07, step_size 0.09910399327750807, test_acc: 1.0\n",
            "Epoch 447, BestLoss: 0.04762167480400626, Temperature 9.185378000517153e-07, step_size 0.09913373042272211, test_acc: 1.0\n",
            "Epoch 448, BestLoss: 0.0476271190690979, Temperature 8.726109100491295e-07, step_size 0.09912381704967983, test_acc: 1.0\n",
            "Epoch 449, BestLoss: 0.04762521357381892, Temperature 8.28980364546673e-07, step_size 0.09911390466797487, test_acc: 1.0\n",
            "Epoch 450, BestLoss: 0.04762141368398677, Temperature 7.875313463193393e-07, step_size 0.09910399327750807, test_acc: 1.0\n",
            "Epoch 451, BestLoss: 0.047621716111378394, Temperature 7.481547790033723e-07, step_size 0.09909408287818032, test_acc: 1.0\n",
            "Epoch 452, BestLoss: 0.047621716111378394, Temperature 7.107470400532036e-07, step_size 0.0990841734698925, test_acc: 1.0\n",
            "Epoch 453, BestLoss: 0.04762225415553118, Temperature 7.481547790033722e-07, step_size 0.09912381704967983, test_acc: 1.0\n",
            "Epoch 454, BestLoss: 0.04762156036589967, Temperature 7.107470400532036e-07, step_size 0.09911390466797487, test_acc: 1.0\n",
            "Epoch 455, BestLoss: 0.047622348615863244, Temperature 6.752096880505434e-07, step_size 0.09910399327750807, test_acc: 1.0\n",
            "Epoch 456, BestLoss: 0.0476215983956064, Temperature 6.414492036480162e-07, step_size 0.09909408287818032, test_acc: 1.0\n",
            "Epoch 457, BestLoss: 0.04762258595334716, Temperature 6.093767434656153e-07, step_size 0.0990841734698925, test_acc: 1.0\n",
            "Epoch 458, BestLoss: 0.04762218141776089, Temperature 5.789079062923345e-07, step_size 0.0990742650525455, test_acc: 1.0\n",
            "Epoch 459, BestLoss: 0.047622038371092364, Temperature 5.499625109777178e-07, step_size 0.09906435762604025, test_acc: 1.0\n",
            "Epoch 460, BestLoss: 0.04762234142982941, Temperature 5.224643854288319e-07, step_size 0.09905445119027766, test_acc: 1.0\n",
            "Epoch 461, BestLoss: 0.04762234142982941, Temperature 4.963411661573902e-07, step_size 0.09904454574515863, test_acc: 1.0\n",
            "Epoch 462, BestLoss: 0.047622347370781505, Temperature 5.224643854288319e-07, step_size 0.09911390466797487, test_acc: 1.0\n",
            "Epoch 463, BestLoss: 0.047622347370781505, Temperature 5.499625109777178e-07, step_size 0.09910399327750807, test_acc: 1.0\n",
            "Epoch 464, BestLoss: 0.047622472160920984, Temperature 5.789079062923345e-07, step_size 0.09909408287818032, test_acc: 1.0\n",
            "Epoch 465, BestLoss: 0.047622472160920984, Temperature 5.499625109777178e-07, step_size 0.0990841734698925, test_acc: 1.0\n",
            "Epoch 466, BestLoss: 0.047622472160920984, Temperature 5.789079062923345e-07, step_size 0.0990841734698925, test_acc: 1.0\n",
            "Epoch 467, BestLoss: 0.047622472160920984, Temperature 6.093767434656153e-07, step_size 0.0990742650525455, test_acc: 1.0\n",
            "Epoch 468, BestLoss: 0.047622354233039295, Temperature 6.414492036480162e-07, step_size 0.09906435762604025, test_acc: 1.0\n",
            "Epoch 469, BestLoss: 0.04762267682585981, Temperature 6.093767434656153e-07, step_size 0.09905445119027766, test_acc: 1.0\n",
            "Epoch 470, BestLoss: 0.04762267682585981, Temperature 5.789079062923345e-07, step_size 0.09904454574515863, test_acc: 1.0\n",
            "Epoch 471, BestLoss: 0.047622554718291944, Temperature 6.093767434656153e-07, step_size 0.09905445119027766, test_acc: 1.0\n",
            "Epoch 472, BestLoss: 0.047622554718291944, Temperature 5.789079062923345e-07, step_size 0.09904454574515863, test_acc: 1.0\n",
            "Epoch 473, BestLoss: 0.047622554718291944, Temperature 6.093767434656153e-07, step_size 0.09904454574515863, test_acc: 1.0\n",
            "Epoch 474, BestLoss: 0.047622554718291944, Temperature 6.414492036480162e-07, step_size 0.09903464129058412, test_acc: 1.0\n",
            "Epoch 475, BestLoss: 0.047622554718291944, Temperature 6.752096880505434e-07, step_size 0.09902473782645506, test_acc: 1.0\n",
            "Epoch 476, BestLoss: 0.047622554718291944, Temperature 7.107470400532036e-07, step_size 0.09901483535267241, test_acc: 1.0\n",
            "Epoch 477, BestLoss: 0.047623981918477463, Temperature 7.481547790033722e-07, step_size 0.09900493386913715, test_acc: 1.0\n",
            "Epoch 478, BestLoss: 0.047623060466849304, Temperature 7.107470400532036e-07, step_size 0.09899503337575025, test_acc: 1.0\n",
            "Epoch 479, BestLoss: 0.047623060466849304, Temperature 6.752096880505434e-07, step_size 0.09898513387241267, test_acc: 1.0\n",
            "Epoch 480, BestLoss: 0.04762293564202028, Temperature 7.107470400532036e-07, step_size 0.09899503337575025, test_acc: 1.0\n",
            "Epoch 481, BestLoss: 0.04762293564202028, Temperature 6.752096880505434e-07, step_size 0.09898513387241267, test_acc: 1.0\n",
            "Epoch 482, BestLoss: 0.04762293564202028, Temperature 7.107470400532036e-07, step_size 0.09898513387241267, test_acc: 1.0\n",
            "Epoch 483, BestLoss: 0.04762293564202028, Temperature 7.481547790033722e-07, step_size 0.09897523535902543, test_acc: 1.0\n",
            "Epoch 484, BestLoss: 0.04762293564202028, Temperature 7.875313463193392e-07, step_size 0.09896533783548953, test_acc: 1.0\n",
            "Epoch 485, BestLoss: 0.04762258684264029, Temperature 8.289803645466729e-07, step_size 0.09895544130170597, test_acc: 1.0\n",
            "Epoch 486, BestLoss: 0.04762300372528652, Temperature 7.875313463193392e-07, step_size 0.0989455457575758, test_acc: 1.0\n",
            "Epoch 487, BestLoss: 0.04762300865464143, Temperature 7.481547790033722e-07, step_size 0.09893565120300005, test_acc: 1.0\n",
            "Epoch 488, BestLoss: 0.04762300865464143, Temperature 7.875313463193392e-07, step_size 0.0989455457575758, test_acc: 1.0\n",
            "Epoch 489, BestLoss: 0.04762300865464143, Temperature 8.289803645466729e-07, step_size 0.09893565120300005, test_acc: 1.0\n",
            "Epoch 490, BestLoss: 0.04762300865464143, Temperature 8.726109100491294e-07, step_size 0.09892575763787975, test_acc: 1.0\n",
            "Epoch 491, BestLoss: 0.04762300865464143, Temperature 9.185378000517152e-07, step_size 0.09891586506211597, test_acc: 1.0\n",
            "Epoch 492, BestLoss: 0.0476261761245831, Temperature 9.66881894791279e-07, step_size 0.09890597347560975, test_acc: 1.0\n",
            "Epoch 493, BestLoss: 0.047624626032738246, Temperature 9.18537800051715e-07, step_size 0.0988960828782622, test_acc: 1.0\n",
            "Epoch 494, BestLoss: 0.04762429747645763, Temperature 8.726109100491293e-07, step_size 0.09888619326997437, test_acc: 1.0\n",
            "Epoch 495, BestLoss: 0.047622907845203746, Temperature 8.289803645466728e-07, step_size 0.09887630465064738, test_acc: 1.0\n",
            "Epoch 496, BestLoss: 0.04762327502016012, Temperature 7.875313463193391e-07, step_size 0.09886641702018231, test_acc: 1.0\n",
            "Epoch 497, BestLoss: 0.04762327502016012, Temperature 7.481547790033721e-07, step_size 0.0988565303784803, test_acc: 1.0\n",
            "Epoch 498, BestLoss: 0.04762327502016012, Temperature 7.875313463193391e-07, step_size 0.0988960828782622, test_acc: 1.0\n",
            "Epoch 499, BestLoss: 0.04762327502016012, Temperature 8.289803645466728e-07, step_size 0.09888619326997437, test_acc: 1.0\n",
            "Epoch 500, BestLoss: 0.047623771848552154, Temperature 8.726109100491293e-07, step_size 0.09887630465064738, test_acc: 1.0\n",
            "Epoch 501, BestLoss: 0.04762387351823486, Temperature 8.289803645466728e-07, step_size 0.09886641702018231, test_acc: 1.0\n",
            "Epoch 502, BestLoss: 0.047624969701005625, Temperature 7.875313463193391e-07, step_size 0.0988565303784803, test_acc: 1.0\n",
            "Epoch 503, BestLoss: 0.04762514334505723, Temperature 7.481547790033721e-07, step_size 0.09884664472544245, test_acc: 1.0\n",
            "Epoch 504, BestLoss: 0.04762514334505723, Temperature 7.107470400532035e-07, step_size 0.0988367600609699, test_acc: 1.0\n",
            "Epoch 505, BestLoss: 0.0476252556712967, Temperature 7.481547790033721e-07, step_size 0.09886641702018231, test_acc: 1.0\n",
            "Epoch 506, BestLoss: 0.04762453897506864, Temperature 7.107470400532035e-07, step_size 0.0988565303784803, test_acc: 1.0\n",
            "Epoch 507, BestLoss: 0.047623852824581654, Temperature 6.752096880505433e-07, step_size 0.09884664472544245, test_acc: 1.0\n",
            "Epoch 508, BestLoss: 0.04762465129607556, Temperature 6.414492036480161e-07, step_size 0.0988367600609699, test_acc: 1.0\n",
            "Epoch 509, BestLoss: 0.04762465129607556, Temperature 6.093767434656152e-07, step_size 0.0988268763849638, test_acc: 1.0\n",
            "Epoch 510, BestLoss: 0.04762465129607556, Temperature 6.414492036480161e-07, step_size 0.0988565303784803, test_acc: 1.0\n",
            "Epoch 511, BestLoss: 0.04762446733707657, Temperature 6.752096880505433e-07, step_size 0.09884664472544245, test_acc: 1.0\n",
            "Epoch 512, BestLoss: 0.0476254728951231, Temperature 6.414492036480161e-07, step_size 0.0988367600609699, test_acc: 1.0\n",
            "Epoch 513, BestLoss: 0.047623785650102925, Temperature 6.093767434656152e-07, step_size 0.0988268763849638, test_acc: 1.0\n",
            "Epoch 514, BestLoss: 0.047623785650102925, Temperature 5.789079062923344e-07, step_size 0.09881699369732531, test_acc: 1.0\n",
            "Epoch 515, BestLoss: 0.047625047338443305, Temperature 6.093767434656152e-07, step_size 0.0988367600609699, test_acc: 1.0\n",
            "Epoch 516, BestLoss: 0.047625047338443305, Temperature 5.789079062923344e-07, step_size 0.0988268763849638, test_acc: 1.0\n",
            "Epoch 517, BestLoss: 0.047625047338443305, Temperature 6.093767434656152e-07, step_size 0.0988268763849638, test_acc: 1.0\n",
            "Epoch 518, BestLoss: 0.04762395294935923, Temperature 6.414492036480161e-07, step_size 0.09881699369732531, test_acc: 1.0\n",
            "Epoch 519, BestLoss: 0.04762374002582245, Temperature 6.093767434656152e-07, step_size 0.09880711199795558, test_acc: 1.0\n",
            "Epoch 520, BestLoss: 0.04762374002582245, Temperature 5.789079062923344e-07, step_size 0.09879723128675579, test_acc: 1.0\n",
            "Epoch 521, BestLoss: 0.04762456157302525, Temperature 6.093767434656152e-07, step_size 0.09880711199795558, test_acc: 1.0\n",
            "Epoch 522, BestLoss: 0.047624049600482665, Temperature 5.789079062923344e-07, step_size 0.09879723128675579, test_acc: 1.0\n",
            "Epoch 523, BestLoss: 0.047624049600482665, Temperature 5.499625109777177e-07, step_size 0.09878735156362711, test_acc: 1.0\n",
            "Epoch 524, BestLoss: 0.04762488394401987, Temperature 5.789079062923344e-07, step_size 0.09879723128675579, test_acc: 1.0\n",
            "Epoch 525, BestLoss: 0.047625121518631026, Temperature 5.499625109777177e-07, step_size 0.09878735156362711, test_acc: 1.0\n",
            "Epoch 526, BestLoss: 0.047625121518631026, Temperature 5.224643854288318e-07, step_size 0.09877747282847076, test_acc: 1.0\n",
            "Epoch 527, BestLoss: 0.047625121518631026, Temperature 5.499625109777177e-07, step_size 0.09878735156362711, test_acc: 1.0\n",
            "Epoch 528, BestLoss: 0.047625121518631026, Temperature 5.789079062923344e-07, step_size 0.09877747282847076, test_acc: 1.0\n",
            "Epoch 529, BestLoss: 0.04762655980832085, Temperature 6.093767434656152e-07, step_size 0.0987675950811879, test_acc: 1.0\n",
            "Epoch 530, BestLoss: 0.04762655980832085, Temperature 5.789079062923344e-07, step_size 0.09875771832167979, test_acc: 1.0\n",
            "Epoch 531, BestLoss: 0.04762575773120179, Temperature 6.093767434656152e-07, step_size 0.09875771832167979, test_acc: 1.0\n",
            "Epoch 532, BestLoss: 0.04762590851829329, Temperature 5.789079062923344e-07, step_size 0.09874784254984763, test_acc: 1.0\n",
            "Epoch 533, BestLoss: 0.04762590851829329, Temperature 5.499625109777177e-07, step_size 0.09873796776559264, test_acc: 1.0\n",
            "Epoch 534, BestLoss: 0.04762496605430025, Temperature 5.789079062923344e-07, step_size 0.09874784254984763, test_acc: 1.0\n",
            "Epoch 535, BestLoss: 0.047625820646430235, Temperature 5.499625109777177e-07, step_size 0.09873796776559264, test_acc: 1.0\n",
            "Epoch 536, BestLoss: 0.047625820646430235, Temperature 5.224643854288318e-07, step_size 0.09872809396881609, test_acc: 1.0\n",
            "Epoch 537, BestLoss: 0.04762472489986914, Temperature 5.499625109777177e-07, step_size 0.09873796776559264, test_acc: 1.0\n",
            "Epoch 538, BestLoss: 0.04762410243073355, Temperature 5.224643854288318e-07, step_size 0.09872809396881609, test_acc: 1.0\n",
            "Epoch 539, BestLoss: 0.04762362808557793, Temperature 4.963411661573901e-07, step_size 0.09871822115941921, test_acc: 1.0\n",
            "Epoch 540, BestLoss: 0.04762364055041157, Temperature 4.715241078495206e-07, step_size 0.09870834933730327, test_acc: 1.0\n",
            "Epoch 541, BestLoss: 0.04762364055041157, Temperature 4.963411661573901e-07, step_size 0.09872809396881609, test_acc: 1.0\n",
            "Epoch 542, BestLoss: 0.04762364055041157, Temperature 5.224643854288317e-07, step_size 0.09871822115941921, test_acc: 1.0\n",
            "Epoch 543, BestLoss: 0.047623801845340194, Temperature 5.499625109777176e-07, step_size 0.09870834933730327, test_acc: 1.0\n",
            "Epoch 544, BestLoss: 0.04762341490822094, Temperature 5.224643854288317e-07, step_size 0.09869847850236954, test_acc: 1.0\n",
            "Epoch 545, BestLoss: 0.04762341490822094, Temperature 4.963411661573901e-07, step_size 0.09868860865451931, test_acc: 1.0\n",
            "Epoch 546, BestLoss: 0.04762441176347222, Temperature 5.224643854288317e-07, step_size 0.09869847850236954, test_acc: 1.0\n",
            "Epoch 547, BestLoss: 0.04762441176347222, Temperature 4.963411661573901e-07, step_size 0.09868860865451931, test_acc: 1.0\n",
            "Epoch 548, BestLoss: 0.047623662773005906, Temperature 5.224643854288317e-07, step_size 0.09868860865451931, test_acc: 1.0\n",
            "Epoch 549, BestLoss: 0.047623662773005906, Temperature 4.963411661573901e-07, step_size 0.09867873979365387, test_acc: 1.0\n",
            "Epoch 550, BestLoss: 0.047623662773005906, Temperature 5.224643854288317e-07, step_size 0.09867873979365387, test_acc: 1.0\n",
            "Epoch 551, BestLoss: 0.047623662773005906, Temperature 5.499625109777176e-07, step_size 0.09866887191967451, test_acc: 1.0\n",
            "Epoch 552, BestLoss: 0.047623597046412225, Temperature 5.789079062923343e-07, step_size 0.09865900503248254, test_acc: 1.0\n",
            "Epoch 553, BestLoss: 0.047623691010451184, Temperature 5.499625109777176e-07, step_size 0.09864913913197929, test_acc: 1.0\n",
            "Epoch 554, BestLoss: 0.04762417310127317, Temperature 5.224643854288317e-07, step_size 0.09863927421806609, test_acc: 1.0\n",
            "Epoch 555, BestLoss: 0.04762417310127317, Temperature 4.963411661573901e-07, step_size 0.09862941029064429, test_acc: 1.0\n",
            "Epoch 556, BestLoss: 0.04762425939992393, Temperature 5.224643854288317e-07, step_size 0.09864913913197929, test_acc: 1.0\n",
            "Epoch 557, BestLoss: 0.047624273378763, Temperature 4.963411661573901e-07, step_size 0.09863927421806609, test_acc: 1.0\n",
            "Epoch 558, BestLoss: 0.04762450623727202, Temperature 5.224643854288317e-07, step_size 0.09863927421806609, test_acc: 1.0\n",
            "Epoch 559, BestLoss: 0.04762450623727202, Temperature 4.963411661573901e-07, step_size 0.09862941029064429, test_acc: 1.0\n",
            "Epoch 560, BestLoss: 0.04762450623727202, Temperature 5.224643854288317e-07, step_size 0.09862941029064429, test_acc: 1.0\n",
            "Epoch 561, BestLoss: 0.04762450623727202, Temperature 5.499625109777176e-07, step_size 0.09861954734961523, test_acc: 1.0\n",
            "Epoch 562, BestLoss: 0.047623547233805026, Temperature 5.789079062923343e-07, step_size 0.09860968539488027, test_acc: 1.0\n",
            "Epoch 563, BestLoss: 0.047623547233805026, Temperature 5.499625109777176e-07, step_size 0.09859982442634078, test_acc: 1.0\n",
            "Epoch 564, BestLoss: 0.047624150201609636, Temperature 5.789079062923343e-07, step_size 0.09859982442634078, test_acc: 1.0\n",
            "Epoch 565, BestLoss: 0.047623917551258, Temperature 5.499625109777176e-07, step_size 0.09858996444389816, test_acc: 1.0\n",
            "Epoch 566, BestLoss: 0.04762446236620245, Temperature 5.224643854288317e-07, step_size 0.09858010544745377, test_acc: 1.0\n",
            "Epoch 567, BestLoss: 0.04762446236620245, Temperature 4.963411661573901e-07, step_size 0.09857024743690902, test_acc: 1.0\n",
            "Epoch 568, BestLoss: 0.04762446236620245, Temperature 5.224643854288317e-07, step_size 0.09858996444389816, test_acc: 1.0\n",
            "Epoch 569, BestLoss: 0.04762446236620245, Temperature 5.499625109777176e-07, step_size 0.09858010544745377, test_acc: 1.0\n",
            "Epoch 570, BestLoss: 0.04762430555568782, Temperature 5.789079062923343e-07, step_size 0.09857024743690902, test_acc: 1.0\n",
            "Epoch 571, BestLoss: 0.04762430555568782, Temperature 5.499625109777176e-07, step_size 0.09856039041216533, test_acc: 1.0\n",
            "Epoch 572, BestLoss: 0.047622653089781065, Temperature 5.789079062923343e-07, step_size 0.09856039041216533, test_acc: 1.0\n",
            "Epoch 573, BestLoss: 0.047622653089781065, Temperature 5.499625109777176e-07, step_size 0.09855053437312411, test_acc: 1.0\n",
            "Epoch 574, BestLoss: 0.04762227545217437, Temperature 5.789079062923343e-07, step_size 0.09855053437312411, test_acc: 1.0\n",
            "Epoch 575, BestLoss: 0.047622484479434436, Temperature 5.499625109777176e-07, step_size 0.0985406793196868, test_acc: 1.0\n",
            "Epoch 576, BestLoss: 0.04762316182242752, Temperature 5.224643854288317e-07, step_size 0.09853082525175483, test_acc: 1.0\n",
            "Epoch 577, BestLoss: 0.04762269110853301, Temperature 4.963411661573901e-07, step_size 0.09852097216922966, test_acc: 1.0\n",
            "Epoch 578, BestLoss: 0.04762269110853301, Temperature 4.715241078495206e-07, step_size 0.09851112007201274, test_acc: 1.0\n",
            "Epoch 579, BestLoss: 0.04762269110853301, Temperature 4.963411661573901e-07, step_size 0.0985406793196868, test_acc: 1.0\n",
            "Epoch 580, BestLoss: 0.04762269110853301, Temperature 5.224643854288317e-07, step_size 0.09853082525175483, test_acc: 1.0\n",
            "Epoch 581, BestLoss: 0.047623783388574654, Temperature 5.499625109777176e-07, step_size 0.09852097216922966, test_acc: 1.0\n",
            "Epoch 582, BestLoss: 0.047623783388574654, Temperature 5.224643854288317e-07, step_size 0.09851112007201274, test_acc: 1.0\n",
            "Epoch 583, BestLoss: 0.0476228564602294, Temperature 5.499625109777176e-07, step_size 0.09851112007201274, test_acc: 1.0\n",
            "Epoch 584, BestLoss: 0.04762270791566078, Temperature 5.224643854288317e-07, step_size 0.09850126896000554, test_acc: 1.0\n",
            "Epoch 585, BestLoss: 0.04762270791566078, Temperature 4.963411661573901e-07, step_size 0.09849141883310954, test_acc: 1.0\n",
            "Epoch 586, BestLoss: 0.047624134189410604, Temperature 5.224643854288317e-07, step_size 0.09850126896000554, test_acc: 1.0\n",
            "Epoch 587, BestLoss: 0.047624392473816654, Temperature 4.963411661573901e-07, step_size 0.09849141883310954, test_acc: 1.0\n",
            "Epoch 588, BestLoss: 0.04762277603244975, Temperature 4.715241078495206e-07, step_size 0.09848156969122623, test_acc: 1.0\n",
            "Epoch 589, BestLoss: 0.04762298989932544, Temperature 4.479479024570445e-07, step_size 0.09847172153425711, test_acc: 1.0\n",
            "Epoch 590, BestLoss: 0.04762298989932544, Temperature 4.255505073341923e-07, step_size 0.09846187436210369, test_acc: 1.0\n",
            "Epoch 591, BestLoss: 0.047623094199226834, Temperature 4.479479024570445e-07, step_size 0.09849141883310954, test_acc: 1.0\n",
            "Epoch 592, BestLoss: 0.04762284209341725, Temperature 4.255505073341923e-07, step_size 0.09848156969122623, test_acc: 1.0\n",
            "Epoch 593, BestLoss: 0.04762247445645454, Temperature 4.0427298196748264e-07, step_size 0.09847172153425711, test_acc: 1.0\n",
            "Epoch 594, BestLoss: 0.04762247445645454, Temperature 3.840593328691085e-07, step_size 0.09846187436210369, test_acc: 1.0\n",
            "Epoch 595, BestLoss: 0.04762288397818546, Temperature 4.0427298196748264e-07, step_size 0.09848156969122623, test_acc: 1.0\n",
            "Epoch 596, BestLoss: 0.04762288397818546, Temperature 3.840593328691085e-07, step_size 0.09847172153425711, test_acc: 1.0\n",
            "Epoch 597, BestLoss: 0.04762288397818546, Temperature 4.0427298196748264e-07, step_size 0.09847172153425711, test_acc: 1.0\n",
            "Epoch 598, BestLoss: 0.04762293811330108, Temperature 4.255505073341923e-07, step_size 0.09846187436210369, test_acc: 1.0\n",
            "Epoch 599, BestLoss: 0.04762400006528574, Temperature 4.0427298196748264e-07, step_size 0.09845202817466747, test_acc: 1.0\n",
            "Epoch 600, BestLoss: 0.04762167096286487, Temperature 3.840593328691085e-07, step_size 0.09844218297185, test_acc: 1.0\n",
            "Epoch 601, BestLoss: 0.04762167096286487, Temperature 3.6485636622565307e-07, step_size 0.09843233875355283, test_acc: 1.0\n",
            "Epoch 602, BestLoss: 0.04762167096286487, Temperature 3.840593328691085e-07, step_size 0.09845202817466747, test_acc: 1.0\n",
            "Epoch 603, BestLoss: 0.04762167096286487, Temperature 4.0427298196748264e-07, step_size 0.09844218297185, test_acc: 1.0\n",
            "Epoch 604, BestLoss: 0.04762167096286487, Temperature 4.255505073341923e-07, step_size 0.09843233875355283, test_acc: 1.0\n",
            "Epoch 605, BestLoss: 0.04762167096286487, Temperature 4.479479024570445e-07, step_size 0.09842249551967747, test_acc: 1.0\n",
            "Epoch 606, BestLoss: 0.047622302347006054, Temperature 4.715241078495206e-07, step_size 0.0984126532701255, test_acc: 1.0\n",
            "Epoch 607, BestLoss: 0.047622302347006054, Temperature 4.479479024570445e-07, step_size 0.09840281200479849, test_acc: 1.0\n",
            "Epoch 608, BestLoss: 0.04762231423392278, Temperature 4.715241078495206e-07, step_size 0.09840281200479849, test_acc: 1.0\n",
            "Epoch 609, BestLoss: 0.04762231423392278, Temperature 4.963411661573901e-07, step_size 0.09839297172359801, test_acc: 1.0\n",
            "Epoch 610, BestLoss: 0.04762231423392278, Temperature 5.224643854288317e-07, step_size 0.09838313242642566, test_acc: 1.0\n",
            "Epoch 611, BestLoss: 0.047622565064653136, Temperature 5.499625109777176e-07, step_size 0.09837329411318302, test_acc: 1.0\n",
            "Epoch 612, BestLoss: 0.047622303983928735, Temperature 5.224643854288317e-07, step_size 0.0983634567837717, test_acc: 1.0\n",
            "Epoch 613, BestLoss: 0.047622303983928735, Temperature 4.963411661573901e-07, step_size 0.09835362043809333, test_acc: 1.0\n",
            "Epoch 614, BestLoss: 0.047622303983928735, Temperature 5.224643854288317e-07, step_size 0.0983634567837717, test_acc: 1.0\n",
            "Epoch 615, BestLoss: 0.047622875601446985, Temperature 5.499625109777176e-07, step_size 0.09835362043809333, test_acc: 1.0\n",
            "Epoch 616, BestLoss: 0.047622875601446985, Temperature 5.224643854288317e-07, step_size 0.09834378507604952, test_acc: 1.0\n",
            "Epoch 617, BestLoss: 0.047622875601446985, Temperature 5.499625109777176e-07, step_size 0.09834378507604952, test_acc: 1.0\n",
            "Epoch 618, BestLoss: 0.04762365649623331, Temperature 5.789079062923343e-07, step_size 0.09833395069754192, test_acc: 1.0\n",
            "Epoch 619, BestLoss: 0.04762365649623331, Temperature 5.499625109777176e-07, step_size 0.09832411730247216, test_acc: 1.0\n",
            "Epoch 620, BestLoss: 0.04762330969209037, Temperature 5.789079062923343e-07, step_size 0.09832411730247216, test_acc: 1.0\n",
            "Epoch 621, BestLoss: 0.04762330969209037, Temperature 5.499625109777176e-07, step_size 0.09831428489074191, test_acc: 1.0\n",
            "Epoch 622, BestLoss: 0.04762330969209037, Temperature 5.789079062923343e-07, step_size 0.09831428489074191, test_acc: 1.0\n",
            "Epoch 623, BestLoss: 0.04762356143078608, Temperature 6.093767434656151e-07, step_size 0.09830445346225283, test_acc: 1.0\n",
            "Epoch 624, BestLoss: 0.04762356143078608, Temperature 5.789079062923343e-07, step_size 0.09829462301690661, test_acc: 1.0\n",
            "Epoch 625, BestLoss: 0.04762356143078608, Temperature 6.093767434656151e-07, step_size 0.09829462301690661, test_acc: 1.0\n",
            "Epoch 626, BestLoss: 0.04762356143078608, Temperature 6.41449203648016e-07, step_size 0.09828479355460493, test_acc: 1.0\n",
            "Epoch 627, BestLoss: 0.04762356143078608, Temperature 6.752096880505432e-07, step_size 0.09827496507524947, test_acc: 1.0\n",
            "Epoch 628, BestLoss: 0.04762288847034474, Temperature 7.107470400532034e-07, step_size 0.09826513757874195, test_acc: 1.0\n",
            "Epoch 629, BestLoss: 0.04762288847034474, Temperature 6.752096880505432e-07, step_size 0.09825531106498407, test_acc: 1.0\n",
            "Epoch 630, BestLoss: 0.04762288847034474, Temperature 7.107470400532034e-07, step_size 0.09825531106498407, test_acc: 1.0\n",
            "Epoch 631, BestLoss: 0.04762291785360544, Temperature 7.48154779003372e-07, step_size 0.09824548553387757, test_acc: 1.0\n",
            "Epoch 632, BestLoss: 0.04762291785360544, Temperature 7.87531346319339e-07, step_size 0.09823566098532419, test_acc: 1.0\n",
            "Epoch 633, BestLoss: 0.04762291785360544, Temperature 8.289803645466727e-07, step_size 0.09822583741922565, test_acc: 1.0\n",
            "Epoch 634, BestLoss: 0.04762291785360544, Temperature 8.726109100491292e-07, step_size 0.09821601483548373, test_acc: 1.0\n",
            "Epoch 635, BestLoss: 0.04762320494841578, Temperature 9.185378000517149e-07, step_size 0.09820619323400018, test_acc: 1.0\n",
            "Epoch 636, BestLoss: 0.04762320494841578, Temperature 8.726109100491292e-07, step_size 0.09819637261467677, test_acc: 1.0\n",
            "Epoch 637, BestLoss: 0.047622469387287966, Temperature 9.185378000517149e-07, step_size 0.09819637261467677, test_acc: 1.0\n",
            "Epoch 638, BestLoss: 0.047623155379324884, Temperature 8.726109100491292e-07, step_size 0.09818655297741531, test_acc: 1.0\n",
            "Epoch 639, BestLoss: 0.047623304613424025, Temperature 8.289803645466727e-07, step_size 0.09817673432211757, test_acc: 1.0\n",
            "Epoch 640, BestLoss: 0.047623304613424025, Temperature 7.87531346319339e-07, step_size 0.09816691664868536, test_acc: 1.0\n",
            "Epoch 641, BestLoss: 0.047622709752915326, Temperature 8.289803645466727e-07, step_size 0.09818655297741531, test_acc: 1.0\n",
            "Epoch 642, BestLoss: 0.047622709752915326, Temperature 7.87531346319339e-07, step_size 0.09817673432211757, test_acc: 1.0\n",
            "Epoch 643, BestLoss: 0.047622709752915326, Temperature 8.289803645466727e-07, step_size 0.09817673432211757, test_acc: 1.0\n",
            "Epoch 644, BestLoss: 0.047622469173796055, Temperature 8.726109100491292e-07, step_size 0.09816691664868536, test_acc: 1.0\n",
            "Epoch 645, BestLoss: 0.047622469173796055, Temperature 8.289803645466727e-07, step_size 0.09815709995702049, test_acc: 1.0\n",
            "Epoch 646, BestLoss: 0.047622651340845173, Temperature 8.726109100491292e-07, step_size 0.09815709995702049, test_acc: 1.0\n",
            "Epoch 647, BestLoss: 0.04762344327999208, Temperature 8.289803645466727e-07, step_size 0.09814728424702479, test_acc: 1.0\n",
            "Epoch 648, BestLoss: 0.047621724383530885, Temperature 7.87531346319339e-07, step_size 0.09813746951860008, test_acc: 1.0\n",
            "Epoch 649, BestLoss: 0.04762201432223062, Temperature 7.48154779003372e-07, step_size 0.09812765577164823, test_acc: 1.0\n",
            "Epoch 650, BestLoss: 0.04762201432223062, Temperature 7.107470400532034e-07, step_size 0.09811784300607106, test_acc: 1.0\n",
            "Epoch 651, BestLoss: 0.04762184853033267, Temperature 7.48154779003372e-07, step_size 0.09814728424702479, test_acc: 1.0\n",
            "Epoch 652, BestLoss: 0.047623114738760276, Temperature 7.107470400532034e-07, step_size 0.09813746951860008, test_acc: 1.0\n",
            "Epoch 653, BestLoss: 0.04762143228375486, Temperature 6.752096880505432e-07, step_size 0.09812765577164823, test_acc: 1.0\n",
            "Epoch 654, BestLoss: 0.047621796271638914, Temperature 6.41449203648016e-07, step_size 0.09811784300607106, test_acc: 1.0\n",
            "Epoch 655, BestLoss: 0.04762212492556415, Temperature 6.093767434656151e-07, step_size 0.09810803122177045, test_acc: 1.0\n",
            "Epoch 656, BestLoss: 0.04762204552817054, Temperature 5.789079062923343e-07, step_size 0.09809822041864827, test_acc: 1.0\n",
            "Epoch 657, BestLoss: 0.047621208441399845, Temperature 5.499625109777176e-07, step_size 0.0980884105966064, test_acc: 1.0\n",
            "Epoch 658, BestLoss: 0.047621208441399845, Temperature 5.224643854288317e-07, step_size 0.09807860175554674, test_acc: 1.0\n",
            "Epoch 659, BestLoss: 0.04762149339353329, Temperature 5.499625109777176e-07, step_size 0.09813746951860008, test_acc: 1.0\n",
            "Epoch 660, BestLoss: 0.04762149339353329, Temperature 5.224643854288317e-07, step_size 0.09812765577164823, test_acc: 1.0\n",
            "Epoch 661, BestLoss: 0.04762091444109796, Temperature 5.499625109777176e-07, step_size 0.09812765577164823, test_acc: 1.0\n",
            "Epoch 662, BestLoss: 0.047621036522491646, Temperature 5.224643854288317e-07, step_size 0.09811784300607106, test_acc: 1.0\n",
            "Epoch 663, BestLoss: 0.047621036522491646, Temperature 4.963411661573901e-07, step_size 0.09810803122177045, test_acc: 1.0\n",
            "Epoch 664, BestLoss: 0.047621036522491646, Temperature 5.224643854288317e-07, step_size 0.09811784300607106, test_acc: 1.0\n",
            "Epoch 665, BestLoss: 0.047621036522491646, Temperature 5.499625109777176e-07, step_size 0.09810803122177045, test_acc: 1.0\n",
            "Epoch 666, BestLoss: 0.047620832225218165, Temperature 5.789079062923343e-07, step_size 0.09809822041864827, test_acc: 1.0\n",
            "Epoch 667, BestLoss: 0.047620832225218165, Temperature 5.499625109777176e-07, step_size 0.0980884105966064, test_acc: 1.0\n",
            "Epoch 668, BestLoss: 0.047620832225218165, Temperature 5.789079062923343e-07, step_size 0.0980884105966064, test_acc: 1.0\n",
            "Epoch 669, BestLoss: 0.047620904186778376, Temperature 6.093767434656151e-07, step_size 0.09807860175554674, test_acc: 1.0\n",
            "Epoch 670, BestLoss: 0.047620904186778376, Temperature 5.789079062923343e-07, step_size 0.09806879389537118, test_acc: 1.0\n",
            "Epoch 671, BestLoss: 0.04762113747064776, Temperature 6.093767434656151e-07, step_size 0.09806879389537118, test_acc: 1.0\n",
            "Epoch 672, BestLoss: 0.04762123371558251, Temperature 5.789079062923343e-07, step_size 0.09805898701598165, test_acc: 1.0\n",
            "Epoch 673, BestLoss: 0.04762123371558251, Temperature 5.499625109777176e-07, step_size 0.09804918111728005, test_acc: 1.0\n",
            "Epoch 674, BestLoss: 0.04762111420668144, Temperature 5.789079062923343e-07, step_size 0.09805898701598165, test_acc: 1.0\n",
            "Epoch 675, BestLoss: 0.0476208743102266, Temperature 5.499625109777176e-07, step_size 0.09804918111728005, test_acc: 1.0\n",
            "Epoch 676, BestLoss: 0.04762118732250383, Temperature 5.224643854288317e-07, step_size 0.09803937619916832, test_acc: 1.0\n",
            "Epoch 677, BestLoss: 0.04762086538690488, Temperature 4.963411661573901e-07, step_size 0.0980295722615484, test_acc: 1.0\n",
            "Epoch 678, BestLoss: 0.047621455210891526, Temperature 4.715241078495206e-07, step_size 0.09801976930432225, test_acc: 1.0\n",
            "Epoch 679, BestLoss: 0.047621031530032755, Temperature 4.479479024570445e-07, step_size 0.09800996732739183, test_acc: 1.0\n",
            "Epoch 680, BestLoss: 0.047620832038581806, Temperature 4.255505073341923e-07, step_size 0.09800016633065908, test_acc: 1.0\n",
            "Epoch 681, BestLoss: 0.047620832038581806, Temperature 4.0427298196748264e-07, step_size 0.09799036631402602, test_acc: 1.0\n",
            "Epoch 682, BestLoss: 0.047620733915269484, Temperature 4.255505073341923e-07, step_size 0.09804918111728005, test_acc: 1.0\n",
            "Epoch 683, BestLoss: 0.047620733915269484, Temperature 4.0427298196748264e-07, step_size 0.09803937619916832, test_acc: 1.0\n",
            "Epoch 684, BestLoss: 0.047620733915269484, Temperature 4.255505073341923e-07, step_size 0.09803937619916832, test_acc: 1.0\n",
            "Epoch 685, BestLoss: 0.047620733915269484, Temperature 4.479479024570445e-07, step_size 0.0980295722615484, test_acc: 1.0\n",
            "Epoch 686, BestLoss: 0.047620733915269484, Temperature 4.715241078495206e-07, step_size 0.09801976930432225, test_acc: 1.0\n",
            "Epoch 687, BestLoss: 0.047620733915269484, Temperature 4.963411661573901e-07, step_size 0.09800996732739183, test_acc: 1.0\n",
            "Epoch 688, BestLoss: 0.047620733915269484, Temperature 5.224643854288317e-07, step_size 0.09800016633065908, test_acc: 1.0\n",
            "Epoch 689, BestLoss: 0.047620733915269484, Temperature 5.499625109777176e-07, step_size 0.09799036631402602, test_acc: 1.0\n",
            "Epoch 690, BestLoss: 0.047620733915269484, Temperature 5.789079062923343e-07, step_size 0.09798056727739463, test_acc: 1.0\n",
            "Epoch 691, BestLoss: 0.04762140625129189, Temperature 6.093767434656151e-07, step_size 0.09797076922066689, test_acc: 1.0\n",
            "Epoch 692, BestLoss: 0.047620513532417676, Temperature 5.789079062923343e-07, step_size 0.09796097214374481, test_acc: 1.0\n",
            "Epoch 693, BestLoss: 0.047620753329122856, Temperature 5.499625109777176e-07, step_size 0.09795117604653045, test_acc: 1.0\n",
            "Epoch 694, BestLoss: 0.047620753329122856, Temperature 5.224643854288317e-07, step_size 0.09794138092892579, test_acc: 1.0\n",
            "Epoch 695, BestLoss: 0.047620431530170676, Temperature 5.499625109777176e-07, step_size 0.09796097214374481, test_acc: 1.0\n",
            "Epoch 696, BestLoss: 0.04762095154289731, Temperature 5.224643854288317e-07, step_size 0.09795117604653045, test_acc: 1.0\n",
            "Epoch 697, BestLoss: 0.04762095154289731, Temperature 4.963411661573901e-07, step_size 0.09794138092892579, test_acc: 1.0\n",
            "Epoch 698, BestLoss: 0.04762095154289731, Temperature 5.224643854288317e-07, step_size 0.09795117604653045, test_acc: 1.0\n",
            "Epoch 699, BestLoss: 0.04762095154289731, Temperature 5.499625109777176e-07, step_size 0.09794138092892579, test_acc: 1.0\n",
            "Epoch 700, BestLoss: 0.0476202470906524, Temperature 5.789079062923343e-07, step_size 0.0979315867908329, test_acc: 1.0\n",
            "Epoch 701, BestLoss: 0.04762012021398937, Temperature 5.499625109777176e-07, step_size 0.09792179363215382, test_acc: 1.0\n",
            "Epoch 702, BestLoss: 0.04762012021398937, Temperature 5.224643854288317e-07, step_size 0.09791200145279061, test_acc: 1.0\n",
            "Epoch 703, BestLoss: 0.04762039931009213, Temperature 5.499625109777176e-07, step_size 0.09792179363215382, test_acc: 1.0\n",
            "Epoch 704, BestLoss: 0.047620199517733594, Temperature 5.224643854288317e-07, step_size 0.09791200145279061, test_acc: 1.0\n",
            "Epoch 705, BestLoss: 0.04762045380073274, Temperature 4.963411661573901e-07, step_size 0.09790221025264532, test_acc: 1.0\n",
            "Epoch 706, BestLoss: 0.04762045380073274, Temperature 4.715241078495206e-07, step_size 0.09789242003162006, test_acc: 1.0\n",
            "Epoch 707, BestLoss: 0.04762045380073274, Temperature 4.963411661573901e-07, step_size 0.09791200145279061, test_acc: 1.0\n",
            "Epoch 708, BestLoss: 0.04762045380073274, Temperature 5.224643854288317e-07, step_size 0.09790221025264532, test_acc: 1.0\n",
            "Epoch 709, BestLoss: 0.04762022764276057, Temperature 5.499625109777176e-07, step_size 0.09789242003162006, test_acc: 1.0\n",
            "Epoch 710, BestLoss: 0.04762038002448072, Temperature 5.224643854288317e-07, step_size 0.0978826307896169, test_acc: 1.0\n",
            "Epoch 711, BestLoss: 0.04762038002448072, Temperature 4.963411661573901e-07, step_size 0.09787284252653794, test_acc: 1.0\n",
            "Epoch 712, BestLoss: 0.047620613427717756, Temperature 5.224643854288317e-07, step_size 0.0978826307896169, test_acc: 1.0\n",
            "Epoch 713, BestLoss: 0.04762091875323594, Temperature 4.963411661573901e-07, step_size 0.09787284252653794, test_acc: 1.0\n",
            "Epoch 714, BestLoss: 0.04762091875323594, Temperature 4.715241078495206e-07, step_size 0.0978630552422853, test_acc: 1.0\n",
            "Epoch 715, BestLoss: 0.04762091875323594, Temperature 4.963411661573901e-07, step_size 0.09787284252653794, test_acc: 1.0\n",
            "Epoch 716, BestLoss: 0.04762100710011603, Temperature 5.224643854288317e-07, step_size 0.0978630552422853, test_acc: 1.0\n",
            "Epoch 717, BestLoss: 0.047620637812939716, Temperature 4.963411661573901e-07, step_size 0.09785326893676106, test_acc: 1.0\n",
            "Epoch 718, BestLoss: 0.047620932371747804, Temperature 4.715241078495206e-07, step_size 0.09784348360986739, test_acc: 1.0\n",
            "Epoch 719, BestLoss: 0.047620932371747804, Temperature 4.479479024570445e-07, step_size 0.0978336992615064, test_acc: 1.0\n",
            "Epoch 720, BestLoss: 0.04762210074950006, Temperature 4.715241078495206e-07, step_size 0.09785326893676106, test_acc: 1.0\n",
            "Epoch 721, BestLoss: 0.047621852053108406, Temperature 4.479479024570445e-07, step_size 0.09784348360986739, test_acc: 1.0\n",
            "Epoch 722, BestLoss: 0.047621852053108406, Temperature 4.255505073341923e-07, step_size 0.0978336992615064, test_acc: 1.0\n",
            "Epoch 723, BestLoss: 0.04762120311518179, Temperature 4.479479024570445e-07, step_size 0.09784348360986739, test_acc: 1.0\n",
            "Epoch 724, BestLoss: 0.047620669225614344, Temperature 4.255505073341923e-07, step_size 0.0978336992615064, test_acc: 1.0\n",
            "Epoch 725, BestLoss: 0.047620669225614344, Temperature 4.0427298196748264e-07, step_size 0.09782391589158025, test_acc: 1.0\n",
            "Epoch 726, BestLoss: 0.04762070811993836, Temperature 4.255505073341923e-07, step_size 0.0978336992615064, test_acc: 1.0\n",
            "Epoch 727, BestLoss: 0.04762070811993836, Temperature 4.0427298196748264e-07, step_size 0.09782391589158025, test_acc: 1.0\n",
            "Epoch 728, BestLoss: 0.04762002739409708, Temperature 4.255505073341923e-07, step_size 0.09782391589158025, test_acc: 1.0\n",
            "Epoch 729, BestLoss: 0.04762002739409708, Temperature 4.0427298196748264e-07, step_size 0.09781413349999109, test_acc: 1.0\n",
            "Epoch 730, BestLoss: 0.04762002739409708, Temperature 4.255505073341923e-07, step_size 0.09781413349999109, test_acc: 1.0\n",
            "Epoch 731, BestLoss: 0.04762002739409708, Temperature 4.479479024570445e-07, step_size 0.0978043520866411, test_acc: 1.0\n",
            "Epoch 732, BestLoss: 0.04762117024511661, Temperature 4.715241078495206e-07, step_size 0.09779457165143243, test_acc: 1.0\n",
            "Epoch 733, BestLoss: 0.04762117024511661, Temperature 4.479479024570445e-07, step_size 0.09778479219426729, test_acc: 1.0\n",
            "Epoch 734, BestLoss: 0.04762117024511661, Temperature 4.715241078495206e-07, step_size 0.09778479219426729, test_acc: 1.0\n",
            "Epoch 735, BestLoss: 0.04762117024511661, Temperature 4.963411661573901e-07, step_size 0.09777501371504786, test_acc: 1.0\n",
            "Epoch 736, BestLoss: 0.04762117024511661, Temperature 5.224643854288317e-07, step_size 0.09776523621367636, test_acc: 1.0\n",
            "Epoch 737, BestLoss: 0.0476202712328212, Temperature 5.499625109777176e-07, step_size 0.09775545969005499, test_acc: 1.0\n",
            "Epoch 738, BestLoss: 0.04761990440173809, Temperature 5.224643854288317e-07, step_size 0.09774568414408598, test_acc: 1.0\n",
            "Epoch 739, BestLoss: 0.04761990440173809, Temperature 4.963411661573901e-07, step_size 0.09773590957567158, test_acc: 1.0\n",
            "Epoch 740, BestLoss: 0.04761983960418128, Temperature 5.224643854288317e-07, step_size 0.09774568414408598, test_acc: 1.0\n",
            "Epoch 741, BestLoss: 0.04761983960418128, Temperature 4.963411661573901e-07, step_size 0.09773590957567158, test_acc: 1.0\n",
            "Epoch 742, BestLoss: 0.04761991226615054, Temperature 5.224643854288317e-07, step_size 0.09773590957567158, test_acc: 1.0\n",
            "Epoch 743, BestLoss: 0.04761998846884453, Temperature 4.963411661573901e-07, step_size 0.09772613598471401, test_acc: 1.0\n",
            "Epoch 744, BestLoss: 0.04761998846884453, Temperature 4.715241078495206e-07, step_size 0.09771636337111554, test_acc: 1.0\n",
            "Epoch 745, BestLoss: 0.04761998846884453, Temperature 4.963411661573901e-07, step_size 0.09772613598471401, test_acc: 1.0\n",
            "Epoch 746, BestLoss: 0.04761998846884453, Temperature 5.224643854288317e-07, step_size 0.09771636337111554, test_acc: 1.0\n",
            "Epoch 747, BestLoss: 0.04761995988580848, Temperature 5.499625109777176e-07, step_size 0.09770659173477843, test_acc: 1.0\n",
            "Epoch 748, BestLoss: 0.04761995988580848, Temperature 5.224643854288317e-07, step_size 0.09769682107560496, test_acc: 1.0\n",
            "Epoch 749, BestLoss: 0.04761995988580848, Temperature 5.499625109777176e-07, step_size 0.09769682107560496, test_acc: 1.0\n",
            "Epoch 750, BestLoss: 0.04762040063405012, Temperature 5.789079062923343e-07, step_size 0.0976870513934974, test_acc: 1.0\n",
            "Epoch 751, BestLoss: 0.04762040063405012, Temperature 5.499625109777176e-07, step_size 0.09767728268835806, test_acc: 1.0\n",
            "Epoch 752, BestLoss: 0.04762358013414625, Temperature 5.789079062923343e-07, step_size 0.09767728268835806, test_acc: 1.0\n",
            "Epoch 753, BestLoss: 0.047621538740868004, Temperature 5.499625109777176e-07, step_size 0.09766751496008923, test_acc: 1.0\n",
            "Epoch 754, BestLoss: 0.04762014633968818, Temperature 5.224643854288317e-07, step_size 0.09765774820859321, test_acc: 1.0\n",
            "Epoch 755, BestLoss: 0.04762014633968818, Temperature 4.963411661573901e-07, step_size 0.09764798243377236, test_acc: 1.0\n",
            "Epoch 756, BestLoss: 0.047620414896067054, Temperature 5.224643854288317e-07, step_size 0.09766751496008923, test_acc: 1.0\n",
            "Epoch 757, BestLoss: 0.047620414896067054, Temperature 4.963411661573901e-07, step_size 0.09765774820859321, test_acc: 1.0\n",
            "Epoch 758, BestLoss: 0.04762058657170017, Temperature 5.224643854288317e-07, step_size 0.09765774820859321, test_acc: 1.0\n",
            "Epoch 759, BestLoss: 0.04762058657170017, Temperature 4.963411661573901e-07, step_size 0.09764798243377236, test_acc: 1.0\n",
            "Epoch 760, BestLoss: 0.04762043092774643, Temperature 5.224643854288317e-07, step_size 0.09764798243377236, test_acc: 1.0\n",
            "Epoch 761, BestLoss: 0.047620876719557705, Temperature 4.963411661573901e-07, step_size 0.09763821763552899, test_acc: 1.0\n",
            "Epoch 762, BestLoss: 0.047620876719557705, Temperature 4.715241078495206e-07, step_size 0.09762845381376543, test_acc: 1.0\n",
            "Epoch 763, BestLoss: 0.04762059360693141, Temperature 4.963411661573901e-07, step_size 0.09763821763552899, test_acc: 1.0\n",
            "Epoch 764, BestLoss: 0.04762064020610243, Temperature 4.715241078495206e-07, step_size 0.09762845381376543, test_acc: 1.0\n",
            "Epoch 765, BestLoss: 0.04762042181862989, Temperature 4.479479024570445e-07, step_size 0.09761869096838406, test_acc: 1.0\n",
            "Epoch 766, BestLoss: 0.04762042181862989, Temperature 4.255505073341923e-07, step_size 0.09760892909928723, test_acc: 1.0\n",
            "Epoch 767, BestLoss: 0.04762042181862989, Temperature 4.479479024570445e-07, step_size 0.09762845381376543, test_acc: 1.0\n",
            "Epoch 768, BestLoss: 0.04762042181862989, Temperature 4.715241078495206e-07, step_size 0.09761869096838406, test_acc: 1.0\n",
            "Epoch 769, BestLoss: 0.04762042181862989, Temperature 4.963411661573901e-07, step_size 0.09760892909928723, test_acc: 1.0\n",
            "Epoch 770, BestLoss: 0.04762042181862989, Temperature 5.224643854288317e-07, step_size 0.0975991682063773, test_acc: 1.0\n",
            "Epoch 771, BestLoss: 0.04762042181862989, Temperature 5.499625109777176e-07, step_size 0.09758940828955667, test_acc: 1.0\n",
            "Epoch 772, BestLoss: 0.04762048151201477, Temperature 5.789079062923343e-07, step_size 0.09757964934872772, test_acc: 1.0\n",
            "Epoch 773, BestLoss: 0.04762048151201477, Temperature 5.499625109777176e-07, step_size 0.09756989138379285, test_acc: 1.0\n",
            "Epoch 774, BestLoss: 0.04762028773993728, Temperature 5.789079062923343e-07, step_size 0.09756989138379285, test_acc: 1.0\n",
            "Epoch 775, BestLoss: 0.04762028773993728, Temperature 5.499625109777176e-07, step_size 0.09756013439465447, test_acc: 1.0\n",
            "Epoch 776, BestLoss: 0.04762028773993728, Temperature 5.789079062923343e-07, step_size 0.09756013439465447, test_acc: 1.0\n",
            "Epoch 777, BestLoss: 0.04762028773993728, Temperature 6.093767434656151e-07, step_size 0.09755037838121501, test_acc: 1.0\n",
            "Epoch 778, BestLoss: 0.04762028773993728, Temperature 6.41449203648016e-07, step_size 0.09754062334337689, test_acc: 1.0\n",
            "Epoch 779, BestLoss: 0.04762028773993728, Temperature 6.752096880505432e-07, step_size 0.09753086928104256, test_acc: 1.0\n",
            "Epoch 780, BestLoss: 0.04762028773993728, Temperature 7.107470400532034e-07, step_size 0.09752111619411445, test_acc: 1.0\n",
            "Epoch 781, BestLoss: 0.04762085729043403, Temperature 7.48154779003372e-07, step_size 0.09751136408249504, test_acc: 1.0\n",
            "Epoch 782, BestLoss: 0.04762052331194873, Temperature 7.107470400532034e-07, step_size 0.0975016129460868, test_acc: 1.0\n",
            "Epoch 783, BestLoss: 0.047620804393255015, Temperature 6.752096880505432e-07, step_size 0.09749186278479219, test_acc: 1.0\n",
            "Epoch 784, BestLoss: 0.04762107016494035, Temperature 6.41449203648016e-07, step_size 0.0974821135985137, test_acc: 1.0\n",
            "Epoch 785, BestLoss: 0.04762055708676706, Temperature 6.093767434656151e-07, step_size 0.09747236538715386, test_acc: 1.0\n",
            "Epoch 786, BestLoss: 0.04762055708676706, Temperature 5.789079062923343e-07, step_size 0.09746261815061515, test_acc: 1.0\n",
            "Epoch 787, BestLoss: 0.04762055708676706, Temperature 6.093767434656151e-07, step_size 0.0975016129460868, test_acc: 1.0\n",
            "Epoch 788, BestLoss: 0.04762055708676706, Temperature 6.41449203648016e-07, step_size 0.09749186278479219, test_acc: 1.0\n",
            "Epoch 789, BestLoss: 0.04762055708676706, Temperature 6.752096880505432e-07, step_size 0.0974821135985137, test_acc: 1.0\n",
            "Epoch 790, BestLoss: 0.04762055708676706, Temperature 7.107470400532034e-07, step_size 0.09747236538715386, test_acc: 1.0\n",
            "Epoch 791, BestLoss: 0.04762053922726796, Temperature 7.48154779003372e-07, step_size 0.09746261815061515, test_acc: 1.0\n",
            "Epoch 792, BestLoss: 0.04762090174028131, Temperature 7.87531346319339e-07, step_size 0.09745287188880009, test_acc: 1.0\n",
            "Epoch 793, BestLoss: 0.04762090174028131, Temperature 7.48154779003372e-07, step_size 0.09744312660161121, test_acc: 1.0\n",
            "Epoch 794, BestLoss: 0.04762097471523998, Temperature 7.87531346319339e-07, step_size 0.09744312660161121, test_acc: 1.0\n",
            "Epoch 795, BestLoss: 0.04762100407248667, Temperature 7.48154779003372e-07, step_size 0.09743338228895106, test_acc: 1.0\n",
            "Epoch 796, BestLoss: 0.04762100407248667, Temperature 7.87531346319339e-07, step_size 0.09743338228895106, test_acc: 1.0\n",
            "Epoch 797, BestLoss: 0.047622062479178134, Temperature 8.289803645466727e-07, step_size 0.09742363895072216, test_acc: 1.0\n",
            "Epoch 798, BestLoss: 0.04762111407505006, Temperature 7.87531346319339e-07, step_size 0.09741389658682709, test_acc: 1.0\n",
            "Epoch 799, BestLoss: 0.04762111407505006, Temperature 7.48154779003372e-07, step_size 0.0974041551971684, test_acc: 1.0\n",
            "Epoch 800, BestLoss: 0.04762078975019105, Temperature 7.87531346319339e-07, step_size 0.09741389658682709, test_acc: 1.0\n",
            "Epoch 801, BestLoss: 0.04762079153296653, Temperature 7.48154779003372e-07, step_size 0.0974041551971684, test_acc: 1.0\n",
            "Epoch 802, BestLoss: 0.047620994885818016, Temperature 7.87531346319339e-07, step_size 0.0974041551971684, test_acc: 1.0\n",
            "Epoch 803, BestLoss: 0.047621470573510134, Temperature 7.48154779003372e-07, step_size 0.09739441478164869, test_acc: 1.0\n",
            "Epoch 804, BestLoss: 0.047621470573510134, Temperature 7.107470400532034e-07, step_size 0.09738467534017052, test_acc: 1.0\n",
            "Epoch 805, BestLoss: 0.047621470573510134, Temperature 7.48154779003372e-07, step_size 0.09739441478164869, test_acc: 1.0\n",
            "Epoch 806, BestLoss: 0.047621060387963494, Temperature 7.87531346319339e-07, step_size 0.09738467534017052, test_acc: 1.0\n",
            "Epoch 807, BestLoss: 0.047621060387963494, Temperature 7.48154779003372e-07, step_size 0.0973749368726365, test_acc: 1.0\n",
            "Epoch 808, BestLoss: 0.04762385528603559, Temperature 7.87531346319339e-07, step_size 0.0973749368726365, test_acc: 1.0\n",
            "Epoch 809, BestLoss: 0.047620893892150774, Temperature 7.48154779003372e-07, step_size 0.09736519937894923, test_acc: 1.0\n",
            "Epoch 810, BestLoss: 0.047620893892150774, Temperature 7.107470400532034e-07, step_size 0.09735546285901134, test_acc: 1.0\n",
            "Epoch 811, BestLoss: 0.04762083959646346, Temperature 7.48154779003372e-07, step_size 0.09736519937894923, test_acc: 1.0\n",
            "Epoch 812, BestLoss: 0.04762068811567671, Temperature 7.107470400532034e-07, step_size 0.09735546285901134, test_acc: 1.0\n",
            "Epoch 813, BestLoss: 0.04762068121057859, Temperature 6.752096880505432e-07, step_size 0.09734572731272544, test_acc: 1.0\n",
            "Epoch 814, BestLoss: 0.04762068121057859, Temperature 7.107470400532034e-07, step_size 0.09735546285901134, test_acc: 1.0\n",
            "Epoch 815, BestLoss: 0.047620521939711453, Temperature 7.48154779003372e-07, step_size 0.09734572731272544, test_acc: 1.0\n",
            "Epoch 816, BestLoss: 0.04762064567528013, Temperature 7.107470400532034e-07, step_size 0.09733599273999416, test_acc: 1.0\n",
            "Epoch 817, BestLoss: 0.04762064567528013, Temperature 6.752096880505432e-07, step_size 0.09732625914072016, test_acc: 1.0\n",
            "Epoch 818, BestLoss: 0.04762080641983667, Temperature 7.107470400532034e-07, step_size 0.09733599273999416, test_acc: 1.0\n",
            "Epoch 819, BestLoss: 0.04762080641983667, Temperature 6.752096880505432e-07, step_size 0.09732625914072016, test_acc: 1.0\n",
            "Epoch 820, BestLoss: 0.04762110838598641, Temperature 7.107470400532034e-07, step_size 0.09732625914072016, test_acc: 1.0\n",
            "Epoch 821, BestLoss: 0.04762105087864331, Temperature 6.752096880505432e-07, step_size 0.09731652651480609, test_acc: 1.0\n",
            "Epoch 822, BestLoss: 0.04762163355470388, Temperature 6.41449203648016e-07, step_size 0.09730679486215461, test_acc: 1.0\n",
            "Epoch 823, BestLoss: 0.04762056597884765, Temperature 6.093767434656151e-07, step_size 0.0972970641826684, test_acc: 1.0\n",
            "Epoch 824, BestLoss: 0.04762062042522727, Temperature 5.789079062923343e-07, step_size 0.09728733447625013, test_acc: 1.0\n",
            "Epoch 825, BestLoss: 0.04762041626096682, Temperature 5.499625109777176e-07, step_size 0.0972776057428025, test_acc: 1.0\n",
            "Epoch 826, BestLoss: 0.04762041626096682, Temperature 5.224643854288317e-07, step_size 0.09726787798222822, test_acc: 1.0\n",
            "Epoch 827, BestLoss: 0.04762041626096682, Temperature 5.499625109777176e-07, step_size 0.09731652651480609, test_acc: 1.0\n",
            "Epoch 828, BestLoss: 0.04762042273085164, Temperature 5.789079062923343e-07, step_size 0.09730679486215461, test_acc: 1.0\n",
            "Epoch 829, BestLoss: 0.04762042273085164, Temperature 6.093767434656151e-07, step_size 0.0972970641826684, test_acc: 1.0\n",
            "Epoch 830, BestLoss: 0.04762042273085164, Temperature 6.41449203648016e-07, step_size 0.09728733447625013, test_acc: 1.0\n",
            "Epoch 831, BestLoss: 0.04762184511525962, Temperature 6.752096880505432e-07, step_size 0.0972776057428025, test_acc: 1.0\n",
            "Epoch 832, BestLoss: 0.04762134478300929, Temperature 6.41449203648016e-07, step_size 0.09726787798222822, test_acc: 1.0\n",
            "Epoch 833, BestLoss: 0.04762134478300929, Temperature 6.093767434656151e-07, step_size 0.09725815119443, test_acc: 1.0\n",
            "Epoch 834, BestLoss: 0.047620687474475856, Temperature 6.41449203648016e-07, step_size 0.09726787798222822, test_acc: 1.0\n",
            "Epoch 835, BestLoss: 0.047620687474475856, Temperature 6.093767434656151e-07, step_size 0.09725815119443, test_acc: 1.0\n",
            "Epoch 836, BestLoss: 0.047620687474475856, Temperature 6.41449203648016e-07, step_size 0.09725815119443, test_acc: 1.0\n",
            "Epoch 837, BestLoss: 0.04762084364840796, Temperature 6.752096880505432e-07, step_size 0.09724842537931055, test_acc: 1.0\n",
            "Epoch 838, BestLoss: 0.04762078930383488, Temperature 6.41449203648016e-07, step_size 0.09723870053677262, test_acc: 1.0\n",
            "Epoch 839, BestLoss: 0.04762098565846447, Temperature 6.093767434656151e-07, step_size 0.09722897666671895, test_acc: 1.0\n",
            "Epoch 840, BestLoss: 0.047620676089539626, Temperature 5.789079062923343e-07, step_size 0.09721925376905229, test_acc: 1.0\n",
            "Epoch 841, BestLoss: 0.047621110060222, Temperature 5.499625109777176e-07, step_size 0.09720953184367538, test_acc: 1.0\n",
            "Epoch 842, BestLoss: 0.047621866802512326, Temperature 5.224643854288317e-07, step_size 0.09719981089049101, test_acc: 1.0\n",
            "Epoch 843, BestLoss: 0.04762050950905375, Temperature 4.963411661573901e-07, step_size 0.09719009090940196, test_acc: 1.0\n",
            "Epoch 844, BestLoss: 0.04762074247120145, Temperature 4.715241078495206e-07, step_size 0.09718037190031102, test_acc: 1.0\n",
            "Epoch 845, BestLoss: 0.04762069215371701, Temperature 4.479479024570445e-07, step_size 0.09717065386312099, test_acc: 1.0\n",
            "Epoch 846, BestLoss: 0.04762069215371701, Temperature 4.255505073341923e-07, step_size 0.09716093679773467, test_acc: 1.0\n",
            "Epoch 847, BestLoss: 0.04762069215371701, Temperature 4.479479024570445e-07, step_size 0.09723870053677262, test_acc: 1.0\n",
            "Epoch 848, BestLoss: 0.04762069215371701, Temperature 4.715241078495206e-07, step_size 0.09722897666671895, test_acc: 1.0\n",
            "Epoch 849, BestLoss: 0.04762069215371701, Temperature 4.963411661573901e-07, step_size 0.09721925376905229, test_acc: 1.0\n",
            "Epoch 850, BestLoss: 0.047621529627405144, Temperature 5.224643854288317e-07, step_size 0.09720953184367538, test_acc: 1.0\n",
            "Epoch 851, BestLoss: 0.04762025066810878, Temperature 4.963411661573901e-07, step_size 0.09719981089049101, test_acc: 1.0\n",
            "Epoch 852, BestLoss: 0.04762052452655376, Temperature 4.715241078495206e-07, step_size 0.09719009090940196, test_acc: 1.0\n",
            "Epoch 853, BestLoss: 0.04762052452655376, Temperature 4.479479024570445e-07, step_size 0.09718037190031102, test_acc: 1.0\n",
            "Epoch 854, BestLoss: 0.04762052452655376, Temperature 4.715241078495206e-07, step_size 0.09719981089049101, test_acc: 1.0\n",
            "Epoch 855, BestLoss: 0.04762027522817569, Temperature 4.963411661573901e-07, step_size 0.09719009090940196, test_acc: 1.0\n",
            "Epoch 856, BestLoss: 0.04762027522817569, Temperature 4.715241078495206e-07, step_size 0.09718037190031102, test_acc: 1.0\n",
            "Epoch 857, BestLoss: 0.04762027522817569, Temperature 4.963411661573901e-07, step_size 0.09718037190031102, test_acc: 1.0\n",
            "Epoch 858, BestLoss: 0.047621352441760134, Temperature 5.224643854288317e-07, step_size 0.09717065386312099, test_acc: 1.0\n",
            "Epoch 859, BestLoss: 0.047620257900315766, Temperature 4.963411661573901e-07, step_size 0.09716093679773467, test_acc: 1.0\n",
            "Epoch 860, BestLoss: 0.047620257900315766, Temperature 4.715241078495206e-07, step_size 0.0971512207040549, test_acc: 1.0\n",
            "Epoch 861, BestLoss: 0.04762019036982507, Temperature 4.963411661573901e-07, step_size 0.09716093679773467, test_acc: 1.0\n",
            "Epoch 862, BestLoss: 0.04762046528640845, Temperature 4.715241078495206e-07, step_size 0.0971512207040549, test_acc: 1.0\n",
            "Epoch 863, BestLoss: 0.047620220695204094, Temperature 4.479479024570445e-07, step_size 0.09714150558198449, test_acc: 1.0\n",
            "Epoch 864, BestLoss: 0.047620622343890716, Temperature 4.255505073341923e-07, step_size 0.09713179143142629, test_acc: 1.0\n",
            "Epoch 865, BestLoss: 0.04762052810997399, Temperature 4.0427298196748264e-07, step_size 0.09712207825228315, test_acc: 1.0\n",
            "Epoch 866, BestLoss: 0.04762037405889941, Temperature 3.840593328691085e-07, step_size 0.09711236604445793, test_acc: 1.0\n",
            "Epoch 867, BestLoss: 0.04762037405889941, Temperature 3.6485636622565307e-07, step_size 0.09710265480785349, test_acc: 1.0\n",
            "Epoch 868, BestLoss: 0.04762037405889941, Temperature 3.840593328691085e-07, step_size 0.0971512207040549, test_acc: 1.0\n",
            "Epoch 869, BestLoss: 0.04762037405889941, Temperature 4.0427298196748264e-07, step_size 0.09714150558198449, test_acc: 1.0\n",
            "Epoch 870, BestLoss: 0.04762037405889941, Temperature 4.255505073341923e-07, step_size 0.09713179143142629, test_acc: 1.0\n",
            "Epoch 871, BestLoss: 0.04762037405889941, Temperature 4.479479024570445e-07, step_size 0.09712207825228315, test_acc: 1.0\n",
            "Epoch 872, BestLoss: 0.04762037405889941, Temperature 4.715241078495206e-07, step_size 0.09711236604445793, test_acc: 1.0\n",
            "Epoch 873, BestLoss: 0.04762037405889941, Temperature 4.963411661573901e-07, step_size 0.09710265480785349, test_acc: 1.0\n",
            "Epoch 874, BestLoss: 0.04762075955845641, Temperature 5.224643854288317e-07, step_size 0.0970929445423727, test_acc: 1.0\n",
            "Epoch 875, BestLoss: 0.04762075955845641, Temperature 4.963411661573901e-07, step_size 0.09708323524791847, test_acc: 1.0\n",
            "Epoch 876, BestLoss: 0.04762075955845641, Temperature 5.224643854288317e-07, step_size 0.09708323524791847, test_acc: 1.0\n",
            "Epoch 877, BestLoss: 0.04762148023388283, Temperature 5.499625109777176e-07, step_size 0.09707352692439368, test_acc: 1.0\n",
            "Epoch 878, BestLoss: 0.04762148023388283, Temperature 5.224643854288317e-07, step_size 0.09706381957170124, test_acc: 1.0\n",
            "Epoch 879, BestLoss: 0.04762151756036172, Temperature 5.499625109777176e-07, step_size 0.09706381957170124, test_acc: 1.0\n",
            "Epoch 880, BestLoss: 0.04762151756036172, Temperature 5.224643854288317e-07, step_size 0.09705411318974407, test_acc: 1.0\n",
            "Epoch 881, BestLoss: 0.04762146887845724, Temperature 5.499625109777176e-07, step_size 0.09705411318974407, test_acc: 1.0\n",
            "Epoch 882, BestLoss: 0.04762146887845724, Temperature 5.224643854288317e-07, step_size 0.09704440777842509, test_acc: 1.0\n",
            "Epoch 883, BestLoss: 0.04762122970053969, Temperature 5.499625109777176e-07, step_size 0.09704440777842509, test_acc: 1.0\n",
            "Epoch 884, BestLoss: 0.04762121823207957, Temperature 5.224643854288317e-07, step_size 0.09703470333764724, test_acc: 1.0\n",
            "Epoch 885, BestLoss: 0.04762121823207957, Temperature 5.499625109777176e-07, step_size 0.09703470333764724, test_acc: 1.0\n",
            "Epoch 886, BestLoss: 0.04762121823207957, Temperature 5.789079062923343e-07, step_size 0.09702499986731349, test_acc: 1.0\n",
            "Epoch 887, BestLoss: 0.04762121823207957, Temperature 6.093767434656151e-07, step_size 0.09701529736732675, test_acc: 1.0\n",
            "Epoch 888, BestLoss: 0.04762121823207957, Temperature 6.41449203648016e-07, step_size 0.09700559583759003, test_acc: 1.0\n",
            "Epoch 889, BestLoss: 0.04762125337966501, Temperature 6.752096880505432e-07, step_size 0.09699589527800627, test_acc: 1.0\n",
            "Epoch 890, BestLoss: 0.04762125337966501, Temperature 6.41449203648016e-07, step_size 0.09698619568847847, test_acc: 1.0\n",
            "Epoch 891, BestLoss: 0.047621133511761206, Temperature 6.752096880505432e-07, step_size 0.09698619568847847, test_acc: 1.0\n",
            "Epoch 892, BestLoss: 0.047621133511761206, Temperature 6.41449203648016e-07, step_size 0.09697649706890962, test_acc: 1.0\n",
            "Epoch 893, BestLoss: 0.047623369733641965, Temperature 6.752096880505432e-07, step_size 0.09697649706890962, test_acc: 1.0\n",
            "Epoch 894, BestLoss: 0.047623369733641965, Temperature 6.41449203648016e-07, step_size 0.09696679941920273, test_acc: 1.0\n",
            "Epoch 895, BestLoss: 0.0476209753049308, Temperature 6.752096880505432e-07, step_size 0.09696679941920273, test_acc: 1.0\n",
            "Epoch 896, BestLoss: 0.0476209753049308, Temperature 6.41449203648016e-07, step_size 0.09695710273926081, test_acc: 1.0\n",
            "Epoch 897, BestLoss: 0.04762051032591017, Temperature 6.752096880505432e-07, step_size 0.09695710273926081, test_acc: 1.0\n",
            "Epoch 898, BestLoss: 0.04762078834583696, Temperature 6.41449203648016e-07, step_size 0.09694740702898688, test_acc: 1.0\n",
            "Epoch 899, BestLoss: 0.04762101337870563, Temperature 6.093767434656151e-07, step_size 0.09693771228828399, test_acc: 1.0\n",
            "Epoch 900, BestLoss: 0.04762101337870563, Temperature 5.789079062923343e-07, step_size 0.09692801851705517, test_acc: 1.0\n",
            "Epoch 901, BestLoss: 0.04762101337870563, Temperature 6.093767434656151e-07, step_size 0.09694740702898688, test_acc: 1.0\n",
            "Epoch 902, BestLoss: 0.04762101337870563, Temperature 6.41449203648016e-07, step_size 0.09693771228828399, test_acc: 1.0\n",
            "Epoch 903, BestLoss: 0.04762101337870563, Temperature 6.752096880505432e-07, step_size 0.09692801851705517, test_acc: 1.0\n",
            "Epoch 904, BestLoss: 0.04762094033505657, Temperature 7.107470400532034e-07, step_size 0.09691832571520347, test_acc: 1.0\n",
            "Epoch 905, BestLoss: 0.04762094033505657, Temperature 6.752096880505432e-07, step_size 0.09690863388263195, test_acc: 1.0\n",
            "Epoch 906, BestLoss: 0.04762094033505657, Temperature 7.107470400532034e-07, step_size 0.09690863388263195, test_acc: 1.0\n",
            "Epoch 907, BestLoss: 0.04762094033505657, Temperature 7.48154779003372e-07, step_size 0.09689894301924369, test_acc: 1.0\n",
            "Epoch 908, BestLoss: 0.04762094033505657, Temperature 7.87531346319339e-07, step_size 0.09688925312494177, test_acc: 1.0\n",
            "Epoch 909, BestLoss: 0.04762094033505657, Temperature 8.289803645466727e-07, step_size 0.09687956419962929, test_acc: 1.0\n",
            "Epoch 910, BestLoss: 0.04762094033505657, Temperature 8.726109100491292e-07, step_size 0.09686987624320932, test_acc: 1.0\n",
            "Epoch 911, BestLoss: 0.04762094033505657, Temperature 9.185378000517149e-07, step_size 0.096860189255585, test_acc: 1.0\n",
            "Epoch 912, BestLoss: 0.04762094033505657, Temperature 9.668818947912789e-07, step_size 0.09685050323665943, test_acc: 1.0\n",
            "Epoch 913, BestLoss: 0.04762094033505657, Temperature 1.0177704155697673e-06, step_size 0.09684081818633576, test_acc: 1.0\n",
            "Epoch 914, BestLoss: 0.047622633878076505, Temperature 1.0713372795471234e-06, step_size 0.09683113410451713, test_acc: 1.0\n",
            "Epoch 915, BestLoss: 0.04762116727923072, Temperature 1.0177704155697673e-06, step_size 0.09682145099110669, test_acc: 1.0\n",
            "Epoch 916, BestLoss: 0.047621136159263354, Temperature 9.668818947912789e-07, step_size 0.09681176884600758, test_acc: 1.0\n",
            "Epoch 917, BestLoss: 0.04762047095863556, Temperature 1.0177704155697673e-06, step_size 0.09682145099110669, test_acc: 1.0\n",
            "Epoch 918, BestLoss: 0.04762036866289657, Temperature 9.668818947912789e-07, step_size 0.09681176884600758, test_acc: 1.0\n",
            "Epoch 919, BestLoss: 0.047620331083265646, Temperature 9.185378000517149e-07, step_size 0.09680208766912297, test_acc: 1.0\n",
            "Epoch 920, BestLoss: 0.047620331083265646, Temperature 9.668818947912789e-07, step_size 0.09681176884600758, test_acc: 1.0\n",
            "Epoch 921, BestLoss: 0.04762070814921418, Temperature 1.0177704155697673e-06, step_size 0.09680208766912297, test_acc: 1.0\n",
            "Epoch 922, BestLoss: 0.04762065811508661, Temperature 9.668818947912789e-07, step_size 0.09679240746035607, test_acc: 1.0\n",
            "Epoch 923, BestLoss: 0.04762065811508661, Temperature 9.185378000517149e-07, step_size 0.09678272821961004, test_acc: 1.0\n",
            "Epoch 924, BestLoss: 0.04762065811508661, Temperature 9.668818947912789e-07, step_size 0.09679240746035607, test_acc: 1.0\n",
            "Epoch 925, BestLoss: 0.04762065811508661, Temperature 1.0177704155697673e-06, step_size 0.09678272821961004, test_acc: 1.0\n",
            "Epoch 926, BestLoss: 0.04762021364976451, Temperature 1.0713372795471234e-06, step_size 0.09677304994678808, test_acc: 1.0\n",
            "Epoch 927, BestLoss: 0.047620312454244224, Temperature 1.0177704155697673e-06, step_size 0.0967633726417934, test_acc: 1.0\n",
            "Epoch 928, BestLoss: 0.047620408796090474, Temperature 9.668818947912789e-07, step_size 0.09675369630452922, test_acc: 1.0\n",
            "Epoch 929, BestLoss: 0.04762163232225483, Temperature 9.185378000517149e-07, step_size 0.09674402093489877, test_acc: 1.0\n",
            "Epoch 930, BestLoss: 0.04762034826985717, Temperature 8.726109100491292e-07, step_size 0.09673434653280528, test_acc: 1.0\n",
            "Epoch 931, BestLoss: 0.04762034826985717, Temperature 8.289803645466727e-07, step_size 0.09672467309815201, test_acc: 1.0\n",
            "Epoch 932, BestLoss: 0.0476204587236394, Temperature 8.726109100491292e-07, step_size 0.0967633726417934, test_acc: 1.0\n",
            "Epoch 933, BestLoss: 0.0476204587236394, Temperature 8.289803645466727e-07, step_size 0.09675369630452922, test_acc: 1.0\n",
            "Epoch 934, BestLoss: 0.0476204587236394, Temperature 8.726109100491292e-07, step_size 0.09675369630452922, test_acc: 1.0\n",
            "Epoch 935, BestLoss: 0.0476204587236394, Temperature 9.185378000517149e-07, step_size 0.09674402093489877, test_acc: 1.0\n",
            "Epoch 936, BestLoss: 0.04762027293753061, Temperature 9.668818947912789e-07, step_size 0.09673434653280528, test_acc: 1.0\n",
            "Epoch 937, BestLoss: 0.04762043163982579, Temperature 9.185378000517149e-07, step_size 0.09672467309815201, test_acc: 1.0\n",
            "Epoch 938, BestLoss: 0.04762023420008408, Temperature 8.726109100491292e-07, step_size 0.0967150006308422, test_acc: 1.0\n",
            "Epoch 939, BestLoss: 0.04762082604470691, Temperature 8.289803645466727e-07, step_size 0.09670532913077912, test_acc: 1.0\n",
            "Epoch 940, BestLoss: 0.047620412893284794, Temperature 7.87531346319339e-07, step_size 0.09669565859786604, test_acc: 1.0\n",
            "Epoch 941, BestLoss: 0.04762251668502393, Temperature 7.48154779003372e-07, step_size 0.09668598903200626, test_acc: 1.0\n",
            "Epoch 942, BestLoss: 0.047620630267950284, Temperature 7.107470400532034e-07, step_size 0.09667632043310306, test_acc: 1.0\n",
            "Epoch 943, BestLoss: 0.04762037595376349, Temperature 6.752096880505432e-07, step_size 0.09666665280105975, test_acc: 1.0\n",
            "Epoch 944, BestLoss: 0.04762048148164652, Temperature 6.41449203648016e-07, step_size 0.09665698613577965, test_acc: 1.0\n",
            "Epoch 945, BestLoss: 0.04762048148164652, Temperature 6.093767434656151e-07, step_size 0.09664732043716608, test_acc: 1.0\n",
            "Epoch 946, BestLoss: 0.04762048148164652, Temperature 6.41449203648016e-07, step_size 0.09672467309815201, test_acc: 1.0\n",
            "Epoch 947, BestLoss: 0.04762087119877398, Temperature 6.752096880505432e-07, step_size 0.0967150006308422, test_acc: 1.0\n",
            "Epoch 948, BestLoss: 0.04762087119877398, Temperature 6.41449203648016e-07, step_size 0.09670532913077912, test_acc: 1.0\n",
            "Epoch 949, BestLoss: 0.04762087119877398, Temperature 6.752096880505432e-07, step_size 0.09670532913077912, test_acc: 1.0\n",
            "Epoch 950, BestLoss: 0.047620399959382845, Temperature 7.107470400532034e-07, step_size 0.09669565859786604, test_acc: 1.0\n",
            "Epoch 951, BestLoss: 0.04762138489331069, Temperature 6.752096880505432e-07, step_size 0.09668598903200626, test_acc: 1.0\n",
            "Epoch 952, BestLoss: 0.04762069883032911, Temperature 6.41449203648016e-07, step_size 0.09667632043310306, test_acc: 1.0\n",
            "Epoch 953, BestLoss: 0.04762053126729861, Temperature 6.093767434656151e-07, step_size 0.09666665280105975, test_acc: 1.0\n",
            "Epoch 954, BestLoss: 0.04762039316727119, Temperature 5.789079062923343e-07, step_size 0.09665698613577965, test_acc: 1.0\n",
            "Epoch 955, BestLoss: 0.047620251976345083, Temperature 5.499625109777176e-07, step_size 0.09664732043716608, test_acc: 1.0\n",
            "Epoch 956, BestLoss: 0.047622052175048814, Temperature 5.224643854288317e-07, step_size 0.09663765570512237, test_acc: 1.0\n",
            "Epoch 957, BestLoss: 0.04762184668488538, Temperature 4.963411661573901e-07, step_size 0.09662799193955185, test_acc: 1.0\n",
            "Epoch 958, BestLoss: 0.047620551137739074, Temperature 4.715241078495206e-07, step_size 0.0966183291403579, test_acc: 1.0\n",
            "Epoch 959, BestLoss: 0.047620551137739074, Temperature 4.479479024570445e-07, step_size 0.09660866730744386, test_acc: 1.0\n",
            "Epoch 960, BestLoss: 0.047620551137739074, Temperature 4.715241078495206e-07, step_size 0.09668598903200626, test_acc: 1.0\n",
            "Epoch 961, BestLoss: 0.047620551137739074, Temperature 4.963411661573901e-07, step_size 0.09667632043310306, test_acc: 1.0\n",
            "Epoch 962, BestLoss: 0.04762053938289505, Temperature 5.224643854288317e-07, step_size 0.09666665280105975, test_acc: 1.0\n",
            "Epoch 963, BestLoss: 0.047620985526225554, Temperature 5.499625109777176e-07, step_size 0.09665698613577965, test_acc: 1.0\n",
            "Epoch 964, BestLoss: 0.04762177314279223, Temperature 5.224643854288317e-07, step_size 0.09664732043716608, test_acc: 1.0\n",
            "Epoch 965, BestLoss: 0.047621569287835876, Temperature 4.963411661573901e-07, step_size 0.09663765570512237, test_acc: 1.0\n",
            "Epoch 966, BestLoss: 0.047620465570341976, Temperature 4.715241078495206e-07, step_size 0.09662799193955185, test_acc: 1.0\n",
            "Epoch 967, BestLoss: 0.047620465570341976, Temperature 4.479479024570445e-07, step_size 0.0966183291403579, test_acc: 1.0\n",
            "Epoch 968, BestLoss: 0.047620465570341976, Temperature 4.715241078495206e-07, step_size 0.09664732043716608, test_acc: 1.0\n",
            "Epoch 969, BestLoss: 0.047620465570341976, Temperature 4.963411661573901e-07, step_size 0.09663765570512237, test_acc: 1.0\n",
            "Epoch 970, BestLoss: 0.047620465570341976, Temperature 5.224643854288317e-07, step_size 0.09662799193955185, test_acc: 1.0\n",
            "Epoch 971, BestLoss: 0.047620465570341976, Temperature 5.499625109777176e-07, step_size 0.0966183291403579, test_acc: 1.0\n",
            "Epoch 972, BestLoss: 0.047620465570341976, Temperature 5.789079062923343e-07, step_size 0.09660866730744386, test_acc: 1.0\n",
            "Epoch 973, BestLoss: 0.047620464541236765, Temperature 6.093767434656151e-07, step_size 0.09659900644071312, test_acc: 1.0\n",
            "Epoch 974, BestLoss: 0.0476212007799044, Temperature 6.41449203648016e-07, step_size 0.09658934654006905, test_acc: 1.0\n",
            "Epoch 975, BestLoss: 0.0476212007799044, Temperature 6.093767434656151e-07, step_size 0.09657968760541505, test_acc: 1.0\n",
            "Epoch 976, BestLoss: 0.0476212007799044, Temperature 6.41449203648016e-07, step_size 0.09657968760541505, test_acc: 1.0\n",
            "Epoch 977, BestLoss: 0.04762079652894571, Temperature 6.752096880505432e-07, step_size 0.09657002963665451, test_acc: 1.0\n",
            "Epoch 978, BestLoss: 0.04762096873348528, Temperature 6.41449203648016e-07, step_size 0.09656037263369084, test_acc: 1.0\n",
            "Epoch 979, BestLoss: 0.04762096873348528, Temperature 6.093767434656151e-07, step_size 0.09655071659642747, test_acc: 1.0\n",
            "Epoch 980, BestLoss: 0.047620651505510724, Temperature 6.41449203648016e-07, step_size 0.09656037263369084, test_acc: 1.0\n",
            "Epoch 981, BestLoss: 0.047620125550192585, Temperature 6.093767434656151e-07, step_size 0.09655071659642747, test_acc: 1.0\n",
            "Epoch 982, BestLoss: 0.04762009372598262, Temperature 5.789079062923343e-07, step_size 0.09654106152476782, test_acc: 1.0\n",
            "Epoch 983, BestLoss: 0.04762019588274275, Temperature 5.499625109777176e-07, step_size 0.09653140741861535, test_acc: 1.0\n",
            "Epoch 984, BestLoss: 0.04762019588274275, Temperature 5.224643854288317e-07, step_size 0.09652175427787349, test_acc: 1.0\n",
            "Epoch 985, BestLoss: 0.04762019588274275, Temperature 5.499625109777176e-07, step_size 0.09655071659642747, test_acc: 1.0\n",
            "Epoch 986, BestLoss: 0.04762019588274275, Temperature 5.789079062923343e-07, step_size 0.09654106152476782, test_acc: 1.0\n",
            "Epoch 987, BestLoss: 0.047620283355008314, Temperature 6.093767434656151e-07, step_size 0.09653140741861535, test_acc: 1.0\n",
            "Epoch 988, BestLoss: 0.047620283355008314, Temperature 5.789079062923343e-07, step_size 0.09652175427787349, test_acc: 1.0\n",
            "Epoch 989, BestLoss: 0.047620283355008314, Temperature 6.093767434656151e-07, step_size 0.09652175427787349, test_acc: 1.0\n",
            "Epoch 990, BestLoss: 0.047620283355008314, Temperature 6.41449203648016e-07, step_size 0.09651210210244571, test_acc: 1.0\n",
            "Epoch 991, BestLoss: 0.047620283355008314, Temperature 6.752096880505432e-07, step_size 0.09650245089223547, test_acc: 1.0\n",
            "Epoch 992, BestLoss: 0.047620283355008314, Temperature 7.107470400532034e-07, step_size 0.09649280064714624, test_acc: 1.0\n",
            "Epoch 993, BestLoss: 0.04762008533598931, Temperature 7.48154779003372e-07, step_size 0.09648315136708153, test_acc: 1.0\n",
            "Epoch 994, BestLoss: 0.04762008533598931, Temperature 7.107470400532034e-07, step_size 0.09647350305194483, test_acc: 1.0\n",
            "Epoch 995, BestLoss: 0.04762061068304382, Temperature 7.48154779003372e-07, step_size 0.09647350305194483, test_acc: 1.0\n",
            "Epoch 996, BestLoss: 0.04762042693398437, Temperature 7.107470400532034e-07, step_size 0.09646385570163964, test_acc: 1.0\n",
            "Epoch 997, BestLoss: 0.04762042693398437, Temperature 6.752096880505432e-07, step_size 0.09645420931606948, test_acc: 1.0\n",
            "Epoch 998, BestLoss: 0.047620548928520266, Temperature 7.107470400532034e-07, step_size 0.09646385570163964, test_acc: 1.0\n",
            "Epoch 999, BestLoss: 0.047620548928520266, Temperature 6.752096880505432e-07, step_size 0.09645420931606948, test_acc: 1.0\n",
            "expected [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "preds [[0.0010465 ]\n",
            " [0.33390704]\n",
            " [0.99797766]\n",
            " [0.33391428]\n",
            " [0.99797766]\n",
            " [0.0010465 ]\n",
            " [0.33391428]]\n"
          ]
        }
      ],
      "source": [
        "# XOR\n",
        "nl.set_random_key(4)\n",
        "layers = [\n",
        "    nl.SADense(2, 3),\n",
        "    nl.Sigmoid(),\n",
        "    nl.SADense(3, 1),\n",
        "    nl.Sigmoid(),\n",
        "]\n",
        "\n",
        "net = nl.NeuralNet(layers)\n",
        "optimizer = SimulatedAnnealingOptimizer(net, learning_rate = 0.1, loss=nl.MeanSquaredError())\n",
        "\n",
        "optimizer.fit((xor_x_train, xor_y_train), (xor_x_train, xor_y_train), epochs=1000, batch_size=60000, sample_per_batch=20, initial_temp=1.0, cooling_rate=0.95, verbose=True)\n",
        "# Infer on cx_test, cy_test\n",
        "preds = net(xor_x_train)\n",
        "expected = xor_y_train\n",
        "\n",
        "print(\"expected\", expected)\n",
        "print(\"preds\", preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pRm8RtSe2V5U"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, BestLoss: 0.08846413571159746, Temperature 1.0, step_size 1, test_acc: 0.1062\n",
            "Epoch 1, BestLoss: 0.08872017271870125, Temperature 0.95, step_size 0.9999, test_acc: 0.1098\n",
            "Epoch 2, BestLoss: 0.08393766354802341, Temperature 0.9025, step_size 0.9998000100000001, test_acc: 0.1572\n",
            "Epoch 3, BestLoss: 0.08797428968054603, Temperature 0.8573749999999999, step_size 0.9997000299990001, test_acc: 0.1163\n",
            "Epoch 4, BestLoss: 0.08848969932164755, Temperature 0.8145062499999999, step_size 0.9996000599960002, test_acc: 0.1067\n",
            "Epoch 5, BestLoss: 0.08799215453884722, Temperature 0.7737809374999999, step_size 0.9995000999900007, test_acc: 0.1199\n",
            "Epoch 6, BestLoss: 0.08608629351141167, Temperature 0.7350918906249998, step_size 0.9994001499800017, test_acc: 0.1372\n",
            "Epoch 7, BestLoss: 0.08783979435639122, Temperature 0.6983372960937497, step_size 0.9993002099650037, test_acc: 0.1208\n",
            "Epoch 8, BestLoss: 0.09009245373456257, Temperature 0.6634204312890623, step_size 0.9992002799440072, test_acc: 0.096\n",
            "Epoch 9, BestLoss: 0.09043472046618505, Temperature 0.6302494097246091, step_size 0.9991003599160128, test_acc: 0.0936\n",
            "Epoch 10, BestLoss: 0.09122176261428643, Temperature 0.5987369392383786, step_size 0.9990004498800211, test_acc: 0.0841\n",
            "Epoch 11, BestLoss: 0.09144050990596317, Temperature 0.5688000922764596, step_size 0.9989005498350332, test_acc: 0.085\n",
            "Epoch 12, BestLoss: 0.09281150051472907, Temperature 0.5403600876626365, step_size 0.9988006597800497, test_acc: 0.0717\n",
            "Epoch 13, BestLoss: 0.09205648264783539, Temperature 0.5133420832795047, step_size 0.9987007797140718, test_acc: 0.0813\n",
            "Epoch 14, BestLoss: 0.09284770775146729, Temperature 0.48767497911552943, step_size 0.9986009096361004, test_acc: 0.0756\n",
            "Epoch 15, BestLoss: 0.09385397538335645, Temperature 0.46329123015975293, step_size 0.9985010495451367, test_acc: 0.0615\n",
            "Epoch 16, BestLoss: 0.09568855016208022, Temperature 0.44012666865176525, step_size 0.9984011994401822, test_acc: 0.041\n",
            "Epoch 17, BestLoss: 0.09544517804215685, Temperature 0.41812033521917696, step_size 0.9983013593202382, test_acc: 0.0461\n",
            "Epoch 18, BestLoss: 0.09594993865315635, Temperature 0.3972143184582181, step_size 0.9982015291843062, test_acc: 0.0401\n",
            "Epoch 19, BestLoss: 0.09559858740795879, Temperature 0.37735360253530714, step_size 0.9981017090313877, test_acc: 0.0436\n",
            "Epoch 20, BestLoss: 0.09483724181063755, Temperature 0.35848592240854177, step_size 0.9980018988604846, test_acc: 0.0521\n",
            "Epoch 21, BestLoss: 0.09496380000568068, Temperature 0.34056162628811465, step_size 0.9979020986705985, test_acc: 0.0479\n",
            "Epoch 22, BestLoss: 0.09462471413396484, Temperature 0.3235335449737089, step_size 0.9978023084607315, test_acc: 0.0543\n",
            "Epoch 23, BestLoss: 0.09459928098960252, Temperature 0.30735686772502346, step_size 0.9977025282298854, test_acc: 0.0527\n",
            "Epoch 24, BestLoss: 0.09469163938947753, Temperature 0.2919890243387723, step_size 0.9976027579770624, test_acc: 0.0504\n",
            "Epoch 25, BestLoss: 0.09342959089929397, Temperature 0.27738957312183365, step_size 0.9975029977012647, test_acc: 0.0655\n",
            "Epoch 26, BestLoss: 0.09313901230602363, Temperature 0.263520094465742, step_size 0.9974032474014946, test_acc: 0.0675\n",
            "Epoch 27, BestLoss: 0.09318275675593427, Temperature 0.25034408974245487, step_size 0.9973035070767544, test_acc: 0.0719\n",
            "Epoch 28, BestLoss: 0.09258512183915964, Temperature 0.2378268852553321, step_size 0.9972037767260468, test_acc: 0.0754\n",
            "Epoch 29, BestLoss: 0.0929975577314183, Temperature 0.2259355409925655, step_size 0.9971040563483742, test_acc: 0.0736\n",
            "Epoch 30, BestLoss: 0.09374342922575772, Temperature 0.2146387639429372, step_size 0.9970043459427393, test_acc: 0.0649\n",
            "Epoch 31, BestLoss: 0.0935933217758036, Temperature 0.20390682574579033, step_size 0.9969046455081451, test_acc: 0.0647\n",
            "Epoch 32, BestLoss: 0.0947288439142032, Temperature 0.1937114844585008, step_size 0.9968049550435942, test_acc: 0.0559\n",
            "Epoch 33, BestLoss: 0.09397768356658386, Temperature 0.18402591023557577, step_size 0.9967052745480899, test_acc: 0.0634\n",
            "Epoch 34, BestLoss: 0.09401736054824784, Temperature 0.17482461472379698, step_size 0.9966056040206351, test_acc: 0.0621\n",
            "Epoch 35, BestLoss: 0.09548892452187412, Temperature 0.16608338398760714, step_size 0.9965059434602331, test_acc: 0.0453\n",
            "Epoch 36, BestLoss: 0.09474854802396146, Temperature 0.15777921478822676, step_size 0.9964062928658871, test_acc: 0.0533\n",
            "Epoch 37, BestLoss: 0.09480481281710186, Temperature 0.14989025404881542, step_size 0.9963066522366005, test_acc: 0.0552\n",
            "Epoch 38, BestLoss: 0.09487629147874388, Temperature 0.14239574134637464, step_size 0.9962070215713769, test_acc: 0.0538\n",
            "Epoch 39, BestLoss: 0.09440053194108576, Temperature 0.1352759542790559, step_size 0.9961074008692198, test_acc: 0.0571\n",
            "Epoch 40, BestLoss: 0.09495894152715575, Temperature 0.1285121565651031, step_size 0.9960077901291329, test_acc: 0.0512\n",
            "Epoch 41, BestLoss: 0.09429447872212433, Temperature 0.12208654873684793, step_size 0.9959081893501199, test_acc: 0.0608\n",
            "Epoch 42, BestLoss: 0.09478480034842204, Temperature 0.11598222130000553, step_size 0.995808598531185, test_acc: 0.0518\n",
            "Epoch 43, BestLoss: 0.09500047219520658, Temperature 0.11018311023500525, step_size 0.9957090176713319, test_acc: 0.0496\n",
            "Epoch 44, BestLoss: 0.09349493689785039, Temperature 0.10467395472325498, step_size 0.9956094467695648, test_acc: 0.0677\n",
            "Epoch 45, BestLoss: 0.09346421076565188, Temperature 0.09944025698709223, step_size 0.9955098858248879, test_acc: 0.0704\n",
            "Epoch 46, BestLoss: 0.09317022509528505, Temperature 0.09446824413773762, step_size 0.9954103348363054, test_acc: 0.0685\n",
            "Epoch 47, BestLoss: 0.09374581578849152, Temperature 0.08974483193085074, step_size 0.9953107938028217, test_acc: 0.0603\n",
            "Epoch 48, BestLoss: 0.09383991094538906, Temperature 0.0852575903343082, step_size 0.9952112627234414, test_acc: 0.0616\n",
            "Epoch 49, BestLoss: 0.09274047914833213, Temperature 0.08099471081759278, step_size 0.9951117415971691, test_acc: 0.073\n",
            "Epoch 50, BestLoss: 0.09458688217552483, Temperature 0.07694497527671314, step_size 0.9950122304230093, test_acc: 0.0527\n",
            "Epoch 51, BestLoss: 0.09515745872371803, Temperature 0.07309772651287748, step_size 0.9949127291999671, test_acc: 0.0461\n",
            "Epoch 52, BestLoss: 0.09528816506099408, Temperature 0.0694428401872336, step_size 0.9948132379270471, test_acc: 0.0456\n",
            "Epoch 53, BestLoss: 0.09584174111758582, Temperature 0.0659706981778719, step_size 0.9947137566032545, test_acc: 0.0427\n",
            "Epoch 54, BestLoss: 0.0953498496424249, Temperature 0.0626721632689783, step_size 0.9946142852275941, test_acc: 0.0459\n",
            "Epoch 55, BestLoss: 0.09514054040150538, Temperature 0.059538555105529384, step_size 0.9945148237990713, test_acc: 0.0494\n",
            "Epoch 56, BestLoss: 0.09489734291207569, Temperature 0.05656162735025291, step_size 0.9944153723166914, test_acc: 0.0502\n",
            "Epoch 57, BestLoss: 0.09543095673954934, Temperature 0.053733545982740265, step_size 0.9943159307794598, test_acc: 0.0449\n",
            "Epoch 58, BestLoss: 0.0960684395842235, Temperature 0.05104686868360325, step_size 0.9942164991863819, test_acc: 0.038\n",
            "Epoch 59, BestLoss: 0.0956874620786899, Temperature 0.04849452524942309, step_size 0.9941170775364633, test_acc: 0.0383\n",
            "Epoch 60, BestLoss: 0.09508756083550433, Temperature 0.04606979898695193, step_size 0.9940176658287097, test_acc: 0.0459\n",
            "Epoch 61, BestLoss: 0.09513442917131018, Temperature 0.04376630903760433, step_size 0.9939182640621268, test_acc: 0.0455\n",
            "Epoch 62, BestLoss: 0.09456880996347929, Temperature 0.041577993585724116, step_size 0.9938188722357206, test_acc: 0.0502\n",
            "Epoch 63, BestLoss: 0.09476144465037231, Temperature 0.03949909390643791, step_size 0.993719490348497, test_acc: 0.049\n",
            "Epoch 64, BestLoss: 0.09465506884042707, Temperature 0.03752413921111601, step_size 0.9936201183994622, test_acc: 0.0497\n",
            "Epoch 65, BestLoss: 0.0939759541020879, Temperature 0.03564793225056021, step_size 0.9935207563876223, test_acc: 0.0573\n",
            "Epoch 66, BestLoss: 0.09363903494006666, Temperature 0.0338655356380322, step_size 0.9934214043119836, test_acc: 0.065\n",
            "Epoch 67, BestLoss: 0.09359194003895331, Temperature 0.032172258856130585, step_size 0.9933220621715524, test_acc: 0.0632\n",
            "Epoch 68, BestLoss: 0.09240445252123732, Temperature 0.030563645913324056, step_size 0.9932227299653352, test_acc: 0.0771\n",
            "Epoch 69, BestLoss: 0.09243900915619384, Temperature 0.029035463617657853, step_size 0.9931234076923388, test_acc: 0.0778\n",
            "Epoch 70, BestLoss: 0.0916167603386195, Temperature 0.027583690436774957, step_size 0.9930240953515695, test_acc: 0.0875\n",
            "Epoch 71, BestLoss: 0.09167817531226208, Temperature 0.02620450591493621, step_size 0.9929247929420344, test_acc: 0.0848\n",
            "Epoch 72, BestLoss: 0.09286255591814417, Temperature 0.0248942806191894, step_size 0.9928255004627402, test_acc: 0.0716\n",
            "Epoch 73, BestLoss: 0.09363119285099808, Temperature 0.023649566588229927, step_size 0.992726217912694, test_acc: 0.0637\n",
            "Epoch 74, BestLoss: 0.09400675493471171, Temperature 0.022467088258818428, step_size 0.9926269452909028, test_acc: 0.0571\n",
            "Epoch 75, BestLoss: 0.09312892264108305, Temperature 0.021343733845877507, step_size 0.9925276825963737, test_acc: 0.0637\n",
            "Epoch 76, BestLoss: 0.09259800400623258, Temperature 0.02027654715358363, step_size 0.9924284298281141, test_acc: 0.0728\n",
            "Epoch 77, BestLoss: 0.09319686635731572, Temperature 0.019262719795904448, step_size 0.9923291869851313, test_acc: 0.0649\n",
            "Epoch 78, BestLoss: 0.0925392076648973, Temperature 0.018299583806109226, step_size 0.9922299540664328, test_acc: 0.0745\n",
            "Epoch 79, BestLoss: 0.09102660764906133, Temperature 0.017384604615803764, step_size 0.9921307310710261, test_acc: 0.0893\n",
            "Epoch 80, BestLoss: 0.09086143208195797, Temperature 0.016515374385013576, step_size 0.992031517997919, test_acc: 0.0908\n",
            "Epoch 81, BestLoss: 0.09044429941426255, Temperature 0.015689605665762895, step_size 0.9919323148461192, test_acc: 0.0962\n",
            "Epoch 82, BestLoss: 0.0914114546817914, Temperature 0.01490512538247475, step_size 0.9918331216146347, test_acc: 0.0877\n",
            "Epoch 83, BestLoss: 0.09160316457537356, Temperature 0.014159869113351011, step_size 0.9917339383024733, test_acc: 0.0857\n",
            "Epoch 84, BestLoss: 0.09143357190885615, Temperature 0.01345187565768346, step_size 0.991634764908643, test_acc: 0.0883\n",
            "Epoch 85, BestLoss: 0.09133482403484655, Temperature 0.012779281874799287, step_size 0.9915356014321521, test_acc: 0.0868\n",
            "Epoch 86, BestLoss: 0.0910334103983799, Temperature 0.012140317781059323, step_size 0.9914364478720089, test_acc: 0.0935\n",
            "Epoch 87, BestLoss: 0.09005643338160645, Temperature 0.011533301892006355, step_size 0.9913373042272218, test_acc: 0.1047\n",
            "Epoch 88, BestLoss: 0.08966559836840274, Temperature 0.010956636797406038, step_size 0.9912381704967991, test_acc: 0.1089\n",
            "Epoch 89, BestLoss: 0.0896894220769208, Temperature 0.010408804957535735, step_size 0.9911390466797494, test_acc: 0.1079\n",
            "Epoch 90, BestLoss: 0.09007419118008023, Temperature 0.009888364709658948, step_size 0.9910399327750814, test_acc: 0.1027\n",
            "Epoch 91, BestLoss: 0.08991684216866197, Temperature 0.009393946474176, step_size 0.9909408287818039, test_acc: 0.1034\n",
            "Epoch 92, BestLoss: 0.09015558041663567, Temperature 0.0089242491504672, step_size 0.9908417346989258, test_acc: 0.0998\n",
            "Epoch 93, BestLoss: 0.0895417209853692, Temperature 0.008478036692943839, step_size 0.9907426505254558, test_acc: 0.1058\n",
            "Epoch 94, BestLoss: 0.08876159104856053, Temperature 0.008054134858296647, step_size 0.9906435762604033, test_acc: 0.1142\n",
            "Epoch 95, BestLoss: 0.0888534653379926, Temperature 0.0076514281153818135, step_size 0.9905445119027773, test_acc: 0.1121\n",
            "Epoch 96, BestLoss: 0.08827529131044817, Temperature 0.0072688567096127225, step_size 0.990445457451587, test_acc: 0.1162\n",
            "Epoch 97, BestLoss: 0.08756138269886149, Temperature 0.006905413874132086, step_size 0.9903464129058418, test_acc: 0.1258\n",
            "Epoch 98, BestLoss: 0.08756138269886149, Temperature 0.006560143180425482, step_size 0.9902473782645512, test_acc: 0.1258\n",
            "Epoch 99, BestLoss: 0.08749987086927082, Temperature 0.006905413874132086, step_size 1, test_acc: 0.1262\n",
            "Epoch 100, BestLoss: 0.08733994204760963, Temperature 0.006560143180425482, step_size 0.9999, test_acc: 0.1276\n",
            "Epoch 101, BestLoss: 0.08796634818679551, Temperature 0.0062321360214042075, step_size 0.9998000100000001, test_acc: 0.1215\n",
            "Epoch 102, BestLoss: 0.08819670724484334, Temperature 0.005920529220333997, step_size 0.9997000299990001, test_acc: 0.1191\n",
            "Epoch 103, BestLoss: 0.08834228691466278, Temperature 0.0056245027593172965, step_size 0.9996000599960002, test_acc: 0.1178\n",
            "Epoch 104, BestLoss: 0.08803177224894708, Temperature 0.005343277621351432, step_size 0.9995000999900007, test_acc: 0.1201\n",
            "Epoch 105, BestLoss: 0.08803177224894708, Temperature 0.0050761137402838595, step_size 0.9994001499800017, test_acc: 0.1201\n",
            "Epoch 106, BestLoss: 0.08827067902752551, Temperature 0.005343277621351432, step_size 0.9999, test_acc: 0.118\n",
            "Epoch 107, BestLoss: 0.08852853144436619, Temperature 0.0050761137402838595, step_size 0.9998000100000001, test_acc: 0.1163\n",
            "Epoch 108, BestLoss: 0.08838152203654075, Temperature 0.004822308053269666, step_size 0.9997000299990001, test_acc: 0.1195\n",
            "Epoch 109, BestLoss: 0.0894737922177919, Temperature 0.004581192650606183, step_size 0.9996000599960002, test_acc: 0.1081\n",
            "Epoch 110, BestLoss: 0.08939908254209897, Temperature 0.0043521330180758735, step_size 0.9995000999900007, test_acc: 0.1054\n",
            "Epoch 111, BestLoss: 0.08846190645581535, Temperature 0.0041345263671720795, step_size 0.9994001499800017, test_acc: 0.1179\n",
            "Epoch 112, BestLoss: 0.08823022855255262, Temperature 0.003927800048813475, step_size 0.9993002099650037, test_acc: 0.1192\n",
            "Epoch 113, BestLoss: 0.08865745895370677, Temperature 0.0037314100463728015, step_size 0.9992002799440072, test_acc: 0.1142\n",
            "Epoch 114, BestLoss: 0.08906102700384964, Temperature 0.0035448395440541612, step_size 0.9991003599160128, test_acc: 0.1124\n",
            "Epoch 115, BestLoss: 0.08842318268660271, Temperature 0.003367597566851453, step_size 0.9990004498800211, test_acc: 0.1182\n",
            "Epoch 116, BestLoss: 0.08882530549536401, Temperature 0.00319921768850888, step_size 0.9989005498350332, test_acc: 0.1139\n",
            "Epoch 117, BestLoss: 0.08937634512522769, Temperature 0.003039256804083436, step_size 0.9988006597800497, test_acc: 0.1043\n",
            "Epoch 118, BestLoss: 0.09052840133130073, Temperature 0.0028872939638792637, step_size 0.9987007797140718, test_acc: 0.0872\n",
            "Epoch 119, BestLoss: 0.09121722586572362, Temperature 0.0027429292656853004, step_size 0.9986009096361004, test_acc: 0.0837\n",
            "Epoch 120, BestLoss: 0.09089366164085062, Temperature 0.0026057828024010354, step_size 0.9985010495451367, test_acc: 0.0839\n",
            "Epoch 121, BestLoss: 0.09175045181473018, Temperature 0.0024754936622809836, step_size 0.9984011994401822, test_acc: 0.0781\n",
            "Epoch 122, BestLoss: 0.09196877298326564, Temperature 0.002351718979166934, step_size 0.9983013593202382, test_acc: 0.0754\n",
            "Epoch 123, BestLoss: 0.09188246694846083, Temperature 0.0022341330302085875, step_size 0.9982015291843062, test_acc: 0.0764\n",
            "Epoch 124, BestLoss: 0.09279464014916843, Temperature 0.002122426378698158, step_size 0.9981017090313877, test_acc: 0.0671\n",
            "Epoch 125, BestLoss: 0.09327774425139053, Temperature 0.0020163050597632503, step_size 0.9980018988604846, test_acc: 0.0649\n",
            "Epoch 126, BestLoss: 0.09331004137616657, Temperature 0.0019154898067750877, step_size 0.9979020986705985, test_acc: 0.0643\n",
            "Epoch 127, BestLoss: 0.09314642834974146, Temperature 0.0018197153164363333, step_size 0.9978023084607315, test_acc: 0.0674\n",
            "Epoch 128, BestLoss: 0.09299895518801127, Temperature 0.0017287295506145165, step_size 0.9977025282298854, test_acc: 0.0682\n",
            "Epoch 129, BestLoss: 0.09223241095590887, Temperature 0.0016422930730837905, step_size 0.9976027579770624, test_acc: 0.0764\n",
            "Epoch 130, BestLoss: 0.0920941827356751, Temperature 0.0015601784194296008, step_size 0.9975029977012647, test_acc: 0.0778\n",
            "Epoch 131, BestLoss: 0.09172367313424998, Temperature 0.0014821694984581207, step_size 0.9974032474014946, test_acc: 0.0814\n",
            "Epoch 132, BestLoss: 0.09113426782247892, Temperature 0.0014080610235352145, step_size 0.9973035070767544, test_acc: 0.0904\n",
            "Epoch 133, BestLoss: 0.09066222556449985, Temperature 0.0013376579723584536, step_size 0.9972037767260468, test_acc: 0.0965\n",
            "Epoch 134, BestLoss: 0.09161426911417715, Temperature 0.0012707750737405309, step_size 0.9971040563483742, test_acc: 0.0871\n",
            "Epoch 135, BestLoss: 0.09161426911417715, Temperature 0.0012072363200535043, step_size 0.9970043459427393, test_acc: 0.0871\n",
            "Epoch 136, BestLoss: 0.09131123719426014, Temperature 0.0012707750737405309, step_size 0.9998000100000001, test_acc: 0.0899\n",
            "Epoch 137, BestLoss: 0.09101098657615891, Temperature 0.0012072363200535043, step_size 0.9997000299990001, test_acc: 0.0943\n",
            "Epoch 138, BestLoss: 0.09072458936212334, Temperature 0.001146874504050829, step_size 0.9996000599960002, test_acc: 0.0963\n",
            "Epoch 139, BestLoss: 0.09074477596194978, Temperature 0.0010895307788482875, step_size 0.9995000999900007, test_acc: 0.0954\n",
            "Epoch 140, BestLoss: 0.09075607902432307, Temperature 0.001035054239905873, step_size 0.9994001499800017, test_acc: 0.0981\n",
            "Epoch 141, BestLoss: 0.09070251679909136, Temperature 0.0009833015279105794, step_size 0.9993002099650037, test_acc: 0.099\n",
            "Epoch 142, BestLoss: 0.091280143107704, Temperature 0.0009341364515150504, step_size 0.9992002799440072, test_acc: 0.0926\n",
            "Epoch 143, BestLoss: 0.09016158358244818, Temperature 0.0008874296289392978, step_size 0.9991003599160128, test_acc: 0.1044\n",
            "Epoch 144, BestLoss: 0.088380410371642, Temperature 0.0008430581474923328, step_size 0.9990004498800211, test_acc: 0.1232\n",
            "Epoch 145, BestLoss: 0.08767817797807882, Temperature 0.0008009052401177162, step_size 0.9989005498350332, test_acc: 0.1311\n",
            "Epoch 146, BestLoss: 0.08732670755689884, Temperature 0.0007608599781118304, step_size 0.9988006597800497, test_acc: 0.1343\n",
            "Epoch 147, BestLoss: 0.0872800006724654, Temperature 0.0007228169792062388, step_size 0.9987007797140718, test_acc: 0.1344\n",
            "Epoch 148, BestLoss: 0.08685804213858965, Temperature 0.0006866761302459269, step_size 0.9986009096361004, test_acc: 0.1395\n",
            "Epoch 149, BestLoss: 0.08685804213858965, Temperature 0.0006523423237336305, step_size 0.9985010495451367, test_acc: 0.1395\n",
            "Epoch 150, BestLoss: 0.08685804213858965, Temperature 0.0006866761302459269, step_size 0.9997000299990001, test_acc: 0.1395\n",
            "Epoch 151, BestLoss: 0.08693582264624551, Temperature 0.0007228169792062388, step_size 0.9996000599960002, test_acc: 0.1406\n",
            "Epoch 152, BestLoss: 0.08689662547133128, Temperature 0.0006866761302459269, step_size 0.9995000999900007, test_acc: 0.1392\n",
            "Epoch 153, BestLoss: 0.08637556031255593, Temperature 0.0006523423237336305, step_size 0.9994001499800017, test_acc: 0.1433\n",
            "Epoch 154, BestLoss: 0.08576997541251472, Temperature 0.0006197252075469489, step_size 0.9993002099650037, test_acc: 0.1493\n",
            "Epoch 155, BestLoss: 0.0859243218162088, Temperature 0.0005887389471696014, step_size 0.9992002799440072, test_acc: 0.1487\n",
            "Epoch 156, BestLoss: 0.08573677584844713, Temperature 0.0005593019998111214, step_size 0.9991003599160128, test_acc: 0.1517\n",
            "Epoch 157, BestLoss: 0.0851671192734263, Temperature 0.0005313368998205653, step_size 0.9990004498800211, test_acc: 0.1565\n",
            "Epoch 158, BestLoss: 0.08500854264951092, Temperature 0.0005047700548295369, step_size 0.9989005498350332, test_acc: 0.1585\n",
            "Epoch 159, BestLoss: 0.08528061944735268, Temperature 0.00047953155208806006, step_size 0.9988006597800497, test_acc: 0.1543\n",
            "Epoch 160, BestLoss: 0.08473165202255602, Temperature 0.000455554974483657, step_size 0.9987007797140718, test_acc: 0.1603\n",
            "Epoch 161, BestLoss: 0.08521199547896645, Temperature 0.0004327772257594741, step_size 0.9986009096361004, test_acc: 0.1539\n",
            "Epoch 162, BestLoss: 0.08521199547896645, Temperature 0.0004111383644715004, step_size 0.9985010495451367, test_acc: 0.1539\n",
            "Epoch 163, BestLoss: 0.08556850579559208, Temperature 0.0004327772257594741, step_size 0.9995000999900007, test_acc: 0.1491\n",
            "Epoch 164, BestLoss: 0.08532430218744964, Temperature 0.0004111383644715004, step_size 0.9994001499800017, test_acc: 0.1535\n",
            "Epoch 165, BestLoss: 0.08532430218744964, Temperature 0.00039058144624792536, step_size 0.9993002099650037, test_acc: 0.1535\n",
            "Epoch 166, BestLoss: 0.08516469726170622, Temperature 0.0004111383644715004, step_size 0.9994001499800017, test_acc: 0.1533\n",
            "Epoch 167, BestLoss: 0.0838303892251232, Temperature 0.00039058144624792536, step_size 0.9993002099650037, test_acc: 0.1686\n",
            "Epoch 168, BestLoss: 0.0839811107314011, Temperature 0.0003710523739355291, step_size 0.9992002799440072, test_acc: 0.1668\n",
            "Epoch 169, BestLoss: 0.08328979476036773, Temperature 0.00035249975523875265, step_size 0.9991003599160128, test_acc: 0.1729\n",
            "Epoch 170, BestLoss: 0.0831625218127364, Temperature 0.000334874767476815, step_size 0.9990004498800211, test_acc: 0.1724\n",
            "Epoch 171, BestLoss: 0.08269172199229329, Temperature 0.00031813102910297424, step_size 0.9989005498350332, test_acc: 0.1744\n",
            "Epoch 172, BestLoss: 0.08240849375212453, Temperature 0.0003022244776478255, step_size 0.9988006597800497, test_acc: 0.1782\n",
            "Epoch 173, BestLoss: 0.08152152668547548, Temperature 0.0002871132537654342, step_size 0.9987007797140718, test_acc: 0.1874\n",
            "Epoch 174, BestLoss: 0.08155334398043772, Temperature 0.00027275759107716247, step_size 0.9986009096361004, test_acc: 0.1905\n",
            "Epoch 175, BestLoss: 0.08123832311779933, Temperature 0.00025911971152330434, step_size 0.9985010495451367, test_acc: 0.1973\n",
            "Epoch 176, BestLoss: 0.08123851589920313, Temperature 0.00024616372594713913, step_size 0.9984011994401822, test_acc: 0.1971\n",
            "Epoch 177, BestLoss: 0.08071261585543461, Temperature 0.00025911971152330434, step_size 0.9993002099650037, test_acc: 0.205\n",
            "Epoch 178, BestLoss: 0.08070873585597779, Temperature 0.00024616372594713913, step_size 0.9992002799440072, test_acc: 0.2059\n",
            "Epoch 179, BestLoss: 0.08033725452105377, Temperature 0.00025911971152330434, step_size 0.9992002799440072, test_acc: 0.207\n",
            "Epoch 180, BestLoss: 0.07996443530202087, Temperature 0.00024616372594713913, step_size 0.9991003599160128, test_acc: 0.2092\n",
            "Epoch 181, BestLoss: 0.07996443530202087, Temperature 0.00023385553964978215, step_size 0.9990004498800211, test_acc: 0.2092\n",
            "Epoch 182, BestLoss: 0.07940354398052814, Temperature 0.00024616372594713913, step_size 0.9991003599160128, test_acc: 0.2143\n",
            "Epoch 183, BestLoss: 0.07940354398052814, Temperature 0.00023385553964978215, step_size 0.9990004498800211, test_acc: 0.2143\n",
            "Epoch 184, BestLoss: 0.07954093112149768, Temperature 0.00024616372594713913, step_size 0.9990004498800211, test_acc: 0.2116\n",
            "Epoch 185, BestLoss: 0.0784067588878228, Temperature 0.00023385553964978215, step_size 0.9989005498350332, test_acc: 0.2244\n",
            "Epoch 186, BestLoss: 0.0784067588878228, Temperature 0.00022216276266729304, step_size 0.9988006597800497, test_acc: 0.2244\n",
            "Epoch 187, BestLoss: 0.07824529841687378, Temperature 0.00023385553964978215, step_size 0.9989005498350332, test_acc: 0.2231\n",
            "Epoch 188, BestLoss: 0.07824529841687378, Temperature 0.00022216276266729304, step_size 0.9988006597800497, test_acc: 0.2231\n",
            "Epoch 189, BestLoss: 0.07857553773984262, Temperature 0.00023385553964978215, step_size 0.9988006597800497, test_acc: 0.2212\n",
            "Epoch 190, BestLoss: 0.07883683399933769, Temperature 0.00022216276266729304, step_size 0.9987007797140718, test_acc: 0.2175\n",
            "Epoch 191, BestLoss: 0.07816224820401743, Temperature 0.00021105462453392839, step_size 0.9986009096361004, test_acc: 0.2247\n",
            "Epoch 192, BestLoss: 0.07775886578103165, Temperature 0.00020050189330723196, step_size 0.9985010495451367, test_acc: 0.2291\n",
            "Epoch 193, BestLoss: 0.07775886578103165, Temperature 0.00019047679864187035, step_size 0.9984011994401822, test_acc: 0.2291\n",
            "Epoch 194, BestLoss: 0.07778943562535315, Temperature 0.00020050189330723196, step_size 0.9987007797140718, test_acc: 0.2278\n",
            "Epoch 195, BestLoss: 0.07778943562535315, Temperature 0.00019047679864187035, step_size 0.9986009096361004, test_acc: 0.2278\n",
            "Epoch 196, BestLoss: 0.07788891333697553, Temperature 0.00020050189330723196, step_size 0.9986009096361004, test_acc: 0.2266\n",
            "Epoch 197, BestLoss: 0.07788891333697553, Temperature 0.00019047679864187035, step_size 0.9985010495451367, test_acc: 0.2266\n",
            "Epoch 198, BestLoss: 0.07788891333697553, Temperature 0.00020050189330723196, step_size 0.9985010495451367, test_acc: 0.2266\n",
            "Epoch 199, BestLoss: 0.07751093933924111, Temperature 0.00021105462453392839, step_size 0.9984011994401822, test_acc: 0.2314\n",
            "Epoch 200, BestLoss: 0.07751093933924111, Temperature 0.00020050189330723196, step_size 0.9983013593202382, test_acc: 0.2314\n",
            "Epoch 201, BestLoss: 0.07781263478255648, Temperature 0.00021105462453392839, step_size 0.9983013593202382, test_acc: 0.2263\n",
            "Epoch 202, BestLoss: 0.07763471257518041, Temperature 0.00020050189330723196, step_size 0.9982015291843062, test_acc: 0.2282\n",
            "Epoch 203, BestLoss: 0.07760531286669153, Temperature 0.00019047679864187035, step_size 0.9981017090313877, test_acc: 0.2288\n",
            "Epoch 204, BestLoss: 0.07741254029379932, Temperature 0.00018095295870977683, step_size 0.9980018988604846, test_acc: 0.2308\n",
            "Epoch 205, BestLoss: 0.07741254029379932, Temperature 0.00017190531077428798, step_size 0.9979020986705985, test_acc: 0.2308\n",
            "Epoch 206, BestLoss: 0.07741254029379932, Temperature 0.00018095295870977683, step_size 0.9982015291843062, test_acc: 0.2308\n",
            "Epoch 207, BestLoss: 0.07712323375032704, Temperature 0.00019047679864187035, step_size 0.9981017090313877, test_acc: 0.2337\n",
            "Epoch 208, BestLoss: 0.07712323375032704, Temperature 0.00018095295870977683, step_size 0.9980018988604846, test_acc: 0.2337\n",
            "Epoch 209, BestLoss: 0.07712323375032704, Temperature 0.00019047679864187035, step_size 0.9980018988604846, test_acc: 0.2337\n",
            "Epoch 210, BestLoss: 0.07692491494076376, Temperature 0.00020050189330723196, step_size 0.9979020986705985, test_acc: 0.2368\n",
            "Epoch 211, BestLoss: 0.07654499618324083, Temperature 0.00019047679864187035, step_size 0.9978023084607315, test_acc: 0.2398\n",
            "Epoch 212, BestLoss: 0.07654499618324083, Temperature 0.00018095295870977683, step_size 0.9977025282298854, test_acc: 0.2398\n",
            "Epoch 213, BestLoss: 0.07654499618324083, Temperature 0.00019047679864187035, step_size 0.9978023084607315, test_acc: 0.2398\n",
            "Epoch 214, BestLoss: 0.07654499618324083, Temperature 0.00020050189330723196, step_size 0.9977025282298854, test_acc: 0.2398\n",
            "Epoch 215, BestLoss: 0.07654499618324083, Temperature 0.00021105462453392839, step_size 0.9976027579770624, test_acc: 0.2398\n",
            "Epoch 216, BestLoss: 0.07642294056508904, Temperature 0.00022216276266729304, step_size 0.9975029977012647, test_acc: 0.2433\n",
            "Epoch 217, BestLoss: 0.07642294056508904, Temperature 0.00021105462453392839, step_size 0.9974032474014946, test_acc: 0.2433\n",
            "Epoch 218, BestLoss: 0.07610015190668651, Temperature 0.00022216276266729304, step_size 0.9974032474014946, test_acc: 0.2473\n",
            "Epoch 219, BestLoss: 0.07610015190668651, Temperature 0.00021105462453392839, step_size 0.9973035070767544, test_acc: 0.2473\n",
            "Epoch 220, BestLoss: 0.07610015190668651, Temperature 0.00022216276266729304, step_size 0.9973035070767544, test_acc: 0.2473\n",
            "Epoch 221, BestLoss: 0.07602269393021414, Temperature 0.00023385553964978215, step_size 0.9972037767260468, test_acc: 0.2464\n",
            "Epoch 222, BestLoss: 0.07616314028758198, Temperature 0.00022216276266729304, step_size 0.9971040563483742, test_acc: 0.2414\n",
            "Epoch 223, BestLoss: 0.07621154951157746, Temperature 0.00021105462453392839, step_size 0.9970043459427393, test_acc: 0.2411\n",
            "Epoch 224, BestLoss: 0.07619373562574255, Temperature 0.00020050189330723196, step_size 0.9969046455081451, test_acc: 0.2435\n",
            "Epoch 225, BestLoss: 0.07619373562574255, Temperature 0.00019047679864187035, step_size 0.9968049550435942, test_acc: 0.2435\n",
            "Epoch 226, BestLoss: 0.07619373562574255, Temperature 0.00020050189330723196, step_size 0.9971040563483742, test_acc: 0.2435\n",
            "Epoch 227, BestLoss: 0.07580947577656948, Temperature 0.00021105462453392839, step_size 0.9970043459427393, test_acc: 0.2464\n",
            "Epoch 228, BestLoss: 0.07580947577656948, Temperature 0.00020050189330723196, step_size 0.9969046455081451, test_acc: 0.2464\n",
            "Epoch 229, BestLoss: 0.07553811427388063, Temperature 0.00021105462453392839, step_size 0.9969046455081451, test_acc: 0.2527\n",
            "Epoch 230, BestLoss: 0.07546404866127086, Temperature 0.00020050189330723196, step_size 0.9968049550435942, test_acc: 0.2543\n",
            "Epoch 231, BestLoss: 0.0750453389884964, Temperature 0.00019047679864187035, step_size 0.9967052745480899, test_acc: 0.2565\n",
            "Epoch 232, BestLoss: 0.0750453389884964, Temperature 0.00018095295870977683, step_size 0.9966056040206351, test_acc: 0.2565\n",
            "Epoch 233, BestLoss: 0.0750453389884964, Temperature 0.00019047679864187035, step_size 0.9968049550435942, test_acc: 0.2565\n",
            "Epoch 234, BestLoss: 0.07502242427710881, Temperature 0.00020050189330723196, step_size 0.9967052745480899, test_acc: 0.2583\n",
            "Epoch 235, BestLoss: 0.07511929358963719, Temperature 0.00019047679864187035, step_size 0.9966056040206351, test_acc: 0.2553\n",
            "Epoch 236, BestLoss: 0.07511929358963719, Temperature 0.00018095295870977683, step_size 0.9965059434602331, test_acc: 0.2553\n",
            "Epoch 237, BestLoss: 0.07565342618028228, Temperature 0.00019047679864187035, step_size 0.9966056040206351, test_acc: 0.248\n",
            "Epoch 238, BestLoss: 0.07565342618028228, Temperature 0.00018095295870977683, step_size 0.9965059434602331, test_acc: 0.248\n",
            "Epoch 239, BestLoss: 0.07565342618028228, Temperature 0.00019047679864187035, step_size 0.9965059434602331, test_acc: 0.248\n",
            "Epoch 240, BestLoss: 0.07571991660221651, Temperature 0.00020050189330723196, step_size 0.9964062928658871, test_acc: 0.2481\n",
            "Epoch 241, BestLoss: 0.07581155759533491, Temperature 0.00019047679864187035, step_size 0.9963066522366005, test_acc: 0.2506\n",
            "Epoch 242, BestLoss: 0.07553747058174998, Temperature 0.00018095295870977683, step_size 0.9962070215713769, test_acc: 0.252\n",
            "Epoch 243, BestLoss: 0.07553747058174998, Temperature 0.00017190531077428798, step_size 0.9961074008692198, test_acc: 0.252\n",
            "Epoch 244, BestLoss: 0.07575543785380805, Temperature 0.00018095295870977683, step_size 0.9963066522366005, test_acc: 0.2487\n",
            "Epoch 245, BestLoss: 0.07554153364912379, Temperature 0.00017190531077428798, step_size 0.9962070215713769, test_acc: 0.252\n",
            "Epoch 246, BestLoss: 0.07554153364912379, Temperature 0.00016331004523557357, step_size 0.9961074008692198, test_acc: 0.252\n",
            "Epoch 247, BestLoss: 0.07554153364912379, Temperature 0.00017190531077428798, step_size 0.9962070215713769, test_acc: 0.252\n",
            "Epoch 248, BestLoss: 0.07554153364912379, Temperature 0.00018095295870977683, step_size 0.9961074008692198, test_acc: 0.252\n",
            "Epoch 249, BestLoss: 0.07529807997764569, Temperature 0.00019047679864187035, step_size 0.9960077901291329, test_acc: 0.2572\n",
            "Epoch 250, BestLoss: 0.07529807997764569, Temperature 0.00018095295870977683, step_size 0.9959081893501199, test_acc: 0.2572\n",
            "Epoch 251, BestLoss: 0.0752915537245487, Temperature 0.00019047679864187035, step_size 0.9959081893501199, test_acc: 0.2529\n",
            "Epoch 252, BestLoss: 0.0752915537245487, Temperature 0.00020050189330723196, step_size 0.995808598531185, test_acc: 0.2529\n",
            "Epoch 253, BestLoss: 0.0752915537245487, Temperature 0.00021105462453392839, step_size 0.9957090176713319, test_acc: 0.2529\n",
            "Epoch 254, BestLoss: 0.07516638828203097, Temperature 0.00022216276266729304, step_size 0.9956094467695648, test_acc: 0.2567\n",
            "Epoch 255, BestLoss: 0.07516638828203097, Temperature 0.00021105462453392839, step_size 0.9955098858248879, test_acc: 0.2567\n",
            "Epoch 256, BestLoss: 0.07493607124639175, Temperature 0.00022216276266729304, step_size 0.9955098858248879, test_acc: 0.2598\n",
            "Epoch 257, BestLoss: 0.0751586090962709, Temperature 0.00021105462453392839, step_size 0.9954103348363054, test_acc: 0.2581\n",
            "Epoch 258, BestLoss: 0.07510431221170875, Temperature 0.00020050189330723196, step_size 0.9953107938028217, test_acc: 0.2585\n",
            "Epoch 259, BestLoss: 0.07504541507930117, Temperature 0.00019047679864187035, step_size 0.9952112627234414, test_acc: 0.2604\n",
            "Epoch 260, BestLoss: 0.07504541507930117, Temperature 0.00018095295870977683, step_size 0.9951117415971691, test_acc: 0.2604\n",
            "Epoch 261, BestLoss: 0.0749347026763472, Temperature 0.00019047679864187035, step_size 0.9954103348363054, test_acc: 0.2601\n",
            "Epoch 262, BestLoss: 0.0749347026763472, Temperature 0.00018095295870977683, step_size 0.9953107938028217, test_acc: 0.2601\n",
            "Epoch 263, BestLoss: 0.07482699863362015, Temperature 0.00019047679864187035, step_size 0.9953107938028217, test_acc: 0.2633\n",
            "Epoch 264, BestLoss: 0.07482088973748001, Temperature 0.00018095295870977683, step_size 0.9952112627234414, test_acc: 0.2627\n",
            "Epoch 265, BestLoss: 0.07480539259606728, Temperature 0.00019047679864187035, step_size 0.9952112627234414, test_acc: 0.2621\n",
            "Epoch 266, BestLoss: 0.07480539259606728, Temperature 0.00018095295870977683, step_size 0.9951117415971691, test_acc: 0.2621\n",
            "Epoch 267, BestLoss: 0.07480539259606728, Temperature 0.00019047679864187035, step_size 0.9951117415971691, test_acc: 0.2621\n",
            "Epoch 268, BestLoss: 0.07481334591691809, Temperature 0.00020050189330723196, step_size 0.9950122304230093, test_acc: 0.2628\n",
            "Epoch 269, BestLoss: 0.07481334591691809, Temperature 0.00019047679864187035, step_size 0.9949127291999671, test_acc: 0.2628\n",
            "Epoch 270, BestLoss: 0.07456222732626741, Temperature 0.00020050189330723196, step_size 0.9949127291999671, test_acc: 0.2668\n",
            "Epoch 271, BestLoss: 0.07485522667847742, Temperature 0.00019047679864187035, step_size 0.9948132379270471, test_acc: 0.264\n",
            "Epoch 272, BestLoss: 0.07459976811602498, Temperature 0.00018095295870977683, step_size 0.9947137566032545, test_acc: 0.268\n",
            "Epoch 273, BestLoss: 0.07459976811602498, Temperature 0.00017190531077428798, step_size 0.9946142852275941, test_acc: 0.268\n",
            "Epoch 274, BestLoss: 0.07468007865658922, Temperature 0.00018095295870977683, step_size 0.9948132379270471, test_acc: 0.2659\n",
            "Epoch 275, BestLoss: 0.07468663734139411, Temperature 0.00017190531077428798, step_size 0.9947137566032545, test_acc: 0.2655\n",
            "Epoch 276, BestLoss: 0.07493851821498057, Temperature 0.00018095295870977683, step_size 0.9947137566032545, test_acc: 0.265\n",
            "Epoch 277, BestLoss: 0.07493851821498057, Temperature 0.00017190531077428798, step_size 0.9946142852275941, test_acc: 0.265\n",
            "Epoch 278, BestLoss: 0.07493851821498057, Temperature 0.00018095295870977683, step_size 0.9946142852275941, test_acc: 0.265\n",
            "Epoch 279, BestLoss: 0.07493851821498057, Temperature 0.00019047679864187035, step_size 0.9945148237990713, test_acc: 0.265\n",
            "Epoch 280, BestLoss: 0.07493851821498057, Temperature 0.00020050189330723196, step_size 0.9944153723166914, test_acc: 0.265\n",
            "Epoch 281, BestLoss: 0.07493851821498057, Temperature 0.00021105462453392839, step_size 0.9943159307794598, test_acc: 0.265\n",
            "Epoch 282, BestLoss: 0.07493851821498057, Temperature 0.00022216276266729304, step_size 0.9942164991863819, test_acc: 0.265\n",
            "Epoch 283, BestLoss: 0.07493851821498057, Temperature 0.00023385553964978215, step_size 0.9941170775364633, test_acc: 0.265\n",
            "Epoch 284, BestLoss: 0.07441718587465097, Temperature 0.00024616372594713913, step_size 0.9940176658287097, test_acc: 0.2704\n",
            "Epoch 285, BestLoss: 0.07348437871265691, Temperature 0.00023385553964978215, step_size 0.9939182640621268, test_acc: 0.2776\n",
            "Epoch 286, BestLoss: 0.07348437871265691, Temperature 0.00022216276266729304, step_size 0.9938188722357206, test_acc: 0.2776\n",
            "Epoch 287, BestLoss: 0.07348437871265691, Temperature 0.00023385553964978215, step_size 0.9939182640621268, test_acc: 0.2776\n",
            "Epoch 288, BestLoss: 0.07359761964278945, Temperature 0.00024616372594713913, step_size 0.9938188722357206, test_acc: 0.2801\n",
            "Epoch 289, BestLoss: 0.07359761964278945, Temperature 0.00023385553964978215, step_size 0.993719490348497, test_acc: 0.2801\n",
            "Epoch 290, BestLoss: 0.07330835591612772, Temperature 0.00024616372594713913, step_size 0.993719490348497, test_acc: 0.2815\n",
            "Epoch 291, BestLoss: 0.07330835591612772, Temperature 0.00023385553964978215, step_size 0.9936201183994622, test_acc: 0.2815\n",
            "Epoch 292, BestLoss: 0.07330835591612772, Temperature 0.00024616372594713913, step_size 0.9936201183994622, test_acc: 0.2815\n",
            "Epoch 293, BestLoss: 0.07264377596638132, Temperature 0.00025911971152330434, step_size 0.9935207563876223, test_acc: 0.2892\n",
            "Epoch 294, BestLoss: 0.07273391406378772, Temperature 0.00024616372594713913, step_size 0.9934214043119836, test_acc: 0.285\n",
            "Epoch 295, BestLoss: 0.07273391406378772, Temperature 0.00023385553964978215, step_size 0.9933220621715524, test_acc: 0.285\n",
            "Epoch 296, BestLoss: 0.07273391406378772, Temperature 0.00024616372594713913, step_size 0.9934214043119836, test_acc: 0.285\n",
            "Epoch 297, BestLoss: 0.0720710639723502, Temperature 0.00025911971152330434, step_size 0.9933220621715524, test_acc: 0.2932\n",
            "Epoch 298, BestLoss: 0.0720710639723502, Temperature 0.00024616372594713913, step_size 0.9932227299653352, test_acc: 0.2932\n",
            "Epoch 299, BestLoss: 0.0720710639723502, Temperature 0.00025911971152330434, step_size 0.9932227299653352, test_acc: 0.2932\n",
            "Epoch 300, BestLoss: 0.0720710639723502, Temperature 0.00027275759107716247, step_size 0.9931234076923388, test_acc: 0.2932\n",
            "Epoch 301, BestLoss: 0.0720710639723502, Temperature 0.0002871132537654342, step_size 0.9930240953515695, test_acc: 0.2932\n",
            "Epoch 302, BestLoss: 0.0720710639723502, Temperature 0.0003022244776478255, step_size 0.9929247929420344, test_acc: 0.2932\n",
            "Epoch 303, BestLoss: 0.0720710639723502, Temperature 0.00031813102910297424, step_size 0.9928255004627402, test_acc: 0.2932\n",
            "Epoch 304, BestLoss: 0.07220400856121859, Temperature 0.000334874767476815, step_size 0.992726217912694, test_acc: 0.294\n",
            "Epoch 305, BestLoss: 0.07220400856121859, Temperature 0.00031813102910297424, step_size 0.9926269452909028, test_acc: 0.294\n",
            "Epoch 306, BestLoss: 0.07225688330497021, Temperature 0.000334874767476815, step_size 0.9926269452909028, test_acc: 0.2939\n",
            "Epoch 307, BestLoss: 0.07225688330497021, Temperature 0.00031813102910297424, step_size 0.9925276825963737, test_acc: 0.2939\n",
            "Epoch 308, BestLoss: 0.07225688330497021, Temperature 0.000334874767476815, step_size 0.9925276825963737, test_acc: 0.2939\n",
            "Epoch 309, BestLoss: 0.07249059753819416, Temperature 0.00035249975523875265, step_size 0.9924284298281141, test_acc: 0.2896\n",
            "Epoch 310, BestLoss: 0.07278184590525491, Temperature 0.000334874767476815, step_size 0.9923291869851313, test_acc: 0.2869\n",
            "Epoch 311, BestLoss: 0.0725958737313594, Temperature 0.00031813102910297424, step_size 0.9922299540664328, test_acc: 0.2895\n",
            "Epoch 312, BestLoss: 0.0725958737313594, Temperature 0.0003022244776478255, step_size 0.9921307310710261, test_acc: 0.2895\n",
            "Epoch 313, BestLoss: 0.07284343294268991, Temperature 0.00031813102910297424, step_size 0.9923291869851313, test_acc: 0.2861\n",
            "Epoch 314, BestLoss: 0.07272444021759657, Temperature 0.0003022244776478255, step_size 0.9922299540664328, test_acc: 0.2903\n",
            "Epoch 315, BestLoss: 0.07272444021759657, Temperature 0.0002871132537654342, step_size 0.9921307310710261, test_acc: 0.2903\n",
            "Epoch 316, BestLoss: 0.07272444021759657, Temperature 0.0003022244776478255, step_size 0.9922299540664328, test_acc: 0.2903\n",
            "Epoch 317, BestLoss: 0.07196483743546059, Temperature 0.00031813102910297424, step_size 0.9921307310710261, test_acc: 0.2937\n",
            "Epoch 318, BestLoss: 0.07196483743546059, Temperature 0.0003022244776478255, step_size 0.992031517997919, test_acc: 0.2937\n",
            "Epoch 319, BestLoss: 0.07215765590924811, Temperature 0.00031813102910297424, step_size 0.992031517997919, test_acc: 0.2928\n",
            "Epoch 320, BestLoss: 0.07229005653076759, Temperature 0.0003022244776478255, step_size 0.9919323148461192, test_acc: 0.2914\n",
            "Epoch 321, BestLoss: 0.07222168085093401, Temperature 0.0002871132537654342, step_size 0.9918331216146347, test_acc: 0.2934\n",
            "Epoch 322, BestLoss: 0.07222376454131998, Temperature 0.00027275759107716247, step_size 0.9917339383024733, test_acc: 0.2924\n",
            "Epoch 323, BestLoss: 0.07206925418558993, Temperature 0.0002871132537654342, step_size 0.9919323148461192, test_acc: 0.2959\n",
            "Epoch 324, BestLoss: 0.07206925418558993, Temperature 0.00027275759107716247, step_size 0.9918331216146347, test_acc: 0.2959\n",
            "Epoch 325, BestLoss: 0.07206925418558993, Temperature 0.0002871132537654342, step_size 0.9918331216146347, test_acc: 0.2959\n",
            "Epoch 326, BestLoss: 0.07229127106340949, Temperature 0.0003022244776478255, step_size 0.9917339383024733, test_acc: 0.2933\n",
            "Epoch 327, BestLoss: 0.07229127106340949, Temperature 0.0002871132537654342, step_size 0.991634764908643, test_acc: 0.2933\n",
            "Epoch 328, BestLoss: 0.07229127106340949, Temperature 0.0003022244776478255, step_size 0.991634764908643, test_acc: 0.2933\n",
            "Epoch 329, BestLoss: 0.07230814641747782, Temperature 0.00031813102910297424, step_size 0.9915356014321521, test_acc: 0.291\n",
            "Epoch 330, BestLoss: 0.07225244294776056, Temperature 0.0003022244776478255, step_size 0.9914364478720089, test_acc: 0.292\n",
            "Epoch 331, BestLoss: 0.07229168176231382, Temperature 0.0002871132537654342, step_size 0.9913373042272218, test_acc: 0.2924\n",
            "Epoch 332, BestLoss: 0.07229168176231382, Temperature 0.00027275759107716247, step_size 0.9912381704967991, test_acc: 0.2924\n",
            "Epoch 333, BestLoss: 0.07241819520145053, Temperature 0.0002871132537654342, step_size 0.9914364478720089, test_acc: 0.2907\n",
            "Epoch 334, BestLoss: 0.07241819520145053, Temperature 0.00027275759107716247, step_size 0.9913373042272218, test_acc: 0.2907\n",
            "Epoch 335, BestLoss: 0.0719948617487321, Temperature 0.0002871132537654342, step_size 0.9913373042272218, test_acc: 0.2941\n",
            "Epoch 336, BestLoss: 0.0719948617487321, Temperature 0.00027275759107716247, step_size 0.9912381704967991, test_acc: 0.2941\n",
            "Epoch 337, BestLoss: 0.0718607060846595, Temperature 0.0002871132537654342, step_size 0.9912381704967991, test_acc: 0.2951\n",
            "Epoch 338, BestLoss: 0.07185985694003308, Temperature 0.00027275759107716247, step_size 0.9911390466797494, test_acc: 0.296\n",
            "Epoch 339, BestLoss: 0.07185985694003308, Temperature 0.0002871132537654342, step_size 0.9911390466797494, test_acc: 0.296\n",
            "Epoch 340, BestLoss: 0.07174043160810965, Temperature 0.0003022244776478255, step_size 0.9910399327750814, test_acc: 0.2978\n",
            "Epoch 341, BestLoss: 0.07174043160810965, Temperature 0.0002871132537654342, step_size 0.9909408287818039, test_acc: 0.2978\n",
            "Epoch 342, BestLoss: 0.07183247099647899, Temperature 0.0003022244776478255, step_size 0.9909408287818039, test_acc: 0.2976\n",
            "Epoch 343, BestLoss: 0.07119256968856072, Temperature 0.0002871132537654342, step_size 0.9908417346989258, test_acc: 0.3028\n",
            "Epoch 344, BestLoss: 0.07119256968856072, Temperature 0.00027275759107716247, step_size 0.9907426505254558, test_acc: 0.3028\n",
            "Epoch 345, BestLoss: 0.07119256968856072, Temperature 0.0002871132537654342, step_size 0.9908417346989258, test_acc: 0.3028\n",
            "Epoch 346, BestLoss: 0.07119256968856072, Temperature 0.0003022244776478255, step_size 0.9907426505254558, test_acc: 0.3028\n",
            "Epoch 347, BestLoss: 0.07119256968856072, Temperature 0.00031813102910297424, step_size 0.9906435762604033, test_acc: 0.3028\n",
            "Epoch 348, BestLoss: 0.07083918649381891, Temperature 0.000334874767476815, step_size 0.9905445119027773, test_acc: 0.308\n",
            "Epoch 349, BestLoss: 0.07080506434766101, Temperature 0.00031813102910297424, step_size 0.990445457451587, test_acc: 0.3075\n",
            "Epoch 350, BestLoss: 0.0704457155229796, Temperature 0.0003022244776478255, step_size 0.9903464129058418, test_acc: 0.3101\n",
            "Epoch 351, BestLoss: 0.06993668470424402, Temperature 0.0002871132537654342, step_size 0.9902473782645512, test_acc: 0.3152\n",
            "Epoch 352, BestLoss: 0.06950393133111653, Temperature 0.00027275759107716247, step_size 0.9901483535267248, test_acc: 0.3184\n",
            "Epoch 353, BestLoss: 0.06977030631265987, Temperature 0.00025911971152330434, step_size 0.9900493386913721, test_acc: 0.3176\n",
            "Epoch 354, BestLoss: 0.06889449912579979, Temperature 0.00024616372594713913, step_size 0.989950333757503, test_acc: 0.325\n",
            "Epoch 355, BestLoss: 0.06875084811886706, Temperature 0.00023385553964978215, step_size 0.9898513387241272, test_acc: 0.3291\n",
            "Epoch 356, BestLoss: 0.06851309467042122, Temperature 0.00022216276266729304, step_size 0.9897523535902548, test_acc: 0.3286\n",
            "Epoch 357, BestLoss: 0.0686848946276692, Temperature 0.00021105462453392839, step_size 0.9896533783548958, test_acc: 0.327\n",
            "Epoch 358, BestLoss: 0.0686848946276692, Temperature 0.00020050189330723196, step_size 0.9895544130170603, test_acc: 0.327\n",
            "Epoch 359, BestLoss: 0.06847949542142207, Temperature 0.00021105462453392839, step_size 0.990445457451587, test_acc: 0.3291\n",
            "Epoch 360, BestLoss: 0.06847949542142207, Temperature 0.00020050189330723196, step_size 0.9903464129058418, test_acc: 0.3291\n",
            "Epoch 361, BestLoss: 0.06861792675243439, Temperature 0.00021105462453392839, step_size 0.9903464129058418, test_acc: 0.3294\n",
            "Epoch 362, BestLoss: 0.06861792675243439, Temperature 0.00020050189330723196, step_size 0.9902473782645512, test_acc: 0.3294\n",
            "Epoch 363, BestLoss: 0.06861792675243439, Temperature 0.00021105462453392839, step_size 0.9902473782645512, test_acc: 0.3294\n",
            "Epoch 364, BestLoss: 0.06861792675243439, Temperature 0.00022216276266729304, step_size 0.9901483535267248, test_acc: 0.3294\n",
            "Epoch 365, BestLoss: 0.06861792675243439, Temperature 0.00023385553964978215, step_size 0.9900493386913721, test_acc: 0.3294\n",
            "Epoch 366, BestLoss: 0.06842965780841723, Temperature 0.00024616372594713913, step_size 0.989950333757503, test_acc: 0.3298\n",
            "Epoch 367, BestLoss: 0.06842965780841723, Temperature 0.00023385553964978215, step_size 0.9898513387241272, test_acc: 0.3298\n",
            "Epoch 368, BestLoss: 0.06842965780841723, Temperature 0.00024616372594713913, step_size 0.9898513387241272, test_acc: 0.3298\n",
            "Epoch 369, BestLoss: 0.06842965780841723, Temperature 0.00025911971152330434, step_size 0.9897523535902548, test_acc: 0.3298\n",
            "Epoch 370, BestLoss: 0.06867836233455385, Temperature 0.00027275759107716247, step_size 0.9896533783548958, test_acc: 0.3268\n",
            "Epoch 371, BestLoss: 0.06867836233455385, Temperature 0.00025911971152330434, step_size 0.9895544130170603, test_acc: 0.3268\n",
            "Epoch 372, BestLoss: 0.06854184995810693, Temperature 0.00027275759107716247, step_size 0.9895544130170603, test_acc: 0.3275\n",
            "Epoch 373, BestLoss: 0.06854184995810693, Temperature 0.00025911971152330434, step_size 0.9894554575757586, test_acc: 0.3275\n",
            "Epoch 374, BestLoss: 0.0684025863924957, Temperature 0.00027275759107716247, step_size 0.9894554575757586, test_acc: 0.3299\n",
            "Epoch 375, BestLoss: 0.06813747220404257, Temperature 0.00025911971152330434, step_size 0.9893565120300011, test_acc: 0.3309\n",
            "Epoch 376, BestLoss: 0.06806546198199505, Temperature 0.00024616372594713913, step_size 0.9892575763787981, test_acc: 0.3307\n",
            "Epoch 377, BestLoss: 0.06815928100635142, Temperature 0.00023385553964978215, step_size 0.9891586506211602, test_acc: 0.3313\n",
            "Epoch 378, BestLoss: 0.06815437798171343, Temperature 0.00022216276266729304, step_size 0.9890597347560981, test_acc: 0.331\n",
            "Epoch 379, BestLoss: 0.06774298475881599, Temperature 0.00023385553964978215, step_size 0.9893565120300011, test_acc: 0.335\n",
            "Epoch 380, BestLoss: 0.06690554497388565, Temperature 0.00022216276266729304, step_size 0.9892575763787981, test_acc: 0.342\n",
            "Epoch 381, BestLoss: 0.06690554497388565, Temperature 0.00021105462453392839, step_size 0.9891586506211602, test_acc: 0.342\n",
            "Epoch 382, BestLoss: 0.0674189471522239, Temperature 0.00022216276266729304, step_size 0.9892575763787981, test_acc: 0.3397\n",
            "Epoch 383, BestLoss: 0.0674189471522239, Temperature 0.00021105462453392839, step_size 0.9891586506211602, test_acc: 0.3397\n",
            "Epoch 384, BestLoss: 0.06727878378897624, Temperature 0.00022216276266729304, step_size 0.9891586506211602, test_acc: 0.3379\n",
            "Epoch 385, BestLoss: 0.06727878378897624, Temperature 0.00021105462453392839, step_size 0.9890597347560981, test_acc: 0.3379\n",
            "Epoch 386, BestLoss: 0.06727878378897624, Temperature 0.00022216276266729304, step_size 0.9890597347560981, test_acc: 0.3379\n",
            "Epoch 387, BestLoss: 0.06681741950879244, Temperature 0.00023385553964978215, step_size 0.9889608287826225, test_acc: 0.3423\n",
            "Epoch 388, BestLoss: 0.06661483289223581, Temperature 0.00022216276266729304, step_size 0.9888619326997442, test_acc: 0.3429\n",
            "Epoch 389, BestLoss: 0.06661483289223581, Temperature 0.00021105462453392839, step_size 0.9887630465064743, test_acc: 0.3429\n",
            "Epoch 390, BestLoss: 0.06661483289223581, Temperature 0.00022216276266729304, step_size 0.9888619326997442, test_acc: 0.3429\n",
            "Epoch 391, BestLoss: 0.06658253304519852, Temperature 0.00023385553964978215, step_size 0.9887630465064743, test_acc: 0.3437\n",
            "Epoch 392, BestLoss: 0.06658076222842904, Temperature 0.00022216276266729304, step_size 0.9886641702018236, test_acc: 0.3437\n",
            "Epoch 393, BestLoss: 0.06658076222842904, Temperature 0.00023385553964978215, step_size 0.9886641702018236, test_acc: 0.3437\n",
            "Epoch 394, BestLoss: 0.06602157724161517, Temperature 0.00024616372594713913, step_size 0.9885653037848035, test_acc: 0.3506\n",
            "Epoch 395, BestLoss: 0.06602157724161517, Temperature 0.00023385553964978215, step_size 0.988466447254425, test_acc: 0.3506\n",
            "Epoch 396, BestLoss: 0.065553980094839, Temperature 0.00024616372594713913, step_size 0.988466447254425, test_acc: 0.3568\n",
            "Epoch 397, BestLoss: 0.06552136934023069, Temperature 0.00023385553964978215, step_size 0.9883676006096995, test_acc: 0.3571\n",
            "Epoch 398, BestLoss: 0.06555937766807218, Temperature 0.00022216276266729304, step_size 0.9882687638496386, test_acc: 0.3586\n",
            "Epoch 399, BestLoss: 0.06555937766807218, Temperature 0.00021105462453392839, step_size 0.9881699369732536, test_acc: 0.3586\n",
            "Epoch 400, BestLoss: 0.06500839281558272, Temperature 0.00022216276266729304, step_size 0.9883676006096995, test_acc: 0.3618\n",
            "Epoch 401, BestLoss: 0.06511943515542147, Temperature 0.00021105462453392839, step_size 0.9882687638496386, test_acc: 0.361\n",
            "Epoch 402, BestLoss: 0.06480381927757005, Temperature 0.00020050189330723196, step_size 0.9881699369732536, test_acc: 0.3651\n",
            "Epoch 403, BestLoss: 0.06480381927757005, Temperature 0.00019047679864187035, step_size 0.9880711199795563, test_acc: 0.3651\n",
            "Epoch 404, BestLoss: 0.06480381927757005, Temperature 0.00020050189330723196, step_size 0.9882687638496386, test_acc: 0.3651\n",
            "Epoch 405, BestLoss: 0.06472002384706896, Temperature 0.00021105462453392839, step_size 0.9881699369732536, test_acc: 0.3667\n",
            "Epoch 406, BestLoss: 0.0645835336999088, Temperature 0.00020050189330723196, step_size 0.9880711199795563, test_acc: 0.3679\n",
            "Epoch 407, BestLoss: 0.0645835336999088, Temperature 0.00019047679864187035, step_size 0.9879723128675584, test_acc: 0.3679\n",
            "Epoch 408, BestLoss: 0.0645835336999088, Temperature 0.00020050189330723196, step_size 0.9880711199795563, test_acc: 0.3679\n",
            "Epoch 409, BestLoss: 0.0645835336999088, Temperature 0.00021105462453392839, step_size 0.9879723128675584, test_acc: 0.3679\n",
            "Epoch 410, BestLoss: 0.06441780568239197, Temperature 0.00022216276266729304, step_size 0.9878735156362717, test_acc: 0.3704\n",
            "Epoch 411, BestLoss: 0.06449685145242415, Temperature 0.00021105462453392839, step_size 0.987774728284708, test_acc: 0.3708\n",
            "Epoch 412, BestLoss: 0.06449685145242415, Temperature 0.00020050189330723196, step_size 0.9876759508118795, test_acc: 0.3708\n",
            "Epoch 413, BestLoss: 0.06406419329423216, Temperature 0.00021105462453392839, step_size 0.987774728284708, test_acc: 0.3751\n",
            "Epoch 414, BestLoss: 0.06407864895088372, Temperature 0.00020050189330723196, step_size 0.9876759508118795, test_acc: 0.3755\n",
            "Epoch 415, BestLoss: 0.06396181246066059, Temperature 0.00019047679864187035, step_size 0.9875771832167983, test_acc: 0.3763\n",
            "Epoch 416, BestLoss: 0.06396181246066059, Temperature 0.00018095295870977683, step_size 0.9874784254984766, test_acc: 0.3763\n",
            "Epoch 417, BestLoss: 0.06394312952013372, Temperature 0.00019047679864187035, step_size 0.9876759508118795, test_acc: 0.3762\n",
            "Epoch 418, BestLoss: 0.06394312952013372, Temperature 0.00018095295870977683, step_size 0.9875771832167983, test_acc: 0.3762\n",
            "Epoch 419, BestLoss: 0.06394312952013372, Temperature 0.00019047679864187035, step_size 0.9875771832167983, test_acc: 0.3762\n",
            "Epoch 420, BestLoss: 0.06394312952013372, Temperature 0.00020050189330723196, step_size 0.9874784254984766, test_acc: 0.3762\n",
            "Epoch 421, BestLoss: 0.06377177541392777, Temperature 0.00021105462453392839, step_size 0.9873796776559268, test_acc: 0.379\n",
            "Epoch 422, BestLoss: 0.06385760837988932, Temperature 0.00020050189330723196, step_size 0.9872809396881612, test_acc: 0.3765\n",
            "Epoch 423, BestLoss: 0.06341607704246839, Temperature 0.00019047679864187035, step_size 0.9871822115941924, test_acc: 0.381\n",
            "Epoch 424, BestLoss: 0.06334749307980726, Temperature 0.00018095295870977683, step_size 0.987083493373033, test_acc: 0.3827\n",
            "Epoch 425, BestLoss: 0.06336350252425361, Temperature 0.00017190531077428798, step_size 0.9869847850236957, test_acc: 0.3784\n",
            "Epoch 426, BestLoss: 0.06336350252425361, Temperature 0.00016331004523557357, step_size 0.9868860865451933, test_acc: 0.3784\n",
            "Epoch 427, BestLoss: 0.06336350252425361, Temperature 0.00017190531077428798, step_size 0.9872809396881612, test_acc: 0.3784\n",
            "Epoch 428, BestLoss: 0.06336350252425361, Temperature 0.00018095295870977683, step_size 0.9871822115941924, test_acc: 0.3784\n",
            "Epoch 429, BestLoss: 0.06336350252425361, Temperature 0.00019047679864187035, step_size 0.987083493373033, test_acc: 0.3784\n",
            "Epoch 430, BestLoss: 0.06326994708092114, Temperature 0.00020050189330723196, step_size 0.9869847850236957, test_acc: 0.3794\n",
            "Epoch 431, BestLoss: 0.06326994708092114, Temperature 0.00019047679864187035, step_size 0.9868860865451933, test_acc: 0.3794\n",
            "Epoch 432, BestLoss: 0.06326994708092114, Temperature 0.00020050189330723196, step_size 0.9868860865451933, test_acc: 0.3794\n",
            "Epoch 433, BestLoss: 0.06336468663117346, Temperature 0.00021105462453392839, step_size 0.9867873979365388, test_acc: 0.377\n",
            "Epoch 434, BestLoss: 0.06336468663117346, Temperature 0.00020050189330723196, step_size 0.9866887191967452, test_acc: 0.377\n",
            "Epoch 435, BestLoss: 0.06336468663117346, Temperature 0.00021105462453392839, step_size 0.9866887191967452, test_acc: 0.377\n",
            "Epoch 436, BestLoss: 0.06336468663117346, Temperature 0.00022216276266729304, step_size 0.9865900503248255, test_acc: 0.377\n",
            "Epoch 437, BestLoss: 0.06336468663117346, Temperature 0.00023385553964978215, step_size 0.986491391319793, test_acc: 0.377\n",
            "Epoch 438, BestLoss: 0.06330919058038999, Temperature 0.00024616372594713913, step_size 0.9863927421806611, test_acc: 0.3791\n",
            "Epoch 439, BestLoss: 0.06330919058038999, Temperature 0.00023385553964978215, step_size 0.986294102906443, test_acc: 0.3791\n",
            "Epoch 440, BestLoss: 0.06330919058038999, Temperature 0.00024616372594713913, step_size 0.986294102906443, test_acc: 0.3791\n",
            "Epoch 441, BestLoss: 0.06347698925367483, Temperature 0.00025911971152330434, step_size 0.9861954734961524, test_acc: 0.377\n",
            "Epoch 442, BestLoss: 0.06356639019822556, Temperature 0.00024616372594713913, step_size 0.9860968539488029, test_acc: 0.3769\n",
            "Epoch 443, BestLoss: 0.06356639019822556, Temperature 0.00023385553964978215, step_size 0.985998244263408, test_acc: 0.3769\n",
            "Epoch 444, BestLoss: 0.06356639019822556, Temperature 0.00024616372594713913, step_size 0.9860968539488029, test_acc: 0.3769\n",
            "Epoch 445, BestLoss: 0.06356639019822556, Temperature 0.00025911971152330434, step_size 0.985998244263408, test_acc: 0.3769\n",
            "Epoch 446, BestLoss: 0.06356639019822556, Temperature 0.00027275759107716247, step_size 0.9858996444389817, test_acc: 0.3769\n",
            "Epoch 447, BestLoss: 0.06356639019822556, Temperature 0.0002871132537654342, step_size 0.9858010544745378, test_acc: 0.3769\n",
            "Epoch 448, BestLoss: 0.06356639019822556, Temperature 0.0003022244776478255, step_size 0.9857024743690904, test_acc: 0.3769\n",
            "Epoch 449, BestLoss: 0.06356639019822556, Temperature 0.00031813102910297424, step_size 0.9856039041216536, test_acc: 0.3769\n",
            "Epoch 450, BestLoss: 0.06356639019822556, Temperature 0.000334874767476815, step_size 0.9855053437312414, test_acc: 0.3769\n",
            "Epoch 451, BestLoss: 0.06357928278110656, Temperature 0.00035249975523875265, step_size 0.9854067931968683, test_acc: 0.3787\n",
            "Epoch 452, BestLoss: 0.06357928278110656, Temperature 0.000334874767476815, step_size 0.9853082525175486, test_acc: 0.3787\n",
            "Epoch 453, BestLoss: 0.06352594355060845, Temperature 0.00035249975523875265, step_size 0.9853082525175486, test_acc: 0.3784\n",
            "Epoch 454, BestLoss: 0.06304327544491448, Temperature 0.000334874767476815, step_size 0.9852097216922968, test_acc: 0.381\n",
            "Epoch 455, BestLoss: 0.06314839918705141, Temperature 0.00031813102910297424, step_size 0.9851112007201276, test_acc: 0.3818\n",
            "Epoch 456, BestLoss: 0.06314839918705141, Temperature 0.0003022244776478255, step_size 0.9850126896000556, test_acc: 0.3818\n",
            "Epoch 457, BestLoss: 0.06292789488210201, Temperature 0.00031813102910297424, step_size 0.9852097216922968, test_acc: 0.3861\n",
            "Epoch 458, BestLoss: 0.06272223814873104, Temperature 0.0003022244776478255, step_size 0.9851112007201276, test_acc: 0.3861\n",
            "Epoch 459, BestLoss: 0.06315349971898543, Temperature 0.0002871132537654342, step_size 0.9850126896000556, test_acc: 0.3814\n",
            "Epoch 460, BestLoss: 0.06313287493724211, Temperature 0.00027275759107716247, step_size 0.9849141883310956, test_acc: 0.382\n",
            "Epoch 461, BestLoss: 0.06313287493724211, Temperature 0.00025911971152330434, step_size 0.9848156969122625, test_acc: 0.382\n",
            "Epoch 462, BestLoss: 0.06325953539343711, Temperature 0.00027275759107716247, step_size 0.9851112007201276, test_acc: 0.3798\n",
            "Epoch 463, BestLoss: 0.06315647451015073, Temperature 0.00025911971152330434, step_size 0.9850126896000556, test_acc: 0.3793\n",
            "Epoch 464, BestLoss: 0.06315647451015073, Temperature 0.00024616372594713913, step_size 0.9849141883310956, test_acc: 0.3793\n",
            "Epoch 465, BestLoss: 0.06314706442350812, Temperature 0.00025911971152330434, step_size 0.9850126896000556, test_acc: 0.381\n",
            "Epoch 466, BestLoss: 0.06298630499281721, Temperature 0.00024616372594713913, step_size 0.9849141883310956, test_acc: 0.3823\n",
            "Epoch 467, BestLoss: 0.06310452496096199, Temperature 0.00023385553964978215, step_size 0.9848156969122625, test_acc: 0.3785\n",
            "Epoch 468, BestLoss: 0.06300837674191774, Temperature 0.00022216276266729304, step_size 0.9847172153425713, test_acc: 0.3831\n",
            "Epoch 469, BestLoss: 0.06324435987647745, Temperature 0.00021105462453392839, step_size 0.9846187436210371, test_acc: 0.3785\n",
            "Epoch 470, BestLoss: 0.06353432197767257, Temperature 0.00020050189330723196, step_size 0.9845202817466749, test_acc: 0.3749\n",
            "Epoch 471, BestLoss: 0.06348128709720849, Temperature 0.00019047679864187035, step_size 0.9844218297185002, test_acc: 0.3769\n",
            "Epoch 472, BestLoss: 0.06347219275413958, Temperature 0.00018095295870977683, step_size 0.9843233875355284, test_acc: 0.3754\n",
            "Epoch 473, BestLoss: 0.06358867817001919, Temperature 0.00017190531077428798, step_size 0.9842249551967749, test_acc: 0.3744\n",
            "Epoch 474, BestLoss: 0.06357895345786908, Temperature 0.00016331004523557357, step_size 0.9841265327012553, test_acc: 0.3747\n",
            "Epoch 475, BestLoss: 0.06357895345786908, Temperature 0.00015514454297379488, step_size 0.9840281200479851, test_acc: 0.3747\n",
            "Epoch 476, BestLoss: 0.06354601679468301, Temperature 0.00016331004523557357, step_size 0.9849141883310956, test_acc: 0.3751\n",
            "Epoch 477, BestLoss: 0.06354601679468301, Temperature 0.00015514454297379488, step_size 0.9848156969122625, test_acc: 0.3751\n",
            "Epoch 478, BestLoss: 0.06354601679468301, Temperature 0.00016331004523557357, step_size 0.9848156969122625, test_acc: 0.3751\n",
            "Epoch 479, BestLoss: 0.06354601679468301, Temperature 0.00017190531077428798, step_size 0.9847172153425713, test_acc: 0.3751\n",
            "Epoch 480, BestLoss: 0.06326263293628141, Temperature 0.00018095295870977683, step_size 0.9846187436210371, test_acc: 0.3782\n",
            "Epoch 481, BestLoss: 0.06326263293628141, Temperature 0.00017190531077428798, step_size 0.9845202817466749, test_acc: 0.3782\n",
            "Epoch 482, BestLoss: 0.06328548125465205, Temperature 0.00018095295870977683, step_size 0.9845202817466749, test_acc: 0.377\n",
            "Epoch 483, BestLoss: 0.06328548125465205, Temperature 0.00017190531077428798, step_size 0.9844218297185002, test_acc: 0.377\n",
            "Epoch 484, BestLoss: 0.06328548125465205, Temperature 0.00018095295870977683, step_size 0.9844218297185002, test_acc: 0.377\n",
            "Epoch 485, BestLoss: 0.06340316128995506, Temperature 0.00019047679864187035, step_size 0.9843233875355284, test_acc: 0.3744\n",
            "Epoch 486, BestLoss: 0.0632750561263376, Temperature 0.00018095295870977683, step_size 0.9842249551967749, test_acc: 0.376\n",
            "Epoch 487, BestLoss: 0.06336236507204063, Temperature 0.00017190531077428798, step_size 0.9841265327012553, test_acc: 0.3767\n",
            "Epoch 488, BestLoss: 0.06336236507204063, Temperature 0.00016331004523557357, step_size 0.9840281200479851, test_acc: 0.3767\n",
            "Epoch 489, BestLoss: 0.06332477430373888, Temperature 0.00017190531077428798, step_size 0.9842249551967749, test_acc: 0.3759\n",
            "Epoch 490, BestLoss: 0.06332477430373888, Temperature 0.00016331004523557357, step_size 0.9841265327012553, test_acc: 0.3759\n",
            "Epoch 491, BestLoss: 0.06332477430373888, Temperature 0.00017190531077428798, step_size 0.9841265327012553, test_acc: 0.3759\n",
            "Epoch 492, BestLoss: 0.0633167168132584, Temperature 0.00018095295870977683, step_size 0.9840281200479851, test_acc: 0.3747\n",
            "Epoch 493, BestLoss: 0.0633167168132584, Temperature 0.00017190531077428798, step_size 0.9839297172359803, test_acc: 0.3747\n",
            "Epoch 494, BestLoss: 0.06327999194048974, Temperature 0.00018095295870977683, step_size 0.9839297172359803, test_acc: 0.3755\n",
            "Epoch 495, BestLoss: 0.06309428792069376, Temperature 0.00017190531077428798, step_size 0.9838313242642568, test_acc: 0.3772\n",
            "Epoch 496, BestLoss: 0.06331163278547348, Temperature 0.00016331004523557357, step_size 0.9837329411318304, test_acc: 0.3757\n",
            "Epoch 497, BestLoss: 0.06321133433114351, Temperature 0.00015514454297379488, step_size 0.9836345678377172, test_acc: 0.3778\n",
            "Epoch 498, BestLoss: 0.06321133433114351, Temperature 0.00014738731582510513, step_size 0.9835362043809335, test_acc: 0.3778\n",
            "Epoch 499, BestLoss: 0.06321133433114351, Temperature 0.00015514454297379488, step_size 0.9838313242642568, test_acc: 0.3778\n",
            "Epoch 500, BestLoss: 0.06321133433114351, Temperature 0.00016331004523557357, step_size 0.9837329411318304, test_acc: 0.3778\n",
            "Epoch 501, BestLoss: 0.06268657637520263, Temperature 0.00017190531077428798, step_size 0.9836345678377172, test_acc: 0.382\n",
            "Epoch 502, BestLoss: 0.06268657637520263, Temperature 0.00016331004523557357, step_size 0.9835362043809335, test_acc: 0.382\n",
            "Epoch 503, BestLoss: 0.06279534468352985, Temperature 0.00017190531077428798, step_size 0.9835362043809335, test_acc: 0.3803\n",
            "Epoch 504, BestLoss: 0.06279534468352985, Temperature 0.00016331004523557357, step_size 0.9834378507604954, test_acc: 0.3803\n",
            "Epoch 505, BestLoss: 0.06268709064225463, Temperature 0.00017190531077428798, step_size 0.9834378507604954, test_acc: 0.3849\n",
            "Epoch 506, BestLoss: 0.06232210280215713, Temperature 0.00016331004523557357, step_size 0.9833395069754194, test_acc: 0.3894\n",
            "Epoch 507, BestLoss: 0.062029343987117125, Temperature 0.00015514454297379488, step_size 0.9832411730247218, test_acc: 0.39\n",
            "Epoch 508, BestLoss: 0.062029343987117125, Temperature 0.00014738731582510513, step_size 0.9831428489074193, test_acc: 0.39\n",
            "Epoch 509, BestLoss: 0.061945984648650795, Temperature 0.00015514454297379488, step_size 0.9833395069754194, test_acc: 0.3903\n",
            "Epoch 510, BestLoss: 0.061945984648650795, Temperature 0.00014738731582510513, step_size 0.9832411730247218, test_acc: 0.3903\n",
            "Epoch 511, BestLoss: 0.061945984648650795, Temperature 0.00015514454297379488, step_size 0.9832411730247218, test_acc: 0.3903\n",
            "Epoch 512, BestLoss: 0.06186265097639233, Temperature 0.00016331004523557357, step_size 0.9831428489074193, test_acc: 0.3901\n",
            "Epoch 513, BestLoss: 0.06176219350711766, Temperature 0.00015514454297379488, step_size 0.9830445346225286, test_acc: 0.3926\n",
            "Epoch 514, BestLoss: 0.06192405502079952, Temperature 0.00014738731582510513, step_size 0.9829462301690663, test_acc: 0.3902\n",
            "Epoch 515, BestLoss: 0.062280469877108065, Temperature 0.00014001795003384986, step_size 0.9828479355460494, test_acc: 0.3864\n",
            "Epoch 516, BestLoss: 0.062280469877108065, Temperature 0.00013301705253215737, step_size 0.9827496507524949, test_acc: 0.3864\n",
            "Epoch 517, BestLoss: 0.062280469877108065, Temperature 0.00014001795003384986, step_size 0.9830445346225286, test_acc: 0.3864\n",
            "Epoch 518, BestLoss: 0.062404792565299794, Temperature 0.00014738731582510513, step_size 0.9829462301690663, test_acc: 0.3872\n",
            "Epoch 519, BestLoss: 0.06253843372567813, Temperature 0.00014001795003384986, step_size 0.9828479355460494, test_acc: 0.3852\n",
            "Epoch 520, BestLoss: 0.06253843372567813, Temperature 0.00013301705253215737, step_size 0.9827496507524949, test_acc: 0.3852\n",
            "Epoch 521, BestLoss: 0.06253843372567813, Temperature 0.00014001795003384986, step_size 0.9828479355460494, test_acc: 0.3852\n",
            "Epoch 522, BestLoss: 0.06253843372567813, Temperature 0.00014738731582510513, step_size 0.9827496507524949, test_acc: 0.3852\n",
            "Epoch 523, BestLoss: 0.06253843372567813, Temperature 0.00015514454297379488, step_size 0.9826513757874197, test_acc: 0.3852\n",
            "Epoch 524, BestLoss: 0.06253843372567813, Temperature 0.00016331004523557357, step_size 0.982553110649841, test_acc: 0.3852\n",
            "Epoch 525, BestLoss: 0.06243701494519009, Temperature 0.00017190531077428798, step_size 0.982454855338776, test_acc: 0.3857\n",
            "Epoch 526, BestLoss: 0.06243701494519009, Temperature 0.00016331004523557357, step_size 0.9823566098532421, test_acc: 0.3857\n",
            "Epoch 527, BestLoss: 0.0625608799406901, Temperature 0.00017190531077428798, step_size 0.9823566098532421, test_acc: 0.3855\n",
            "Epoch 528, BestLoss: 0.0623578927624223, Temperature 0.00016331004523557357, step_size 0.9822583741922568, test_acc: 0.3898\n",
            "Epoch 529, BestLoss: 0.0623578927624223, Temperature 0.00015514454297379488, step_size 0.9821601483548376, test_acc: 0.3898\n",
            "Epoch 530, BestLoss: 0.0623578927624223, Temperature 0.00016331004523557357, step_size 0.9822583741922568, test_acc: 0.3898\n",
            "Epoch 531, BestLoss: 0.06246053872793583, Temperature 0.00017190531077428798, step_size 0.9821601483548376, test_acc: 0.389\n",
            "Epoch 532, BestLoss: 0.06246053872793583, Temperature 0.00016331004523557357, step_size 0.982061932340002, test_acc: 0.389\n",
            "Epoch 533, BestLoss: 0.06242757041442705, Temperature 0.00017190531077428798, step_size 0.982061932340002, test_acc: 0.3886\n",
            "Epoch 534, BestLoss: 0.06233921967231506, Temperature 0.00016331004523557357, step_size 0.9819637261467681, test_acc: 0.3904\n",
            "Epoch 535, BestLoss: 0.062190250022050315, Temperature 0.00015514454297379488, step_size 0.9818655297741534, test_acc: 0.3916\n",
            "Epoch 536, BestLoss: 0.062190250022050315, Temperature 0.00014738731582510513, step_size 0.981767343221176, test_acc: 0.3916\n",
            "Epoch 537, BestLoss: 0.062190250022050315, Temperature 0.00015514454297379488, step_size 0.9819637261467681, test_acc: 0.3916\n",
            "Epoch 538, BestLoss: 0.06199393684261852, Temperature 0.00016331004523557357, step_size 0.9818655297741534, test_acc: 0.3916\n",
            "Epoch 539, BestLoss: 0.06199393684261852, Temperature 0.00015514454297379488, step_size 0.981767343221176, test_acc: 0.3916\n",
            "Epoch 540, BestLoss: 0.06194606405128963, Temperature 0.00016331004523557357, step_size 0.981767343221176, test_acc: 0.3928\n",
            "Epoch 541, BestLoss: 0.06194606405128963, Temperature 0.00015514454297379488, step_size 0.9816691664868539, test_acc: 0.3928\n",
            "Epoch 542, BestLoss: 0.061457518705515246, Temperature 0.00016331004523557357, step_size 0.9816691664868539, test_acc: 0.3952\n",
            "Epoch 543, BestLoss: 0.06155947900050366, Temperature 0.00015514454297379488, step_size 0.9815709995702052, test_acc: 0.3954\n",
            "Epoch 544, BestLoss: 0.06179654506155612, Temperature 0.00014738731582510513, step_size 0.9814728424702482, test_acc: 0.3935\n",
            "Epoch 545, BestLoss: 0.06190552487531537, Temperature 0.00014001795003384986, step_size 0.9813746951860012, test_acc: 0.3916\n",
            "Epoch 546, BestLoss: 0.06190552487531537, Temperature 0.00013301705253215737, step_size 0.9812765577164826, test_acc: 0.3916\n",
            "Epoch 547, BestLoss: 0.06190552487531537, Temperature 0.00014001795003384986, step_size 0.9815709995702052, test_acc: 0.3916\n",
            "Epoch 548, BestLoss: 0.06190552487531537, Temperature 0.00014738731582510513, step_size 0.9814728424702482, test_acc: 0.3916\n",
            "Epoch 549, BestLoss: 0.06190552487531537, Temperature 0.00015514454297379488, step_size 0.9813746951860012, test_acc: 0.3916\n",
            "Epoch 550, BestLoss: 0.06166206731663977, Temperature 0.00016331004523557357, step_size 0.9812765577164826, test_acc: 0.392\n",
            "Epoch 551, BestLoss: 0.0614220588804422, Temperature 0.00015514454297379488, step_size 0.9811784300607109, test_acc: 0.3949\n",
            "Epoch 552, BestLoss: 0.0614220588804422, Temperature 0.00014738731582510513, step_size 0.9810803122177049, test_acc: 0.3949\n",
            "Epoch 553, BestLoss: 0.0614220588804422, Temperature 0.00015514454297379488, step_size 0.9811784300607109, test_acc: 0.3949\n",
            "Epoch 554, BestLoss: 0.0614220588804422, Temperature 0.00016331004523557357, step_size 0.9810803122177049, test_acc: 0.3949\n",
            "Epoch 555, BestLoss: 0.061453278630738545, Temperature 0.00017190531077428798, step_size 0.9809822041864831, test_acc: 0.396\n",
            "Epoch 556, BestLoss: 0.0614038798346711, Temperature 0.00016331004523557357, step_size 0.9808841059660645, test_acc: 0.3956\n",
            "Epoch 557, BestLoss: 0.0614626418560613, Temperature 0.00015514454297379488, step_size 0.9807860175554679, test_acc: 0.3955\n",
            "Epoch 558, BestLoss: 0.06134587553915786, Temperature 0.00014738731582510513, step_size 0.9806879389537123, test_acc: 0.3936\n",
            "Epoch 559, BestLoss: 0.061469743063158624, Temperature 0.00014001795003384986, step_size 0.9805898701598169, test_acc: 0.3948\n",
            "Epoch 560, BestLoss: 0.06137589457898019, Temperature 0.00013301705253215737, step_size 0.9804918111728009, test_acc: 0.3938\n",
            "Epoch 561, BestLoss: 0.06115038657901875, Temperature 0.0001263661999055495, step_size 0.9803937619916837, test_acc: 0.3973\n",
            "Epoch 562, BestLoss: 0.06115038657901875, Temperature 0.000120047889910272, step_size 0.9802957226154846, test_acc: 0.3973\n",
            "Epoch 563, BestLoss: 0.06115038657901875, Temperature 0.0001263661999055495, step_size 0.9808841059660645, test_acc: 0.3973\n",
            "Epoch 564, BestLoss: 0.06115038657901875, Temperature 0.00013301705253215737, step_size 0.9807860175554679, test_acc: 0.3973\n",
            "Epoch 565, BestLoss: 0.06115038657901875, Temperature 0.00014001795003384986, step_size 0.9806879389537123, test_acc: 0.3973\n",
            "Epoch 566, BestLoss: 0.061005273431346756, Temperature 0.00014738731582510513, step_size 0.9805898701598169, test_acc: 0.4\n",
            "Epoch 567, BestLoss: 0.061005273431346756, Temperature 0.00014001795003384986, step_size 0.9804918111728009, test_acc: 0.4\n",
            "Epoch 568, BestLoss: 0.06106496235197148, Temperature 0.00014738731582510513, step_size 0.9804918111728009, test_acc: 0.4003\n",
            "Epoch 569, BestLoss: 0.061007962494657356, Temperature 0.00014001795003384986, step_size 0.9803937619916837, test_acc: 0.3996\n",
            "Epoch 570, BestLoss: 0.06119784312072227, Temperature 0.00013301705253215737, step_size 0.9802957226154846, test_acc: 0.3953\n",
            "Epoch 571, BestLoss: 0.06151681401022994, Temperature 0.0001263661999055495, step_size 0.980197693043223, test_acc: 0.3952\n",
            "Epoch 572, BestLoss: 0.06151681401022994, Temperature 0.000120047889910272, step_size 0.9800996732739187, test_acc: 0.3952\n",
            "Epoch 573, BestLoss: 0.06132464059063054, Temperature 0.0001263661999055495, step_size 0.9803937619916837, test_acc: 0.3963\n",
            "Epoch 574, BestLoss: 0.06132464059063054, Temperature 0.000120047889910272, step_size 0.9802957226154846, test_acc: 0.3963\n",
            "Epoch 575, BestLoss: 0.06115292352193211, Temperature 0.0001263661999055495, step_size 0.9802957226154846, test_acc: 0.3973\n",
            "Epoch 576, BestLoss: 0.06115292352193211, Temperature 0.000120047889910272, step_size 0.980197693043223, test_acc: 0.3973\n",
            "Epoch 577, BestLoss: 0.06115292352193211, Temperature 0.0001263661999055495, step_size 0.980197693043223, test_acc: 0.3973\n",
            "Epoch 578, BestLoss: 0.06115292352193211, Temperature 0.00013301705253215737, step_size 0.9800996732739187, test_acc: 0.3973\n",
            "Epoch 579, BestLoss: 0.061230629723463034, Temperature 0.00014001795003384986, step_size 0.9800016633065913, test_acc: 0.3957\n",
            "Epoch 580, BestLoss: 0.061156901272229926, Temperature 0.00013301705253215737, step_size 0.9799036631402607, test_acc: 0.3977\n",
            "Epoch 581, BestLoss: 0.061156901272229926, Temperature 0.0001263661999055495, step_size 0.9798056727739467, test_acc: 0.3977\n",
            "Epoch 582, BestLoss: 0.061156901272229926, Temperature 0.00013301705253215737, step_size 0.9799036631402607, test_acc: 0.3977\n",
            "Epoch 583, BestLoss: 0.061156901272229926, Temperature 0.00014001795003384986, step_size 0.9798056727739467, test_acc: 0.3977\n",
            "Epoch 584, BestLoss: 0.061214460481669376, Temperature 0.00014738731582510513, step_size 0.9797076922066693, test_acc: 0.397\n",
            "Epoch 585, BestLoss: 0.0612303973408049, Temperature 0.00014001795003384986, step_size 0.9796097214374486, test_acc: 0.3954\n",
            "Epoch 586, BestLoss: 0.0612303973408049, Temperature 0.00013301705253215737, step_size 0.9795117604653049, test_acc: 0.3954\n",
            "Epoch 587, BestLoss: 0.0612303973408049, Temperature 0.00014001795003384986, step_size 0.9796097214374486, test_acc: 0.3954\n",
            "Epoch 588, BestLoss: 0.0612303973408049, Temperature 0.00014738731582510513, step_size 0.9795117604653049, test_acc: 0.3954\n",
            "Epoch 589, BestLoss: 0.06118538486545942, Temperature 0.00015514454297379488, step_size 0.9794138092892584, test_acc: 0.397\n",
            "Epoch 590, BestLoss: 0.06118538486545942, Temperature 0.00014738731582510513, step_size 0.9793158679083295, test_acc: 0.397\n",
            "Epoch 591, BestLoss: 0.060955815168746194, Temperature 0.00015514454297379488, step_size 0.9793158679083295, test_acc: 0.4001\n",
            "Epoch 592, BestLoss: 0.060955815168746194, Temperature 0.00014738731582510513, step_size 0.9792179363215386, test_acc: 0.4001\n",
            "Epoch 593, BestLoss: 0.060955815168746194, Temperature 0.00015514454297379488, step_size 0.9792179363215386, test_acc: 0.4001\n",
            "Epoch 594, BestLoss: 0.060955815168746194, Temperature 0.00016331004523557357, step_size 0.9791200145279065, test_acc: 0.4001\n",
            "Epoch 595, BestLoss: 0.060955815168746194, Temperature 0.00017190531077428798, step_size 0.9790221025264537, test_acc: 0.4001\n",
            "Epoch 596, BestLoss: 0.060955815168746194, Temperature 0.00018095295870977683, step_size 0.9789242003162011, test_acc: 0.4001\n",
            "Epoch 597, BestLoss: 0.060955815168746194, Temperature 0.00019047679864187035, step_size 0.9788263078961694, test_acc: 0.4001\n",
            "Epoch 598, BestLoss: 0.06093730967158927, Temperature 0.00020050189330723196, step_size 0.9787284252653798, test_acc: 0.3993\n",
            "Epoch 599, BestLoss: 0.06098549869147993, Temperature 0.00019047679864187035, step_size 0.9786305524228534, test_acc: 0.3989\n",
            "Epoch 600, BestLoss: 0.06098549869147993, Temperature 0.00018095295870977683, step_size 0.9785326893676111, test_acc: 0.3989\n",
            "Epoch 601, BestLoss: 0.06060265122214703, Temperature 0.00019047679864187035, step_size 0.9786305524228534, test_acc: 0.4016\n",
            "Epoch 602, BestLoss: 0.06060265122214703, Temperature 0.00018095295870977683, step_size 0.9785326893676111, test_acc: 0.4016\n",
            "Epoch 603, BestLoss: 0.06060265122214703, Temperature 0.00019047679864187035, step_size 0.9785326893676111, test_acc: 0.4016\n",
            "Epoch 604, BestLoss: 0.06060265122214703, Temperature 0.00020050189330723196, step_size 0.9784348360986743, test_acc: 0.4016\n",
            "Epoch 605, BestLoss: 0.06060265122214703, Temperature 0.00021105462453392839, step_size 0.9783369926150645, test_acc: 0.4016\n",
            "Epoch 606, BestLoss: 0.06060265122214703, Temperature 0.00022216276266729304, step_size 0.9782391589158029, test_acc: 0.4016\n",
            "Epoch 607, BestLoss: 0.06060265122214703, Temperature 0.00023385553964978215, step_size 0.9781413349999114, test_acc: 0.4016\n",
            "Epoch 608, BestLoss: 0.06051897066416096, Temperature 0.00024616372594713913, step_size 0.9780435208664114, test_acc: 0.3996\n",
            "Epoch 609, BestLoss: 0.06051897066416096, Temperature 0.00023385553964978215, step_size 0.9779457165143248, test_acc: 0.3996\n",
            "Epoch 610, BestLoss: 0.06051897066416096, Temperature 0.00024616372594713913, step_size 0.9779457165143248, test_acc: 0.3996\n",
            "Epoch 611, BestLoss: 0.06065509014638628, Temperature 0.00025911971152330434, step_size 0.9778479219426734, test_acc: 0.3979\n",
            "Epoch 612, BestLoss: 0.06065509014638628, Temperature 0.00024616372594713913, step_size 0.9777501371504792, test_acc: 0.3979\n",
            "Epoch 613, BestLoss: 0.06100182004696616, Temperature 0.00025911971152330434, step_size 0.9777501371504792, test_acc: 0.3949\n",
            "Epoch 614, BestLoss: 0.06088968897408616, Temperature 0.00024616372594713913, step_size 0.9776523621367642, test_acc: 0.3958\n",
            "Epoch 615, BestLoss: 0.06085391002026941, Temperature 0.00023385553964978215, step_size 0.9775545969005506, test_acc: 0.3975\n",
            "Epoch 616, BestLoss: 0.06091064583118463, Temperature 0.00022216276266729304, step_size 0.9774568414408605, test_acc: 0.398\n",
            "Epoch 617, BestLoss: 0.06091064583118463, Temperature 0.00021105462453392839, step_size 0.9773590957567164, test_acc: 0.398\n",
            "Epoch 618, BestLoss: 0.060894175068568014, Temperature 0.00022216276266729304, step_size 0.9776523621367642, test_acc: 0.3979\n",
            "Epoch 619, BestLoss: 0.060894175068568014, Temperature 0.00021105462453392839, step_size 0.9775545969005506, test_acc: 0.3979\n",
            "Epoch 620, BestLoss: 0.061256487674273524, Temperature 0.00022216276266729304, step_size 0.9775545969005506, test_acc: 0.3937\n",
            "Epoch 621, BestLoss: 0.061256487674273524, Temperature 0.00021105462453392839, step_size 0.9774568414408605, test_acc: 0.3937\n",
            "Epoch 622, BestLoss: 0.061038731127107115, Temperature 0.00022216276266729304, step_size 0.9774568414408605, test_acc: 0.3951\n",
            "Epoch 623, BestLoss: 0.061038731127107115, Temperature 0.00021105462453392839, step_size 0.9773590957567164, test_acc: 0.3951\n",
            "Epoch 624, BestLoss: 0.061038731127107115, Temperature 0.00022216276266729304, step_size 0.9773590957567164, test_acc: 0.3951\n",
            "Epoch 625, BestLoss: 0.061038731127107115, Temperature 0.00023385553964978215, step_size 0.9772613598471408, test_acc: 0.3951\n",
            "Epoch 626, BestLoss: 0.06100749178023826, Temperature 0.00024616372594713913, step_size 0.9771636337111561, test_acc: 0.3972\n",
            "Epoch 627, BestLoss: 0.061319279615647974, Temperature 0.00023385553964978215, step_size 0.977065917347785, test_acc: 0.3913\n",
            "Epoch 628, BestLoss: 0.06117220821127497, Temperature 0.00022216276266729304, step_size 0.9769682107560502, test_acc: 0.3952\n",
            "Epoch 629, BestLoss: 0.06124488267780712, Temperature 0.00021105462453392839, step_size 0.9768705139349746, test_acc: 0.3934\n",
            "Epoch 630, BestLoss: 0.06118230236246663, Temperature 0.00020050189330723196, step_size 0.9767728268835811, test_acc: 0.3958\n",
            "Epoch 631, BestLoss: 0.06118230236246663, Temperature 0.00019047679864187035, step_size 0.9766751496008927, test_acc: 0.3958\n",
            "Epoch 632, BestLoss: 0.06118230236246663, Temperature 0.00020050189330723196, step_size 0.977065917347785, test_acc: 0.3958\n",
            "Epoch 633, BestLoss: 0.06101489493108713, Temperature 0.00021105462453392839, step_size 0.9769682107560502, test_acc: 0.3974\n",
            "Epoch 634, BestLoss: 0.06101489493108713, Temperature 0.00020050189330723196, step_size 0.9768705139349746, test_acc: 0.3974\n",
            "Epoch 635, BestLoss: 0.06101489493108713, Temperature 0.00021105462453392839, step_size 0.9768705139349746, test_acc: 0.3974\n",
            "Epoch 636, BestLoss: 0.0610925783502356, Temperature 0.00022216276266729304, step_size 0.9767728268835811, test_acc: 0.3954\n",
            "Epoch 637, BestLoss: 0.06125769677624713, Temperature 0.00021105462453392839, step_size 0.9766751496008927, test_acc: 0.3953\n",
            "Epoch 638, BestLoss: 0.061396204945559946, Temperature 0.00020050189330723196, step_size 0.9765774820859326, test_acc: 0.3939\n",
            "Epoch 639, BestLoss: 0.061290606480328476, Temperature 0.00019047679864187035, step_size 0.9764798243377241, test_acc: 0.3946\n",
            "Epoch 640, BestLoss: 0.061473574319886856, Temperature 0.00018095295870977683, step_size 0.9763821763552903, test_acc: 0.3927\n",
            "Epoch 641, BestLoss: 0.061473574319886856, Temperature 0.00017190531077428798, step_size 0.9762845381376548, test_acc: 0.3927\n",
            "Epoch 642, BestLoss: 0.06141707502364994, Temperature 0.00018095295870977683, step_size 0.9766751496008927, test_acc: 0.394\n",
            "Epoch 643, BestLoss: 0.061597167110962206, Temperature 0.00017190531077428798, step_size 0.9765774820859326, test_acc: 0.3897\n",
            "Epoch 644, BestLoss: 0.061597167110962206, Temperature 0.00016331004523557357, step_size 0.9764798243377241, test_acc: 0.3897\n",
            "Epoch 645, BestLoss: 0.061597167110962206, Temperature 0.00017190531077428798, step_size 0.9765774820859326, test_acc: 0.3897\n",
            "Epoch 646, BestLoss: 0.061597167110962206, Temperature 0.00018095295870977683, step_size 0.9764798243377241, test_acc: 0.3897\n",
            "Epoch 647, BestLoss: 0.061607528107205614, Temperature 0.00019047679864187035, step_size 0.9763821763552903, test_acc: 0.3915\n",
            "Epoch 648, BestLoss: 0.061607528107205614, Temperature 0.00018095295870977683, step_size 0.9762845381376548, test_acc: 0.3915\n",
            "Epoch 649, BestLoss: 0.06148719309828404, Temperature 0.00019047679864187035, step_size 0.9762845381376548, test_acc: 0.3908\n",
            "Epoch 650, BestLoss: 0.061554619776033576, Temperature 0.00018095295870977683, step_size 0.976186909683841, test_acc: 0.3917\n",
            "Epoch 651, BestLoss: 0.061472153471491826, Temperature 0.00017190531077428798, step_size 0.9760892909928727, test_acc: 0.3926\n",
            "Epoch 652, BestLoss: 0.06121886867404433, Temperature 0.00016331004523557357, step_size 0.9759916820637734, test_acc: 0.3939\n",
            "Epoch 653, BestLoss: 0.061392704571035454, Temperature 0.00015514454297379488, step_size 0.975894082895567, test_acc: 0.3939\n",
            "Epoch 654, BestLoss: 0.061392704571035454, Temperature 0.00014738731582510513, step_size 0.9757964934872775, test_acc: 0.3939\n",
            "Epoch 655, BestLoss: 0.061392704571035454, Temperature 0.00015514454297379488, step_size 0.976186909683841, test_acc: 0.3939\n",
            "Epoch 656, BestLoss: 0.06139585128307823, Temperature 0.00016331004523557357, step_size 0.9760892909928727, test_acc: 0.3947\n",
            "Epoch 657, BestLoss: 0.061416270077097795, Temperature 0.00017190531077428798, step_size 0.9759916820637734, test_acc: 0.3953\n",
            "Epoch 658, BestLoss: 0.06153856822198034, Temperature 0.00016331004523557357, step_size 0.975894082895567, test_acc: 0.3927\n",
            "Epoch 659, BestLoss: 0.06153856822198034, Temperature 0.00015514454297379488, step_size 0.9757964934872775, test_acc: 0.3927\n",
            "Epoch 660, BestLoss: 0.06153856822198034, Temperature 0.00016331004523557357, step_size 0.975894082895567, test_acc: 0.3927\n",
            "Epoch 661, BestLoss: 0.06137469536160383, Temperature 0.00017190531077428798, step_size 0.9757964934872775, test_acc: 0.3939\n",
            "Epoch 662, BestLoss: 0.06137469536160383, Temperature 0.00016331004523557357, step_size 0.9756989138379287, test_acc: 0.3939\n",
            "Epoch 663, BestLoss: 0.06137469536160383, Temperature 0.00017190531077428798, step_size 0.9756989138379287, test_acc: 0.3939\n",
            "Epoch 664, BestLoss: 0.06141064427557074, Temperature 0.00018095295870977683, step_size 0.975601343946545, test_acc: 0.393\n",
            "Epoch 665, BestLoss: 0.06141064427557074, Temperature 0.00017190531077428798, step_size 0.9755037838121503, test_acc: 0.393\n",
            "Epoch 666, BestLoss: 0.061722071139807134, Temperature 0.00018095295870977683, step_size 0.9755037838121503, test_acc: 0.393\n",
            "Epoch 667, BestLoss: 0.0615258683602258, Temperature 0.00017190531077428798, step_size 0.9754062334337691, test_acc: 0.3943\n",
            "Epoch 668, BestLoss: 0.061230058650718774, Temperature 0.00016331004523557357, step_size 0.9753086928104258, test_acc: 0.3987\n",
            "Epoch 669, BestLoss: 0.061230058650718774, Temperature 0.00015514454297379488, step_size 0.9752111619411448, test_acc: 0.3987\n",
            "Epoch 670, BestLoss: 0.06098388992072687, Temperature 0.00016331004523557357, step_size 0.9754062334337691, test_acc: 0.3994\n",
            "Epoch 671, BestLoss: 0.06098388992072687, Temperature 0.00015514454297379488, step_size 0.9753086928104258, test_acc: 0.3994\n",
            "Epoch 672, BestLoss: 0.06098388992072687, Temperature 0.00016331004523557357, step_size 0.9753086928104258, test_acc: 0.3994\n",
            "Epoch 673, BestLoss: 0.06115358908736273, Temperature 0.00017190531077428798, step_size 0.9752111619411448, test_acc: 0.3995\n",
            "Epoch 674, BestLoss: 0.06115358908736273, Temperature 0.00016331004523557357, step_size 0.9751136408249507, test_acc: 0.3995\n",
            "Epoch 675, BestLoss: 0.06100113351907482, Temperature 0.00017190531077428798, step_size 0.9751136408249507, test_acc: 0.4014\n",
            "Epoch 676, BestLoss: 0.06089480341111203, Temperature 0.00016331004523557357, step_size 0.9750161294608681, test_acc: 0.402\n",
            "Epoch 677, BestLoss: 0.06103902107432909, Temperature 0.00015514454297379488, step_size 0.974918627847922, test_acc: 0.3993\n",
            "Epoch 678, BestLoss: 0.06103902107432909, Temperature 0.00014738731582510513, step_size 0.9748211359851373, test_acc: 0.3993\n",
            "Epoch 679, BestLoss: 0.06102811503159817, Temperature 0.00015514454297379488, step_size 0.9750161294608681, test_acc: 0.3995\n",
            "Epoch 680, BestLoss: 0.06122310507398683, Temperature 0.00014738731582510513, step_size 0.974918627847922, test_acc: 0.4008\n",
            "Epoch 681, BestLoss: 0.06122310507398683, Temperature 0.00014001795003384986, step_size 0.9748211359851373, test_acc: 0.4008\n",
            "Epoch 682, BestLoss: 0.06122310507398683, Temperature 0.00014738731582510513, step_size 0.974918627847922, test_acc: 0.4008\n",
            "Epoch 683, BestLoss: 0.06122310507398683, Temperature 0.00015514454297379488, step_size 0.9748211359851373, test_acc: 0.4008\n",
            "Epoch 684, BestLoss: 0.06086567702865325, Temperature 0.00016331004523557357, step_size 0.9747236538715388, test_acc: 0.4057\n",
            "Epoch 685, BestLoss: 0.06086567702865325, Temperature 0.00015514454297379488, step_size 0.9746261815061517, test_acc: 0.4057\n",
            "Epoch 686, BestLoss: 0.06086567702865325, Temperature 0.00016331004523557357, step_size 0.9746261815061517, test_acc: 0.4057\n",
            "Epoch 687, BestLoss: 0.06061109007351311, Temperature 0.00017190531077428798, step_size 0.9745287188880011, test_acc: 0.4086\n",
            "Epoch 688, BestLoss: 0.06061109007351311, Temperature 0.00016331004523557357, step_size 0.9744312660161123, test_acc: 0.4086\n",
            "Epoch 689, BestLoss: 0.06064482809523927, Temperature 0.00017190531077428798, step_size 0.9744312660161123, test_acc: 0.4104\n",
            "Epoch 690, BestLoss: 0.06064482809523927, Temperature 0.00016331004523557357, step_size 0.9743338228895106, test_acc: 0.4104\n",
            "Epoch 691, BestLoss: 0.06064482809523927, Temperature 0.00017190531077428798, step_size 0.9743338228895106, test_acc: 0.4104\n",
            "Epoch 692, BestLoss: 0.06057451755852561, Temperature 0.00018095295870977683, step_size 0.9742363895072217, test_acc: 0.4089\n",
            "Epoch 693, BestLoss: 0.060605656469098323, Temperature 0.00017190531077428798, step_size 0.974138965868271, test_acc: 0.4078\n",
            "Epoch 694, BestLoss: 0.060605656469098323, Temperature 0.00016331004523557357, step_size 0.9740415519716842, test_acc: 0.4078\n",
            "Epoch 695, BestLoss: 0.06061047483916649, Temperature 0.00017190531077428798, step_size 0.974138965868271, test_acc: 0.4082\n",
            "Epoch 696, BestLoss: 0.06084241167360255, Temperature 0.00018095295870977683, step_size 0.9740415519716842, test_acc: 0.4073\n",
            "Epoch 697, BestLoss: 0.060764489535816014, Temperature 0.00017190531077428798, step_size 0.973944147816487, test_acc: 0.4074\n",
            "Epoch 698, BestLoss: 0.06071382452076536, Temperature 0.00016331004523557357, step_size 0.9738467534017053, test_acc: 0.4072\n",
            "Epoch 699, BestLoss: 0.06076906029956789, Temperature 0.00015514454297379488, step_size 0.9737493687263652, test_acc: 0.4071\n",
            "Epoch 700, BestLoss: 0.06031368620620655, Temperature 0.00014738731582510513, step_size 0.9736519937894925, test_acc: 0.4101\n",
            "Epoch 701, BestLoss: 0.06031368620620655, Temperature 0.00014001795003384986, step_size 0.9735546285901135, test_acc: 0.4101\n",
            "Epoch 702, BestLoss: 0.06031368620620655, Temperature 0.00014738731582510513, step_size 0.973944147816487, test_acc: 0.4101\n",
            "Epoch 703, BestLoss: 0.06031368620620655, Temperature 0.00015514454297379488, step_size 0.9738467534017053, test_acc: 0.4101\n",
            "Epoch 704, BestLoss: 0.06028375620928262, Temperature 0.00016331004523557357, step_size 0.9737493687263652, test_acc: 0.4114\n",
            "Epoch 705, BestLoss: 0.06028375620928262, Temperature 0.00015514454297379488, step_size 0.9736519937894925, test_acc: 0.4114\n",
            "Epoch 706, BestLoss: 0.06028375620928262, Temperature 0.00016331004523557357, step_size 0.9736519937894925, test_acc: 0.4114\n",
            "Epoch 707, BestLoss: 0.06048785271454884, Temperature 0.00017190531077428798, step_size 0.9735546285901135, test_acc: 0.4102\n",
            "Epoch 708, BestLoss: 0.060365714937531886, Temperature 0.00016331004523557357, step_size 0.9734572731272545, test_acc: 0.4122\n",
            "Epoch 709, BestLoss: 0.060365714937531886, Temperature 0.00015514454297379488, step_size 0.9733599273999418, test_acc: 0.4122\n",
            "Epoch 710, BestLoss: 0.060365714937531886, Temperature 0.00016331004523557357, step_size 0.9734572731272545, test_acc: 0.4122\n",
            "Epoch 711, BestLoss: 0.0602142899363247, Temperature 0.00017190531077428798, step_size 0.9733599273999418, test_acc: 0.4141\n",
            "Epoch 712, BestLoss: 0.06050508233829073, Temperature 0.00016331004523557357, step_size 0.9732625914072018, test_acc: 0.4102\n",
            "Epoch 713, BestLoss: 0.06050508233829073, Temperature 0.00015514454297379488, step_size 0.9731652651480611, test_acc: 0.4102\n",
            "Epoch 714, BestLoss: 0.06049746762869821, Temperature 0.00016331004523557357, step_size 0.9732625914072018, test_acc: 0.4119\n",
            "Epoch 715, BestLoss: 0.06040813411407161, Temperature 0.00015514454297379488, step_size 0.9731652651480611, test_acc: 0.4108\n",
            "Epoch 716, BestLoss: 0.060316855275238584, Temperature 0.00014738731582510513, step_size 0.9730679486215463, test_acc: 0.4125\n",
            "Epoch 717, BestLoss: 0.060591006306801025, Temperature 0.00014001795003384986, step_size 0.9729706418266841, test_acc: 0.4102\n",
            "Epoch 718, BestLoss: 0.06064953508089676, Temperature 0.00013301705253215737, step_size 0.9728733447625014, test_acc: 0.4082\n",
            "Epoch 719, BestLoss: 0.06051567628607871, Temperature 0.0001263661999055495, step_size 0.9727760574280252, test_acc: 0.4104\n",
            "Epoch 720, BestLoss: 0.06051567628607871, Temperature 0.000120047889910272, step_size 0.9726787798222825, test_acc: 0.4104\n",
            "Epoch 721, BestLoss: 0.060497110482813414, Temperature 0.0001263661999055495, step_size 0.9731652651480611, test_acc: 0.41\n",
            "Epoch 722, BestLoss: 0.060497110482813414, Temperature 0.000120047889910272, step_size 0.9730679486215463, test_acc: 0.41\n",
            "Epoch 723, BestLoss: 0.060497110482813414, Temperature 0.0001263661999055495, step_size 0.9730679486215463, test_acc: 0.41\n",
            "Epoch 724, BestLoss: 0.060497110482813414, Temperature 0.00013301705253215737, step_size 0.9729706418266841, test_acc: 0.41\n",
            "Epoch 725, BestLoss: 0.060497110482813414, Temperature 0.00014001795003384986, step_size 0.9728733447625014, test_acc: 0.41\n",
            "Epoch 726, BestLoss: 0.06033380481381944, Temperature 0.00014738731582510513, step_size 0.9727760574280252, test_acc: 0.4133\n",
            "Epoch 727, BestLoss: 0.06045311894499861, Temperature 0.00014001795003384986, step_size 0.9726787798222825, test_acc: 0.4138\n",
            "Epoch 728, BestLoss: 0.060492331543720135, Temperature 0.00013301705253215737, step_size 0.9725815119443002, test_acc: 0.4133\n",
            "Epoch 729, BestLoss: 0.06029438190581542, Temperature 0.0001263661999055495, step_size 0.9724842537931058, test_acc: 0.4132\n",
            "Epoch 730, BestLoss: 0.0602141048018044, Temperature 0.000120047889910272, step_size 0.9723870053677265, test_acc: 0.4132\n",
            "Epoch 731, BestLoss: 0.0602141048018044, Temperature 0.0001140454954147584, step_size 0.9722897666671897, test_acc: 0.4132\n",
            "Epoch 732, BestLoss: 0.06032717596574883, Temperature 0.000120047889910272, step_size 0.9726787798222825, test_acc: 0.4115\n",
            "Epoch 733, BestLoss: 0.06032717596574883, Temperature 0.0001140454954147584, step_size 0.9725815119443002, test_acc: 0.4115\n",
            "Epoch 734, BestLoss: 0.06032717596574883, Temperature 0.000120047889910272, step_size 0.9725815119443002, test_acc: 0.4115\n",
            "Epoch 735, BestLoss: 0.06032717596574883, Temperature 0.0001263661999055495, step_size 0.9724842537931058, test_acc: 0.4115\n",
            "Epoch 736, BestLoss: 0.06023112791537482, Temperature 0.00013301705253215737, step_size 0.9723870053677265, test_acc: 0.4103\n",
            "Epoch 737, BestLoss: 0.06049533919410922, Temperature 0.0001263661999055495, step_size 0.9722897666671897, test_acc: 0.4077\n",
            "Epoch 738, BestLoss: 0.06049533919410922, Temperature 0.000120047889910272, step_size 0.9721925376905229, test_acc: 0.4077\n",
            "Epoch 739, BestLoss: 0.06006689108584133, Temperature 0.0001263661999055495, step_size 0.9722897666671897, test_acc: 0.4106\n",
            "Epoch 740, BestLoss: 0.06006689108584133, Temperature 0.000120047889910272, step_size 0.9721925376905229, test_acc: 0.4106\n",
            "Epoch 741, BestLoss: 0.06017333014019908, Temperature 0.0001263661999055495, step_size 0.9721925376905229, test_acc: 0.4133\n",
            "Epoch 742, BestLoss: 0.060136761559027196, Temperature 0.000120047889910272, step_size 0.9720953184367539, test_acc: 0.411\n",
            "Epoch 743, BestLoss: 0.0597139300716364, Temperature 0.0001140454954147584, step_size 0.9719981089049102, test_acc: 0.4148\n",
            "Epoch 744, BestLoss: 0.05975828891066817, Temperature 0.00010834322064402047, step_size 0.9719009090940197, test_acc: 0.4144\n",
            "Epoch 745, BestLoss: 0.05975828891066817, Temperature 0.00010292605961181944, step_size 0.9718037190031104, test_acc: 0.4144\n",
            "Epoch 746, BestLoss: 0.05975828891066817, Temperature 0.00010834322064402047, step_size 0.9720953184367539, test_acc: 0.4144\n",
            "Epoch 747, BestLoss: 0.05979190878103856, Temperature 0.0001140454954147584, step_size 0.9719981089049102, test_acc: 0.4123\n",
            "Epoch 748, BestLoss: 0.0599117142799773, Temperature 0.00010834322064402047, step_size 0.9719009090940197, test_acc: 0.4102\n",
            "Epoch 749, BestLoss: 0.05985388002762156, Temperature 0.00010292605961181944, step_size 0.9718037190031104, test_acc: 0.4104\n",
            "Epoch 750, BestLoss: 0.05985388002762156, Temperature 9.777975663122846e-05, step_size 0.97170653863121, test_acc: 0.4104\n",
            "Epoch 751, BestLoss: 0.05982838558009299, Temperature 0.00010292605961181944, step_size 0.9719009090940197, test_acc: 0.4108\n",
            "Epoch 752, BestLoss: 0.05968974832548529, Temperature 9.777975663122846e-05, step_size 0.9718037190031104, test_acc: 0.4102\n",
            "Epoch 753, BestLoss: 0.05968974832548529, Temperature 9.289076879966704e-05, step_size 0.97170653863121, test_acc: 0.4102\n",
            "Epoch 754, BestLoss: 0.05968974832548529, Temperature 9.777975663122846e-05, step_size 0.9718037190031104, test_acc: 0.4102\n",
            "Epoch 755, BestLoss: 0.05968974832548529, Temperature 0.00010292605961181944, step_size 0.97170653863121, test_acc: 0.4102\n",
            "Epoch 756, BestLoss: 0.05981352351169442, Temperature 0.00010834322064402047, step_size 0.9716093679773469, test_acc: 0.4094\n",
            "Epoch 757, BestLoss: 0.05981352351169442, Temperature 0.00010292605961181944, step_size 0.9715122070405492, test_acc: 0.4094\n",
            "Epoch 758, BestLoss: 0.05981352351169442, Temperature 0.00010834322064402047, step_size 0.9715122070405492, test_acc: 0.4094\n",
            "Epoch 759, BestLoss: 0.05981152130993107, Temperature 0.0001140454954147584, step_size 0.9714150558198451, test_acc: 0.4086\n",
            "Epoch 760, BestLoss: 0.059750200473045106, Temperature 0.000120047889910272, step_size 0.9713179143142632, test_acc: 0.4089\n",
            "Epoch 761, BestLoss: 0.059750200473045106, Temperature 0.0001140454954147584, step_size 0.9712207825228317, test_acc: 0.4089\n",
            "Epoch 762, BestLoss: 0.059750200473045106, Temperature 0.000120047889910272, step_size 0.9712207825228317, test_acc: 0.4089\n",
            "Epoch 763, BestLoss: 0.059750200473045106, Temperature 0.0001263661999055495, step_size 0.9711236604445794, test_acc: 0.4089\n",
            "Epoch 764, BestLoss: 0.059750200473045106, Temperature 0.00013301705253215737, step_size 0.971026548078535, test_acc: 0.4089\n",
            "Epoch 765, BestLoss: 0.060158580267113064, Temperature 0.00014001795003384986, step_size 0.9709294454237271, test_acc: 0.4058\n",
            "Epoch 766, BestLoss: 0.060158580267113064, Temperature 0.00013301705253215737, step_size 0.9708323524791846, test_acc: 0.4058\n",
            "Epoch 767, BestLoss: 0.060158580267113064, Temperature 0.00014001795003384986, step_size 0.9708323524791846, test_acc: 0.4058\n",
            "Epoch 768, BestLoss: 0.06003176936210126, Temperature 0.00014738731582510513, step_size 0.9707352692439367, test_acc: 0.4078\n",
            "Epoch 769, BestLoss: 0.060142346764338994, Temperature 0.00014001795003384986, step_size 0.9706381957170124, test_acc: 0.4078\n",
            "Epoch 770, BestLoss: 0.06007931445649934, Temperature 0.00013301705253215737, step_size 0.9705411318974407, test_acc: 0.408\n",
            "Epoch 771, BestLoss: 0.05979436306994906, Temperature 0.0001263661999055495, step_size 0.970444077784251, test_acc: 0.4106\n",
            "Epoch 772, BestLoss: 0.05979436306994906, Temperature 0.000120047889910272, step_size 0.9703470333764725, test_acc: 0.4106\n",
            "Epoch 773, BestLoss: 0.05979436306994906, Temperature 0.0001263661999055495, step_size 0.9706381957170124, test_acc: 0.4106\n",
            "Epoch 774, BestLoss: 0.05979436306994906, Temperature 0.00013301705253215737, step_size 0.9705411318974407, test_acc: 0.4106\n",
            "Epoch 775, BestLoss: 0.05979436306994906, Temperature 0.00014001795003384986, step_size 0.970444077784251, test_acc: 0.4106\n",
            "Epoch 776, BestLoss: 0.05979436306994906, Temperature 0.00014738731582510513, step_size 0.9703470333764725, test_acc: 0.4106\n",
            "Epoch 777, BestLoss: 0.05979436306994906, Temperature 0.00015514454297379488, step_size 0.9702499986731349, test_acc: 0.4106\n",
            "Epoch 778, BestLoss: 0.05979436306994906, Temperature 0.00016331004523557357, step_size 0.9701529736732676, test_acc: 0.4106\n",
            "Epoch 779, BestLoss: 0.05966857201212008, Temperature 0.00017190531077428798, step_size 0.9700559583759003, test_acc: 0.4122\n",
            "Epoch 780, BestLoss: 0.05966857201212008, Temperature 0.00016331004523557357, step_size 0.9699589527800627, test_acc: 0.4122\n",
            "Epoch 781, BestLoss: 0.059798004671830905, Temperature 0.00017190531077428798, step_size 0.9699589527800627, test_acc: 0.4091\n",
            "Epoch 782, BestLoss: 0.059798004671830905, Temperature 0.00016331004523557357, step_size 0.9698619568847847, test_acc: 0.4091\n",
            "Epoch 783, BestLoss: 0.05957601071212022, Temperature 0.00017190531077428798, step_size 0.9698619568847847, test_acc: 0.4116\n",
            "Epoch 784, BestLoss: 0.05992962598226174, Temperature 0.00016331004523557357, step_size 0.9697649706890963, test_acc: 0.4086\n",
            "Epoch 785, BestLoss: 0.060188267348227735, Temperature 0.00015514454297379488, step_size 0.9696679941920274, test_acc: 0.4035\n",
            "Epoch 786, BestLoss: 0.060188267348227735, Temperature 0.00014738731582510513, step_size 0.9695710273926083, test_acc: 0.4035\n",
            "Epoch 787, BestLoss: 0.060090124720940115, Temperature 0.00015514454297379488, step_size 0.9697649706890963, test_acc: 0.4055\n",
            "Epoch 788, BestLoss: 0.060090124720940115, Temperature 0.00014738731582510513, step_size 0.9696679941920274, test_acc: 0.4055\n",
            "Epoch 789, BestLoss: 0.060090124720940115, Temperature 0.00015514454297379488, step_size 0.9696679941920274, test_acc: 0.4055\n",
            "Epoch 790, BestLoss: 0.060090124720940115, Temperature 0.00016331004523557357, step_size 0.9695710273926083, test_acc: 0.4055\n",
            "Epoch 791, BestLoss: 0.060046992047938653, Temperature 0.00017190531077428798, step_size 0.969474070289869, test_acc: 0.4069\n",
            "Epoch 792, BestLoss: 0.06004213360173885, Temperature 0.00016331004523557357, step_size 0.9693771228828401, test_acc: 0.4085\n",
            "Epoch 793, BestLoss: 0.06008501016508419, Temperature 0.00017190531077428798, step_size 0.9693771228828401, test_acc: 0.4064\n",
            "Epoch 794, BestLoss: 0.06060455155480052, Temperature 0.00016331004523557357, step_size 0.9692801851705518, test_acc: 0.3997\n",
            "Epoch 795, BestLoss: 0.06060455155480052, Temperature 0.00015514454297379488, step_size 0.9691832571520348, test_acc: 0.3997\n",
            "Epoch 796, BestLoss: 0.06011226351523784, Temperature 0.00016331004523557357, step_size 0.9692801851705518, test_acc: 0.4076\n",
            "Epoch 797, BestLoss: 0.06011226351523784, Temperature 0.00015514454297379488, step_size 0.9691832571520348, test_acc: 0.4076\n",
            "Epoch 798, BestLoss: 0.06018616275061732, Temperature 0.00016331004523557357, step_size 0.9691832571520348, test_acc: 0.4064\n",
            "Epoch 799, BestLoss: 0.060224378272230025, Temperature 0.00015514454297379488, step_size 0.9690863388263196, test_acc: 0.4054\n",
            "Epoch 800, BestLoss: 0.06015496089824484, Temperature 0.00014738731582510513, step_size 0.9689894301924369, test_acc: 0.4046\n",
            "Epoch 801, BestLoss: 0.06021795543310242, Temperature 0.00014001795003384986, step_size 0.9688925312494177, test_acc: 0.4063\n",
            "Epoch 802, BestLoss: 0.06021795543310242, Temperature 0.00013301705253215737, step_size 0.9687956419962928, test_acc: 0.4063\n",
            "Epoch 803, BestLoss: 0.0601221461271424, Temperature 0.00014001795003384986, step_size 0.9690863388263196, test_acc: 0.4085\n",
            "Epoch 804, BestLoss: 0.060431752913321965, Temperature 0.00013301705253215737, step_size 0.9689894301924369, test_acc: 0.4036\n",
            "Epoch 805, BestLoss: 0.06029386633344205, Temperature 0.0001263661999055495, step_size 0.9688925312494177, test_acc: 0.4049\n",
            "Epoch 806, BestLoss: 0.06031632605015232, Temperature 0.000120047889910272, step_size 0.9687956419962928, test_acc: 0.4051\n",
            "Epoch 807, BestLoss: 0.06030310907334214, Temperature 0.0001140454954147584, step_size 0.9686987624320932, test_acc: 0.4089\n",
            "Epoch 808, BestLoss: 0.060389346243949246, Temperature 0.00010834322064402047, step_size 0.9686018925558499, test_acc: 0.4067\n",
            "Epoch 809, BestLoss: 0.060389346243949246, Temperature 0.00010292605961181944, step_size 0.9685050323665944, test_acc: 0.4067\n",
            "Epoch 810, BestLoss: 0.06048596440310862, Temperature 0.00010834322064402047, step_size 0.9689894301924369, test_acc: 0.4059\n",
            "Epoch 811, BestLoss: 0.06052760861382313, Temperature 0.00010292605961181944, step_size 0.9688925312494177, test_acc: 0.4048\n",
            "Epoch 812, BestLoss: 0.060620216429007875, Temperature 9.777975663122846e-05, step_size 0.9687956419962928, test_acc: 0.4027\n",
            "Epoch 813, BestLoss: 0.060620216429007875, Temperature 9.289076879966704e-05, step_size 0.9686987624320932, test_acc: 0.4027\n",
            "Epoch 814, BestLoss: 0.060372117130188856, Temperature 9.777975663122846e-05, step_size 0.9688925312494177, test_acc: 0.4044\n",
            "Epoch 815, BestLoss: 0.060372117130188856, Temperature 9.289076879966704e-05, step_size 0.9687956419962928, test_acc: 0.4044\n",
            "Epoch 816, BestLoss: 0.060541667814214474, Temperature 9.777975663122846e-05, step_size 0.9687956419962928, test_acc: 0.4038\n",
            "Epoch 817, BestLoss: 0.06068950485588398, Temperature 9.289076879966704e-05, step_size 0.9686987624320932, test_acc: 0.4008\n",
            "Epoch 818, BestLoss: 0.06068950485588398, Temperature 8.824623035968368e-05, step_size 0.9686018925558499, test_acc: 0.4008\n",
            "Epoch 819, BestLoss: 0.06068950485588398, Temperature 9.289076879966704e-05, step_size 0.9686987624320932, test_acc: 0.4008\n",
            "Epoch 820, BestLoss: 0.060861012881908295, Temperature 9.777975663122846e-05, step_size 0.9686018925558499, test_acc: 0.3998\n",
            "Epoch 821, BestLoss: 0.060861012881908295, Temperature 9.289076879966704e-05, step_size 0.9685050323665944, test_acc: 0.3998\n",
            "Epoch 822, BestLoss: 0.06084066924435025, Temperature 9.777975663122846e-05, step_size 0.9685050323665944, test_acc: 0.4018\n",
            "Epoch 823, BestLoss: 0.06084066924435025, Temperature 9.289076879966704e-05, step_size 0.9684081818633578, test_acc: 0.4018\n",
            "Epoch 824, BestLoss: 0.06087963216813709, Temperature 9.777975663122846e-05, step_size 0.9684081818633578, test_acc: 0.4027\n",
            "Epoch 825, BestLoss: 0.06087963216813709, Temperature 9.289076879966704e-05, step_size 0.9683113410451715, test_acc: 0.4027\n",
            "Epoch 826, BestLoss: 0.06063168031803039, Temperature 9.777975663122846e-05, step_size 0.9683113410451715, test_acc: 0.4039\n",
            "Epoch 827, BestLoss: 0.06063168031803039, Temperature 9.289076879966704e-05, step_size 0.968214509911067, test_acc: 0.4039\n",
            "Epoch 828, BestLoss: 0.06064939490187963, Temperature 9.777975663122846e-05, step_size 0.968214509911067, test_acc: 0.4029\n",
            "Epoch 829, BestLoss: 0.060704269601076985, Temperature 9.289076879966704e-05, step_size 0.9681176884600758, test_acc: 0.4017\n",
            "Epoch 830, BestLoss: 0.060795396641818905, Temperature 8.824623035968368e-05, step_size 0.9680208766912298, test_acc: 0.4001\n",
            "Epoch 831, BestLoss: 0.06054742087834163, Temperature 8.383391884169949e-05, step_size 0.9679240746035607, test_acc: 0.4017\n",
            "Epoch 832, BestLoss: 0.06054742087834163, Temperature 7.96422228996145e-05, step_size 0.9678272821961004, test_acc: 0.4017\n",
            "Epoch 833, BestLoss: 0.06054742087834163, Temperature 8.383391884169949e-05, step_size 0.9681176884600758, test_acc: 0.4017\n",
            "Epoch 834, BestLoss: 0.06054742087834163, Temperature 8.824623035968368e-05, step_size 0.9680208766912298, test_acc: 0.4017\n",
            "Epoch 835, BestLoss: 0.06038104405021164, Temperature 9.289076879966704e-05, step_size 0.9679240746035607, test_acc: 0.4046\n",
            "Epoch 836, BestLoss: 0.06038104405021164, Temperature 8.824623035968368e-05, step_size 0.9678272821961004, test_acc: 0.4046\n",
            "Epoch 837, BestLoss: 0.060520159235928524, Temperature 9.289076879966704e-05, step_size 0.9678272821961004, test_acc: 0.4026\n",
            "Epoch 838, BestLoss: 0.060520159235928524, Temperature 8.824623035968368e-05, step_size 0.9677304994678808, test_acc: 0.4026\n",
            "Epoch 839, BestLoss: 0.060555902408391434, Temperature 9.289076879966704e-05, step_size 0.9677304994678808, test_acc: 0.3996\n",
            "Epoch 840, BestLoss: 0.06051802865207718, Temperature 8.824623035968368e-05, step_size 0.967633726417934, test_acc: 0.4018\n",
            "Epoch 841, BestLoss: 0.06051802865207718, Temperature 8.383391884169949e-05, step_size 0.9675369630452922, test_acc: 0.4018\n",
            "Epoch 842, BestLoss: 0.06030924439581737, Temperature 8.824623035968368e-05, step_size 0.967633726417934, test_acc: 0.4023\n",
            "Epoch 843, BestLoss: 0.06014129139534164, Temperature 8.383391884169949e-05, step_size 0.9675369630452922, test_acc: 0.4061\n",
            "Epoch 844, BestLoss: 0.06014129139534164, Temperature 7.96422228996145e-05, step_size 0.9674402093489878, test_acc: 0.4061\n",
            "Epoch 845, BestLoss: 0.06023800694707107, Temperature 8.383391884169949e-05, step_size 0.9675369630452922, test_acc: 0.4041\n",
            "Epoch 846, BestLoss: 0.06023800694707107, Temperature 7.96422228996145e-05, step_size 0.9674402093489878, test_acc: 0.4041\n",
            "Epoch 847, BestLoss: 0.06023800694707107, Temperature 8.383391884169949e-05, step_size 0.9674402093489878, test_acc: 0.4041\n",
            "Epoch 848, BestLoss: 0.06007463692204413, Temperature 8.824623035968368e-05, step_size 0.9673434653280529, test_acc: 0.4088\n",
            "Epoch 849, BestLoss: 0.05964927150558525, Temperature 8.383391884169949e-05, step_size 0.9672467309815201, test_acc: 0.4117\n",
            "Epoch 850, BestLoss: 0.05974225526093682, Temperature 7.96422228996145e-05, step_size 0.967150006308422, test_acc: 0.4128\n",
            "Epoch 851, BestLoss: 0.05974225526093682, Temperature 7.566011175463378e-05, step_size 0.9670532913077912, test_acc: 0.4128\n",
            "Epoch 852, BestLoss: 0.059513464595106515, Temperature 7.96422228996145e-05, step_size 0.9672467309815201, test_acc: 0.4154\n",
            "Epoch 853, BestLoss: 0.059513464595106515, Temperature 7.566011175463378e-05, step_size 0.967150006308422, test_acc: 0.4154\n",
            "Epoch 854, BestLoss: 0.059513464595106515, Temperature 7.96422228996145e-05, step_size 0.967150006308422, test_acc: 0.4154\n",
            "Epoch 855, BestLoss: 0.059513464595106515, Temperature 8.383391884169949e-05, step_size 0.9670532913077912, test_acc: 0.4154\n",
            "Epoch 856, BestLoss: 0.059513464595106515, Temperature 8.824623035968368e-05, step_size 0.9669565859786604, test_acc: 0.4154\n",
            "Epoch 857, BestLoss: 0.059513464595106515, Temperature 9.289076879966704e-05, step_size 0.9668598903200626, test_acc: 0.4154\n",
            "Epoch 858, BestLoss: 0.059534928586187946, Temperature 9.777975663122846e-05, step_size 0.9667632043310306, test_acc: 0.4143\n",
            "Epoch 859, BestLoss: 0.05924713218500069, Temperature 9.289076879966704e-05, step_size 0.9666665280105975, test_acc: 0.4147\n",
            "Epoch 860, BestLoss: 0.05924713218500069, Temperature 8.824623035968368e-05, step_size 0.9665698613577964, test_acc: 0.4147\n",
            "Epoch 861, BestLoss: 0.05924713218500069, Temperature 9.289076879966704e-05, step_size 0.9666665280105975, test_acc: 0.4147\n",
            "Epoch 862, BestLoss: 0.05924713218500069, Temperature 9.777975663122846e-05, step_size 0.9665698613577964, test_acc: 0.4147\n",
            "Epoch 863, BestLoss: 0.05953692837690795, Temperature 0.00010292605961181944, step_size 0.9664732043716606, test_acc: 0.4128\n",
            "Epoch 864, BestLoss: 0.05953692837690795, Temperature 9.777975663122846e-05, step_size 0.9663765570512235, test_acc: 0.4128\n",
            "Epoch 865, BestLoss: 0.05965862004859693, Temperature 0.00010292605961181944, step_size 0.9663765570512235, test_acc: 0.4103\n",
            "Epoch 866, BestLoss: 0.05965862004859693, Temperature 9.777975663122846e-05, step_size 0.9662799193955184, test_acc: 0.4103\n",
            "Epoch 867, BestLoss: 0.05965862004859693, Temperature 0.00010292605961181944, step_size 0.9662799193955184, test_acc: 0.4103\n",
            "Epoch 868, BestLoss: 0.05965862004859693, Temperature 0.00010834322064402047, step_size 0.9661832914035788, test_acc: 0.4103\n",
            "Epoch 869, BestLoss: 0.05965862004859693, Temperature 0.0001140454954147584, step_size 0.9660866730744385, test_acc: 0.4103\n",
            "Epoch 870, BestLoss: 0.059754632033609534, Temperature 0.000120047889910272, step_size 0.9659900644071311, test_acc: 0.4108\n",
            "Epoch 871, BestLoss: 0.059754632033609534, Temperature 0.0001140454954147584, step_size 0.9658934654006904, test_acc: 0.4108\n",
            "Epoch 872, BestLoss: 0.059754632033609534, Temperature 0.000120047889910272, step_size 0.9658934654006904, test_acc: 0.4108\n",
            "Epoch 873, BestLoss: 0.059928555789647155, Temperature 0.0001263661999055495, step_size 0.9657968760541503, test_acc: 0.4077\n",
            "Epoch 874, BestLoss: 0.05979651089170691, Temperature 0.000120047889910272, step_size 0.9657002963665449, test_acc: 0.4083\n",
            "Epoch 875, BestLoss: 0.05979651089170691, Temperature 0.0001140454954147584, step_size 0.9656037263369083, test_acc: 0.4083\n",
            "Epoch 876, BestLoss: 0.05979651089170691, Temperature 0.000120047889910272, step_size 0.9657002963665449, test_acc: 0.4083\n",
            "Epoch 877, BestLoss: 0.05968135630006703, Temperature 0.0001263661999055495, step_size 0.9656037263369083, test_acc: 0.4098\n",
            "Epoch 878, BestLoss: 0.05968135630006703, Temperature 0.000120047889910272, step_size 0.9655071659642745, test_acc: 0.4098\n",
            "Epoch 879, BestLoss: 0.05968135630006703, Temperature 0.0001263661999055495, step_size 0.9655071659642745, test_acc: 0.4098\n",
            "Epoch 880, BestLoss: 0.05968135630006703, Temperature 0.00013301705253215737, step_size 0.9654106152476781, test_acc: 0.4098\n",
            "Epoch 881, BestLoss: 0.059797284756107585, Temperature 0.00014001795003384986, step_size 0.9653140741861533, test_acc: 0.4074\n",
            "Epoch 882, BestLoss: 0.05980584469925213, Temperature 0.00013301705253215737, step_size 0.9652175427787347, test_acc: 0.4076\n",
            "Epoch 883, BestLoss: 0.06010346252770357, Temperature 0.0001263661999055495, step_size 0.9651210210244568, test_acc: 0.4037\n",
            "Epoch 884, BestLoss: 0.05992526129675896, Temperature 0.000120047889910272, step_size 0.9650245089223544, test_acc: 0.4064\n",
            "Epoch 885, BestLoss: 0.059581165611620863, Temperature 0.0001140454954147584, step_size 0.9649280064714622, test_acc: 0.4097\n",
            "Epoch 886, BestLoss: 0.059304001737330046, Temperature 0.00010834322064402047, step_size 0.964831513670815, test_acc: 0.413\n",
            "Epoch 887, BestLoss: 0.059000059276817736, Temperature 0.00010292605961181944, step_size 0.9647350305194479, test_acc: 0.4151\n",
            "Epoch 888, BestLoss: 0.059000059276817736, Temperature 9.777975663122846e-05, step_size 0.9646385570163959, test_acc: 0.4151\n",
            "Epoch 889, BestLoss: 0.059000059276817736, Temperature 0.00010292605961181944, step_size 0.9652175427787347, test_acc: 0.4151\n",
            "Epoch 890, BestLoss: 0.059000059276817736, Temperature 0.00010834322064402047, step_size 0.9651210210244568, test_acc: 0.4151\n",
            "Epoch 891, BestLoss: 0.059000059276817736, Temperature 0.0001140454954147584, step_size 0.9650245089223544, test_acc: 0.4151\n",
            "Epoch 892, BestLoss: 0.059000059276817736, Temperature 0.000120047889910272, step_size 0.9649280064714622, test_acc: 0.4151\n",
            "Epoch 893, BestLoss: 0.059000059276817736, Temperature 0.0001263661999055495, step_size 0.964831513670815, test_acc: 0.4151\n",
            "Epoch 894, BestLoss: 0.05917529567930714, Temperature 0.00013301705253215737, step_size 0.9647350305194479, test_acc: 0.4144\n",
            "Epoch 895, BestLoss: 0.05934475695700551, Temperature 0.0001263661999055495, step_size 0.9646385570163959, test_acc: 0.4116\n",
            "Epoch 896, BestLoss: 0.05934475695700551, Temperature 0.000120047889910272, step_size 0.9645420931606943, test_acc: 0.4116\n",
            "Epoch 897, BestLoss: 0.05934355467311434, Temperature 0.0001263661999055495, step_size 0.9646385570163959, test_acc: 0.4132\n",
            "Epoch 898, BestLoss: 0.0594514269158029, Temperature 0.00013301705253215737, step_size 0.9645420931606943, test_acc: 0.4126\n",
            "Epoch 899, BestLoss: 0.05947427808801635, Temperature 0.0001263661999055495, step_size 0.9644456389513782, test_acc: 0.4135\n",
            "Epoch 900, BestLoss: 0.05930533876901815, Temperature 0.000120047889910272, step_size 0.9643491943874831, test_acc: 0.4121\n",
            "Epoch 901, BestLoss: 0.059065988896620694, Temperature 0.0001140454954147584, step_size 0.9642527594680443, test_acc: 0.4157\n",
            "Epoch 902, BestLoss: 0.059065988896620694, Temperature 0.00010834322064402047, step_size 0.9641563341920976, test_acc: 0.4157\n",
            "Epoch 903, BestLoss: 0.059065988896620694, Temperature 0.0001140454954147584, step_size 0.9644456389513782, test_acc: 0.4157\n",
            "Epoch 904, BestLoss: 0.059065988896620694, Temperature 0.000120047889910272, step_size 0.9643491943874831, test_acc: 0.4157\n",
            "Epoch 905, BestLoss: 0.05908164908972018, Temperature 0.0001263661999055495, step_size 0.9642527594680443, test_acc: 0.4169\n",
            "Epoch 906, BestLoss: 0.05909368120232238, Temperature 0.000120047889910272, step_size 0.9641563341920976, test_acc: 0.4174\n",
            "Epoch 907, BestLoss: 0.05909368120232238, Temperature 0.0001140454954147584, step_size 0.9640599185586783, test_acc: 0.4174\n",
            "Epoch 908, BestLoss: 0.05909368120232238, Temperature 0.000120047889910272, step_size 0.9641563341920976, test_acc: 0.4174\n",
            "Epoch 909, BestLoss: 0.05909368120232238, Temperature 0.0001263661999055495, step_size 0.9640599185586783, test_acc: 0.4174\n",
            "Epoch 910, BestLoss: 0.05910881144531234, Temperature 0.00013301705253215737, step_size 0.9639635125668224, test_acc: 0.4143\n",
            "Epoch 911, BestLoss: 0.05883652366543538, Temperature 0.0001263661999055495, step_size 0.9638671162155658, test_acc: 0.4184\n",
            "Epoch 912, BestLoss: 0.058864367604602875, Temperature 0.000120047889910272, step_size 0.9637707295039442, test_acc: 0.4193\n",
            "Epoch 913, BestLoss: 0.058934584891688256, Temperature 0.0001140454954147584, step_size 0.9636743524309938, test_acc: 0.4192\n",
            "Epoch 914, BestLoss: 0.059130123007284915, Temperature 0.00010834322064402047, step_size 0.9635779849957506, test_acc: 0.4157\n",
            "Epoch 915, BestLoss: 0.059130123007284915, Temperature 0.00010292605961181944, step_size 0.9634816271972511, test_acc: 0.4157\n",
            "Epoch 916, BestLoss: 0.059130123007284915, Temperature 0.00010834322064402047, step_size 0.9638671162155658, test_acc: 0.4157\n",
            "Epoch 917, BestLoss: 0.059008625408550834, Temperature 0.0001140454954147584, step_size 0.9637707295039442, test_acc: 0.4175\n",
            "Epoch 918, BestLoss: 0.05906216509934123, Temperature 0.00010834322064402047, step_size 0.9636743524309938, test_acc: 0.4187\n",
            "Epoch 919, BestLoss: 0.05906216509934123, Temperature 0.00010292605961181944, step_size 0.9635779849957506, test_acc: 0.4187\n",
            "Epoch 920, BestLoss: 0.05889977278326015, Temperature 0.00010834322064402047, step_size 0.9636743524309938, test_acc: 0.421\n",
            "Epoch 921, BestLoss: 0.05889977278326015, Temperature 0.00010292605961181944, step_size 0.9635779849957506, test_acc: 0.421\n",
            "Epoch 922, BestLoss: 0.05889977278326015, Temperature 0.00010834322064402047, step_size 0.9635779849957506, test_acc: 0.421\n",
            "Epoch 923, BestLoss: 0.05889977278326015, Temperature 0.0001140454954147584, step_size 0.9634816271972511, test_acc: 0.421\n",
            "Epoch 924, BestLoss: 0.05889977278326015, Temperature 0.000120047889910272, step_size 0.9633852790345313, test_acc: 0.421\n",
            "Epoch 925, BestLoss: 0.05889977278326015, Temperature 0.0001263661999055495, step_size 0.9632889405066278, test_acc: 0.421\n",
            "Epoch 926, BestLoss: 0.05889977278326015, Temperature 0.00013301705253215737, step_size 0.9631926116125772, test_acc: 0.421\n",
            "Epoch 927, BestLoss: 0.05889977278326015, Temperature 0.00014001795003384986, step_size 0.9630962923514159, test_acc: 0.421\n",
            "Epoch 928, BestLoss: 0.05883021720365095, Temperature 0.00014738731582510513, step_size 0.9629999827221808, test_acc: 0.4211\n",
            "Epoch 929, BestLoss: 0.05883021720365095, Temperature 0.00014001795003384986, step_size 0.9629036827239086, test_acc: 0.4211\n",
            "Epoch 930, BestLoss: 0.05883021720365095, Temperature 0.00014738731582510513, step_size 0.9629036827239086, test_acc: 0.4211\n",
            "Epoch 931, BestLoss: 0.05883021720365095, Temperature 0.00015514454297379488, step_size 0.9628073923556362, test_acc: 0.4211\n",
            "Epoch 932, BestLoss: 0.05864527061197299, Temperature 0.00016331004523557357, step_size 0.9627111116164007, test_acc: 0.4236\n",
            "Epoch 933, BestLoss: 0.058596866769382056, Temperature 0.00015514454297379488, step_size 0.962614840505239, test_acc: 0.4243\n",
            "Epoch 934, BestLoss: 0.058596866769382056, Temperature 0.00014738731582510513, step_size 0.9625185790211885, test_acc: 0.4243\n",
            "Epoch 935, BestLoss: 0.058596866769382056, Temperature 0.00015514454297379488, step_size 0.962614840505239, test_acc: 0.4243\n",
            "Epoch 936, BestLoss: 0.05856088757867685, Temperature 0.00016331004523557357, step_size 0.9625185790211885, test_acc: 0.4238\n",
            "Epoch 937, BestLoss: 0.05856088757867685, Temperature 0.00015514454297379488, step_size 0.9624223271632865, test_acc: 0.4238\n",
            "Epoch 938, BestLoss: 0.05865563980955678, Temperature 0.00016331004523557357, step_size 0.9624223271632865, test_acc: 0.422\n",
            "Epoch 939, BestLoss: 0.05865563980955678, Temperature 0.00015514454297379488, step_size 0.9623260849305701, test_acc: 0.422\n",
            "Epoch 940, BestLoss: 0.05862436490383979, Temperature 0.00016331004523557357, step_size 0.9623260849305701, test_acc: 0.4219\n",
            "Epoch 941, BestLoss: 0.05862436490383979, Temperature 0.00015514454297379488, step_size 0.9622298523220771, test_acc: 0.4219\n",
            "Epoch 942, BestLoss: 0.05845225930044106, Temperature 0.00016331004523557357, step_size 0.9622298523220771, test_acc: 0.422\n",
            "Epoch 943, BestLoss: 0.05845225930044106, Temperature 0.00015514454297379488, step_size 0.962133629336845, test_acc: 0.422\n",
            "Epoch 944, BestLoss: 0.058416382191341314, Temperature 0.00016331004523557357, step_size 0.962133629336845, test_acc: 0.4207\n",
            "Epoch 945, BestLoss: 0.05840582923325276, Temperature 0.00015514454297379488, step_size 0.9620374159739113, test_acc: 0.4217\n",
            "Epoch 946, BestLoss: 0.05816416979818794, Temperature 0.00014738731582510513, step_size 0.961941212232314, test_acc: 0.4236\n",
            "Epoch 947, BestLoss: 0.05794077551624527, Temperature 0.00014001795003384986, step_size 0.9618450181110908, test_acc: 0.4268\n",
            "Epoch 948, BestLoss: 0.05794077551624527, Temperature 0.00013301705253215737, step_size 0.9617488336092797, test_acc: 0.4268\n",
            "Epoch 949, BestLoss: 0.05790781748191005, Temperature 0.00014001795003384986, step_size 0.9620374159739113, test_acc: 0.4284\n",
            "Epoch 950, BestLoss: 0.058082695300194345, Temperature 0.00013301705253215737, step_size 0.961941212232314, test_acc: 0.4245\n",
            "Epoch 951, BestLoss: 0.058082695300194345, Temperature 0.0001263661999055495, step_size 0.9618450181110908, test_acc: 0.4245\n",
            "Epoch 952, BestLoss: 0.05788657750145242, Temperature 0.00013301705253215737, step_size 0.961941212232314, test_acc: 0.4277\n",
            "Epoch 953, BestLoss: 0.05788796898778751, Temperature 0.0001263661999055495, step_size 0.9618450181110908, test_acc: 0.4264\n",
            "Epoch 954, BestLoss: 0.057747636072425876, Temperature 0.00013301705253215737, step_size 0.9618450181110908, test_acc: 0.428\n",
            "Epoch 955, BestLoss: 0.057699360356137694, Temperature 0.0001263661999055495, step_size 0.9617488336092797, test_acc: 0.4273\n",
            "Epoch 956, BestLoss: 0.057699360356137694, Temperature 0.000120047889910272, step_size 0.9616526587259188, test_acc: 0.4273\n",
            "Epoch 957, BestLoss: 0.05766911450854738, Temperature 0.0001263661999055495, step_size 0.9617488336092797, test_acc: 0.4298\n",
            "Epoch 958, BestLoss: 0.05786058681149807, Temperature 0.000120047889910272, step_size 0.9616526587259188, test_acc: 0.4291\n",
            "Epoch 959, BestLoss: 0.05786058681149807, Temperature 0.0001140454954147584, step_size 0.9615564934600462, test_acc: 0.4291\n",
            "Epoch 960, BestLoss: 0.05786058681149807, Temperature 0.000120047889910272, step_size 0.9616526587259188, test_acc: 0.4291\n",
            "Epoch 961, BestLoss: 0.05789583975553034, Temperature 0.0001263661999055495, step_size 0.9615564934600462, test_acc: 0.4287\n",
            "Epoch 962, BestLoss: 0.05789875474670371, Temperature 0.000120047889910272, step_size 0.9614603378107003, test_acc: 0.4288\n",
            "Epoch 963, BestLoss: 0.05799870727262285, Temperature 0.0001263661999055495, step_size 0.9614603378107003, test_acc: 0.4267\n",
            "Epoch 964, BestLoss: 0.057663281679799595, Temperature 0.000120047889910272, step_size 0.9613641917769192, test_acc: 0.4287\n",
            "Epoch 965, BestLoss: 0.057663281679799595, Temperature 0.0001140454954147584, step_size 0.9612680553577415, test_acc: 0.4287\n",
            "Epoch 966, BestLoss: 0.057663281679799595, Temperature 0.000120047889910272, step_size 0.9613641917769192, test_acc: 0.4287\n",
            "Epoch 967, BestLoss: 0.057718196839244784, Temperature 0.0001263661999055495, step_size 0.9612680553577415, test_acc: 0.4269\n",
            "Epoch 968, BestLoss: 0.05766943814294398, Temperature 0.000120047889910272, step_size 0.9611719285522058, test_acc: 0.429\n",
            "Epoch 969, BestLoss: 0.05766943814294398, Temperature 0.0001140454954147584, step_size 0.9610758113593506, test_acc: 0.429\n",
            "Epoch 970, BestLoss: 0.05747940652968215, Temperature 0.000120047889910272, step_size 0.9611719285522058, test_acc: 0.4301\n",
            "Epoch 971, BestLoss: 0.05740553029396486, Temperature 0.0001140454954147584, step_size 0.9610758113593506, test_acc: 0.432\n",
            "Epoch 972, BestLoss: 0.05740553029396486, Temperature 0.00010834322064402047, step_size 0.9609797037782147, test_acc: 0.432\n",
            "Epoch 973, BestLoss: 0.05740553029396486, Temperature 0.0001140454954147584, step_size 0.9610758113593506, test_acc: 0.432\n",
            "Epoch 974, BestLoss: 0.057341695931802446, Temperature 0.000120047889910272, step_size 0.9609797037782147, test_acc: 0.4316\n",
            "Epoch 975, BestLoss: 0.057341695931802446, Temperature 0.0001140454954147584, step_size 0.9608836058078369, test_acc: 0.4316\n",
            "Epoch 976, BestLoss: 0.057341695931802446, Temperature 0.000120047889910272, step_size 0.9608836058078369, test_acc: 0.4316\n",
            "Epoch 977, BestLoss: 0.057348545042927336, Temperature 0.0001263661999055495, step_size 0.9607875174472562, test_acc: 0.4314\n",
            "Epoch 978, BestLoss: 0.057264511140102524, Temperature 0.000120047889910272, step_size 0.9606914386955115, test_acc: 0.4328\n",
            "Epoch 979, BestLoss: 0.05730634138235876, Temperature 0.0001140454954147584, step_size 0.960595369551642, test_acc: 0.4329\n",
            "Epoch 980, BestLoss: 0.05722966966390314, Temperature 0.00010834322064402047, step_size 0.9604993100146869, test_acc: 0.4345\n",
            "Epoch 981, BestLoss: 0.05722966966390314, Temperature 0.00010292605961181944, step_size 0.9604032600836855, test_acc: 0.4345\n",
            "Epoch 982, BestLoss: 0.05722966966390314, Temperature 0.00010834322064402047, step_size 0.9606914386955115, test_acc: 0.4345\n",
            "Epoch 983, BestLoss: 0.05729129100246063, Temperature 0.0001140454954147584, step_size 0.960595369551642, test_acc: 0.4338\n",
            "Epoch 984, BestLoss: 0.05719113355784104, Temperature 0.00010834322064402047, step_size 0.9604993100146869, test_acc: 0.4342\n",
            "Epoch 985, BestLoss: 0.05719113355784104, Temperature 0.00010292605961181944, step_size 0.9604032600836855, test_acc: 0.4342\n",
            "Epoch 986, BestLoss: 0.05719113355784104, Temperature 0.00010834322064402047, step_size 0.9604993100146869, test_acc: 0.4342\n",
            "Epoch 987, BestLoss: 0.05719113355784104, Temperature 0.0001140454954147584, step_size 0.9604032600836855, test_acc: 0.4342\n",
            "Epoch 988, BestLoss: 0.05719113355784104, Temperature 0.000120047889910272, step_size 0.9603072197576771, test_acc: 0.4342\n",
            "Epoch 989, BestLoss: 0.0571439313324885, Temperature 0.0001263661999055495, step_size 0.9602111890357014, test_acc: 0.4344\n",
            "Epoch 990, BestLoss: 0.05724009615406001, Temperature 0.000120047889910272, step_size 0.9601151679167977, test_acc: 0.4315\n",
            "Epoch 991, BestLoss: 0.057239004113101476, Temperature 0.0001140454954147584, step_size 0.9600191564000061, test_acc: 0.4294\n",
            "Epoch 992, BestLoss: 0.05707211059754076, Temperature 0.000120047889910272, step_size 0.9601151679167977, test_acc: 0.4326\n",
            "Epoch 993, BestLoss: 0.05707211059754076, Temperature 0.0001140454954147584, step_size 0.9600191564000061, test_acc: 0.4326\n",
            "Epoch 994, BestLoss: 0.05707211059754076, Temperature 0.000120047889910272, step_size 0.9600191564000061, test_acc: 0.4326\n",
            "Epoch 995, BestLoss: 0.05671468390456864, Temperature 0.0001263661999055495, step_size 0.9599231544843662, test_acc: 0.4376\n",
            "Epoch 996, BestLoss: 0.05670565009694277, Temperature 0.000120047889910272, step_size 0.9598271621689177, test_acc: 0.4368\n",
            "Epoch 997, BestLoss: 0.05670565009694277, Temperature 0.0001140454954147584, step_size 0.9597311794527008, test_acc: 0.4368\n",
            "Epoch 998, BestLoss: 0.05694569240782279, Temperature 0.000120047889910272, step_size 0.9598271621689177, test_acc: 0.4348\n",
            "Epoch 999, BestLoss: 0.05694569240782279, Temperature 0.0001140454954147584, step_size 0.9597311794527008, test_acc: 0.4348\n",
            "Epoch 1000, BestLoss: 0.05696194806357676, Temperature 0.000120047889910272, step_size 0.9597311794527008, test_acc: 0.4364\n",
            "Epoch 1001, BestLoss: 0.05711406192858932, Temperature 0.0001140454954147584, step_size 0.9596352063347555, test_acc: 0.4361\n",
            "Epoch 1002, BestLoss: 0.05711406192858932, Temperature 0.00010834322064402047, step_size 0.9595392428141221, test_acc: 0.4361\n",
            "Epoch 1003, BestLoss: 0.0571753867900857, Temperature 0.0001140454954147584, step_size 0.9596352063347555, test_acc: 0.4344\n",
            "Epoch 1004, BestLoss: 0.0571753867900857, Temperature 0.00010834322064402047, step_size 0.9595392428141221, test_acc: 0.4344\n",
            "Epoch 1005, BestLoss: 0.057375328131245476, Temperature 0.0001140454954147584, step_size 0.9595392428141221, test_acc: 0.4318\n",
            "Epoch 1006, BestLoss: 0.057375328131245476, Temperature 0.00010834322064402047, step_size 0.9594432888898407, test_acc: 0.4318\n",
            "Epoch 1007, BestLoss: 0.057375328131245476, Temperature 0.0001140454954147584, step_size 0.9594432888898407, test_acc: 0.4318\n",
            "Epoch 1008, BestLoss: 0.057375328131245476, Temperature 0.000120047889910272, step_size 0.9593473445609517, test_acc: 0.4318\n",
            "Epoch 1009, BestLoss: 0.05744064980499388, Temperature 0.0001263661999055495, step_size 0.9592514098264956, test_acc: 0.429\n",
            "Epoch 1010, BestLoss: 0.05732677984696922, Temperature 0.000120047889910272, step_size 0.9591554846855129, test_acc: 0.4292\n",
            "Epoch 1011, BestLoss: 0.05732677984696922, Temperature 0.0001140454954147584, step_size 0.9590595691370444, test_acc: 0.4292\n",
            "Epoch 1012, BestLoss: 0.05732677984696922, Temperature 0.000120047889910272, step_size 0.9591554846855129, test_acc: 0.4292\n",
            "Epoch 1013, BestLoss: 0.05732677984696922, Temperature 0.0001263661999055495, step_size 0.9590595691370444, test_acc: 0.4292\n",
            "Epoch 1014, BestLoss: 0.0575157344464663, Temperature 0.00013301705253215737, step_size 0.9589636631801307, test_acc: 0.4285\n",
            "Epoch 1015, BestLoss: 0.0575157344464663, Temperature 0.0001263661999055495, step_size 0.9588677668138127, test_acc: 0.4285\n",
            "Epoch 1016, BestLoss: 0.0575157344464663, Temperature 0.00013301705253215737, step_size 0.9588677668138127, test_acc: 0.4285\n",
            "Epoch 1017, BestLoss: 0.0575157344464663, Temperature 0.00014001795003384986, step_size 0.9587718800371313, test_acc: 0.4285\n",
            "Epoch 1018, BestLoss: 0.05735665415596714, Temperature 0.00014738731582510513, step_size 0.9586760028491276, test_acc: 0.4296\n",
            "Epoch 1019, BestLoss: 0.05735665415596714, Temperature 0.00014001795003384986, step_size 0.9585801352488427, test_acc: 0.4296\n",
            "Epoch 1020, BestLoss: 0.05735665415596714, Temperature 0.00014738731582510513, step_size 0.9585801352488427, test_acc: 0.4296\n",
            "Epoch 1021, BestLoss: 0.05735665415596714, Temperature 0.00015514454297379488, step_size 0.9584842772353178, test_acc: 0.4296\n",
            "Epoch 1022, BestLoss: 0.05735665415596714, Temperature 0.00016331004523557357, step_size 0.9583884288075943, test_acc: 0.4296\n",
            "Epoch 1023, BestLoss: 0.05721820379131777, Temperature 0.00017190531077428798, step_size 0.9582925899647136, test_acc: 0.4313\n",
            "Epoch 1024, BestLoss: 0.057149954151824896, Temperature 0.00016331004523557357, step_size 0.9581967607057171, test_acc: 0.4326\n",
            "Epoch 1025, BestLoss: 0.05716378397777788, Temperature 0.00015514454297379488, step_size 0.9581009410296466, test_acc: 0.4336\n",
            "Epoch 1026, BestLoss: 0.05715560571133676, Temperature 0.00014738731582510513, step_size 0.9580051309355436, test_acc: 0.4359\n",
            "Epoch 1027, BestLoss: 0.05715560571133676, Temperature 0.00014001795003384986, step_size 0.9579093304224501, test_acc: 0.4359\n",
            "Epoch 1028, BestLoss: 0.05722093626027245, Temperature 0.00014738731582510513, step_size 0.9581967607057171, test_acc: 0.4327\n",
            "Epoch 1029, BestLoss: 0.057626454852276826, Temperature 0.00014001795003384986, step_size 0.9581009410296466, test_acc: 0.4307\n",
            "Epoch 1030, BestLoss: 0.0573017930803122, Temperature 0.00013301705253215737, step_size 0.9580051309355436, test_acc: 0.4344\n",
            "Epoch 1031, BestLoss: 0.0573017930803122, Temperature 0.0001263661999055495, step_size 0.9579093304224501, test_acc: 0.4344\n",
            "Epoch 1032, BestLoss: 0.0573017930803122, Temperature 0.00013301705253215737, step_size 0.9581009410296466, test_acc: 0.4344\n",
            "Epoch 1033, BestLoss: 0.0573017930803122, Temperature 0.00014001795003384986, step_size 0.9580051309355436, test_acc: 0.4344\n",
            "Epoch 1034, BestLoss: 0.0573017930803122, Temperature 0.00014738731582510513, step_size 0.9579093304224501, test_acc: 0.4344\n",
            "Epoch 1035, BestLoss: 0.05725722207374912, Temperature 0.00015514454297379488, step_size 0.9578135394894078, test_acc: 0.4354\n",
            "Epoch 1036, BestLoss: 0.05725722207374912, Temperature 0.00014738731582510513, step_size 0.9577177581354589, test_acc: 0.4354\n",
            "Epoch 1037, BestLoss: 0.05725722207374912, Temperature 0.00015514454297379488, step_size 0.9577177581354589, test_acc: 0.4354\n",
            "Epoch 1038, BestLoss: 0.05725722207374912, Temperature 0.00016331004523557357, step_size 0.9576219863596453, test_acc: 0.4354\n",
            "Epoch 1039, BestLoss: 0.05725722207374912, Temperature 0.00017190531077428798, step_size 0.9575262241610094, test_acc: 0.4354\n",
            "Epoch 1040, BestLoss: 0.05725722207374912, Temperature 0.00018095295870977683, step_size 0.9574304715385933, test_acc: 0.4354\n",
            "Epoch 1041, BestLoss: 0.05746871871263657, Temperature 0.00019047679864187035, step_size 0.9573347284914394, test_acc: 0.4309\n",
            "Epoch 1042, BestLoss: 0.05746871871263657, Temperature 0.00018095295870977683, step_size 0.9572389950185903, test_acc: 0.4309\n",
            "Epoch 1043, BestLoss: 0.05746871871263657, Temperature 0.00019047679864187035, step_size 0.9572389950185903, test_acc: 0.4309\n",
            "Epoch 1044, BestLoss: 0.05780491720678604, Temperature 0.00020050189330723196, step_size 0.9571432711190885, test_acc: 0.4297\n",
            "Epoch 1045, BestLoss: 0.05780491720678604, Temperature 0.00019047679864187035, step_size 0.9570475567919766, test_acc: 0.4297\n",
            "Epoch 1046, BestLoss: 0.05780491720678604, Temperature 0.00020050189330723196, step_size 0.9570475567919766, test_acc: 0.4297\n",
            "Epoch 1047, BestLoss: 0.05780491720678604, Temperature 0.00021105462453392839, step_size 0.9569518520362974, test_acc: 0.4297\n",
            "Epoch 1048, BestLoss: 0.05780491720678604, Temperature 0.00022216276266729304, step_size 0.9568561568510938, test_acc: 0.4297\n",
            "Epoch 1049, BestLoss: 0.057713624956430676, Temperature 0.00023385553964978215, step_size 0.9567604712354087, test_acc: 0.4312\n",
            "Epoch 1050, BestLoss: 0.05805728589761431, Temperature 0.00022216276266729304, step_size 0.9566647951882852, test_acc: 0.4276\n",
            "Epoch 1051, BestLoss: 0.05791279134063673, Temperature 0.00021105462453392839, step_size 0.9565691287087663, test_acc: 0.4278\n",
            "Epoch 1052, BestLoss: 0.05791279134063673, Temperature 0.00020050189330723196, step_size 0.9564734717958955, test_acc: 0.4278\n",
            "Epoch 1053, BestLoss: 0.0578741052107842, Temperature 0.00021105462453392839, step_size 0.9566647951882852, test_acc: 0.4273\n",
            "Epoch 1054, BestLoss: 0.05805205307584405, Temperature 0.00020050189330723196, step_size 0.9565691287087663, test_acc: 0.4241\n",
            "Epoch 1055, BestLoss: 0.05805205307584405, Temperature 0.00019047679864187035, step_size 0.9564734717958955, test_acc: 0.4241\n",
            "Epoch 1056, BestLoss: 0.05803913667649605, Temperature 0.00020050189330723196, step_size 0.9565691287087663, test_acc: 0.4247\n",
            "Epoch 1057, BestLoss: 0.05779433853041904, Temperature 0.00019047679864187035, step_size 0.9564734717958955, test_acc: 0.4294\n",
            "Epoch 1058, BestLoss: 0.05792362703727617, Temperature 0.00018095295870977683, step_size 0.9563778244487159, test_acc: 0.4277\n",
            "Epoch 1059, BestLoss: 0.05792362703727617, Temperature 0.00017190531077428798, step_size 0.9562821866662711, test_acc: 0.4277\n",
            "Epoch 1060, BestLoss: 0.05791527365354244, Temperature 0.00018095295870977683, step_size 0.9564734717958955, test_acc: 0.4263\n",
            "Epoch 1061, BestLoss: 0.05801699977342866, Temperature 0.00017190531077428798, step_size 0.9563778244487159, test_acc: 0.4257\n",
            "Epoch 1062, BestLoss: 0.05801699977342866, Temperature 0.00016331004523557357, step_size 0.9562821866662711, test_acc: 0.4257\n",
            "Epoch 1063, BestLoss: 0.05809639595212718, Temperature 0.00017190531077428798, step_size 0.9563778244487159, test_acc: 0.4235\n",
            "Epoch 1064, BestLoss: 0.05794712531359878, Temperature 0.00016331004523557357, step_size 0.9562821866662711, test_acc: 0.4268\n",
            "Epoch 1065, BestLoss: 0.05794712531359878, Temperature 0.00015514454297379488, step_size 0.9561865584476045, test_acc: 0.4268\n",
            "Epoch 1066, BestLoss: 0.058480806296490655, Temperature 0.00016331004523557357, step_size 0.9562821866662711, test_acc: 0.4211\n",
            "Epoch 1067, BestLoss: 0.0585441488329622, Temperature 0.00015514454297379488, step_size 0.9561865584476045, test_acc: 0.4191\n",
            "Epoch 1068, BestLoss: 0.0585441488329622, Temperature 0.00014738731582510513, step_size 0.9560909397917597, test_acc: 0.4191\n",
            "Epoch 1069, BestLoss: 0.05832904122581645, Temperature 0.00015514454297379488, step_size 0.9561865584476045, test_acc: 0.4208\n",
            "Epoch 1070, BestLoss: 0.05832904122581645, Temperature 0.00014738731582510513, step_size 0.9560909397917597, test_acc: 0.4208\n",
            "Epoch 1071, BestLoss: 0.058314043365376586, Temperature 0.00015514454297379488, step_size 0.9560909397917597, test_acc: 0.422\n",
            "Epoch 1072, BestLoss: 0.058314043365376586, Temperature 0.00014738731582510513, step_size 0.9559953306977805, test_acc: 0.422\n",
            "Epoch 1073, BestLoss: 0.057937297471274164, Temperature 0.00015514454297379488, step_size 0.9559953306977805, test_acc: 0.4229\n",
            "Epoch 1074, BestLoss: 0.05800730896943305, Temperature 0.00014738731582510513, step_size 0.9558997311647107, test_acc: 0.4241\n",
            "Epoch 1075, BestLoss: 0.05800730896943305, Temperature 0.00014001795003384986, step_size 0.9558041411915943, test_acc: 0.4241\n",
            "Epoch 1076, BestLoss: 0.05800730896943305, Temperature 0.00014738731582510513, step_size 0.9558997311647107, test_acc: 0.4241\n",
            "Epoch 1077, BestLoss: 0.05800730896943305, Temperature 0.00015514454297379488, step_size 0.9558041411915943, test_acc: 0.4241\n",
            "Epoch 1078, BestLoss: 0.05785526028705295, Temperature 0.00016331004523557357, step_size 0.9557085607774751, test_acc: 0.4243\n",
            "Epoch 1079, BestLoss: 0.05785526028705295, Temperature 0.00015514454297379488, step_size 0.9556129899213974, test_acc: 0.4243\n",
            "Epoch 1080, BestLoss: 0.057787266106071294, Temperature 0.00016331004523557357, step_size 0.9556129899213974, test_acc: 0.4257\n",
            "Epoch 1081, BestLoss: 0.057787266106071294, Temperature 0.00015514454297379488, step_size 0.9555174286224053, test_acc: 0.4257\n",
            "Epoch 1082, BestLoss: 0.0574907512392619, Temperature 0.00016331004523557357, step_size 0.9555174286224053, test_acc: 0.4276\n",
            "Epoch 1083, BestLoss: 0.0574907512392619, Temperature 0.00015514454297379488, step_size 0.955421876879543, test_acc: 0.4276\n",
            "Epoch 1084, BestLoss: 0.05732757654513145, Temperature 0.00016331004523557357, step_size 0.955421876879543, test_acc: 0.4293\n",
            "Epoch 1085, BestLoss: 0.05721178637001075, Temperature 0.00015514454297379488, step_size 0.9553263346918551, test_acc: 0.4299\n",
            "Epoch 1086, BestLoss: 0.05721178637001075, Temperature 0.00014738731582510513, step_size 0.955230802058386, test_acc: 0.4299\n",
            "Epoch 1087, BestLoss: 0.05721178637001075, Temperature 0.00015514454297379488, step_size 0.9553263346918551, test_acc: 0.4299\n",
            "Epoch 1088, BestLoss: 0.05733937450547033, Temperature 0.00016331004523557357, step_size 0.955230802058386, test_acc: 0.4287\n",
            "Epoch 1089, BestLoss: 0.05733937450547033, Temperature 0.00015514454297379488, step_size 0.9551352789781802, test_acc: 0.4287\n",
            "Epoch 1090, BestLoss: 0.05733937450547033, Temperature 0.00016331004523557357, step_size 0.9551352789781802, test_acc: 0.4287\n",
            "Epoch 1091, BestLoss: 0.057306647367655214, Temperature 0.00017190531077428798, step_size 0.9550397654502824, test_acc: 0.4284\n",
            "Epoch 1092, BestLoss: 0.05754036470312245, Temperature 0.00016331004523557357, step_size 0.9549442614737373, test_acc: 0.4268\n",
            "Epoch 1093, BestLoss: 0.05754036470312245, Temperature 0.00015514454297379488, step_size 0.95484876704759, test_acc: 0.4268\n",
            "Epoch 1094, BestLoss: 0.05754036470312245, Temperature 0.00016331004523557357, step_size 0.9549442614737373, test_acc: 0.4268\n",
            "Epoch 1095, BestLoss: 0.05754036470312245, Temperature 0.00017190531077428798, step_size 0.95484876704759, test_acc: 0.4268\n",
            "Epoch 1096, BestLoss: 0.057748936276183424, Temperature 0.00018095295870977683, step_size 0.9547532821708853, test_acc: 0.4236\n",
            "Epoch 1097, BestLoss: 0.057749489585045666, Temperature 0.00017190531077428798, step_size 0.9546578068426682, test_acc: 0.4252\n",
            "Epoch 1098, BestLoss: 0.057749489585045666, Temperature 0.00018095295870977683, step_size 0.9546578068426682, test_acc: 0.4252\n",
            "Epoch 1099, BestLoss: 0.057749489585045666, Temperature 0.00019047679864187035, step_size 0.9545623410619839, test_acc: 0.4252\n",
            "Epoch 1100, BestLoss: 0.057742920910947314, Temperature 0.00020050189330723196, step_size 0.9544668848278777, test_acc: 0.4261\n",
            "Epoch 1101, BestLoss: 0.05776266910885443, Temperature 0.00019047679864187035, step_size 0.9543714381393948, test_acc: 0.4245\n",
            "Epoch 1102, BestLoss: 0.05776266910885443, Temperature 0.00018095295870977683, step_size 0.954276000995581, test_acc: 0.4245\n",
            "Epoch 1103, BestLoss: 0.05777036231818986, Temperature 0.00019047679864187035, step_size 0.9543714381393948, test_acc: 0.4241\n",
            "Epoch 1104, BestLoss: 0.05756337523777768, Temperature 0.00018095295870977683, step_size 0.954276000995581, test_acc: 0.4258\n",
            "Epoch 1105, BestLoss: 0.05733735537820265, Temperature 0.00017190531077428798, step_size 0.9541805733954815, test_acc: 0.4311\n",
            "Epoch 1106, BestLoss: 0.05746398409826019, Temperature 0.00016331004523557357, step_size 0.9540851553381419, test_acc: 0.4283\n",
            "Epoch 1107, BestLoss: 0.05746398409826019, Temperature 0.00015514454297379488, step_size 0.9539897468226081, test_acc: 0.4283\n",
            "Epoch 1108, BestLoss: 0.057481640480592434, Temperature 0.00016331004523557357, step_size 0.954276000995581, test_acc: 0.4307\n",
            "Epoch 1109, BestLoss: 0.05775601887257171, Temperature 0.00015514454297379488, step_size 0.9541805733954815, test_acc: 0.4246\n",
            "Epoch 1110, BestLoss: 0.057743682650245425, Temperature 0.00014738731582510513, step_size 0.9540851553381419, test_acc: 0.4263\n",
            "Epoch 1111, BestLoss: 0.057806951634776775, Temperature 0.00014001795003384986, step_size 0.9539897468226081, test_acc: 0.4252\n",
            "Epoch 1112, BestLoss: 0.057806951634776775, Temperature 0.00013301705253215737, step_size 0.9538943478479258, test_acc: 0.4252\n",
            "Epoch 1113, BestLoss: 0.058022125977318054, Temperature 0.00014001795003384986, step_size 0.9541805733954815, test_acc: 0.4218\n",
            "Epoch 1114, BestLoss: 0.05785594593813941, Temperature 0.00013301705253215737, step_size 0.9540851553381419, test_acc: 0.4252\n",
            "Epoch 1115, BestLoss: 0.05785594593813941, Temperature 0.0001263661999055495, step_size 0.9539897468226081, test_acc: 0.4252\n",
            "Epoch 1116, BestLoss: 0.05795026044451217, Temperature 0.00013301705253215737, step_size 0.9540851553381419, test_acc: 0.4229\n",
            "Epoch 1117, BestLoss: 0.057875378206669874, Temperature 0.0001263661999055495, step_size 0.9539897468226081, test_acc: 0.4255\n",
            "Epoch 1118, BestLoss: 0.057875378206669874, Temperature 0.000120047889910272, step_size 0.9538943478479258, test_acc: 0.4255\n",
            "Epoch 1119, BestLoss: 0.057875378206669874, Temperature 0.0001263661999055495, step_size 0.9539897468226081, test_acc: 0.4255\n",
            "Epoch 1120, BestLoss: 0.057875378206669874, Temperature 0.00013301705253215737, step_size 0.9538943478479258, test_acc: 0.4255\n",
            "Epoch 1121, BestLoss: 0.057880587172106, Temperature 0.00014001795003384986, step_size 0.953798958413141, test_acc: 0.4267\n",
            "Epoch 1122, BestLoss: 0.05753062067730873, Temperature 0.00014738731582510513, step_size 0.9537035785172997, test_acc: 0.4271\n",
            "Epoch 1123, BestLoss: 0.05727797775737831, Temperature 0.00014001795003384986, step_size 0.953608208159448, test_acc: 0.4308\n",
            "Epoch 1124, BestLoss: 0.05727797775737831, Temperature 0.00013301705253215737, step_size 0.9535128473386321, test_acc: 0.4308\n",
            "Epoch 1125, BestLoss: 0.05727797775737831, Temperature 0.00014001795003384986, step_size 0.953608208159448, test_acc: 0.4308\n",
            "Epoch 1126, BestLoss: 0.057022484472351864, Temperature 0.00014738731582510513, step_size 0.9535128473386321, test_acc: 0.4335\n",
            "Epoch 1127, BestLoss: 0.057022484472351864, Temperature 0.00014001795003384986, step_size 0.9534174960538983, test_acc: 0.4335\n",
            "Epoch 1128, BestLoss: 0.057022484472351864, Temperature 0.00014738731582510513, step_size 0.9534174960538983, test_acc: 0.4335\n",
            "Epoch 1129, BestLoss: 0.057022484472351864, Temperature 0.00015514454297379488, step_size 0.9533221543042929, test_acc: 0.4335\n",
            "Epoch 1130, BestLoss: 0.056957778643794685, Temperature 0.00016331004523557357, step_size 0.9532268220888624, test_acc: 0.4346\n",
            "Epoch 1131, BestLoss: 0.056957778643794685, Temperature 0.00015514454297379488, step_size 0.9531314994066535, test_acc: 0.4346\n",
            "Epoch 1132, BestLoss: 0.056957778643794685, Temperature 0.00016331004523557357, step_size 0.9531314994066535, test_acc: 0.4346\n",
            "Epoch 1133, BestLoss: 0.056829293470254026, Temperature 0.00017190531077428798, step_size 0.9530361862567129, test_acc: 0.4358\n",
            "Epoch 1134, BestLoss: 0.056829293470254026, Temperature 0.00016331004523557357, step_size 0.9529408826380873, test_acc: 0.4358\n",
            "Epoch 1135, BestLoss: 0.056829293470254026, Temperature 0.00017190531077428798, step_size 0.9529408826380873, test_acc: 0.4358\n",
            "Epoch 1136, BestLoss: 0.056829293470254026, Temperature 0.00018095295870977683, step_size 0.9528455885498235, test_acc: 0.4358\n",
            "Epoch 1137, BestLoss: 0.056808030664008004, Temperature 0.00019047679864187035, step_size 0.9527503039909685, test_acc: 0.4355\n",
            "Epoch 1138, BestLoss: 0.056808030664008004, Temperature 0.00018095295870977683, step_size 0.9526550289605694, test_acc: 0.4355\n",
            "Epoch 1139, BestLoss: 0.056767338061688946, Temperature 0.00019047679864187035, step_size 0.9526550289605694, test_acc: 0.4351\n",
            "Epoch 1140, BestLoss: 0.056767338061688946, Temperature 0.00018095295870977683, step_size 0.9525597634576733, test_acc: 0.4351\n",
            "Epoch 1141, BestLoss: 0.056767338061688946, Temperature 0.00019047679864187035, step_size 0.9525597634576733, test_acc: 0.4351\n",
            "Epoch 1142, BestLoss: 0.05687907525361704, Temperature 0.00020050189330723196, step_size 0.9524645074813276, test_acc: 0.4349\n",
            "Epoch 1143, BestLoss: 0.05668832673228188, Temperature 0.00019047679864187035, step_size 0.9523692610305795, test_acc: 0.4373\n",
            "Epoch 1144, BestLoss: 0.056876124751344834, Temperature 0.00018095295870977683, step_size 0.9522740241044765, test_acc: 0.4366\n",
            "Epoch 1145, BestLoss: 0.056876124751344834, Temperature 0.00017190531077428798, step_size 0.9521787967020661, test_acc: 0.4366\n",
            "Epoch 1146, BestLoss: 0.05704715807029526, Temperature 0.00018095295870977683, step_size 0.9523692610305795, test_acc: 0.433\n",
            "Epoch 1147, BestLoss: 0.05688462715441227, Temperature 0.00017190531077428798, step_size 0.9522740241044765, test_acc: 0.4362\n",
            "Epoch 1148, BestLoss: 0.05670165001962632, Temperature 0.00016331004523557357, step_size 0.9521787967020661, test_acc: 0.4388\n",
            "Epoch 1149, BestLoss: 0.056436326015550355, Temperature 0.00015514454297379488, step_size 0.9520835788223959, test_acc: 0.443\n",
            "Epoch 1150, BestLoss: 0.056436326015550355, Temperature 0.00014738731582510513, step_size 0.9519883704645137, test_acc: 0.443\n",
            "Epoch 1151, BestLoss: 0.056132831348476346, Temperature 0.00015514454297379488, step_size 0.9522740241044765, test_acc: 0.4452\n",
            "Epoch 1152, BestLoss: 0.0562177449902262, Temperature 0.00014738731582510513, step_size 0.9521787967020661, test_acc: 0.4455\n",
            "Epoch 1153, BestLoss: 0.056400980975207564, Temperature 0.00014001795003384986, step_size 0.9520835788223959, test_acc: 0.4432\n",
            "Epoch 1154, BestLoss: 0.056348569786262424, Temperature 0.00013301705253215737, step_size 0.9519883704645137, test_acc: 0.4422\n",
            "Epoch 1155, BestLoss: 0.056348569786262424, Temperature 0.0001263661999055495, step_size 0.9518931716274672, test_acc: 0.4422\n",
            "Epoch 1156, BestLoss: 0.056159360568731866, Temperature 0.00013301705253215737, step_size 0.9521787967020661, test_acc: 0.4445\n",
            "Epoch 1157, BestLoss: 0.056159360568731866, Temperature 0.0001263661999055495, step_size 0.9520835788223959, test_acc: 0.4445\n",
            "Epoch 1158, BestLoss: 0.056159360568731866, Temperature 0.00013301705253215737, step_size 0.9520835788223959, test_acc: 0.4445\n",
            "Epoch 1159, BestLoss: 0.05604553253453928, Temperature 0.00014001795003384986, step_size 0.9519883704645137, test_acc: 0.4454\n",
            "Epoch 1160, BestLoss: 0.05604553253453928, Temperature 0.00013301705253215737, step_size 0.9518931716274672, test_acc: 0.4454\n",
            "Epoch 1161, BestLoss: 0.05604553253453928, Temperature 0.00014001795003384986, step_size 0.9518931716274672, test_acc: 0.4454\n",
            "Epoch 1162, BestLoss: 0.05604553253453928, Temperature 0.00014738731582510513, step_size 0.9517979823103044, test_acc: 0.4454\n",
            "Epoch 1163, BestLoss: 0.05604553253453928, Temperature 0.00015514454297379488, step_size 0.9517028025120734, test_acc: 0.4454\n",
            "Epoch 1164, BestLoss: 0.055783324069111524, Temperature 0.00016331004523557357, step_size 0.9516076322318222, test_acc: 0.4484\n",
            "Epoch 1165, BestLoss: 0.055783324069111524, Temperature 0.00015514454297379488, step_size 0.9515124714685991, test_acc: 0.4484\n",
            "Epoch 1166, BestLoss: 0.055783324069111524, Temperature 0.00016331004523557357, step_size 0.9515124714685991, test_acc: 0.4484\n",
            "Epoch 1167, BestLoss: 0.05580611047474532, Temperature 0.00017190531077428798, step_size 0.9514173202214522, test_acc: 0.4482\n",
            "Epoch 1168, BestLoss: 0.05580611047474532, Temperature 0.00016331004523557357, step_size 0.95132217848943, test_acc: 0.4482\n",
            "Epoch 1169, BestLoss: 0.05580611047474532, Temperature 0.00017190531077428798, step_size 0.95132217848943, test_acc: 0.4482\n",
            "Epoch 1170, BestLoss: 0.05595966122613189, Temperature 0.00018095295870977683, step_size 0.9512270462715811, test_acc: 0.4471\n",
            "Epoch 1171, BestLoss: 0.05595966122613189, Temperature 0.00017190531077428798, step_size 0.9511319235669539, test_acc: 0.4471\n",
            "Epoch 1172, BestLoss: 0.05595966122613189, Temperature 0.00018095295870977683, step_size 0.9511319235669539, test_acc: 0.4471\n",
            "Epoch 1173, BestLoss: 0.05586901351035102, Temperature 0.00019047679864187035, step_size 0.9510368103745972, test_acc: 0.449\n",
            "Epoch 1174, BestLoss: 0.05586901351035102, Temperature 0.00018095295870977683, step_size 0.9509417066935597, test_acc: 0.449\n",
            "Epoch 1175, BestLoss: 0.055873389308135374, Temperature 0.00019047679864187035, step_size 0.9509417066935597, test_acc: 0.4487\n",
            "Epoch 1176, BestLoss: 0.05586046721740794, Temperature 0.00020050189330723196, step_size 0.9508466125228904, test_acc: 0.4485\n",
            "Epoch 1177, BestLoss: 0.05586046721740794, Temperature 0.00019047679864187035, step_size 0.9507515278616381, test_acc: 0.4485\n",
            "Epoch 1178, BestLoss: 0.05608163458913471, Temperature 0.00020050189330723196, step_size 0.9507515278616381, test_acc: 0.4466\n",
            "Epoch 1179, BestLoss: 0.05622319753704401, Temperature 0.00019047679864187035, step_size 0.9506564527088519, test_acc: 0.4438\n",
            "Epoch 1180, BestLoss: 0.05622319753704401, Temperature 0.00018095295870977683, step_size 0.9505613870635811, test_acc: 0.4438\n",
            "Epoch 1181, BestLoss: 0.05597496989270015, Temperature 0.00019047679864187035, step_size 0.9506564527088519, test_acc: 0.4435\n",
            "Epoch 1182, BestLoss: 0.05597496989270015, Temperature 0.00018095295870977683, step_size 0.9505613870635811, test_acc: 0.4435\n",
            "Epoch 1183, BestLoss: 0.0559332827237976, Temperature 0.00019047679864187035, step_size 0.9505613870635811, test_acc: 0.4459\n",
            "Epoch 1184, BestLoss: 0.05601431158677643, Temperature 0.00018095295870977683, step_size 0.9504663309248748, test_acc: 0.4472\n",
            "Epoch 1185, BestLoss: 0.05601431158677643, Temperature 0.00017190531077428798, step_size 0.9503712842917823, test_acc: 0.4472\n",
            "Epoch 1186, BestLoss: 0.05613269415924296, Temperature 0.00018095295870977683, step_size 0.9504663309248748, test_acc: 0.4453\n",
            "Epoch 1187, BestLoss: 0.05600886189060676, Temperature 0.00017190531077428798, step_size 0.9503712842917823, test_acc: 0.4472\n",
            "Epoch 1188, BestLoss: 0.05600886189060676, Temperature 0.00016331004523557357, step_size 0.9502762471633531, test_acc: 0.4472\n",
            "Epoch 1189, BestLoss: 0.05600886189060676, Temperature 0.00017190531077428798, step_size 0.9503712842917823, test_acc: 0.4472\n",
            "Epoch 1190, BestLoss: 0.05600886189060676, Temperature 0.00018095295870977683, step_size 0.9502762471633531, test_acc: 0.4472\n",
            "Epoch 1191, BestLoss: 0.05600886189060676, Temperature 0.00019047679864187035, step_size 0.9501812195386368, test_acc: 0.4472\n",
            "Epoch 1192, BestLoss: 0.05600886189060676, Temperature 0.00020050189330723196, step_size 0.9500862014166829, test_acc: 0.4472\n",
            "Epoch 1193, BestLoss: 0.05600886189060676, Temperature 0.00021105462453392839, step_size 0.9499911927965412, test_acc: 0.4472\n",
            "Epoch 1194, BestLoss: 0.05600886189060676, Temperature 0.00022216276266729304, step_size 0.9498961936772615, test_acc: 0.4472\n",
            "Epoch 1195, BestLoss: 0.05600886189060676, Temperature 0.00023385553964978215, step_size 0.9498012040578938, test_acc: 0.4472\n",
            "Epoch 1196, BestLoss: 0.05615376065286803, Temperature 0.00024616372594713913, step_size 0.949706223937488, test_acc: 0.4452\n",
            "Epoch 1197, BestLoss: 0.05615376065286803, Temperature 0.00023385553964978215, step_size 0.9496112533150943, test_acc: 0.4452\n",
            "Epoch 1198, BestLoss: 0.055918844131523135, Temperature 0.00024616372594713913, step_size 0.9496112533150943, test_acc: 0.4467\n",
            "Epoch 1199, BestLoss: 0.05593050523295163, Temperature 0.00023385553964978215, step_size 0.9495162921897629, test_acc: 0.4453\n",
            "Epoch 1200, BestLoss: 0.055897649033345514, Temperature 0.00022216276266729304, step_size 0.9494213405605438, test_acc: 0.4453\n",
            "Epoch 1201, BestLoss: 0.055761145979136735, Temperature 0.00021105462453392839, step_size 0.9493263984264878, test_acc: 0.4468\n",
            "Epoch 1202, BestLoss: 0.05559733306480067, Temperature 0.00020050189330723196, step_size 0.9492314657866452, test_acc: 0.448\n",
            "Epoch 1203, BestLoss: 0.05559733306480067, Temperature 0.00019047679864187035, step_size 0.9491365426400665, test_acc: 0.448\n",
            "Epoch 1204, BestLoss: 0.055679855298205246, Temperature 0.00020050189330723196, step_size 0.9495162921897629, test_acc: 0.4468\n",
            "Epoch 1205, BestLoss: 0.055679855298205246, Temperature 0.00019047679864187035, step_size 0.9494213405605438, test_acc: 0.4468\n",
            "Epoch 1206, BestLoss: 0.055679855298205246, Temperature 0.00020050189330723196, step_size 0.9494213405605438, test_acc: 0.4468\n",
            "Epoch 1207, BestLoss: 0.05558603368334894, Temperature 0.00021105462453392839, step_size 0.9493263984264878, test_acc: 0.4476\n",
            "Epoch 1208, BestLoss: 0.05532476795312232, Temperature 0.00020050189330723196, step_size 0.9492314657866452, test_acc: 0.4499\n",
            "Epoch 1209, BestLoss: 0.05533550896506171, Temperature 0.00019047679864187035, step_size 0.9491365426400665, test_acc: 0.451\n",
            "Epoch 1210, BestLoss: 0.05528093003132675, Temperature 0.00018095295870977683, step_size 0.9490416289858026, test_acc: 0.4511\n",
            "Epoch 1211, BestLoss: 0.05537912974452129, Temperature 0.00017190531077428798, step_size 0.948946724822904, test_acc: 0.4519\n",
            "Epoch 1212, BestLoss: 0.05537912974452129, Temperature 0.00016331004523557357, step_size 0.9488518301504217, test_acc: 0.4519\n",
            "Epoch 1213, BestLoss: 0.05537912974452129, Temperature 0.00017190531077428798, step_size 0.9492314657866452, test_acc: 0.4519\n",
            "Epoch 1214, BestLoss: 0.05562091913514123, Temperature 0.00018095295870977683, step_size 0.9491365426400665, test_acc: 0.4494\n",
            "Epoch 1215, BestLoss: 0.05562091913514123, Temperature 0.00017190531077428798, step_size 0.9490416289858026, test_acc: 0.4494\n",
            "Epoch 1216, BestLoss: 0.055602458456751845, Temperature 0.00018095295870977683, step_size 0.9490416289858026, test_acc: 0.4492\n",
            "Epoch 1217, BestLoss: 0.055773463063236266, Temperature 0.00017190531077428798, step_size 0.948946724822904, test_acc: 0.4484\n",
            "Epoch 1218, BestLoss: 0.05565169458009127, Temperature 0.00016331004523557357, step_size 0.9488518301504217, test_acc: 0.4487\n",
            "Epoch 1219, BestLoss: 0.05569386794206143, Temperature 0.00015514454297379488, step_size 0.9487569449674067, test_acc: 0.4471\n",
            "Epoch 1220, BestLoss: 0.05569386794206143, Temperature 0.00014738731582510513, step_size 0.94866206927291, test_acc: 0.4471\n",
            "Epoch 1221, BestLoss: 0.05569916831590958, Temperature 0.00015514454297379488, step_size 0.948946724822904, test_acc: 0.4452\n",
            "Epoch 1222, BestLoss: 0.05559616370117254, Temperature 0.00016331004523557357, step_size 0.9488518301504217, test_acc: 0.4473\n",
            "Epoch 1223, BestLoss: 0.05559616370117254, Temperature 0.00015514454297379488, step_size 0.9487569449674067, test_acc: 0.4473\n",
            "Epoch 1224, BestLoss: 0.05559616370117254, Temperature 0.00016331004523557357, step_size 0.9487569449674067, test_acc: 0.4473\n",
            "Epoch 1225, BestLoss: 0.05549208128623599, Temperature 0.00017190531077428798, step_size 0.94866206927291, test_acc: 0.4477\n",
            "Epoch 1226, BestLoss: 0.05567509917004656, Temperature 0.00016331004523557357, step_size 0.9485672030659826, test_acc: 0.4479\n",
            "Epoch 1227, BestLoss: 0.05564375934435741, Temperature 0.00015514454297379488, step_size 0.948472346345676, test_acc: 0.4481\n",
            "Epoch 1228, BestLoss: 0.05560474309719497, Temperature 0.00014738731582510513, step_size 0.9483774991110414, test_acc: 0.4471\n",
            "Epoch 1229, BestLoss: 0.0558869283205027, Temperature 0.00014001795003384986, step_size 0.9482826613611303, test_acc: 0.4436\n",
            "Epoch 1230, BestLoss: 0.05579994526365509, Temperature 0.00013301705253215737, step_size 0.9481878330949942, test_acc: 0.4433\n",
            "Epoch 1231, BestLoss: 0.05583946131409461, Temperature 0.0001263661999055495, step_size 0.9480930143116847, test_acc: 0.4435\n",
            "Epoch 1232, BestLoss: 0.05583946131409461, Temperature 0.000120047889910272, step_size 0.9479982050102536, test_acc: 0.4435\n",
            "Epoch 1233, BestLoss: 0.05583946131409461, Temperature 0.0001263661999055495, step_size 0.9485672030659826, test_acc: 0.4435\n",
            "Epoch 1234, BestLoss: 0.05583946131409461, Temperature 0.00013301705253215737, step_size 0.948472346345676, test_acc: 0.4435\n",
            "Epoch 1235, BestLoss: 0.05567815811882496, Temperature 0.00014001795003384986, step_size 0.9483774991110414, test_acc: 0.4446\n",
            "Epoch 1236, BestLoss: 0.05567815811882496, Temperature 0.00013301705253215737, step_size 0.9482826613611303, test_acc: 0.4446\n",
            "Epoch 1237, BestLoss: 0.05567815811882496, Temperature 0.00014001795003384986, step_size 0.9482826613611303, test_acc: 0.4446\n",
            "Epoch 1238, BestLoss: 0.0558152509211948, Temperature 0.00014738731582510513, step_size 0.9481878330949942, test_acc: 0.443\n",
            "Epoch 1239, BestLoss: 0.05584279828840913, Temperature 0.00014001795003384986, step_size 0.9480930143116847, test_acc: 0.4441\n",
            "Epoch 1240, BestLoss: 0.05598117148753738, Temperature 0.00013301705253215737, step_size 0.9479982050102536, test_acc: 0.4449\n",
            "Epoch 1241, BestLoss: 0.05598117148753738, Temperature 0.0001263661999055495, step_size 0.9479034051897526, test_acc: 0.4449\n",
            "Epoch 1242, BestLoss: 0.05598117148753738, Temperature 0.00013301705253215737, step_size 0.9480930143116847, test_acc: 0.4449\n",
            "Epoch 1243, BestLoss: 0.05598117148753738, Temperature 0.00014001795003384986, step_size 0.9479982050102536, test_acc: 0.4449\n",
            "Epoch 1244, BestLoss: 0.05600651975379784, Temperature 0.00014738731582510513, step_size 0.9479034051897526, test_acc: 0.4464\n",
            "Epoch 1245, BestLoss: 0.05600651975379784, Temperature 0.00014001795003384986, step_size 0.9478086148492336, test_acc: 0.4464\n",
            "Epoch 1246, BestLoss: 0.055936663921347475, Temperature 0.00014738731582510513, step_size 0.9478086148492336, test_acc: 0.4468\n",
            "Epoch 1247, BestLoss: 0.055865724136303495, Temperature 0.00014001795003384986, step_size 0.9477138339877487, test_acc: 0.4457\n",
            "Epoch 1248, BestLoss: 0.0557973707696652, Temperature 0.00013301705253215737, step_size 0.9476190626043499, test_acc: 0.4465\n",
            "Epoch 1249, BestLoss: 0.05581907837948698, Temperature 0.0001263661999055495, step_size 0.9475243006980895, test_acc: 0.4469\n",
            "Epoch 1250, BestLoss: 0.05581907837948698, Temperature 0.000120047889910272, step_size 0.9474295482680196, test_acc: 0.4469\n",
            "Epoch 1251, BestLoss: 0.05590936324131874, Temperature 0.0001263661999055495, step_size 0.9477138339877487, test_acc: 0.4485\n",
            "Epoch 1252, BestLoss: 0.056132929359135525, Temperature 0.000120047889910272, step_size 0.9476190626043499, test_acc: 0.4456\n",
            "Epoch 1253, BestLoss: 0.056132929359135525, Temperature 0.0001140454954147584, step_size 0.9475243006980895, test_acc: 0.4456\n",
            "Epoch 1254, BestLoss: 0.056132929359135525, Temperature 0.000120047889910272, step_size 0.9476190626043499, test_acc: 0.4456\n",
            "Epoch 1255, BestLoss: 0.056132929359135525, Temperature 0.0001263661999055495, step_size 0.9475243006980895, test_acc: 0.4456\n",
            "Epoch 1256, BestLoss: 0.056132929359135525, Temperature 0.00013301705253215737, step_size 0.9474295482680196, test_acc: 0.4456\n",
            "Epoch 1257, BestLoss: 0.05621541591882113, Temperature 0.00014001795003384986, step_size 0.9473348053131928, test_acc: 0.4449\n",
            "Epoch 1258, BestLoss: 0.05606969257963196, Temperature 0.00013301705253215737, step_size 0.9472400718326615, test_acc: 0.4465\n",
            "Epoch 1259, BestLoss: 0.05606969257963196, Temperature 0.0001263661999055495, step_size 0.9471453478254782, test_acc: 0.4465\n",
            "Epoch 1260, BestLoss: 0.05606969257963196, Temperature 0.00013301705253215737, step_size 0.9472400718326615, test_acc: 0.4465\n",
            "Epoch 1261, BestLoss: 0.05606969257963196, Temperature 0.00014001795003384986, step_size 0.9471453478254782, test_acc: 0.4465\n",
            "Epoch 1262, BestLoss: 0.05604770495263743, Temperature 0.00014738731582510513, step_size 0.9470506332906957, test_acc: 0.4463\n",
            "Epoch 1263, BestLoss: 0.056006605540275776, Temperature 0.00014001795003384986, step_size 0.9469559282273666, test_acc: 0.4454\n",
            "Epoch 1264, BestLoss: 0.0557455170524459, Temperature 0.00013301705253215737, step_size 0.9468612326345439, test_acc: 0.4452\n",
            "Epoch 1265, BestLoss: 0.05578113684993144, Temperature 0.0001263661999055495, step_size 0.9467665465112804, test_acc: 0.4443\n",
            "Epoch 1266, BestLoss: 0.05578113684993144, Temperature 0.000120047889910272, step_size 0.9466718698566293, test_acc: 0.4443\n",
            "Epoch 1267, BestLoss: 0.05578113684993144, Temperature 0.0001263661999055495, step_size 0.9469559282273666, test_acc: 0.4443\n",
            "Epoch 1268, BestLoss: 0.05578113684993144, Temperature 0.00013301705253215737, step_size 0.9468612326345439, test_acc: 0.4443\n",
            "Epoch 1269, BestLoss: 0.05578113684993144, Temperature 0.00014001795003384986, step_size 0.9467665465112804, test_acc: 0.4443\n",
            "Epoch 1270, BestLoss: 0.055799969326753344, Temperature 0.00014738731582510513, step_size 0.9466718698566293, test_acc: 0.4447\n",
            "Epoch 1271, BestLoss: 0.055769544346140794, Temperature 0.00014001795003384986, step_size 0.9465772026696436, test_acc: 0.4434\n",
            "Epoch 1272, BestLoss: 0.055769544346140794, Temperature 0.00013301705253215737, step_size 0.9464825449493767, test_acc: 0.4434\n",
            "Epoch 1273, BestLoss: 0.055769544346140794, Temperature 0.00014001795003384986, step_size 0.9465772026696436, test_acc: 0.4434\n",
            "Epoch 1274, BestLoss: 0.05563588440552971, Temperature 0.00014738731582510513, step_size 0.9464825449493767, test_acc: 0.4438\n",
            "Epoch 1275, BestLoss: 0.0556873440084586, Temperature 0.00014001795003384986, step_size 0.9463878966948818, test_acc: 0.4451\n",
            "Epoch 1276, BestLoss: 0.05548978229528657, Temperature 0.00013301705253215737, step_size 0.9462932579052122, test_acc: 0.4485\n",
            "Epoch 1277, BestLoss: 0.05548978229528657, Temperature 0.0001263661999055495, step_size 0.9461986285794217, test_acc: 0.4485\n",
            "Epoch 1278, BestLoss: 0.055736385846663856, Temperature 0.00013301705253215737, step_size 0.9463878966948818, test_acc: 0.4492\n",
            "Epoch 1279, BestLoss: 0.055736385846663856, Temperature 0.0001263661999055495, step_size 0.9462932579052122, test_acc: 0.4492\n",
            "Epoch 1280, BestLoss: 0.05595384330816225, Temperature 0.00013301705253215737, step_size 0.9462932579052122, test_acc: 0.4499\n",
            "Epoch 1281, BestLoss: 0.05595384330816225, Temperature 0.0001263661999055495, step_size 0.9461986285794217, test_acc: 0.4499\n",
            "Epoch 1282, BestLoss: 0.05588075858293349, Temperature 0.00013301705253215737, step_size 0.9461986285794217, test_acc: 0.4498\n",
            "Epoch 1283, BestLoss: 0.05585701135247119, Temperature 0.0001263661999055495, step_size 0.9461040087165637, test_acc: 0.4469\n",
            "Epoch 1284, BestLoss: 0.056147780795050964, Temperature 0.000120047889910272, step_size 0.9460093983156921, test_acc: 0.4447\n",
            "Epoch 1285, BestLoss: 0.05603672489886599, Temperature 0.0001140454954147584, step_size 0.9459147973758605, test_acc: 0.4469\n",
            "Epoch 1286, BestLoss: 0.0559599966962491, Temperature 0.00010834322064402047, step_size 0.9458202058961229, test_acc: 0.448\n",
            "Epoch 1287, BestLoss: 0.055681147169809, Temperature 0.00010292605961181944, step_size 0.9457256238755333, test_acc: 0.4496\n",
            "Epoch 1288, BestLoss: 0.055681147169809, Temperature 9.777975663122846e-05, step_size 0.9456310513131457, test_acc: 0.4496\n",
            "Epoch 1289, BestLoss: 0.055681147169809, Temperature 0.00010292605961181944, step_size 0.9461040087165637, test_acc: 0.4496\n",
            "Epoch 1290, BestLoss: 0.055681147169809, Temperature 0.00010834322064402047, step_size 0.9460093983156921, test_acc: 0.4496\n",
            "Epoch 1291, BestLoss: 0.055513547199528585, Temperature 0.0001140454954147584, step_size 0.9459147973758605, test_acc: 0.4493\n",
            "Epoch 1292, BestLoss: 0.055513547199528585, Temperature 0.00010834322064402047, step_size 0.9458202058961229, test_acc: 0.4493\n",
            "Epoch 1293, BestLoss: 0.0555076440194962, Temperature 0.0001140454954147584, step_size 0.9458202058961229, test_acc: 0.4485\n",
            "Epoch 1294, BestLoss: 0.0555076440194962, Temperature 0.00010834322064402047, step_size 0.9457256238755333, test_acc: 0.4485\n",
            "Epoch 1295, BestLoss: 0.0555076440194962, Temperature 0.0001140454954147584, step_size 0.9457256238755333, test_acc: 0.4485\n",
            "Epoch 1296, BestLoss: 0.0555076440194962, Temperature 0.000120047889910272, step_size 0.9456310513131457, test_acc: 0.4485\n",
            "Epoch 1297, BestLoss: 0.0555076440194962, Temperature 0.0001263661999055495, step_size 0.9455364882080144, test_acc: 0.4485\n",
            "Epoch 1298, BestLoss: 0.055662745148709995, Temperature 0.00013301705253215737, step_size 0.9454419345591936, test_acc: 0.4483\n",
            "Epoch 1299, BestLoss: 0.055662745148709995, Temperature 0.0001263661999055495, step_size 0.9453473903657377, test_acc: 0.4483\n",
            "Epoch 1300, BestLoss: 0.055662745148709995, Temperature 0.00013301705253215737, step_size 0.9453473903657377, test_acc: 0.4483\n",
            "Epoch 1301, BestLoss: 0.055667542618646405, Temperature 0.00014001795003384986, step_size 0.9452528556267011, test_acc: 0.4488\n",
            "Epoch 1302, BestLoss: 0.055699207332742515, Temperature 0.00014738731582510513, step_size 0.9451583303411385, test_acc: 0.4489\n",
            "Epoch 1303, BestLoss: 0.055734793631535454, Temperature 0.00014001795003384986, step_size 0.9450638145081044, test_acc: 0.4474\n",
            "Epoch 1304, BestLoss: 0.055734793631535454, Temperature 0.00013301705253215737, step_size 0.9449693081266536, test_acc: 0.4474\n",
            "Epoch 1305, BestLoss: 0.055734793631535454, Temperature 0.00014001795003384986, step_size 0.9450638145081044, test_acc: 0.4474\n",
            "Epoch 1306, BestLoss: 0.055734793631535454, Temperature 0.00014738731582510513, step_size 0.9449693081266536, test_acc: 0.4474\n",
            "Epoch 1307, BestLoss: 0.055667524313945685, Temperature 0.00015514454297379488, step_size 0.9448748111958409, test_acc: 0.4486\n",
            "Epoch 1308, BestLoss: 0.055667524313945685, Temperature 0.00014738731582510513, step_size 0.9447803237147213, test_acc: 0.4486\n",
            "Epoch 1309, BestLoss: 0.055661733012472125, Temperature 0.00015514454297379488, step_size 0.9447803237147213, test_acc: 0.4483\n",
            "Epoch 1310, BestLoss: 0.05557750973886264, Temperature 0.00014738731582510513, step_size 0.9446858456823498, test_acc: 0.4471\n",
            "Epoch 1311, BestLoss: 0.0553711878105829, Temperature 0.00014001795003384986, step_size 0.9445913770977816, test_acc: 0.4499\n",
            "Epoch 1312, BestLoss: 0.0553711878105829, Temperature 0.00013301705253215737, step_size 0.9444969179600718, test_acc: 0.4499\n",
            "Epoch 1313, BestLoss: 0.055436209733485196, Temperature 0.00014001795003384986, step_size 0.9446858456823498, test_acc: 0.4512\n",
            "Epoch 1314, BestLoss: 0.055428136177765736, Temperature 0.00013301705253215737, step_size 0.9445913770977816, test_acc: 0.45\n",
            "Epoch 1315, BestLoss: 0.055490213486116, Temperature 0.0001263661999055495, step_size 0.9444969179600718, test_acc: 0.4493\n",
            "Epoch 1316, BestLoss: 0.05547458473221078, Temperature 0.000120047889910272, step_size 0.9444024682682759, test_acc: 0.449\n",
            "Epoch 1317, BestLoss: 0.05547458473221078, Temperature 0.0001140454954147584, step_size 0.9443080280214491, test_acc: 0.449\n",
            "Epoch 1318, BestLoss: 0.05547458473221078, Temperature 0.000120047889910272, step_size 0.9445913770977816, test_acc: 0.449\n",
            "Epoch 1319, BestLoss: 0.05535352069570353, Temperature 0.0001263661999055495, step_size 0.9444969179600718, test_acc: 0.4487\n",
            "Epoch 1320, BestLoss: 0.05535352069570353, Temperature 0.000120047889910272, step_size 0.9444024682682759, test_acc: 0.4487\n",
            "Epoch 1321, BestLoss: 0.05513752435534564, Temperature 0.0001263661999055495, step_size 0.9444024682682759, test_acc: 0.4502\n",
            "Epoch 1322, BestLoss: 0.05513752435534564, Temperature 0.000120047889910272, step_size 0.9443080280214491, test_acc: 0.4502\n",
            "Epoch 1323, BestLoss: 0.05504909053716869, Temperature 0.0001263661999055495, step_size 0.9443080280214491, test_acc: 0.4512\n",
            "Epoch 1324, BestLoss: 0.055087912487896684, Temperature 0.000120047889910272, step_size 0.944213597218647, test_acc: 0.4517\n",
            "Epoch 1325, BestLoss: 0.055087912487896684, Temperature 0.0001140454954147584, step_size 0.9441191758589251, test_acc: 0.4517\n",
            "Epoch 1326, BestLoss: 0.055213966598455684, Temperature 0.000120047889910272, step_size 0.944213597218647, test_acc: 0.45\n",
            "Epoch 1327, BestLoss: 0.05509287750003613, Temperature 0.0001140454954147584, step_size 0.9441191758589251, test_acc: 0.4507\n",
            "Epoch 1328, BestLoss: 0.05509287750003613, Temperature 0.00010834322064402047, step_size 0.9440247639413393, test_acc: 0.4507\n",
            "Epoch 1329, BestLoss: 0.05509287750003613, Temperature 0.0001140454954147584, step_size 0.9441191758589251, test_acc: 0.4507\n",
            "Epoch 1330, BestLoss: 0.055004230303573105, Temperature 0.000120047889910272, step_size 0.9440247639413393, test_acc: 0.4517\n",
            "Epoch 1331, BestLoss: 0.055004230303573105, Temperature 0.0001140454954147584, step_size 0.9439303614649451, test_acc: 0.4517\n",
            "Epoch 1332, BestLoss: 0.05483538683152098, Temperature 0.000120047889910272, step_size 0.9439303614649451, test_acc: 0.4533\n",
            "Epoch 1333, BestLoss: 0.05480725640508441, Temperature 0.0001140454954147584, step_size 0.9438359684287987, test_acc: 0.4525\n",
            "Epoch 1334, BestLoss: 0.05480725640508441, Temperature 0.00010834322064402047, step_size 0.9437415848319558, test_acc: 0.4525\n",
            "Epoch 1335, BestLoss: 0.05490803655992911, Temperature 0.0001140454954147584, step_size 0.9438359684287987, test_acc: 0.4524\n",
            "Epoch 1336, BestLoss: 0.05490803655992911, Temperature 0.00010834322064402047, step_size 0.9437415848319558, test_acc: 0.4524\n",
            "Epoch 1337, BestLoss: 0.05487055564962259, Temperature 0.0001140454954147584, step_size 0.9437415848319558, test_acc: 0.4547\n",
            "Epoch 1338, BestLoss: 0.05487055564962259, Temperature 0.00010834322064402047, step_size 0.9436472106734726, test_acc: 0.4547\n",
            "Epoch 1339, BestLoss: 0.05487055564962259, Temperature 0.0001140454954147584, step_size 0.9436472106734726, test_acc: 0.4547\n",
            "Epoch 1340, BestLoss: 0.05487055564962259, Temperature 0.000120047889910272, step_size 0.9435528459524052, test_acc: 0.4547\n",
            "Epoch 1341, BestLoss: 0.054953750062268394, Temperature 0.0001263661999055495, step_size 0.94345849066781, test_acc: 0.453\n",
            "Epoch 1342, BestLoss: 0.054953750062268394, Temperature 0.000120047889910272, step_size 0.9433641448187432, test_acc: 0.453\n",
            "Epoch 1343, BestLoss: 0.0549060605265466, Temperature 0.0001263661999055495, step_size 0.9433641448187432, test_acc: 0.4531\n",
            "Epoch 1344, BestLoss: 0.054993760682471284, Temperature 0.000120047889910272, step_size 0.9432698084042613, test_acc: 0.4515\n",
            "Epoch 1345, BestLoss: 0.054897989631370644, Temperature 0.0001140454954147584, step_size 0.9431754814234209, test_acc: 0.4523\n",
            "Epoch 1346, BestLoss: 0.05489917804456076, Temperature 0.00010834322064402047, step_size 0.9430811638752785, test_acc: 0.4513\n",
            "Epoch 1347, BestLoss: 0.05489917804456076, Temperature 0.0001140454954147584, step_size 0.9432698084042613, test_acc: 0.4513\n",
            "Epoch 1348, BestLoss: 0.05489917804456076, Temperature 0.000120047889910272, step_size 0.9431754814234209, test_acc: 0.4513\n",
            "Epoch 1349, BestLoss: 0.054779426043027685, Temperature 0.0001263661999055495, step_size 0.9430811638752785, test_acc: 0.452\n",
            "Epoch 1350, BestLoss: 0.054779426043027685, Temperature 0.000120047889910272, step_size 0.942986855758891, test_acc: 0.452\n",
            "Epoch 1351, BestLoss: 0.054779426043027685, Temperature 0.0001263661999055495, step_size 0.942986855758891, test_acc: 0.452\n",
            "Epoch 1352, BestLoss: 0.054543231831676246, Temperature 0.00013301705253215737, step_size 0.9428925570733151, test_acc: 0.455\n",
            "Epoch 1353, BestLoss: 0.05443511116214032, Temperature 0.0001263661999055495, step_size 0.9427982678176078, test_acc: 0.455\n",
            "Epoch 1354, BestLoss: 0.054352995478800986, Temperature 0.000120047889910272, step_size 0.942703987990826, test_acc: 0.4558\n",
            "Epoch 1355, BestLoss: 0.0543258283509046, Temperature 0.0001140454954147584, step_size 0.9426097175920269, test_acc: 0.456\n",
            "Epoch 1356, BestLoss: 0.054337363865676, Temperature 0.00010834322064402047, step_size 0.9425154566202677, test_acc: 0.4556\n",
            "Epoch 1357, BestLoss: 0.054337363865676, Temperature 0.00010292605961181944, step_size 0.9424212050746057, test_acc: 0.4556\n",
            "Epoch 1358, BestLoss: 0.054337363865676, Temperature 0.00010834322064402047, step_size 0.9427982678176078, test_acc: 0.4556\n",
            "Epoch 1359, BestLoss: 0.054337363865676, Temperature 0.0001140454954147584, step_size 0.942703987990826, test_acc: 0.4556\n",
            "Epoch 1360, BestLoss: 0.054337363865676, Temperature 0.000120047889910272, step_size 0.9426097175920269, test_acc: 0.4556\n",
            "Epoch 1361, BestLoss: 0.054337363865676, Temperature 0.0001263661999055495, step_size 0.9425154566202677, test_acc: 0.4556\n",
            "Epoch 1362, BestLoss: 0.05461557799770936, Temperature 0.00013301705253215737, step_size 0.9424212050746057, test_acc: 0.4526\n",
            "Epoch 1363, BestLoss: 0.05461557799770936, Temperature 0.0001263661999055495, step_size 0.9423269629540982, test_acc: 0.4526\n",
            "Epoch 1364, BestLoss: 0.054529216699914104, Temperature 0.00013301705253215737, step_size 0.9423269629540982, test_acc: 0.4525\n",
            "Epoch 1365, BestLoss: 0.05421934503062561, Temperature 0.0001263661999055495, step_size 0.9422327302578029, test_acc: 0.4574\n",
            "Epoch 1366, BestLoss: 0.05421934503062561, Temperature 0.000120047889910272, step_size 0.9421385069847771, test_acc: 0.4574\n",
            "Epoch 1367, BestLoss: 0.05421934503062561, Temperature 0.0001263661999055495, step_size 0.9422327302578029, test_acc: 0.4574\n",
            "Epoch 1368, BestLoss: 0.05404079691483571, Temperature 0.00013301705253215737, step_size 0.9421385069847771, test_acc: 0.4601\n",
            "Epoch 1369, BestLoss: 0.05404229653213185, Temperature 0.0001263661999055495, step_size 0.9420442931340786, test_acc: 0.4598\n",
            "Epoch 1370, BestLoss: 0.05404229653213185, Temperature 0.00013301705253215737, step_size 0.9420442931340786, test_acc: 0.4598\n",
            "Epoch 1371, BestLoss: 0.05404229653213185, Temperature 0.00014001795003384986, step_size 0.9419500887047652, test_acc: 0.4598\n",
            "Epoch 1372, BestLoss: 0.05404229653213185, Temperature 0.00014738731582510513, step_size 0.9418558936958947, test_acc: 0.4598\n",
            "Epoch 1373, BestLoss: 0.05391995126765943, Temperature 0.00015514454297379488, step_size 0.9417617081065252, test_acc: 0.4611\n",
            "Epoch 1374, BestLoss: 0.05392692918772835, Temperature 0.00014738731582510513, step_size 0.9416675319357145, test_acc: 0.4587\n",
            "Epoch 1375, BestLoss: 0.05415707904159584, Temperature 0.00014001795003384986, step_size 0.941573365182521, test_acc: 0.4567\n",
            "Epoch 1376, BestLoss: 0.05415707904159584, Temperature 0.00013301705253215737, step_size 0.9414792078460027, test_acc: 0.4567\n",
            "Epoch 1377, BestLoss: 0.05389294932816131, Temperature 0.00014001795003384986, step_size 0.9416675319357145, test_acc: 0.4588\n",
            "Epoch 1378, BestLoss: 0.05385063754326484, Temperature 0.00013301705253215737, step_size 0.941573365182521, test_acc: 0.4604\n",
            "Epoch 1379, BestLoss: 0.05385063754326484, Temperature 0.0001263661999055495, step_size 0.9414792078460027, test_acc: 0.4604\n",
            "Epoch 1380, BestLoss: 0.053748464129331874, Temperature 0.00013301705253215737, step_size 0.941573365182521, test_acc: 0.4633\n",
            "Epoch 1381, BestLoss: 0.05370908989809409, Temperature 0.0001263661999055495, step_size 0.9414792078460027, test_acc: 0.4621\n",
            "Epoch 1382, BestLoss: 0.05368369823471722, Temperature 0.000120047889910272, step_size 0.9413850599252181, test_acc: 0.4635\n",
            "Epoch 1383, BestLoss: 0.05370735110950793, Temperature 0.0001140454954147584, step_size 0.9412909214192257, test_acc: 0.4636\n",
            "Epoch 1384, BestLoss: 0.05358775773293737, Temperature 0.00010834322064402047, step_size 0.9411967923270838, test_acc: 0.4641\n",
            "Epoch 1385, BestLoss: 0.05365747819915156, Temperature 0.00010292605961181944, step_size 0.9411026726478511, test_acc: 0.4653\n",
            "Epoch 1386, BestLoss: 0.05365747819915156, Temperature 9.777975663122846e-05, step_size 0.9410085623805863, test_acc: 0.4653\n",
            "Epoch 1387, BestLoss: 0.05365747819915156, Temperature 0.00010292605961181944, step_size 0.9414792078460027, test_acc: 0.4653\n",
            "Epoch 1388, BestLoss: 0.05365747819915156, Temperature 0.00010834322064402047, step_size 0.9413850599252181, test_acc: 0.4653\n",
            "Epoch 1389, BestLoss: 0.05365747819915156, Temperature 0.0001140454954147584, step_size 0.9412909214192257, test_acc: 0.4653\n",
            "Epoch 1390, BestLoss: 0.05380359503082563, Temperature 0.000120047889910272, step_size 0.9411967923270838, test_acc: 0.4646\n",
            "Epoch 1391, BestLoss: 0.05366856050182122, Temperature 0.0001140454954147584, step_size 0.9411026726478511, test_acc: 0.4664\n",
            "Epoch 1392, BestLoss: 0.0536845627302708, Temperature 0.00010834322064402047, step_size 0.9410085623805863, test_acc: 0.4654\n",
            "Epoch 1393, BestLoss: 0.05371274044880928, Temperature 0.00010292605961181944, step_size 0.9409144615243482, test_acc: 0.464\n",
            "Epoch 1394, BestLoss: 0.05371274044880928, Temperature 9.777975663122846e-05, step_size 0.9408203700781957, test_acc: 0.464\n",
            "Epoch 1395, BestLoss: 0.053714607251142216, Temperature 0.00010292605961181944, step_size 0.9411026726478511, test_acc: 0.465\n",
            "Epoch 1396, BestLoss: 0.053767777317112325, Temperature 0.00010834322064402047, step_size 0.9410085623805863, test_acc: 0.464\n",
            "Epoch 1397, BestLoss: 0.05386372046868282, Temperature 0.00010292605961181944, step_size 0.9409144615243482, test_acc: 0.4654\n",
            "Epoch 1398, BestLoss: 0.053603071945941445, Temperature 9.777975663122846e-05, step_size 0.9408203700781957, test_acc: 0.4683\n",
            "Epoch 1399, BestLoss: 0.053603071945941445, Temperature 9.289076879966704e-05, step_size 0.940726288041188, test_acc: 0.4683\n",
            "Epoch 1400, BestLoss: 0.05351371633881804, Temperature 9.777975663122846e-05, step_size 0.9409144615243482, test_acc: 0.4707\n",
            "Epoch 1401, BestLoss: 0.05351371633881804, Temperature 9.289076879966704e-05, step_size 0.9408203700781957, test_acc: 0.4707\n",
            "Epoch 1402, BestLoss: 0.053636432403797736, Temperature 9.777975663122846e-05, step_size 0.9408203700781957, test_acc: 0.4683\n",
            "Epoch 1403, BestLoss: 0.053636432403797736, Temperature 9.289076879966704e-05, step_size 0.940726288041188, test_acc: 0.4683\n",
            "Epoch 1404, BestLoss: 0.053636432403797736, Temperature 9.777975663122846e-05, step_size 0.940726288041188, test_acc: 0.4683\n",
            "Epoch 1405, BestLoss: 0.053636432403797736, Temperature 0.00010292605961181944, step_size 0.9406322154123838, test_acc: 0.4683\n",
            "Epoch 1406, BestLoss: 0.05361554901490616, Temperature 0.00010834322064402047, step_size 0.9405381521908426, test_acc: 0.467\n",
            "Epoch 1407, BestLoss: 0.05361554901490616, Temperature 0.00010292605961181944, step_size 0.9404440983756235, test_acc: 0.467\n",
            "Epoch 1408, BestLoss: 0.0535011462841937, Temperature 0.00010834322064402047, step_size 0.9404440983756235, test_acc: 0.4687\n",
            "Epoch 1409, BestLoss: 0.0535011462841937, Temperature 0.00010292605961181944, step_size 0.940350053965786, test_acc: 0.4687\n",
            "Epoch 1410, BestLoss: 0.0535011462841937, Temperature 0.00010834322064402047, step_size 0.940350053965786, test_acc: 0.4687\n",
            "Epoch 1411, BestLoss: 0.0535011462841937, Temperature 0.0001140454954147584, step_size 0.9402560189603894, test_acc: 0.4687\n",
            "Epoch 1412, BestLoss: 0.05362897124551355, Temperature 0.000120047889910272, step_size 0.9401619933584934, test_acc: 0.4682\n",
            "Epoch 1413, BestLoss: 0.05356691039697912, Temperature 0.0001140454954147584, step_size 0.9400679771591576, test_acc: 0.4673\n",
            "Epoch 1414, BestLoss: 0.05340753208497853, Temperature 0.00010834322064402047, step_size 0.9399739703614417, test_acc: 0.4679\n",
            "Epoch 1415, BestLoss: 0.05340753208497853, Temperature 0.00010292605961181944, step_size 0.9398799729644056, test_acc: 0.4679\n",
            "Epoch 1416, BestLoss: 0.05340753208497853, Temperature 0.00010834322064402047, step_size 0.9400679771591576, test_acc: 0.4679\n",
            "Epoch 1417, BestLoss: 0.05344474275052492, Temperature 0.0001140454954147584, step_size 0.9399739703614417, test_acc: 0.4674\n",
            "Epoch 1418, BestLoss: 0.0533386563423833, Temperature 0.00010834322064402047, step_size 0.9398799729644056, test_acc: 0.4674\n",
            "Epoch 1419, BestLoss: 0.0533386563423833, Temperature 0.00010292605961181944, step_size 0.9397859849671092, test_acc: 0.4674\n",
            "Epoch 1420, BestLoss: 0.05339301155409703, Temperature 0.00010834322064402047, step_size 0.9398799729644056, test_acc: 0.4686\n",
            "Epoch 1421, BestLoss: 0.053417445903221075, Temperature 0.00010292605961181944, step_size 0.9397859849671092, test_acc: 0.4681\n",
            "Epoch 1422, BestLoss: 0.053417445903221075, Temperature 9.777975663122846e-05, step_size 0.9396920063686125, test_acc: 0.4681\n",
            "Epoch 1423, BestLoss: 0.053417445903221075, Temperature 0.00010292605961181944, step_size 0.9397859849671092, test_acc: 0.4681\n",
            "Epoch 1424, BestLoss: 0.05351231309799538, Temperature 0.00010834322064402047, step_size 0.9396920063686125, test_acc: 0.4667\n",
            "Epoch 1425, BestLoss: 0.05351231309799538, Temperature 0.00010292605961181944, step_size 0.9395980371679756, test_acc: 0.4667\n",
            "Epoch 1426, BestLoss: 0.05361783005183538, Temperature 0.00010834322064402047, step_size 0.9395980371679756, test_acc: 0.466\n",
            "Epoch 1427, BestLoss: 0.05361783005183538, Temperature 0.00010292605961181944, step_size 0.9395040773642589, test_acc: 0.466\n",
            "Epoch 1428, BestLoss: 0.05370399687674845, Temperature 0.00010834322064402047, step_size 0.9395040773642589, test_acc: 0.4656\n",
            "Epoch 1429, BestLoss: 0.053803014555232356, Temperature 0.00010292605961181944, step_size 0.9394101269565225, test_acc: 0.4651\n",
            "Epoch 1430, BestLoss: 0.0538180608540233, Temperature 9.777975663122846e-05, step_size 0.9393161859438268, test_acc: 0.4675\n",
            "Epoch 1431, BestLoss: 0.05384331825151023, Temperature 9.289076879966704e-05, step_size 0.9392222543252324, test_acc: 0.4677\n",
            "Epoch 1432, BestLoss: 0.05387186505649038, Temperature 8.824623035968368e-05, step_size 0.9391283320998, test_acc: 0.4662\n",
            "Epoch 1433, BestLoss: 0.053866341638805375, Temperature 8.383391884169949e-05, step_size 0.93903441926659, test_acc: 0.4647\n",
            "Epoch 1434, BestLoss: 0.053866341638805375, Temperature 7.96422228996145e-05, step_size 0.9389405158246634, test_acc: 0.4647\n",
            "Epoch 1435, BestLoss: 0.053925560294766826, Temperature 8.383391884169949e-05, step_size 0.9394101269565225, test_acc: 0.4646\n",
            "Epoch 1436, BestLoss: 0.053925560294766826, Temperature 7.96422228996145e-05, step_size 0.9393161859438268, test_acc: 0.4646\n",
            "Epoch 1437, BestLoss: 0.053944493161399217, Temperature 8.383391884169949e-05, step_size 0.9393161859438268, test_acc: 0.4659\n",
            "Epoch 1438, BestLoss: 0.053944493161399217, Temperature 7.96422228996145e-05, step_size 0.9392222543252324, test_acc: 0.4659\n",
            "Epoch 1439, BestLoss: 0.05378517646199019, Temperature 8.383391884169949e-05, step_size 0.9392222543252324, test_acc: 0.4673\n",
            "Epoch 1440, BestLoss: 0.0537829677830654, Temperature 7.96422228996145e-05, step_size 0.9391283320998, test_acc: 0.4668\n",
            "Epoch 1441, BestLoss: 0.0537829677830654, Temperature 8.383391884169949e-05, step_size 0.9391283320998, test_acc: 0.4668\n",
            "Epoch 1442, BestLoss: 0.05377540784525157, Temperature 8.824623035968368e-05, step_size 0.93903441926659, test_acc: 0.465\n",
            "Epoch 1443, BestLoss: 0.05376232629486212, Temperature 8.383391884169949e-05, step_size 0.9389405158246634, test_acc: 0.4664\n",
            "Epoch 1444, BestLoss: 0.05372560625018086, Temperature 7.96422228996145e-05, step_size 0.938846621773081, test_acc: 0.4688\n",
            "Epoch 1445, BestLoss: 0.05372560625018086, Temperature 7.566011175463378e-05, step_size 0.9387527371109037, test_acc: 0.4688\n",
            "Epoch 1446, BestLoss: 0.05344950189151671, Temperature 7.96422228996145e-05, step_size 0.9389405158246634, test_acc: 0.4696\n",
            "Epoch 1447, BestLoss: 0.053453528500182514, Temperature 7.566011175463378e-05, step_size 0.938846621773081, test_acc: 0.4695\n",
            "Epoch 1448, BestLoss: 0.053503629812579494, Temperature 7.96422228996145e-05, step_size 0.938846621773081, test_acc: 0.4695\n",
            "Epoch 1449, BestLoss: 0.053503629812579494, Temperature 7.566011175463378e-05, step_size 0.9387527371109037, test_acc: 0.4695\n",
            "Epoch 1450, BestLoss: 0.053464868006911914, Temperature 7.96422228996145e-05, step_size 0.9387527371109037, test_acc: 0.4685\n",
            "Epoch 1451, BestLoss: 0.053464868006911914, Temperature 7.566011175463378e-05, step_size 0.9386588618371926, test_acc: 0.4685\n",
            "Epoch 1452, BestLoss: 0.053464752479950785, Temperature 7.96422228996145e-05, step_size 0.9386588618371926, test_acc: 0.4698\n",
            "Epoch 1453, BestLoss: 0.05354379270319562, Temperature 8.383391884169949e-05, step_size 0.9385649959510088, test_acc: 0.4687\n",
            "Epoch 1454, BestLoss: 0.05354379270319562, Temperature 7.96422228996145e-05, step_size 0.9384711394514138, test_acc: 0.4687\n",
            "Epoch 1455, BestLoss: 0.05347579703279885, Temperature 8.383391884169949e-05, step_size 0.9384711394514138, test_acc: 0.4691\n",
            "Epoch 1456, BestLoss: 0.053390482894911974, Temperature 7.96422228996145e-05, step_size 0.9383772923374687, test_acc: 0.4693\n",
            "Epoch 1457, BestLoss: 0.053390482894911974, Temperature 7.566011175463378e-05, step_size 0.9382834546082349, test_acc: 0.4693\n",
            "Epoch 1458, BestLoss: 0.053390482894911974, Temperature 7.96422228996145e-05, step_size 0.9383772923374687, test_acc: 0.4693\n",
            "Epoch 1459, BestLoss: 0.053390482894911974, Temperature 8.383391884169949e-05, step_size 0.9382834546082349, test_acc: 0.4693\n",
            "Epoch 1460, BestLoss: 0.053324331262937584, Temperature 8.824623035968368e-05, step_size 0.9381896262627741, test_acc: 0.4701\n",
            "Epoch 1461, BestLoss: 0.05329904399303735, Temperature 8.383391884169949e-05, step_size 0.9380958073001479, test_acc: 0.4715\n",
            "Epoch 1462, BestLoss: 0.05329904399303735, Temperature 7.96422228996145e-05, step_size 0.9380019977194178, test_acc: 0.4715\n",
            "Epoch 1463, BestLoss: 0.05325891145660542, Temperature 8.383391884169949e-05, step_size 0.9380958073001479, test_acc: 0.4715\n",
            "Epoch 1464, BestLoss: 0.05325891145660542, Temperature 7.96422228996145e-05, step_size 0.9380019977194178, test_acc: 0.4715\n",
            "Epoch 1465, BestLoss: 0.053081477843733356, Temperature 8.383391884169949e-05, step_size 0.9380019977194178, test_acc: 0.4723\n",
            "Epoch 1466, BestLoss: 0.053081477843733356, Temperature 7.96422228996145e-05, step_size 0.9379081975196459, test_acc: 0.4723\n",
            "Epoch 1467, BestLoss: 0.053081477843733356, Temperature 8.383391884169949e-05, step_size 0.9379081975196459, test_acc: 0.4723\n",
            "Epoch 1468, BestLoss: 0.053081477843733356, Temperature 8.824623035968368e-05, step_size 0.937814406699894, test_acc: 0.4723\n",
            "Epoch 1469, BestLoss: 0.053158583118537224, Temperature 9.289076879966704e-05, step_size 0.9377206252592241, test_acc: 0.4707\n",
            "Epoch 1470, BestLoss: 0.053158583118537224, Temperature 8.824623035968368e-05, step_size 0.9376268531966981, test_acc: 0.4707\n",
            "Epoch 1471, BestLoss: 0.05318444458234391, Temperature 9.289076879966704e-05, step_size 0.9376268531966981, test_acc: 0.4706\n",
            "Epoch 1472, BestLoss: 0.05318444458234391, Temperature 8.824623035968368e-05, step_size 0.9375330905113785, test_acc: 0.4706\n",
            "Epoch 1473, BestLoss: 0.053044372188942854, Temperature 9.289076879966704e-05, step_size 0.9375330905113785, test_acc: 0.4743\n",
            "Epoch 1474, BestLoss: 0.053004620489114744, Temperature 8.824623035968368e-05, step_size 0.9374393372023273, test_acc: 0.4744\n",
            "Epoch 1475, BestLoss: 0.053004620489114744, Temperature 8.383391884169949e-05, step_size 0.9373455932686071, test_acc: 0.4744\n",
            "Epoch 1476, BestLoss: 0.05299258654927955, Temperature 8.824623035968368e-05, step_size 0.9374393372023273, test_acc: 0.4736\n",
            "Epoch 1477, BestLoss: 0.05299258654927955, Temperature 8.383391884169949e-05, step_size 0.9373455932686071, test_acc: 0.4736\n",
            "Epoch 1478, BestLoss: 0.05299258654927955, Temperature 8.824623035968368e-05, step_size 0.9373455932686071, test_acc: 0.4736\n",
            "Epoch 1479, BestLoss: 0.05298610734664514, Temperature 9.289076879966704e-05, step_size 0.9372518587092803, test_acc: 0.4752\n",
            "Epoch 1480, BestLoss: 0.05295135613019034, Temperature 8.824623035968368e-05, step_size 0.9371581335234094, test_acc: 0.4764\n",
            "Epoch 1481, BestLoss: 0.05294481243759887, Temperature 8.383391884169949e-05, step_size 0.937064417710057, test_acc: 0.4758\n",
            "Epoch 1482, BestLoss: 0.05294481243759887, Temperature 7.96422228996145e-05, step_size 0.936970711268286, test_acc: 0.4758\n",
            "Epoch 1483, BestLoss: 0.0530828722074628, Temperature 8.383391884169949e-05, step_size 0.9371581335234094, test_acc: 0.4756\n",
            "Epoch 1484, BestLoss: 0.0530828722074628, Temperature 7.96422228996145e-05, step_size 0.937064417710057, test_acc: 0.4756\n",
            "Epoch 1485, BestLoss: 0.0529958312279981, Temperature 8.383391884169949e-05, step_size 0.937064417710057, test_acc: 0.4757\n",
            "Epoch 1486, BestLoss: 0.05306455907590996, Temperature 7.96422228996145e-05, step_size 0.936970711268286, test_acc: 0.4746\n",
            "Epoch 1487, BestLoss: 0.05307782032881357, Temperature 7.566011175463378e-05, step_size 0.9368770141971592, test_acc: 0.4746\n",
            "Epoch 1488, BestLoss: 0.053069571804461264, Temperature 7.187710616690208e-05, step_size 0.9367833264957395, test_acc: 0.4732\n",
            "Epoch 1489, BestLoss: 0.05310392783714321, Temperature 6.828325085855697e-05, step_size 0.9366896481630899, test_acc: 0.4735\n",
            "Epoch 1490, BestLoss: 0.053142870553675545, Temperature 6.486908831562912e-05, step_size 0.9365959791982735, test_acc: 0.4719\n",
            "Epoch 1491, BestLoss: 0.05320485431674402, Temperature 6.162563389984766e-05, step_size 0.9365023196003537, test_acc: 0.4703\n",
            "Epoch 1492, BestLoss: 0.05320485431674402, Temperature 5.8544352204855274e-05, step_size 0.9364086693683936, test_acc: 0.4703\n",
            "Epoch 1493, BestLoss: 0.05316068938966261, Temperature 6.162563389984766e-05, step_size 0.936970711268286, test_acc: 0.4728\n",
            "Epoch 1494, BestLoss: 0.05316068938966261, Temperature 5.8544352204855274e-05, step_size 0.9368770141971592, test_acc: 0.4728\n",
            "Epoch 1495, BestLoss: 0.05316068938966261, Temperature 6.162563389984766e-05, step_size 0.9368770141971592, test_acc: 0.4728\n",
            "Epoch 1496, BestLoss: 0.05316068938966261, Temperature 6.486908831562912e-05, step_size 0.9367833264957395, test_acc: 0.4728\n",
            "Epoch 1497, BestLoss: 0.052987231219126664, Temperature 6.828325085855697e-05, step_size 0.9366896481630899, test_acc: 0.4735\n",
            "Epoch 1498, BestLoss: 0.052987231219126664, Temperature 6.486908831562912e-05, step_size 0.9365959791982735, test_acc: 0.4735\n",
            "Epoch 1499, BestLoss: 0.052987231219126664, Temperature 6.828325085855697e-05, step_size 0.9365959791982735, test_acc: 0.4735\n",
            "Epoch 1500, BestLoss: 0.052987231219126664, Temperature 7.187710616690208e-05, step_size 0.9365023196003537, test_acc: 0.4735\n",
            "Epoch 1501, BestLoss: 0.052987231219126664, Temperature 7.566011175463378e-05, step_size 0.9364086693683936, test_acc: 0.4735\n",
            "Epoch 1502, BestLoss: 0.052987231219126664, Temperature 7.96422228996145e-05, step_size 0.9363150285014568, test_acc: 0.4735\n",
            "Epoch 1503, BestLoss: 0.052987231219126664, Temperature 8.383391884169949e-05, step_size 0.9362213969986066, test_acc: 0.4735\n",
            "Epoch 1504, BestLoss: 0.052987231219126664, Temperature 8.824623035968368e-05, step_size 0.9361277748589067, test_acc: 0.4735\n",
            "Epoch 1505, BestLoss: 0.052987231219126664, Temperature 9.289076879966704e-05, step_size 0.9360341620814209, test_acc: 0.4735\n",
            "Epoch 1506, BestLoss: 0.05310554812857485, Temperature 9.777975663122846e-05, step_size 0.9359405586652128, test_acc: 0.4722\n",
            "Epoch 1507, BestLoss: 0.05310554812857485, Temperature 9.289076879966704e-05, step_size 0.9358469646093462, test_acc: 0.4722\n",
            "Epoch 1508, BestLoss: 0.05313849451496922, Temperature 9.777975663122846e-05, step_size 0.9358469646093462, test_acc: 0.473\n",
            "Epoch 1509, BestLoss: 0.05317593753075857, Temperature 9.289076879966704e-05, step_size 0.9357533799128853, test_acc: 0.4713\n",
            "Epoch 1510, BestLoss: 0.053361312320126766, Temperature 8.824623035968368e-05, step_size 0.9356598045748941, test_acc: 0.4689\n",
            "Epoch 1511, BestLoss: 0.0533675540019029, Temperature 8.383391884169949e-05, step_size 0.9355662385944366, test_acc: 0.4701\n",
            "Epoch 1512, BestLoss: 0.0533675540019029, Temperature 7.96422228996145e-05, step_size 0.9354726819705771, test_acc: 0.4701\n",
            "Epoch 1513, BestLoss: 0.0533675540019029, Temperature 8.383391884169949e-05, step_size 0.9357533799128853, test_acc: 0.4701\n",
            "Epoch 1514, BestLoss: 0.053501997742313456, Temperature 8.824623035968368e-05, step_size 0.9356598045748941, test_acc: 0.4674\n",
            "Epoch 1515, BestLoss: 0.05323450094301325, Temperature 8.383391884169949e-05, step_size 0.9355662385944366, test_acc: 0.47\n",
            "Epoch 1516, BestLoss: 0.05323450094301325, Temperature 7.96422228996145e-05, step_size 0.9354726819705771, test_acc: 0.47\n",
            "Epoch 1517, BestLoss: 0.05302664404484717, Temperature 8.383391884169949e-05, step_size 0.9355662385944366, test_acc: 0.4724\n",
            "Epoch 1518, BestLoss: 0.05302664404484717, Temperature 7.96422228996145e-05, step_size 0.9354726819705771, test_acc: 0.4724\n",
            "Epoch 1519, BestLoss: 0.05299746750101954, Temperature 8.383391884169949e-05, step_size 0.9354726819705771, test_acc: 0.4749\n",
            "Epoch 1520, BestLoss: 0.05299746750101954, Temperature 7.96422228996145e-05, step_size 0.93537913470238, test_acc: 0.4749\n",
            "Epoch 1521, BestLoss: 0.05299746750101954, Temperature 8.383391884169949e-05, step_size 0.93537913470238, test_acc: 0.4749\n",
            "Epoch 1522, BestLoss: 0.05299746750101954, Temperature 8.824623035968368e-05, step_size 0.9352855967889098, test_acc: 0.4749\n",
            "Epoch 1523, BestLoss: 0.053049355388842485, Temperature 9.289076879966704e-05, step_size 0.9351920682292308, test_acc: 0.474\n",
            "Epoch 1524, BestLoss: 0.053054949199209694, Temperature 8.824623035968368e-05, step_size 0.935098549022408, test_acc: 0.4734\n",
            "Epoch 1525, BestLoss: 0.053054949199209694, Temperature 8.383391884169949e-05, step_size 0.9350050391675058, test_acc: 0.4734\n",
            "Epoch 1526, BestLoss: 0.053074012160677836, Temperature 8.824623035968368e-05, step_size 0.935098549022408, test_acc: 0.4732\n",
            "Epoch 1527, BestLoss: 0.0529218148114473, Temperature 8.383391884169949e-05, step_size 0.9350050391675058, test_acc: 0.4742\n",
            "Epoch 1528, BestLoss: 0.0529218148114473, Temperature 7.96422228996145e-05, step_size 0.934911538663589, test_acc: 0.4742\n",
            "Epoch 1529, BestLoss: 0.0529218148114473, Temperature 8.383391884169949e-05, step_size 0.9350050391675058, test_acc: 0.4742\n",
            "Epoch 1530, BestLoss: 0.0529218148114473, Temperature 8.824623035968368e-05, step_size 0.934911538663589, test_acc: 0.4742\n",
            "Epoch 1531, BestLoss: 0.0529218148114473, Temperature 9.289076879966704e-05, step_size 0.9348180475097226, test_acc: 0.4742\n",
            "Epoch 1532, BestLoss: 0.052948979036594526, Temperature 9.777975663122846e-05, step_size 0.9347245657049716, test_acc: 0.4737\n",
            "Epoch 1533, BestLoss: 0.052948979036594526, Temperature 9.289076879966704e-05, step_size 0.9346310932484012, test_acc: 0.4737\n",
            "Epoch 1534, BestLoss: 0.052948979036594526, Temperature 9.777975663122846e-05, step_size 0.9346310932484012, test_acc: 0.4737\n",
            "Epoch 1535, BestLoss: 0.052895457066331766, Temperature 0.00010292605961181944, step_size 0.9345376301390764, test_acc: 0.4741\n",
            "Epoch 1536, BestLoss: 0.05278989526224267, Temperature 9.777975663122846e-05, step_size 0.9344441763760625, test_acc: 0.4735\n",
            "Epoch 1537, BestLoss: 0.05278989526224267, Temperature 9.289076879966704e-05, step_size 0.9343507319584249, test_acc: 0.4735\n",
            "Epoch 1538, BestLoss: 0.05278989526224267, Temperature 9.777975663122846e-05, step_size 0.9344441763760625, test_acc: 0.4735\n",
            "Epoch 1539, BestLoss: 0.052825738504032334, Temperature 0.00010292605961181944, step_size 0.9343507319584249, test_acc: 0.4718\n",
            "Epoch 1540, BestLoss: 0.05294527507022291, Temperature 9.777975663122846e-05, step_size 0.9342572968852291, test_acc: 0.472\n",
            "Epoch 1541, BestLoss: 0.05294527507022291, Temperature 9.289076879966704e-05, step_size 0.9341638711555406, test_acc: 0.472\n",
            "Epoch 1542, BestLoss: 0.05288649282139766, Temperature 9.777975663122846e-05, step_size 0.9342572968852291, test_acc: 0.4732\n",
            "Epoch 1543, BestLoss: 0.053111049039054815, Temperature 9.289076879966704e-05, step_size 0.9341638711555406, test_acc: 0.4695\n",
            "Epoch 1544, BestLoss: 0.053111049039054815, Temperature 8.824623035968368e-05, step_size 0.934070454768425, test_acc: 0.4695\n",
            "Epoch 1545, BestLoss: 0.053111049039054815, Temperature 9.289076879966704e-05, step_size 0.9341638711555406, test_acc: 0.4695\n",
            "Epoch 1546, BestLoss: 0.05317168798256961, Temperature 9.777975663122846e-05, step_size 0.934070454768425, test_acc: 0.4695\n",
            "Epoch 1547, BestLoss: 0.05318897148227588, Temperature 9.289076879966704e-05, step_size 0.9339770477229482, test_acc: 0.4683\n",
            "Epoch 1548, BestLoss: 0.053152728004355, Temperature 8.824623035968368e-05, step_size 0.933883650018176, test_acc: 0.4696\n",
            "Epoch 1549, BestLoss: 0.053152728004355, Temperature 8.383391884169949e-05, step_size 0.9337902616531741, test_acc: 0.4696\n",
            "Epoch 1550, BestLoss: 0.05311630852135405, Temperature 8.824623035968368e-05, step_size 0.9339770477229482, test_acc: 0.4722\n",
            "Epoch 1551, BestLoss: 0.05317971461684907, Temperature 8.383391884169949e-05, step_size 0.933883650018176, test_acc: 0.4706\n",
            "Epoch 1552, BestLoss: 0.05317971461684907, Temperature 7.96422228996145e-05, step_size 0.9337902616531741, test_acc: 0.4706\n",
            "Epoch 1553, BestLoss: 0.05317154698441085, Temperature 8.383391884169949e-05, step_size 0.933883650018176, test_acc: 0.4718\n",
            "Epoch 1554, BestLoss: 0.05316927031891663, Temperature 7.96422228996145e-05, step_size 0.9337902616531741, test_acc: 0.4725\n",
            "Epoch 1555, BestLoss: 0.053211296322962, Temperature 8.383391884169949e-05, step_size 0.9337902616531741, test_acc: 0.4719\n",
            "Epoch 1556, BestLoss: 0.05309752939578592, Temperature 7.96422228996145e-05, step_size 0.9336968826270088, test_acc: 0.4709\n",
            "Epoch 1557, BestLoss: 0.053061757259488494, Temperature 7.566011175463378e-05, step_size 0.9336035129387461, test_acc: 0.4703\n",
            "Epoch 1558, BestLoss: 0.05307797415626568, Temperature 7.187710616690208e-05, step_size 0.9335101525874523, test_acc: 0.4702\n",
            "Epoch 1559, BestLoss: 0.05316874360076919, Temperature 6.828325085855697e-05, step_size 0.9334168015721935, test_acc: 0.4697\n",
            "Epoch 1560, BestLoss: 0.05305351122333248, Temperature 6.486908831562912e-05, step_size 0.9333234598920364, test_acc: 0.4714\n",
            "Epoch 1561, BestLoss: 0.05305351122333248, Temperature 6.162563389984766e-05, step_size 0.9332301275460472, test_acc: 0.4714\n",
            "Epoch 1562, BestLoss: 0.0530304120103129, Temperature 6.486908831562912e-05, step_size 0.9336968826270088, test_acc: 0.4711\n",
            "Epoch 1563, BestLoss: 0.0530304120103129, Temperature 6.162563389984766e-05, step_size 0.9336035129387461, test_acc: 0.4711\n",
            "Epoch 1564, BestLoss: 0.0530304120103129, Temperature 6.486908831562912e-05, step_size 0.9336035129387461, test_acc: 0.4711\n",
            "Epoch 1565, BestLoss: 0.05299640559759396, Temperature 6.828325085855697e-05, step_size 0.9335101525874523, test_acc: 0.4712\n",
            "Epoch 1566, BestLoss: 0.05299640559759396, Temperature 6.486908831562912e-05, step_size 0.9334168015721935, test_acc: 0.4712\n",
            "Epoch 1567, BestLoss: 0.053075362421399784, Temperature 6.828325085855697e-05, step_size 0.9334168015721935, test_acc: 0.4702\n",
            "Epoch 1568, BestLoss: 0.052915868711512666, Temperature 6.486908831562912e-05, step_size 0.9333234598920364, test_acc: 0.4728\n",
            "Epoch 1569, BestLoss: 0.052915868711512666, Temperature 6.162563389984766e-05, step_size 0.9332301275460472, test_acc: 0.4728\n",
            "Epoch 1570, BestLoss: 0.052712318770581586, Temperature 6.486908831562912e-05, step_size 0.9333234598920364, test_acc: 0.4748\n",
            "Epoch 1571, BestLoss: 0.05266294884052316, Temperature 6.162563389984766e-05, step_size 0.9332301275460472, test_acc: 0.4767\n",
            "Epoch 1572, BestLoss: 0.052496213707332796, Temperature 5.8544352204855274e-05, step_size 0.9331368045332926, test_acc: 0.4783\n",
            "Epoch 1573, BestLoss: 0.052260618079893136, Temperature 5.561713459461251e-05, step_size 0.9330434908528393, test_acc: 0.4807\n",
            "Epoch 1574, BestLoss: 0.052260618079893136, Temperature 5.283627786488188e-05, step_size 0.932950186503754, test_acc: 0.4807\n",
            "Epoch 1575, BestLoss: 0.052260618079893136, Temperature 5.561713459461251e-05, step_size 0.9332301275460472, test_acc: 0.4807\n",
            "Epoch 1576, BestLoss: 0.052247628429646344, Temperature 5.8544352204855274e-05, step_size 0.9331368045332926, test_acc: 0.482\n",
            "Epoch 1577, BestLoss: 0.05213459896739097, Temperature 5.561713459461251e-05, step_size 0.9330434908528393, test_acc: 0.4823\n",
            "Epoch 1578, BestLoss: 0.05198544432706739, Temperature 5.283627786488188e-05, step_size 0.932950186503754, test_acc: 0.483\n",
            "Epoch 1579, BestLoss: 0.052021025577893336, Temperature 5.019446397163778e-05, step_size 0.9328568914851036, test_acc: 0.4836\n",
            "Epoch 1580, BestLoss: 0.052021025577893336, Temperature 4.768474077305589e-05, step_size 0.9327636057959552, test_acc: 0.4836\n",
            "Epoch 1581, BestLoss: 0.052021025577893336, Temperature 5.019446397163778e-05, step_size 0.9330434908528393, test_acc: 0.4836\n",
            "Epoch 1582, BestLoss: 0.05197878660696432, Temperature 5.283627786488188e-05, step_size 0.932950186503754, test_acc: 0.4838\n",
            "Epoch 1583, BestLoss: 0.05197878660696432, Temperature 5.019446397163778e-05, step_size 0.9328568914851036, test_acc: 0.4838\n",
            "Epoch 1584, BestLoss: 0.05197878660696432, Temperature 5.283627786488188e-05, step_size 0.9328568914851036, test_acc: 0.4838\n",
            "Epoch 1585, BestLoss: 0.051831031367921034, Temperature 5.561713459461251e-05, step_size 0.9327636057959552, test_acc: 0.4839\n",
            "Epoch 1586, BestLoss: 0.051831031367921034, Temperature 5.283627786488188e-05, step_size 0.9326703294353756, test_acc: 0.4839\n",
            "Epoch 1587, BestLoss: 0.05162889117937221, Temperature 5.561713459461251e-05, step_size 0.9326703294353756, test_acc: 0.4851\n",
            "Epoch 1588, BestLoss: 0.051656302743861564, Temperature 5.283627786488188e-05, step_size 0.9325770624024321, test_acc: 0.4864\n",
            "Epoch 1589, BestLoss: 0.05166103656995772, Temperature 5.019446397163778e-05, step_size 0.9324838046961919, test_acc: 0.4861\n",
            "Epoch 1590, BestLoss: 0.051590730887732, Temperature 4.768474077305589e-05, step_size 0.9323905563157222, test_acc: 0.4873\n",
            "Epoch 1591, BestLoss: 0.05154308692291228, Temperature 4.53005037344031e-05, step_size 0.9322973172600907, test_acc: 0.4876\n",
            "Epoch 1592, BestLoss: 0.05154308692291228, Temperature 4.303547854768294e-05, step_size 0.9322040875283647, test_acc: 0.4876\n",
            "Epoch 1593, BestLoss: 0.05154308692291228, Temperature 4.53005037344031e-05, step_size 0.9325770624024321, test_acc: 0.4876\n",
            "Epoch 1594, BestLoss: 0.05154308692291228, Temperature 4.768474077305589e-05, step_size 0.9324838046961919, test_acc: 0.4876\n",
            "Epoch 1595, BestLoss: 0.05154308692291228, Temperature 5.019446397163778e-05, step_size 0.9323905563157222, test_acc: 0.4876\n",
            "Epoch 1596, BestLoss: 0.05154308692291228, Temperature 5.283627786488188e-05, step_size 0.9322973172600907, test_acc: 0.4876\n",
            "Epoch 1597, BestLoss: 0.051588221561083954, Temperature 5.561713459461251e-05, step_size 0.9322040875283647, test_acc: 0.4874\n",
            "Epoch 1598, BestLoss: 0.051588221561083954, Temperature 5.283627786488188e-05, step_size 0.9321108671196119, test_acc: 0.4874\n",
            "Epoch 1599, BestLoss: 0.051588221561083954, Temperature 5.561713459461251e-05, step_size 0.9321108671196119, test_acc: 0.4874\n",
            "Epoch 1600, BestLoss: 0.051588221561083954, Temperature 5.8544352204855274e-05, step_size 0.9320176560329, test_acc: 0.4874\n",
            "Epoch 1601, BestLoss: 0.05162116781198006, Temperature 6.162563389984766e-05, step_size 0.9319244542672968, test_acc: 0.4863\n",
            "Epoch 1602, BestLoss: 0.05170497775775564, Temperature 5.8544352204855274e-05, step_size 0.93183126182187, test_acc: 0.4857\n",
            "Epoch 1603, BestLoss: 0.05163101724445884, Temperature 5.561713459461251e-05, step_size 0.9317380786956878, test_acc: 0.484\n",
            "Epoch 1604, BestLoss: 0.05163101724445884, Temperature 5.283627786488188e-05, step_size 0.9316449048878183, test_acc: 0.484\n",
            "Epoch 1605, BestLoss: 0.05163101724445884, Temperature 5.561713459461251e-05, step_size 0.93183126182187, test_acc: 0.484\n",
            "Epoch 1606, BestLoss: 0.05163101724445884, Temperature 5.8544352204855274e-05, step_size 0.9317380786956878, test_acc: 0.484\n",
            "Epoch 1607, BestLoss: 0.051579511833405464, Temperature 6.162563389984766e-05, step_size 0.9316449048878183, test_acc: 0.4844\n",
            "Epoch 1608, BestLoss: 0.05152245047439108, Temperature 5.8544352204855274e-05, step_size 0.9315517403973295, test_acc: 0.487\n",
            "Epoch 1609, BestLoss: 0.051527702928358496, Temperature 5.561713459461251e-05, step_size 0.9314585852232897, test_acc: 0.4883\n",
            "Epoch 1610, BestLoss: 0.051527702928358496, Temperature 5.283627786488188e-05, step_size 0.9313654393647675, test_acc: 0.4883\n",
            "Epoch 1611, BestLoss: 0.051527702928358496, Temperature 5.561713459461251e-05, step_size 0.9315517403973295, test_acc: 0.4883\n",
            "Epoch 1612, BestLoss: 0.05143646902379086, Temperature 5.8544352204855274e-05, step_size 0.9314585852232897, test_acc: 0.4893\n",
            "Epoch 1613, BestLoss: 0.05143646902379086, Temperature 5.561713459461251e-05, step_size 0.9313654393647675, test_acc: 0.4893\n",
            "Epoch 1614, BestLoss: 0.05127784936878782, Temperature 5.8544352204855274e-05, step_size 0.9313654393647675, test_acc: 0.4912\n",
            "Epoch 1615, BestLoss: 0.051340526531796195, Temperature 5.561713459461251e-05, step_size 0.931272302820831, test_acc: 0.492\n",
            "Epoch 1616, BestLoss: 0.05127268382419667, Temperature 5.283627786488188e-05, step_size 0.9311791755905489, test_acc: 0.4895\n",
            "Epoch 1617, BestLoss: 0.05127268382419667, Temperature 5.019446397163778e-05, step_size 0.9310860576729898, test_acc: 0.4895\n",
            "Epoch 1618, BestLoss: 0.05127080722184862, Temperature 5.283627786488188e-05, step_size 0.931272302820831, test_acc: 0.4908\n",
            "Epoch 1619, BestLoss: 0.051274350470424813, Temperature 5.561713459461251e-05, step_size 0.9311791755905489, test_acc: 0.4927\n",
            "Epoch 1620, BestLoss: 0.05121753956935875, Temperature 5.283627786488188e-05, step_size 0.9310860576729898, test_acc: 0.4928\n",
            "Epoch 1621, BestLoss: 0.05118293913608338, Temperature 5.019446397163778e-05, step_size 0.9309929490672225, test_acc: 0.4962\n",
            "Epoch 1622, BestLoss: 0.05118293913608338, Temperature 4.768474077305589e-05, step_size 0.9308998497723158, test_acc: 0.4962\n",
            "Epoch 1623, BestLoss: 0.05113233539369006, Temperature 5.019446397163778e-05, step_size 0.9310860576729898, test_acc: 0.4969\n",
            "Epoch 1624, BestLoss: 0.0509668835222411, Temperature 4.768474077305589e-05, step_size 0.9309929490672225, test_acc: 0.4956\n",
            "Epoch 1625, BestLoss: 0.050994186355669054, Temperature 4.53005037344031e-05, step_size 0.9308998497723158, test_acc: 0.4951\n",
            "Epoch 1626, BestLoss: 0.05107137378464497, Temperature 4.303547854768294e-05, step_size 0.9308067597873385, test_acc: 0.4942\n",
            "Epoch 1627, BestLoss: 0.051079998835112064, Temperature 4.0883704620298796e-05, step_size 0.9307136791113598, test_acc: 0.4943\n",
            "Epoch 1628, BestLoss: 0.051079998835112064, Temperature 3.883951938928385e-05, step_size 0.9306206077434487, test_acc: 0.4943\n",
            "Epoch 1629, BestLoss: 0.051079998835112064, Temperature 4.0883704620298796e-05, step_size 0.9309929490672225, test_acc: 0.4943\n",
            "Epoch 1630, BestLoss: 0.0510998443047265, Temperature 4.303547854768294e-05, step_size 0.9308998497723158, test_acc: 0.4929\n",
            "Epoch 1631, BestLoss: 0.0510998443047265, Temperature 4.0883704620298796e-05, step_size 0.9308067597873385, test_acc: 0.4929\n",
            "Epoch 1632, BestLoss: 0.0510998443047265, Temperature 4.303547854768294e-05, step_size 0.9308067597873385, test_acc: 0.4929\n",
            "Epoch 1633, BestLoss: 0.0510998443047265, Temperature 4.53005037344031e-05, step_size 0.9307136791113598, test_acc: 0.4929\n",
            "Epoch 1634, BestLoss: 0.0510998443047265, Temperature 4.768474077305589e-05, step_size 0.9306206077434487, test_acc: 0.4929\n",
            "Epoch 1635, BestLoss: 0.051204591508755365, Temperature 5.019446397163778e-05, step_size 0.9305275456826744, test_acc: 0.4924\n",
            "Epoch 1636, BestLoss: 0.05100489050724742, Temperature 4.768474077305589e-05, step_size 0.9304344929281061, test_acc: 0.4945\n",
            "Epoch 1637, BestLoss: 0.05100489050724742, Temperature 4.53005037344031e-05, step_size 0.9303414494788133, test_acc: 0.4945\n",
            "Epoch 1638, BestLoss: 0.050932579719168265, Temperature 4.768474077305589e-05, step_size 0.9304344929281061, test_acc: 0.4949\n",
            "Epoch 1639, BestLoss: 0.050907010226869, Temperature 4.53005037344031e-05, step_size 0.9303414494788133, test_acc: 0.4951\n",
            "Epoch 1640, BestLoss: 0.05089444303426778, Temperature 4.303547854768294e-05, step_size 0.9302484153338654, test_acc: 0.4958\n",
            "Epoch 1641, BestLoss: 0.05089444303426778, Temperature 4.0883704620298796e-05, step_size 0.930155390492332, test_acc: 0.4958\n",
            "Epoch 1642, BestLoss: 0.05089444303426778, Temperature 4.303547854768294e-05, step_size 0.9303414494788133, test_acc: 0.4958\n",
            "Epoch 1643, BestLoss: 0.05089444303426778, Temperature 4.53005037344031e-05, step_size 0.9302484153338654, test_acc: 0.4958\n",
            "Epoch 1644, BestLoss: 0.05089444303426778, Temperature 4.768474077305589e-05, step_size 0.930155390492332, test_acc: 0.4958\n",
            "Epoch 1645, BestLoss: 0.05089444303426778, Temperature 5.019446397163778e-05, step_size 0.9300623749532828, test_acc: 0.4958\n",
            "Epoch 1646, BestLoss: 0.05089444303426778, Temperature 5.283627786488188e-05, step_size 0.9299693687157875, test_acc: 0.4958\n",
            "Epoch 1647, BestLoss: 0.05089444303426778, Temperature 5.561713459461251e-05, step_size 0.9298763717789159, test_acc: 0.4958\n",
            "Epoch 1648, BestLoss: 0.05091652524431821, Temperature 5.8544352204855274e-05, step_size 0.929783384141738, test_acc: 0.4961\n",
            "Epoch 1649, BestLoss: 0.05091371907712768, Temperature 5.561713459461251e-05, step_size 0.9296904058033238, test_acc: 0.4966\n",
            "Epoch 1650, BestLoss: 0.05085415395302755, Temperature 5.8544352204855274e-05, step_size 0.9296904058033238, test_acc: 0.4967\n",
            "Epoch 1651, BestLoss: 0.05085415395302755, Temperature 5.561713459461251e-05, step_size 0.9295974367627435, test_acc: 0.4967\n",
            "Epoch 1652, BestLoss: 0.05085415395302755, Temperature 5.8544352204855274e-05, step_size 0.9295974367627435, test_acc: 0.4967\n",
            "Epoch 1653, BestLoss: 0.05085415395302755, Temperature 6.162563389984766e-05, step_size 0.9295044770190672, test_acc: 0.4967\n",
            "Epoch 1654, BestLoss: 0.050898354950191106, Temperature 6.486908831562912e-05, step_size 0.9294115265713654, test_acc: 0.4957\n",
            "Epoch 1655, BestLoss: 0.05090646832180908, Temperature 6.162563389984766e-05, step_size 0.9293185854187083, test_acc: 0.4969\n",
            "Epoch 1656, BestLoss: 0.05078290769053579, Temperature 5.8544352204855274e-05, step_size 0.9292256535601664, test_acc: 0.4964\n",
            "Epoch 1657, BestLoss: 0.05078290769053579, Temperature 5.561713459461251e-05, step_size 0.9291327309948104, test_acc: 0.4964\n",
            "Epoch 1658, BestLoss: 0.05078290769053579, Temperature 5.8544352204855274e-05, step_size 0.9293185854187083, test_acc: 0.4964\n",
            "Epoch 1659, BestLoss: 0.050671259966842526, Temperature 6.162563389984766e-05, step_size 0.9292256535601664, test_acc: 0.4965\n",
            "Epoch 1660, BestLoss: 0.050671259966842526, Temperature 5.8544352204855274e-05, step_size 0.9291327309948104, test_acc: 0.4965\n",
            "Epoch 1661, BestLoss: 0.050671259966842526, Temperature 6.162563389984766e-05, step_size 0.9291327309948104, test_acc: 0.4965\n",
            "Epoch 1662, BestLoss: 0.050671259966842526, Temperature 6.486908831562912e-05, step_size 0.929039817721711, test_acc: 0.4965\n",
            "Epoch 1663, BestLoss: 0.050671259966842526, Temperature 6.828325085855697e-05, step_size 0.9289469137399388, test_acc: 0.4965\n",
            "Epoch 1664, BestLoss: 0.050671259966842526, Temperature 7.187710616690208e-05, step_size 0.9288540190485648, test_acc: 0.4965\n",
            "Epoch 1665, BestLoss: 0.05063752665332239, Temperature 7.566011175463378e-05, step_size 0.9287611336466599, test_acc: 0.4992\n",
            "Epoch 1666, BestLoss: 0.0506512221846983, Temperature 7.187710616690208e-05, step_size 0.9286682575332953, test_acc: 0.4971\n",
            "Epoch 1667, BestLoss: 0.050651196365887406, Temperature 6.828325085855697e-05, step_size 0.928575390707542, test_acc: 0.4973\n",
            "Epoch 1668, BestLoss: 0.050651196365887406, Temperature 7.187710616690208e-05, step_size 0.9286682575332953, test_acc: 0.4973\n",
            "Epoch 1669, BestLoss: 0.05070861185436347, Temperature 7.566011175463378e-05, step_size 0.928575390707542, test_acc: 0.4972\n",
            "Epoch 1670, BestLoss: 0.05043814137330444, Temperature 7.187710616690208e-05, step_size 0.9284825331684713, test_acc: 0.4996\n",
            "Epoch 1671, BestLoss: 0.05038335483937478, Temperature 6.828325085855697e-05, step_size 0.9283896849151545, test_acc: 0.4992\n",
            "Epoch 1672, BestLoss: 0.05038335483937478, Temperature 6.486908831562912e-05, step_size 0.928296845946663, test_acc: 0.4992\n",
            "Epoch 1673, BestLoss: 0.05038335483937478, Temperature 6.828325085855697e-05, step_size 0.9284825331684713, test_acc: 0.4992\n",
            "Epoch 1674, BestLoss: 0.05045672621689412, Temperature 7.187710616690208e-05, step_size 0.9283896849151545, test_acc: 0.4988\n",
            "Epoch 1675, BestLoss: 0.05045672621689412, Temperature 6.828325085855697e-05, step_size 0.928296845946663, test_acc: 0.4988\n",
            "Epoch 1676, BestLoss: 0.05045672621689412, Temperature 7.187710616690208e-05, step_size 0.928296845946663, test_acc: 0.4988\n",
            "Epoch 1677, BestLoss: 0.05045672621689412, Temperature 7.566011175463378e-05, step_size 0.9282040162620683, test_acc: 0.4988\n",
            "Epoch 1678, BestLoss: 0.05045672621689412, Temperature 7.96422228996145e-05, step_size 0.9281111958604421, test_acc: 0.4988\n",
            "Epoch 1679, BestLoss: 0.05045672621689412, Temperature 8.383391884169949e-05, step_size 0.9280183847408561, test_acc: 0.4988\n",
            "Epoch 1680, BestLoss: 0.05045672621689412, Temperature 8.824623035968368e-05, step_size 0.927925582902382, test_acc: 0.4988\n",
            "Epoch 1681, BestLoss: 0.05043257220365817, Temperature 9.289076879966704e-05, step_size 0.9278327903440918, test_acc: 0.5001\n",
            "Epoch 1682, BestLoss: 0.050432812957880775, Temperature 8.824623035968368e-05, step_size 0.9277400070650574, test_acc: 0.4993\n",
            "Epoch 1683, BestLoss: 0.050391567560322655, Temperature 9.289076879966704e-05, step_size 0.9277400070650574, test_acc: 0.5005\n",
            "Epoch 1684, BestLoss: 0.05049962629833588, Temperature 8.824623035968368e-05, step_size 0.9276472330643509, test_acc: 0.4989\n",
            "Epoch 1685, BestLoss: 0.0503288812823327, Temperature 8.383391884169949e-05, step_size 0.9275544683410445, test_acc: 0.5003\n",
            "Epoch 1686, BestLoss: 0.050298854689604024, Temperature 7.96422228996145e-05, step_size 0.9274617128942104, test_acc: 0.4989\n",
            "Epoch 1687, BestLoss: 0.05034096585505653, Temperature 7.566011175463378e-05, step_size 0.927368966722921, test_acc: 0.4994\n",
            "Epoch 1688, BestLoss: 0.05034096585505653, Temperature 7.187710616690208e-05, step_size 0.9272762298262487, test_acc: 0.4994\n",
            "Epoch 1689, BestLoss: 0.05034096585505653, Temperature 7.566011175463378e-05, step_size 0.9276472330643509, test_acc: 0.4994\n",
            "Epoch 1690, BestLoss: 0.05034096585505653, Temperature 7.96422228996145e-05, step_size 0.9275544683410445, test_acc: 0.4994\n",
            "Epoch 1691, BestLoss: 0.05034096585505653, Temperature 8.383391884169949e-05, step_size 0.9274617128942104, test_acc: 0.4994\n",
            "Epoch 1692, BestLoss: 0.05034096585505653, Temperature 8.824623035968368e-05, step_size 0.927368966722921, test_acc: 0.4994\n",
            "Epoch 1693, BestLoss: 0.05034096585505653, Temperature 9.289076879966704e-05, step_size 0.9272762298262487, test_acc: 0.4994\n",
            "Epoch 1694, BestLoss: 0.050391882444474574, Temperature 9.777975663122846e-05, step_size 0.9271835022032661, test_acc: 0.5002\n",
            "Epoch 1695, BestLoss: 0.050391882444474574, Temperature 9.289076879966704e-05, step_size 0.9270907838530458, test_acc: 0.5002\n",
            "Epoch 1696, BestLoss: 0.050391882444474574, Temperature 9.777975663122846e-05, step_size 0.9270907838530458, test_acc: 0.5002\n",
            "Epoch 1697, BestLoss: 0.050391882444474574, Temperature 0.00010292605961181944, step_size 0.9269980747746605, test_acc: 0.5002\n",
            "Epoch 1698, BestLoss: 0.050401099734605936, Temperature 0.00010834322064402047, step_size 0.926905374967183, test_acc: 0.5007\n",
            "Epoch 1699, BestLoss: 0.05042627469466855, Temperature 0.00010292605961181944, step_size 0.9268126844296862, test_acc: 0.5001\n",
            "Epoch 1700, BestLoss: 0.05038745460411765, Temperature 9.777975663122846e-05, step_size 0.9267200031612433, test_acc: 0.5018\n",
            "Epoch 1701, BestLoss: 0.05038232513967544, Temperature 9.289076879966704e-05, step_size 0.9266273311609271, test_acc: 0.5008\n",
            "Epoch 1702, BestLoss: 0.05038232513967544, Temperature 8.824623035968368e-05, step_size 0.9265346684278111, test_acc: 0.5008\n",
            "Epoch 1703, BestLoss: 0.050263125247366494, Temperature 9.289076879966704e-05, step_size 0.9268126844296862, test_acc: 0.5029\n",
            "Epoch 1704, BestLoss: 0.05040305541269179, Temperature 8.824623035968368e-05, step_size 0.9267200031612433, test_acc: 0.5028\n",
            "Epoch 1705, BestLoss: 0.05040305541269179, Temperature 8.383391884169949e-05, step_size 0.9266273311609271, test_acc: 0.5028\n",
            "Epoch 1706, BestLoss: 0.05013910867388032, Temperature 8.824623035968368e-05, step_size 0.9267200031612433, test_acc: 0.5043\n",
            "Epoch 1707, BestLoss: 0.05013910867388032, Temperature 8.383391884169949e-05, step_size 0.9266273311609271, test_acc: 0.5043\n",
            "Epoch 1708, BestLoss: 0.05013910867388032, Temperature 8.824623035968368e-05, step_size 0.9266273311609271, test_acc: 0.5043\n",
            "Epoch 1709, BestLoss: 0.05013910867388032, Temperature 9.289076879966704e-05, step_size 0.9265346684278111, test_acc: 0.5043\n",
            "Epoch 1710, BestLoss: 0.050135955909086795, Temperature 9.777975663122846e-05, step_size 0.9264420149609683, test_acc: 0.5035\n",
            "Epoch 1711, BestLoss: 0.05019551826064324, Temperature 0.00010292605961181944, step_size 0.9263493707594722, test_acc: 0.5035\n",
            "Epoch 1712, BestLoss: 0.05019551826064324, Temperature 9.777975663122846e-05, step_size 0.9262567358223963, test_acc: 0.5035\n",
            "Epoch 1713, BestLoss: 0.05019551826064324, Temperature 0.00010292605961181944, step_size 0.9262567358223963, test_acc: 0.5035\n",
            "Epoch 1714, BestLoss: 0.05019551826064324, Temperature 0.00010834322064402047, step_size 0.9261641101488141, test_acc: 0.5035\n",
            "Epoch 1715, BestLoss: 0.05027671780577541, Temperature 0.0001140454954147584, step_size 0.9260714937377992, test_acc: 0.5047\n",
            "Epoch 1716, BestLoss: 0.050281276174791785, Temperature 0.00010834322064402047, step_size 0.9259788865884254, test_acc: 0.5046\n",
            "Epoch 1717, BestLoss: 0.050281276174791785, Temperature 0.0001140454954147584, step_size 0.9259788865884254, test_acc: 0.5046\n",
            "Epoch 1718, BestLoss: 0.05060892950754142, Temperature 0.000120047889910272, step_size 0.9258862886997666, test_acc: 0.5031\n",
            "Epoch 1719, BestLoss: 0.05065588139338412, Temperature 0.0001140454954147584, step_size 0.9257937000708967, test_acc: 0.5033\n",
            "Epoch 1720, BestLoss: 0.05091567901354485, Temperature 0.00010834322064402047, step_size 0.9257011207008896, test_acc: 0.5\n",
            "Epoch 1721, BestLoss: 0.05083817471332634, Temperature 0.00010292605961181944, step_size 0.9256085505888195, test_acc: 0.5005\n",
            "Epoch 1722, BestLoss: 0.050826651911664, Temperature 9.777975663122846e-05, step_size 0.9255159897337607, test_acc: 0.5001\n",
            "Epoch 1723, BestLoss: 0.050826651911664, Temperature 9.289076879966704e-05, step_size 0.9254234381347873, test_acc: 0.5001\n",
            "Epoch 1724, BestLoss: 0.05087653868362073, Temperature 9.777975663122846e-05, step_size 0.9257937000708967, test_acc: 0.4983\n",
            "Epoch 1725, BestLoss: 0.05082425277384492, Temperature 9.289076879966704e-05, step_size 0.9257011207008896, test_acc: 0.4998\n",
            "Epoch 1726, BestLoss: 0.050858201883670205, Temperature 8.824623035968368e-05, step_size 0.9256085505888195, test_acc: 0.4998\n",
            "Epoch 1727, BestLoss: 0.050858201883670205, Temperature 8.383391884169949e-05, step_size 0.9255159897337607, test_acc: 0.4998\n",
            "Epoch 1728, BestLoss: 0.050751317310633495, Temperature 8.824623035968368e-05, step_size 0.9257011207008896, test_acc: 0.5009\n",
            "Epoch 1729, BestLoss: 0.050539623974959764, Temperature 8.383391884169949e-05, step_size 0.9256085505888195, test_acc: 0.5018\n",
            "Epoch 1730, BestLoss: 0.05059639801688609, Temperature 7.96422228996145e-05, step_size 0.9255159897337607, test_acc: 0.5017\n",
            "Epoch 1731, BestLoss: 0.05064681908469711, Temperature 7.566011175463378e-05, step_size 0.9254234381347873, test_acc: 0.5012\n",
            "Epoch 1732, BestLoss: 0.05064681908469711, Temperature 7.187710616690208e-05, step_size 0.9253308957909738, test_acc: 0.5012\n",
            "Epoch 1733, BestLoss: 0.050518237397607496, Temperature 7.566011175463378e-05, step_size 0.9256085505888195, test_acc: 0.501\n",
            "Epoch 1734, BestLoss: 0.05060776157593285, Temperature 7.187710616690208e-05, step_size 0.9255159897337607, test_acc: 0.5013\n",
            "Epoch 1735, BestLoss: 0.05050057167780277, Temperature 6.828325085855697e-05, step_size 0.9254234381347873, test_acc: 0.5035\n",
            "Epoch 1736, BestLoss: 0.05050057167780277, Temperature 6.486908831562912e-05, step_size 0.9253308957909738, test_acc: 0.5035\n",
            "Epoch 1737, BestLoss: 0.05052288700360435, Temperature 6.828325085855697e-05, step_size 0.9255159897337607, test_acc: 0.5031\n",
            "Epoch 1738, BestLoss: 0.05050579965737692, Temperature 6.486908831562912e-05, step_size 0.9254234381347873, test_acc: 0.5032\n",
            "Epoch 1739, BestLoss: 0.05050579965737692, Temperature 6.162563389984766e-05, step_size 0.9253308957909738, test_acc: 0.5032\n",
            "Epoch 1740, BestLoss: 0.05050579965737692, Temperature 6.486908831562912e-05, step_size 0.9254234381347873, test_acc: 0.5032\n",
            "Epoch 1741, BestLoss: 0.0507200805285234, Temperature 6.828325085855697e-05, step_size 0.9253308957909738, test_acc: 0.5016\n",
            "Epoch 1742, BestLoss: 0.05051980299511365, Temperature 6.486908831562912e-05, step_size 0.9252383627013947, test_acc: 0.5032\n",
            "Epoch 1743, BestLoss: 0.05051980299511365, Temperature 6.162563389984766e-05, step_size 0.9251458388651246, test_acc: 0.5032\n",
            "Epoch 1744, BestLoss: 0.05051980299511365, Temperature 6.486908831562912e-05, step_size 0.9252383627013947, test_acc: 0.5032\n",
            "Epoch 1745, BestLoss: 0.05051980299511365, Temperature 6.828325085855697e-05, step_size 0.9251458388651246, test_acc: 0.5032\n",
            "Epoch 1746, BestLoss: 0.050586991920210655, Temperature 7.187710616690208e-05, step_size 0.9250533242812381, test_acc: 0.5028\n",
            "Epoch 1747, BestLoss: 0.05045942485319675, Temperature 6.828325085855697e-05, step_size 0.92496081894881, test_acc: 0.5036\n",
            "Epoch 1748, BestLoss: 0.05049956788076113, Temperature 6.486908831562912e-05, step_size 0.9248683228669151, test_acc: 0.5032\n",
            "Epoch 1749, BestLoss: 0.050484558316026586, Temperature 6.162563389984766e-05, step_size 0.9247758360346284, test_acc: 0.5036\n",
            "Epoch 1750, BestLoss: 0.050484558316026586, Temperature 5.8544352204855274e-05, step_size 0.924683358451025, test_acc: 0.5036\n",
            "Epoch 1751, BestLoss: 0.050220946310234355, Temperature 6.162563389984766e-05, step_size 0.92496081894881, test_acc: 0.5037\n",
            "Epoch 1752, BestLoss: 0.050132090758774644, Temperature 5.8544352204855274e-05, step_size 0.9248683228669151, test_acc: 0.5056\n",
            "Epoch 1753, BestLoss: 0.050132090758774644, Temperature 5.561713459461251e-05, step_size 0.9247758360346284, test_acc: 0.5056\n",
            "Epoch 1754, BestLoss: 0.05010548778621635, Temperature 5.8544352204855274e-05, step_size 0.9248683228669151, test_acc: 0.505\n",
            "Epoch 1755, BestLoss: 0.050092688723713835, Temperature 5.561713459461251e-05, step_size 0.9247758360346284, test_acc: 0.5053\n",
            "Epoch 1756, BestLoss: 0.050092688723713835, Temperature 5.283627786488188e-05, step_size 0.924683358451025, test_acc: 0.5053\n",
            "Epoch 1757, BestLoss: 0.0498028344317499, Temperature 5.561713459461251e-05, step_size 0.9247758360346284, test_acc: 0.5079\n",
            "Epoch 1758, BestLoss: 0.04962607556420335, Temperature 5.283627786488188e-05, step_size 0.924683358451025, test_acc: 0.5092\n",
            "Epoch 1759, BestLoss: 0.04962607556420335, Temperature 5.019446397163778e-05, step_size 0.9245908901151799, test_acc: 0.5092\n",
            "Epoch 1760, BestLoss: 0.04953228274247473, Temperature 5.283627786488188e-05, step_size 0.924683358451025, test_acc: 0.5103\n",
            "Epoch 1761, BestLoss: 0.04952945568506634, Temperature 5.019446397163778e-05, step_size 0.9245908901151799, test_acc: 0.5127\n",
            "Epoch 1762, BestLoss: 0.04952945568506634, Temperature 4.768474077305589e-05, step_size 0.9244984310261685, test_acc: 0.5127\n",
            "Epoch 1763, BestLoss: 0.049461292484808045, Temperature 5.019446397163778e-05, step_size 0.9245908901151799, test_acc: 0.5124\n",
            "Epoch 1764, BestLoss: 0.04940054346694902, Temperature 4.768474077305589e-05, step_size 0.9244984310261685, test_acc: 0.5117\n",
            "Epoch 1765, BestLoss: 0.049411184953865386, Temperature 4.53005037344031e-05, step_size 0.9244059811830658, test_acc: 0.5113\n",
            "Epoch 1766, BestLoss: 0.049411184953865386, Temperature 4.303547854768294e-05, step_size 0.9243135405849475, test_acc: 0.5113\n",
            "Epoch 1767, BestLoss: 0.049411184953865386, Temperature 4.53005037344031e-05, step_size 0.9244984310261685, test_acc: 0.5113\n",
            "Epoch 1768, BestLoss: 0.049486673003763, Temperature 4.768474077305589e-05, step_size 0.9244059811830658, test_acc: 0.5104\n",
            "Epoch 1769, BestLoss: 0.049533433716024484, Temperature 4.53005037344031e-05, step_size 0.9243135405849475, test_acc: 0.5102\n",
            "Epoch 1770, BestLoss: 0.049533433716024484, Temperature 4.303547854768294e-05, step_size 0.9242211092308891, test_acc: 0.5102\n",
            "Epoch 1771, BestLoss: 0.049533433716024484, Temperature 4.53005037344031e-05, step_size 0.9243135405849475, test_acc: 0.5102\n",
            "Epoch 1772, BestLoss: 0.049533433716024484, Temperature 4.768474077305589e-05, step_size 0.9242211092308891, test_acc: 0.5102\n",
            "Epoch 1773, BestLoss: 0.049533433716024484, Temperature 5.019446397163778e-05, step_size 0.924128687119966, test_acc: 0.5102\n",
            "Epoch 1774, BestLoss: 0.049533433716024484, Temperature 5.283627786488188e-05, step_size 0.924036274251254, test_acc: 0.5102\n",
            "Epoch 1775, BestLoss: 0.049533433716024484, Temperature 5.561713459461251e-05, step_size 0.9239438706238289, test_acc: 0.5102\n",
            "Epoch 1776, BestLoss: 0.04950252061316685, Temperature 5.8544352204855274e-05, step_size 0.9238514762367666, test_acc: 0.51\n",
            "Epoch 1777, BestLoss: 0.04956210576545955, Temperature 5.561713459461251e-05, step_size 0.9237590910891429, test_acc: 0.5083\n",
            "Epoch 1778, BestLoss: 0.04958125490677994, Temperature 5.283627786488188e-05, step_size 0.923666715180034, test_acc: 0.5074\n",
            "Epoch 1779, BestLoss: 0.04958125490677994, Temperature 5.019446397163778e-05, step_size 0.9235743485085159, test_acc: 0.5074\n",
            "Epoch 1780, BestLoss: 0.04958125490677994, Temperature 5.283627786488188e-05, step_size 0.9237590910891429, test_acc: 0.5074\n",
            "Epoch 1781, BestLoss: 0.04958791503079034, Temperature 5.561713459461251e-05, step_size 0.923666715180034, test_acc: 0.5071\n",
            "Epoch 1782, BestLoss: 0.04958791503079034, Temperature 5.283627786488188e-05, step_size 0.9235743485085159, test_acc: 0.5071\n",
            "Epoch 1783, BestLoss: 0.04958791503079034, Temperature 5.561713459461251e-05, step_size 0.9235743485085159, test_acc: 0.5071\n",
            "Epoch 1784, BestLoss: 0.04958791503079034, Temperature 5.8544352204855274e-05, step_size 0.9234819910736651, test_acc: 0.5071\n",
            "Epoch 1785, BestLoss: 0.04958791503079034, Temperature 6.162563389984766e-05, step_size 0.9233896428745578, test_acc: 0.5071\n",
            "Epoch 1786, BestLoss: 0.04958791503079034, Temperature 6.486908831562912e-05, step_size 0.9232973039102704, test_acc: 0.5071\n",
            "Epoch 1787, BestLoss: 0.049597941500900404, Temperature 6.828325085855697e-05, step_size 0.9232049741798795, test_acc: 0.5082\n",
            "Epoch 1788, BestLoss: 0.0495796497945792, Temperature 6.486908831562912e-05, step_size 0.9231126536824614, test_acc: 0.5073\n",
            "Epoch 1789, BestLoss: 0.049626715243260865, Temperature 6.162563389984766e-05, step_size 0.9230203424170932, test_acc: 0.5089\n",
            "Epoch 1790, BestLoss: 0.04960589537206294, Temperature 5.8544352204855274e-05, step_size 0.9229280403828515, test_acc: 0.51\n",
            "Epoch 1791, BestLoss: 0.04960589537206294, Temperature 5.561713459461251e-05, step_size 0.9228357475788131, test_acc: 0.51\n",
            "Epoch 1792, BestLoss: 0.04947034698423121, Temperature 5.8544352204855274e-05, step_size 0.9231126536824614, test_acc: 0.5093\n",
            "Epoch 1793, BestLoss: 0.04947034698423121, Temperature 5.561713459461251e-05, step_size 0.9230203424170932, test_acc: 0.5093\n",
            "Epoch 1794, BestLoss: 0.04947034698423121, Temperature 5.8544352204855274e-05, step_size 0.9230203424170932, test_acc: 0.5093\n",
            "Epoch 1795, BestLoss: 0.04947799483989771, Temperature 6.162563389984766e-05, step_size 0.9229280403828515, test_acc: 0.5095\n",
            "Epoch 1796, BestLoss: 0.049379169203958156, Temperature 5.8544352204855274e-05, step_size 0.9228357475788131, test_acc: 0.5116\n",
            "Epoch 1797, BestLoss: 0.04938352008607356, Temperature 5.561713459461251e-05, step_size 0.9227434640040553, test_acc: 0.5118\n",
            "Epoch 1798, BestLoss: 0.04935987791005426, Temperature 5.283627786488188e-05, step_size 0.9226511896576549, test_acc: 0.5145\n",
            "Epoch 1799, BestLoss: 0.04935987791005426, Temperature 5.019446397163778e-05, step_size 0.9225589245386892, test_acc: 0.5145\n",
            "Epoch 1800, BestLoss: 0.04935987791005426, Temperature 5.283627786488188e-05, step_size 0.9228357475788131, test_acc: 0.5145\n",
            "Epoch 1801, BestLoss: 0.04935987791005426, Temperature 5.561713459461251e-05, step_size 0.9227434640040553, test_acc: 0.5145\n",
            "Epoch 1802, BestLoss: 0.04935987791005426, Temperature 5.8544352204855274e-05, step_size 0.9226511896576549, test_acc: 0.5145\n",
            "Epoch 1803, BestLoss: 0.04935987791005426, Temperature 6.162563389984766e-05, step_size 0.9225589245386892, test_acc: 0.5145\n",
            "Epoch 1804, BestLoss: 0.04924435936334203, Temperature 6.486908831562912e-05, step_size 0.9224666686462353, test_acc: 0.5137\n",
            "Epoch 1805, BestLoss: 0.04914770605250329, Temperature 6.162563389984766e-05, step_size 0.9223744219793707, test_acc: 0.5119\n",
            "Epoch 1806, BestLoss: 0.04917101532907249, Temperature 5.8544352204855274e-05, step_size 0.9222821845371728, test_acc: 0.5111\n",
            "Epoch 1807, BestLoss: 0.04916549582896787, Temperature 5.561713459461251e-05, step_size 0.9221899563187191, test_acc: 0.5124\n",
            "Epoch 1808, BestLoss: 0.04918602382153645, Temperature 5.283627786488188e-05, step_size 0.9220977373230873, test_acc: 0.5118\n",
            "Epoch 1809, BestLoss: 0.04914646598674825, Temperature 5.019446397163778e-05, step_size 0.922005527549355, test_acc: 0.511\n",
            "Epoch 1810, BestLoss: 0.04914646598674825, Temperature 4.768474077305589e-05, step_size 0.9219133269966001, test_acc: 0.511\n",
            "Epoch 1811, BestLoss: 0.049102141800716946, Temperature 5.019446397163778e-05, step_size 0.9223744219793707, test_acc: 0.5127\n",
            "Epoch 1812, BestLoss: 0.049102141800716946, Temperature 4.768474077305589e-05, step_size 0.9222821845371728, test_acc: 0.5127\n",
            "Epoch 1813, BestLoss: 0.048998898901846846, Temperature 5.019446397163778e-05, step_size 0.9222821845371728, test_acc: 0.5129\n",
            "Epoch 1814, BestLoss: 0.04897940440458902, Temperature 4.768474077305589e-05, step_size 0.9221899563187191, test_acc: 0.5153\n",
            "Epoch 1815, BestLoss: 0.04897940440458902, Temperature 4.53005037344031e-05, step_size 0.9220977373230873, test_acc: 0.5153\n",
            "Epoch 1816, BestLoss: 0.04892315546628813, Temperature 4.768474077305589e-05, step_size 0.9221899563187191, test_acc: 0.5155\n",
            "Epoch 1817, BestLoss: 0.04892315546628813, Temperature 4.53005037344031e-05, step_size 0.9220977373230873, test_acc: 0.5155\n",
            "Epoch 1818, BestLoss: 0.04885768573407407, Temperature 4.768474077305589e-05, step_size 0.9220977373230873, test_acc: 0.5159\n",
            "Epoch 1819, BestLoss: 0.04881714501750722, Temperature 4.53005037344031e-05, step_size 0.922005527549355, test_acc: 0.5164\n",
            "Epoch 1820, BestLoss: 0.04881714501750722, Temperature 4.303547854768294e-05, step_size 0.9219133269966001, test_acc: 0.5164\n",
            "Epoch 1821, BestLoss: 0.04881714501750722, Temperature 4.53005037344031e-05, step_size 0.922005527549355, test_acc: 0.5164\n",
            "Epoch 1822, BestLoss: 0.04884133161109154, Temperature 4.768474077305589e-05, step_size 0.9219133269966001, test_acc: 0.5164\n",
            "Epoch 1823, BestLoss: 0.04870808381353439, Temperature 4.53005037344031e-05, step_size 0.9218211356639004, test_acc: 0.5171\n",
            "Epoch 1824, BestLoss: 0.04870808381353439, Temperature 4.303547854768294e-05, step_size 0.921728953550334, test_acc: 0.5171\n",
            "Epoch 1825, BestLoss: 0.04870808381353439, Temperature 4.53005037344031e-05, step_size 0.9218211356639004, test_acc: 0.5171\n",
            "Epoch 1826, BestLoss: 0.04870808381353439, Temperature 4.768474077305589e-05, step_size 0.921728953550334, test_acc: 0.5171\n",
            "Epoch 1827, BestLoss: 0.04872680986170833, Temperature 5.019446397163778e-05, step_size 0.921636780654979, test_acc: 0.5177\n",
            "Epoch 1828, BestLoss: 0.04872680986170833, Temperature 4.768474077305589e-05, step_size 0.9215446169769135, test_acc: 0.5177\n",
            "Epoch 1829, BestLoss: 0.04872680986170833, Temperature 5.019446397163778e-05, step_size 0.9215446169769135, test_acc: 0.5177\n",
            "Epoch 1830, BestLoss: 0.04873562604199126, Temperature 5.283627786488188e-05, step_size 0.9214524625152158, test_acc: 0.5167\n",
            "Epoch 1831, BestLoss: 0.048722882095572795, Temperature 5.019446397163778e-05, step_size 0.9213603172689643, test_acc: 0.5166\n",
            "Epoch 1832, BestLoss: 0.048765015364585045, Temperature 4.768474077305589e-05, step_size 0.9212681812372374, test_acc: 0.5162\n",
            "Epoch 1833, BestLoss: 0.04866058120153757, Temperature 4.53005037344031e-05, step_size 0.9211760544191137, test_acc: 0.518\n",
            "Epoch 1834, BestLoss: 0.04875859744018395, Temperature 4.303547854768294e-05, step_size 0.9210839368136717, test_acc: 0.5161\n",
            "Epoch 1835, BestLoss: 0.04875859744018395, Temperature 4.0883704620298796e-05, step_size 0.9209918284199904, test_acc: 0.5161\n",
            "Epoch 1836, BestLoss: 0.04875859744018395, Temperature 4.303547854768294e-05, step_size 0.9213603172689643, test_acc: 0.5161\n",
            "Epoch 1837, BestLoss: 0.04873296382717941, Temperature 4.53005037344031e-05, step_size 0.9212681812372374, test_acc: 0.5178\n",
            "Epoch 1838, BestLoss: 0.04850829048826547, Temperature 4.303547854768294e-05, step_size 0.9211760544191137, test_acc: 0.5184\n",
            "Epoch 1839, BestLoss: 0.04855636573917897, Temperature 4.0883704620298796e-05, step_size 0.9210839368136717, test_acc: 0.5188\n",
            "Epoch 1840, BestLoss: 0.04855636573917897, Temperature 3.883951938928385e-05, step_size 0.9209918284199904, test_acc: 0.5188\n",
            "Epoch 1841, BestLoss: 0.04855636573917897, Temperature 4.0883704620298796e-05, step_size 0.9211760544191137, test_acc: 0.5188\n",
            "Epoch 1842, BestLoss: 0.04855636573917897, Temperature 4.303547854768294e-05, step_size 0.9210839368136717, test_acc: 0.5188\n",
            "Epoch 1843, BestLoss: 0.04855636573917897, Temperature 4.53005037344031e-05, step_size 0.9209918284199904, test_acc: 0.5188\n",
            "Epoch 1844, BestLoss: 0.04852611215030707, Temperature 4.768474077305589e-05, step_size 0.9208997292371484, test_acc: 0.5174\n",
            "Epoch 1845, BestLoss: 0.04852611215030707, Temperature 4.53005037344031e-05, step_size 0.9208076392642246, test_acc: 0.5174\n",
            "Epoch 1846, BestLoss: 0.04852611215030707, Temperature 4.768474077305589e-05, step_size 0.9208076392642246, test_acc: 0.5174\n",
            "Epoch 1847, BestLoss: 0.04852611215030707, Temperature 5.019446397163778e-05, step_size 0.9207155585002982, test_acc: 0.5174\n",
            "Epoch 1848, BestLoss: 0.04852611215030707, Temperature 5.283627786488188e-05, step_size 0.9206234869444482, test_acc: 0.5174\n",
            "Epoch 1849, BestLoss: 0.04852611215030707, Temperature 5.561713459461251e-05, step_size 0.9205314245957538, test_acc: 0.5174\n",
            "Epoch 1850, BestLoss: 0.04852611215030707, Temperature 5.8544352204855274e-05, step_size 0.9204393714532942, test_acc: 0.5174\n",
            "Epoch 1851, BestLoss: 0.04852611215030707, Temperature 6.162563389984766e-05, step_size 0.9203473275161489, test_acc: 0.5174\n",
            "Epoch 1852, BestLoss: 0.04852611215030707, Temperature 6.486908831562912e-05, step_size 0.9202552927833972, test_acc: 0.5174\n",
            "Epoch 1853, BestLoss: 0.04852611215030707, Temperature 6.828325085855697e-05, step_size 0.9201632672541189, test_acc: 0.5174\n",
            "Epoch 1854, BestLoss: 0.04852611215030707, Temperature 7.187710616690208e-05, step_size 0.9200712509273935, test_acc: 0.5174\n",
            "Epoch 1855, BestLoss: 0.04852611215030707, Temperature 7.566011175463378e-05, step_size 0.9199792438023008, test_acc: 0.5174\n",
            "Epoch 1856, BestLoss: 0.04852611215030707, Temperature 7.96422228996145e-05, step_size 0.9198872458779206, test_acc: 0.5174\n",
            "Epoch 1857, BestLoss: 0.04852611215030707, Temperature 8.383391884169949e-05, step_size 0.9197952571533328, test_acc: 0.5174\n",
            "Epoch 1858, BestLoss: 0.04849163245981166, Temperature 8.824623035968368e-05, step_size 0.9197032776276175, test_acc: 0.5194\n",
            "Epoch 1859, BestLoss: 0.04842003264829919, Temperature 8.383391884169949e-05, step_size 0.9196113072998547, test_acc: 0.5218\n",
            "Epoch 1860, BestLoss: 0.04847737329064068, Temperature 7.96422228996145e-05, step_size 0.9195193461691248, test_acc: 0.5205\n",
            "Epoch 1861, BestLoss: 0.04849935949720064, Temperature 7.566011175463378e-05, step_size 0.9194273942345079, test_acc: 0.5204\n",
            "Epoch 1862, BestLoss: 0.04849315162685891, Temperature 7.187710616690208e-05, step_size 0.9193354514950844, test_acc: 0.5197\n",
            "Epoch 1863, BestLoss: 0.04849315162685891, Temperature 6.828325085855697e-05, step_size 0.919243517949935, test_acc: 0.5197\n",
            "Epoch 1864, BestLoss: 0.04849315162685891, Temperature 7.187710616690208e-05, step_size 0.9196113072998547, test_acc: 0.5197\n",
            "Epoch 1865, BestLoss: 0.04857615262604352, Temperature 7.566011175463378e-05, step_size 0.9195193461691248, test_acc: 0.5187\n",
            "Epoch 1866, BestLoss: 0.04857615262604352, Temperature 7.187710616690208e-05, step_size 0.9194273942345079, test_acc: 0.5187\n",
            "Epoch 1867, BestLoss: 0.04857615262604352, Temperature 7.566011175463378e-05, step_size 0.9194273942345079, test_acc: 0.5187\n",
            "Epoch 1868, BestLoss: 0.04857615262604352, Temperature 7.96422228996145e-05, step_size 0.9193354514950844, test_acc: 0.5187\n",
            "Epoch 1869, BestLoss: 0.04862625709408174, Temperature 8.383391884169949e-05, step_size 0.919243517949935, test_acc: 0.5192\n",
            "Epoch 1870, BestLoss: 0.04872923046608275, Temperature 7.96422228996145e-05, step_size 0.91915159359814, test_acc: 0.5174\n",
            "Epoch 1871, BestLoss: 0.04872923046608275, Temperature 7.566011175463378e-05, step_size 0.9190596784387802, test_acc: 0.5174\n",
            "Epoch 1872, BestLoss: 0.04872923046608275, Temperature 7.96422228996145e-05, step_size 0.91915159359814, test_acc: 0.5174\n",
            "Epoch 1873, BestLoss: 0.04887147105864851, Temperature 8.383391884169949e-05, step_size 0.9190596784387802, test_acc: 0.5174\n",
            "Epoch 1874, BestLoss: 0.04868235306113173, Temperature 7.96422228996145e-05, step_size 0.9189677724709363, test_acc: 0.5186\n",
            "Epoch 1875, BestLoss: 0.04868265658728393, Temperature 7.566011175463378e-05, step_size 0.9188758756936892, test_acc: 0.5176\n",
            "Epoch 1876, BestLoss: 0.04868265658728393, Temperature 7.96422228996145e-05, step_size 0.9189677724709363, test_acc: 0.5176\n",
            "Epoch 1877, BestLoss: 0.04868265658728393, Temperature 8.383391884169949e-05, step_size 0.9188758756936892, test_acc: 0.5176\n",
            "Epoch 1878, BestLoss: 0.04871798065974051, Temperature 8.824623035968368e-05, step_size 0.9187839881061198, test_acc: 0.5174\n",
            "Epoch 1879, BestLoss: 0.04871798065974051, Temperature 8.383391884169949e-05, step_size 0.9186921097073092, test_acc: 0.5174\n",
            "Epoch 1880, BestLoss: 0.0486346086029453, Temperature 8.824623035968368e-05, step_size 0.9186921097073092, test_acc: 0.5187\n",
            "Epoch 1881, BestLoss: 0.0486346086029453, Temperature 8.383391884169949e-05, step_size 0.9186002404963385, test_acc: 0.5187\n",
            "Epoch 1882, BestLoss: 0.0486346086029453, Temperature 8.824623035968368e-05, step_size 0.9186002404963385, test_acc: 0.5187\n",
            "Epoch 1883, BestLoss: 0.0486346086029453, Temperature 9.289076879966704e-05, step_size 0.9185083804722889, test_acc: 0.5187\n",
            "Epoch 1884, BestLoss: 0.0486346086029453, Temperature 9.777975663122846e-05, step_size 0.9184165296342417, test_acc: 0.5187\n",
            "Epoch 1885, BestLoss: 0.0486346086029453, Temperature 0.00010292605961181944, step_size 0.9183246879812783, test_acc: 0.5187\n",
            "Epoch 1886, BestLoss: 0.0486346086029453, Temperature 0.00010834322064402047, step_size 0.9182328555124802, test_acc: 0.5187\n",
            "Epoch 1887, BestLoss: 0.048620429794299466, Temperature 0.0001140454954147584, step_size 0.918141032226929, test_acc: 0.5205\n",
            "Epoch 1888, BestLoss: 0.04861233830670463, Temperature 0.00010834322064402047, step_size 0.9180492181237063, test_acc: 0.52\n",
            "Epoch 1889, BestLoss: 0.04856591029671238, Temperature 0.00010292605961181944, step_size 0.917957413201894, test_acc: 0.5192\n",
            "Epoch 1890, BestLoss: 0.048527699205036516, Temperature 9.777975663122846e-05, step_size 0.9178656174605737, test_acc: 0.52\n",
            "Epoch 1891, BestLoss: 0.048527699205036516, Temperature 9.289076879966704e-05, step_size 0.9177738308988277, test_acc: 0.52\n",
            "Epoch 1892, BestLoss: 0.048527699205036516, Temperature 9.777975663122846e-05, step_size 0.9180492181237063, test_acc: 0.52\n",
            "Epoch 1893, BestLoss: 0.048527699205036516, Temperature 0.00010292605961181944, step_size 0.917957413201894, test_acc: 0.52\n",
            "Epoch 1894, BestLoss: 0.048456559350072294, Temperature 0.00010834322064402047, step_size 0.9178656174605737, test_acc: 0.5211\n",
            "Epoch 1895, BestLoss: 0.048456559350072294, Temperature 0.00010292605961181944, step_size 0.9177738308988277, test_acc: 0.5211\n",
            "Epoch 1896, BestLoss: 0.04827588995004409, Temperature 0.00010834322064402047, step_size 0.9177738308988277, test_acc: 0.5199\n",
            "Epoch 1897, BestLoss: 0.04827588995004409, Temperature 0.00010292605961181944, step_size 0.9176820535157378, test_acc: 0.5199\n",
            "Epoch 1898, BestLoss: 0.048253483932388284, Temperature 0.00010834322064402047, step_size 0.9176820535157378, test_acc: 0.5194\n",
            "Epoch 1899, BestLoss: 0.048200102413742014, Temperature 0.00010292605961181944, step_size 0.9175902853103862, test_acc: 0.5194\n",
            "Epoch 1900, BestLoss: 0.048200102413742014, Temperature 9.777975663122846e-05, step_size 0.9174985262818552, test_acc: 0.5194\n",
            "Epoch 1901, BestLoss: 0.048168046252009385, Temperature 0.00010292605961181944, step_size 0.9175902853103862, test_acc: 0.5212\n",
            "Epoch 1902, BestLoss: 0.0481399892665057, Temperature 9.777975663122846e-05, step_size 0.9174985262818552, test_acc: 0.522\n",
            "Epoch 1903, BestLoss: 0.0481399892665057, Temperature 9.289076879966704e-05, step_size 0.9174067764292271, test_acc: 0.522\n",
            "Epoch 1904, BestLoss: 0.0481399892665057, Temperature 9.777975663122846e-05, step_size 0.9174985262818552, test_acc: 0.522\n",
            "Epoch 1905, BestLoss: 0.04805636695120931, Temperature 0.00010292605961181944, step_size 0.9174067764292271, test_acc: 0.52\n",
            "Epoch 1906, BestLoss: 0.04805636695120931, Temperature 9.777975663122846e-05, step_size 0.9173150357515841, test_acc: 0.52\n",
            "Epoch 1907, BestLoss: 0.048036368573527374, Temperature 0.00010292605961181944, step_size 0.9173150357515841, test_acc: 0.5203\n",
            "Epoch 1908, BestLoss: 0.048036368573527374, Temperature 9.777975663122846e-05, step_size 0.917223304248009, test_acc: 0.5203\n",
            "Epoch 1909, BestLoss: 0.048096607785107215, Temperature 0.00010292605961181944, step_size 0.917223304248009, test_acc: 0.5206\n",
            "Epoch 1910, BestLoss: 0.048201280606906996, Temperature 9.777975663122846e-05, step_size 0.9171315819175843, test_acc: 0.5203\n",
            "Epoch 1911, BestLoss: 0.04816234653681712, Temperature 9.289076879966704e-05, step_size 0.9170398687593925, test_acc: 0.5211\n",
            "Epoch 1912, BestLoss: 0.04816234653681712, Temperature 8.824623035968368e-05, step_size 0.9169481647725165, test_acc: 0.5211\n",
            "Epoch 1913, BestLoss: 0.04823255660748178, Temperature 9.289076879966704e-05, step_size 0.9171315819175843, test_acc: 0.5214\n",
            "Epoch 1914, BestLoss: 0.048046795222006305, Temperature 8.824623035968368e-05, step_size 0.9170398687593925, test_acc: 0.5237\n",
            "Epoch 1915, BestLoss: 0.048046795222006305, Temperature 8.383391884169949e-05, step_size 0.9169481647725165, test_acc: 0.5237\n",
            "Epoch 1916, BestLoss: 0.048046795222006305, Temperature 8.824623035968368e-05, step_size 0.9170398687593925, test_acc: 0.5237\n",
            "Epoch 1917, BestLoss: 0.048174624709499875, Temperature 9.289076879966704e-05, step_size 0.9169481647725165, test_acc: 0.5226\n",
            "Epoch 1918, BestLoss: 0.048174624709499875, Temperature 8.824623035968368e-05, step_size 0.9168564699560393, test_acc: 0.5226\n",
            "Epoch 1919, BestLoss: 0.048174624709499875, Temperature 9.289076879966704e-05, step_size 0.9168564699560393, test_acc: 0.5226\n",
            "Epoch 1920, BestLoss: 0.04816131230534073, Temperature 9.777975663122846e-05, step_size 0.9167647843090437, test_acc: 0.5202\n",
            "Epoch 1921, BestLoss: 0.04815436784110631, Temperature 9.289076879966704e-05, step_size 0.9166731078306128, test_acc: 0.5211\n",
            "Epoch 1922, BestLoss: 0.04815436784110631, Temperature 8.824623035968368e-05, step_size 0.9165814405198298, test_acc: 0.5211\n",
            "Epoch 1923, BestLoss: 0.04788095192015525, Temperature 9.289076879966704e-05, step_size 0.9166731078306128, test_acc: 0.5228\n",
            "Epoch 1924, BestLoss: 0.047828190174143914, Temperature 8.824623035968368e-05, step_size 0.9165814405198298, test_acc: 0.523\n",
            "Epoch 1925, BestLoss: 0.04785600277489013, Temperature 8.383391884169949e-05, step_size 0.9164897823757778, test_acc: 0.5218\n",
            "Epoch 1926, BestLoss: 0.04789136642950894, Temperature 7.96422228996145e-05, step_size 0.9163981333975403, test_acc: 0.522\n",
            "Epoch 1927, BestLoss: 0.04788464590737743, Temperature 7.566011175463378e-05, step_size 0.9163064935842006, test_acc: 0.5232\n",
            "Epoch 1928, BestLoss: 0.047791327983395825, Temperature 7.187710616690208e-05, step_size 0.9162148629348421, test_acc: 0.5237\n",
            "Epoch 1929, BestLoss: 0.047791327983395825, Temperature 6.828325085855697e-05, step_size 0.9161232414485486, test_acc: 0.5237\n",
            "Epoch 1930, BestLoss: 0.047791327983395825, Temperature 7.187710616690208e-05, step_size 0.9165814405198298, test_acc: 0.5237\n",
            "Epoch 1931, BestLoss: 0.047791327983395825, Temperature 7.566011175463378e-05, step_size 0.9164897823757778, test_acc: 0.5237\n",
            "Epoch 1932, BestLoss: 0.04768297721401467, Temperature 7.96422228996145e-05, step_size 0.9163981333975403, test_acc: 0.5237\n",
            "Epoch 1933, BestLoss: 0.04768297721401467, Temperature 7.566011175463378e-05, step_size 0.9163064935842006, test_acc: 0.5237\n",
            "Epoch 1934, BestLoss: 0.047638693025480246, Temperature 7.96422228996145e-05, step_size 0.9163064935842006, test_acc: 0.5252\n",
            "Epoch 1935, BestLoss: 0.047638693025480246, Temperature 7.566011175463378e-05, step_size 0.9162148629348421, test_acc: 0.5252\n",
            "Epoch 1936, BestLoss: 0.04766272738954712, Temperature 7.96422228996145e-05, step_size 0.9162148629348421, test_acc: 0.526\n",
            "Epoch 1937, BestLoss: 0.047474267086550996, Temperature 7.566011175463378e-05, step_size 0.9161232414485486, test_acc: 0.5267\n",
            "Epoch 1938, BestLoss: 0.04748308610082562, Temperature 7.187710616690208e-05, step_size 0.9160316291244037, test_acc: 0.5266\n",
            "Epoch 1939, BestLoss: 0.04748308610082562, Temperature 6.828325085855697e-05, step_size 0.9159400259614913, test_acc: 0.5266\n",
            "Epoch 1940, BestLoss: 0.04748308610082562, Temperature 7.187710616690208e-05, step_size 0.9161232414485486, test_acc: 0.5266\n",
            "Epoch 1941, BestLoss: 0.047456254057759516, Temperature 7.566011175463378e-05, step_size 0.9160316291244037, test_acc: 0.527\n",
            "Epoch 1942, BestLoss: 0.04729124251139726, Temperature 7.187710616690208e-05, step_size 0.9159400259614913, test_acc: 0.5279\n",
            "Epoch 1943, BestLoss: 0.04729124251139726, Temperature 6.828325085855697e-05, step_size 0.9158484319588951, test_acc: 0.5279\n",
            "Epoch 1944, BestLoss: 0.04729124251139726, Temperature 7.187710616690208e-05, step_size 0.9159400259614913, test_acc: 0.5279\n",
            "Epoch 1945, BestLoss: 0.04741119591778457, Temperature 7.566011175463378e-05, step_size 0.9158484319588951, test_acc: 0.5273\n",
            "Epoch 1946, BestLoss: 0.047445924602909584, Temperature 7.187710616690208e-05, step_size 0.9157568471156993, test_acc: 0.5259\n",
            "Epoch 1947, BestLoss: 0.047445924602909584, Temperature 6.828325085855697e-05, step_size 0.9156652714309877, test_acc: 0.5259\n",
            "Epoch 1948, BestLoss: 0.04748599737978116, Temperature 7.187710616690208e-05, step_size 0.9157568471156993, test_acc: 0.5258\n",
            "Epoch 1949, BestLoss: 0.04748599737978116, Temperature 6.828325085855697e-05, step_size 0.9156652714309877, test_acc: 0.5258\n",
            "Epoch 1950, BestLoss: 0.04748599737978116, Temperature 7.187710616690208e-05, step_size 0.9156652714309877, test_acc: 0.5258\n",
            "Epoch 1951, BestLoss: 0.047538921201416076, Temperature 7.566011175463378e-05, step_size 0.9155737049038447, test_acc: 0.5262\n",
            "Epoch 1952, BestLoss: 0.047538921201416076, Temperature 7.187710616690208e-05, step_size 0.9154821475333543, test_acc: 0.5262\n",
            "Epoch 1953, BestLoss: 0.047538921201416076, Temperature 7.566011175463378e-05, step_size 0.9154821475333543, test_acc: 0.5262\n",
            "Epoch 1954, BestLoss: 0.047538921201416076, Temperature 7.96422228996145e-05, step_size 0.915390599318601, test_acc: 0.5262\n",
            "Epoch 1955, BestLoss: 0.047565376325214626, Temperature 8.383391884169949e-05, step_size 0.9152990602586691, test_acc: 0.5264\n",
            "Epoch 1956, BestLoss: 0.047371345764944214, Temperature 7.96422228996145e-05, step_size 0.9152075303526432, test_acc: 0.5275\n",
            "Epoch 1957, BestLoss: 0.04736678496938457, Temperature 7.566011175463378e-05, step_size 0.915116009599608, test_acc: 0.527\n",
            "Epoch 1958, BestLoss: 0.04736678496938457, Temperature 7.187710616690208e-05, step_size 0.915024497998648, test_acc: 0.527\n",
            "Epoch 1959, BestLoss: 0.047374922458962306, Temperature 7.566011175463378e-05, step_size 0.9152075303526432, test_acc: 0.5265\n",
            "Epoch 1960, BestLoss: 0.047374922458962306, Temperature 7.187710616690208e-05, step_size 0.915116009599608, test_acc: 0.5265\n",
            "Epoch 1961, BestLoss: 0.047253722639766384, Temperature 7.566011175463378e-05, step_size 0.915116009599608, test_acc: 0.5279\n",
            "Epoch 1962, BestLoss: 0.047253722639766384, Temperature 7.187710616690208e-05, step_size 0.915024497998648, test_acc: 0.5279\n",
            "Epoch 1963, BestLoss: 0.04722108573321897, Temperature 7.566011175463378e-05, step_size 0.915024497998648, test_acc: 0.5278\n",
            "Epoch 1964, BestLoss: 0.04722108573321897, Temperature 7.187710616690208e-05, step_size 0.9149329955488482, test_acc: 0.5278\n",
            "Epoch 1965, BestLoss: 0.04722108573321897, Temperature 7.566011175463378e-05, step_size 0.9149329955488482, test_acc: 0.5278\n",
            "Epoch 1966, BestLoss: 0.0471138211130052, Temperature 7.96422228996145e-05, step_size 0.9148415022492934, test_acc: 0.5286\n",
            "Epoch 1967, BestLoss: 0.04718993683127629, Temperature 7.566011175463378e-05, step_size 0.9147500180990684, test_acc: 0.5268\n",
            "Epoch 1968, BestLoss: 0.04719743846322238, Temperature 7.187710616690208e-05, step_size 0.9146585430972585, test_acc: 0.5282\n",
            "Epoch 1969, BestLoss: 0.04721943311065793, Temperature 6.828325085855697e-05, step_size 0.9145670772429487, test_acc: 0.5283\n",
            "Epoch 1970, BestLoss: 0.04722423147240833, Temperature 6.486908831562912e-05, step_size 0.9144756205352245, test_acc: 0.5282\n",
            "Epoch 1971, BestLoss: 0.04722423147240833, Temperature 6.162563389984766e-05, step_size 0.914384172973171, test_acc: 0.5282\n",
            "Epoch 1972, BestLoss: 0.04714413452333428, Temperature 6.486908831562912e-05, step_size 0.9147500180990684, test_acc: 0.5298\n",
            "Epoch 1973, BestLoss: 0.04714413452333428, Temperature 6.162563389984766e-05, step_size 0.9146585430972585, test_acc: 0.5298\n",
            "Epoch 1974, BestLoss: 0.04710436295478319, Temperature 6.486908831562912e-05, step_size 0.9146585430972585, test_acc: 0.5315\n",
            "Epoch 1975, BestLoss: 0.04717236621178687, Temperature 6.162563389984766e-05, step_size 0.9145670772429487, test_acc: 0.528\n",
            "Epoch 1976, BestLoss: 0.04717236621178687, Temperature 5.8544352204855274e-05, step_size 0.9144756205352245, test_acc: 0.528\n",
            "Epoch 1977, BestLoss: 0.04717236621178687, Temperature 6.162563389984766e-05, step_size 0.9145670772429487, test_acc: 0.528\n",
            "Epoch 1978, BestLoss: 0.04717236621178687, Temperature 6.486908831562912e-05, step_size 0.9144756205352245, test_acc: 0.528\n",
            "Epoch 1979, BestLoss: 0.04717236621178687, Temperature 6.828325085855697e-05, step_size 0.914384172973171, test_acc: 0.528\n",
            "Epoch 1980, BestLoss: 0.0471821729233013, Temperature 7.187710616690208e-05, step_size 0.9142927345558737, test_acc: 0.5286\n",
            "Epoch 1981, BestLoss: 0.04711708476038577, Temperature 6.828325085855697e-05, step_size 0.914201305282418, test_acc: 0.5282\n",
            "Epoch 1982, BestLoss: 0.04711708476038577, Temperature 6.486908831562912e-05, step_size 0.9141098851518898, test_acc: 0.5282\n",
            "Epoch 1983, BestLoss: 0.04711708476038577, Temperature 6.828325085855697e-05, step_size 0.914201305282418, test_acc: 0.5282\n",
            "Epoch 1984, BestLoss: 0.04728036443948268, Temperature 7.187710616690208e-05, step_size 0.9141098851518898, test_acc: 0.5278\n",
            "Epoch 1985, BestLoss: 0.04728036443948268, Temperature 6.828325085855697e-05, step_size 0.9140184741633747, test_acc: 0.5278\n",
            "Epoch 1986, BestLoss: 0.04728036443948268, Temperature 7.187710616690208e-05, step_size 0.9140184741633747, test_acc: 0.5278\n",
            "Epoch 1987, BestLoss: 0.04728036443948268, Temperature 7.566011175463378e-05, step_size 0.9139270723159584, test_acc: 0.5278\n",
            "Epoch 1988, BestLoss: 0.04728040285595005, Temperature 7.96422228996145e-05, step_size 0.9138356796087268, test_acc: 0.5276\n",
            "Epoch 1989, BestLoss: 0.04728040285595005, Temperature 8.383391884169949e-05, step_size 0.9137442960407659, test_acc: 0.5276\n",
            "Epoch 1990, BestLoss: 0.04728040285595005, Temperature 8.824623035968368e-05, step_size 0.9136529216111619, test_acc: 0.5276\n",
            "Epoch 1991, BestLoss: 0.04728040285595005, Temperature 9.289076879966704e-05, step_size 0.9135615563190007, test_acc: 0.5276\n",
            "Epoch 1992, BestLoss: 0.04732368858468367, Temperature 9.777975663122846e-05, step_size 0.9134702001633688, test_acc: 0.528\n",
            "Epoch 1993, BestLoss: 0.04732368858468367, Temperature 9.289076879966704e-05, step_size 0.9133788531433524, test_acc: 0.528\n",
            "Epoch 1994, BestLoss: 0.047437371464010065, Temperature 9.777975663122846e-05, step_size 0.9133788531433524, test_acc: 0.5245\n",
            "Epoch 1995, BestLoss: 0.047437371464010065, Temperature 9.289076879966704e-05, step_size 0.9132875152580381, test_acc: 0.5245\n",
            "Epoch 1996, BestLoss: 0.047437371464010065, Temperature 9.777975663122846e-05, step_size 0.9132875152580381, test_acc: 0.5245\n",
            "Epoch 1997, BestLoss: 0.047437371464010065, Temperature 0.00010292605961181944, step_size 0.9131961865065122, test_acc: 0.5245\n",
            "Epoch 1998, BestLoss: 0.04735210661210194, Temperature 0.00010834322064402047, step_size 0.9131048668878616, test_acc: 0.5257\n",
            "Epoch 1999, BestLoss: 0.04735210661210194, Temperature 0.00010292605961181944, step_size 0.9130135564011729, test_acc: 0.5257\n",
            "Epoch 2000, BestLoss: 0.04735210661210194, Temperature 0.00010834322064402047, step_size 0.9130135564011729, test_acc: 0.5257\n",
            "Epoch 2001, BestLoss: 0.04729912874218233, Temperature 0.0001140454954147584, step_size 0.9129222550455328, test_acc: 0.5278\n",
            "Epoch 2002, BestLoss: 0.04729912874218233, Temperature 0.00010834322064402047, step_size 0.9128309628200283, test_acc: 0.5278\n",
            "Epoch 2003, BestLoss: 0.04729912874218233, Temperature 0.0001140454954147584, step_size 0.9128309628200283, test_acc: 0.5278\n",
            "Epoch 2004, BestLoss: 0.04725758638057651, Temperature 0.000120047889910272, step_size 0.9127396797237463, test_acc: 0.5278\n",
            "Epoch 2005, BestLoss: 0.04717583372372901, Temperature 0.0001140454954147584, step_size 0.9126484057557739, test_acc: 0.5294\n",
            "Epoch 2006, BestLoss: 0.04717583372372901, Temperature 0.00010834322064402047, step_size 0.9125571409151984, test_acc: 0.5294\n",
            "Epoch 2007, BestLoss: 0.047127684692450024, Temperature 0.0001140454954147584, step_size 0.9126484057557739, test_acc: 0.5277\n",
            "Epoch 2008, BestLoss: 0.04730039661332001, Temperature 0.00010834322064402047, step_size 0.9125571409151984, test_acc: 0.526\n",
            "Epoch 2009, BestLoss: 0.04730039661332001, Temperature 0.00010292605961181944, step_size 0.9124658852011068, test_acc: 0.526\n",
            "Epoch 2010, BestLoss: 0.04728324242832868, Temperature 0.00010834322064402047, step_size 0.9125571409151984, test_acc: 0.526\n",
            "Epoch 2011, BestLoss: 0.04728324242832868, Temperature 0.00010292605961181944, step_size 0.9124658852011068, test_acc: 0.526\n",
            "Epoch 2012, BestLoss: 0.04728324242832868, Temperature 0.00010834322064402047, step_size 0.9124658852011068, test_acc: 0.526\n",
            "Epoch 2013, BestLoss: 0.04728324242832868, Temperature 0.0001140454954147584, step_size 0.9123746386125867, test_acc: 0.526\n",
            "Epoch 2014, BestLoss: 0.0473078981132754, Temperature 0.000120047889910272, step_size 0.9122834011487255, test_acc: 0.5263\n",
            "Epoch 2015, BestLoss: 0.04727192225033691, Temperature 0.0001140454954147584, step_size 0.9121921728086106, test_acc: 0.5265\n",
            "Epoch 2016, BestLoss: 0.04723300966415365, Temperature 0.00010834322064402047, step_size 0.9121009535913298, test_acc: 0.5264\n",
            "Epoch 2017, BestLoss: 0.04723300966415365, Temperature 0.00010292605961181944, step_size 0.9120097434959706, test_acc: 0.5264\n",
            "Epoch 2018, BestLoss: 0.04723300966415365, Temperature 0.00010834322064402047, step_size 0.9121921728086106, test_acc: 0.5264\n",
            "Epoch 2019, BestLoss: 0.047461660947148196, Temperature 0.0001140454954147584, step_size 0.9121009535913298, test_acc: 0.5242\n",
            "Epoch 2020, BestLoss: 0.04754067381180363, Temperature 0.00010834322064402047, step_size 0.9120097434959706, test_acc: 0.5233\n",
            "Epoch 2021, BestLoss: 0.047481193431992086, Temperature 0.00010292605961181944, step_size 0.9119185425216211, test_acc: 0.5246\n",
            "Epoch 2022, BestLoss: 0.04745977918924964, Temperature 9.777975663122846e-05, step_size 0.911827350667369, test_acc: 0.5241\n",
            "Epoch 2023, BestLoss: 0.04745977918924964, Temperature 9.289076879966704e-05, step_size 0.9117361679323023, test_acc: 0.5241\n",
            "Epoch 2024, BestLoss: 0.047521826726750004, Temperature 9.777975663122846e-05, step_size 0.9120097434959706, test_acc: 0.5228\n",
            "Epoch 2025, BestLoss: 0.047521826726750004, Temperature 9.289076879966704e-05, step_size 0.9119185425216211, test_acc: 0.5228\n",
            "Epoch 2026, BestLoss: 0.047521826726750004, Temperature 9.777975663122846e-05, step_size 0.9119185425216211, test_acc: 0.5228\n",
            "Epoch 2027, BestLoss: 0.047521826726750004, Temperature 0.00010292605961181944, step_size 0.911827350667369, test_acc: 0.5228\n",
            "Epoch 2028, BestLoss: 0.047521826726750004, Temperature 0.00010834322064402047, step_size 0.9117361679323023, test_acc: 0.5228\n",
            "Epoch 2029, BestLoss: 0.0477754208580232, Temperature 0.0001140454954147584, step_size 0.911644994315509, test_acc: 0.5225\n",
            "Epoch 2030, BestLoss: 0.0477754208580232, Temperature 0.00010834322064402047, step_size 0.9115538298160775, test_acc: 0.5225\n",
            "Epoch 2031, BestLoss: 0.04780950020778495, Temperature 0.0001140454954147584, step_size 0.9115538298160775, test_acc: 0.5213\n",
            "Epoch 2032, BestLoss: 0.04791657896730959, Temperature 0.00010834322064402047, step_size 0.9114626744330959, test_acc: 0.5199\n",
            "Epoch 2033, BestLoss: 0.04791657896730959, Temperature 0.00010292605961181944, step_size 0.9113715281656526, test_acc: 0.5199\n",
            "Epoch 2034, BestLoss: 0.04791657896730959, Temperature 0.00010834322064402047, step_size 0.9114626744330959, test_acc: 0.5199\n",
            "Epoch 2035, BestLoss: 0.04783630895638614, Temperature 0.0001140454954147584, step_size 0.9113715281656526, test_acc: 0.5202\n",
            "Epoch 2036, BestLoss: 0.04783630895638614, Temperature 0.00010834322064402047, step_size 0.9112803910128361, test_acc: 0.5202\n",
            "Epoch 2037, BestLoss: 0.04783630895638614, Temperature 0.0001140454954147584, step_size 0.9112803910128361, test_acc: 0.5202\n",
            "Epoch 2038, BestLoss: 0.04783630895638614, Temperature 0.000120047889910272, step_size 0.9111892629737348, test_acc: 0.5202\n",
            "Epoch 2039, BestLoss: 0.04779862557285965, Temperature 0.0001263661999055495, step_size 0.9110981440474375, test_acc: 0.5228\n",
            "Epoch 2040, BestLoss: 0.04779862557285965, Temperature 0.000120047889910272, step_size 0.9110070342330328, test_acc: 0.5228\n",
            "Epoch 2041, BestLoss: 0.04779862557285965, Temperature 0.0001263661999055495, step_size 0.9110070342330328, test_acc: 0.5228\n",
            "Epoch 2042, BestLoss: 0.04779862557285965, Temperature 0.00013301705253215737, step_size 0.9109159335296094, test_acc: 0.5228\n",
            "Epoch 2043, BestLoss: 0.04779862557285965, Temperature 0.00014001795003384986, step_size 0.9108248419362565, test_acc: 0.5228\n",
            "Epoch 2044, BestLoss: 0.048090780797921784, Temperature 0.00014738731582510513, step_size 0.9107337594520628, test_acc: 0.52\n",
            "Epoch 2045, BestLoss: 0.0480247984732073, Temperature 0.00014001795003384986, step_size 0.9106426860761176, test_acc: 0.5204\n",
            "Epoch 2046, BestLoss: 0.048069649113070094, Temperature 0.00013301705253215737, step_size 0.91055162180751, test_acc: 0.5201\n",
            "Epoch 2047, BestLoss: 0.048399552944856976, Temperature 0.0001263661999055495, step_size 0.9104605666453293, test_acc: 0.5192\n",
            "Epoch 2048, BestLoss: 0.048399552944856976, Temperature 0.000120047889910272, step_size 0.9103695205886647, test_acc: 0.5192\n",
            "Epoch 2049, BestLoss: 0.04836909240594689, Temperature 0.0001263661999055495, step_size 0.9106426860761176, test_acc: 0.5184\n",
            "Epoch 2050, BestLoss: 0.04836909240594689, Temperature 0.000120047889910272, step_size 0.91055162180751, test_acc: 0.5184\n",
            "Epoch 2051, BestLoss: 0.048237521144104706, Temperature 0.0001263661999055495, step_size 0.91055162180751, test_acc: 0.5177\n",
            "Epoch 2052, BestLoss: 0.04810084120771212, Temperature 0.000120047889910272, step_size 0.9104605666453293, test_acc: 0.519\n",
            "Epoch 2053, BestLoss: 0.04810084120771212, Temperature 0.0001140454954147584, step_size 0.9103695205886647, test_acc: 0.519\n",
            "Epoch 2054, BestLoss: 0.04810084120771212, Temperature 0.000120047889910272, step_size 0.9104605666453293, test_acc: 0.519\n",
            "Epoch 2055, BestLoss: 0.04808967919066948, Temperature 0.0001263661999055495, step_size 0.9103695205886647, test_acc: 0.5201\n",
            "Epoch 2056, BestLoss: 0.048153721318328825, Temperature 0.000120047889910272, step_size 0.9102784836366059, test_acc: 0.5202\n",
            "Epoch 2057, BestLoss: 0.048153721318328825, Temperature 0.0001140454954147584, step_size 0.9101874557882422, test_acc: 0.5202\n",
            "Epoch 2058, BestLoss: 0.04819826055684196, Temperature 0.000120047889910272, step_size 0.9102784836366059, test_acc: 0.5202\n",
            "Epoch 2059, BestLoss: 0.04815449391846447, Temperature 0.0001140454954147584, step_size 0.9101874557882422, test_acc: 0.5183\n",
            "Epoch 2060, BestLoss: 0.04822152225397885, Temperature 0.00010834322064402047, step_size 0.9100964370426634, test_acc: 0.5189\n",
            "Epoch 2061, BestLoss: 0.048342575353663715, Temperature 0.00010292605961181944, step_size 0.9100054273989592, test_acc: 0.5173\n",
            "Epoch 2062, BestLoss: 0.04815294999871946, Temperature 9.777975663122846e-05, step_size 0.9099144268562193, test_acc: 0.5194\n",
            "Epoch 2063, BestLoss: 0.0481797888634379, Temperature 9.289076879966704e-05, step_size 0.9098234354135336, test_acc: 0.5172\n",
            "Epoch 2064, BestLoss: 0.04821455358134789, Temperature 8.824623035968368e-05, step_size 0.9097324530699923, test_acc: 0.5187\n",
            "Epoch 2065, BestLoss: 0.04821455358134789, Temperature 8.383391884169949e-05, step_size 0.9096414798246854, test_acc: 0.5187\n",
            "Epoch 2066, BestLoss: 0.0481560575250101, Temperature 8.824623035968368e-05, step_size 0.9101874557882422, test_acc: 0.5197\n",
            "Epoch 2067, BestLoss: 0.0481560575250101, Temperature 8.383391884169949e-05, step_size 0.9100964370426634, test_acc: 0.5197\n",
            "Epoch 2068, BestLoss: 0.04817470129216056, Temperature 8.824623035968368e-05, step_size 0.9100964370426634, test_acc: 0.5192\n",
            "Epoch 2069, BestLoss: 0.04830865841373196, Temperature 8.383391884169949e-05, step_size 0.9100054273989592, test_acc: 0.5171\n",
            "Epoch 2070, BestLoss: 0.048296592659622384, Temperature 7.96422228996145e-05, step_size 0.9099144268562193, test_acc: 0.5161\n",
            "Epoch 2071, BestLoss: 0.048296592659622384, Temperature 7.566011175463378e-05, step_size 0.9098234354135336, test_acc: 0.5161\n",
            "Epoch 2072, BestLoss: 0.048322799316524306, Temperature 7.96422228996145e-05, step_size 0.9100054273989592, test_acc: 0.5164\n",
            "Epoch 2073, BestLoss: 0.04807949173172964, Temperature 7.566011175463378e-05, step_size 0.9099144268562193, test_acc: 0.5181\n",
            "Epoch 2074, BestLoss: 0.04807949173172964, Temperature 7.187710616690208e-05, step_size 0.9098234354135336, test_acc: 0.5181\n",
            "Epoch 2075, BestLoss: 0.04807949173172964, Temperature 7.566011175463378e-05, step_size 0.9099144268562193, test_acc: 0.5181\n",
            "Epoch 2076, BestLoss: 0.04807949173172964, Temperature 7.96422228996145e-05, step_size 0.9098234354135336, test_acc: 0.5181\n",
            "Epoch 2077, BestLoss: 0.04807949173172964, Temperature 8.383391884169949e-05, step_size 0.9097324530699923, test_acc: 0.5181\n",
            "Epoch 2078, BestLoss: 0.04807949173172964, Temperature 8.824623035968368e-05, step_size 0.9096414798246854, test_acc: 0.5181\n",
            "Epoch 2079, BestLoss: 0.04807949173172964, Temperature 9.289076879966704e-05, step_size 0.9095505156767029, test_acc: 0.5181\n",
            "Epoch 2080, BestLoss: 0.04807949173172964, Temperature 9.777975663122846e-05, step_size 0.9094595606251352, test_acc: 0.5181\n",
            "Epoch 2081, BestLoss: 0.04807949173172964, Temperature 0.00010292605961181944, step_size 0.9093686146690727, test_acc: 0.5181\n",
            "Epoch 2082, BestLoss: 0.04807949173172964, Temperature 0.00010834322064402047, step_size 0.9092776778076058, test_acc: 0.5181\n",
            "Epoch 2083, BestLoss: 0.04807949173172964, Temperature 0.0001140454954147584, step_size 0.9091867500398251, test_acc: 0.5181\n",
            "Epoch 2084, BestLoss: 0.04807949173172964, Temperature 0.000120047889910272, step_size 0.9090958313648211, test_acc: 0.5181\n",
            "Epoch 2085, BestLoss: 0.048152114590292755, Temperature 0.0001263661999055495, step_size 0.9090049217816846, test_acc: 0.5181\n",
            "Epoch 2086, BestLoss: 0.04815840516568175, Temperature 0.000120047889910272, step_size 0.9089140212895064, test_acc: 0.5184\n",
            "Epoch 2087, BestLoss: 0.04815840516568175, Temperature 0.0001140454954147584, step_size 0.9088231298873775, test_acc: 0.5184\n",
            "Epoch 2088, BestLoss: 0.04815840516568175, Temperature 0.000120047889910272, step_size 0.9089140212895064, test_acc: 0.5184\n",
            "Epoch 2089, BestLoss: 0.048060019669472126, Temperature 0.0001263661999055495, step_size 0.9088231298873775, test_acc: 0.5199\n",
            "Epoch 2090, BestLoss: 0.048060019669472126, Temperature 0.000120047889910272, step_size 0.9087322475743888, test_acc: 0.5199\n",
            "Epoch 2091, BestLoss: 0.04833413224164309, Temperature 0.0001263661999055495, step_size 0.9087322475743888, test_acc: 0.5185\n",
            "Epoch 2092, BestLoss: 0.04833413224164309, Temperature 0.000120047889910272, step_size 0.9086413743496313, test_acc: 0.5185\n",
            "Epoch 2093, BestLoss: 0.0482599323086328, Temperature 0.0001263661999055495, step_size 0.9086413743496313, test_acc: 0.5182\n",
            "Epoch 2094, BestLoss: 0.0482599323086328, Temperature 0.000120047889910272, step_size 0.9085505102121963, test_acc: 0.5182\n",
            "Epoch 2095, BestLoss: 0.048165956822563215, Temperature 0.0001263661999055495, step_size 0.9085505102121963, test_acc: 0.5211\n",
            "Epoch 2096, BestLoss: 0.048139618507847065, Temperature 0.000120047889910272, step_size 0.9084596551611751, test_acc: 0.5187\n",
            "Epoch 2097, BestLoss: 0.048139618507847065, Temperature 0.0001140454954147584, step_size 0.908368809195659, test_acc: 0.5187\n",
            "Epoch 2098, BestLoss: 0.04825473908305937, Temperature 0.000120047889910272, step_size 0.9084596551611751, test_acc: 0.5187\n",
            "Epoch 2099, BestLoss: 0.04825473908305937, Temperature 0.0001140454954147584, step_size 0.908368809195659, test_acc: 0.5187\n",
            "Epoch 2100, BestLoss: 0.04825473908305937, Temperature 0.000120047889910272, step_size 0.908368809195659, test_acc: 0.5187\n",
            "Epoch 2101, BestLoss: 0.04825473908305937, Temperature 0.0001263661999055495, step_size 0.9082779723147394, test_acc: 0.5187\n",
            "Epoch 2102, BestLoss: 0.04825473908305937, Temperature 0.00013301705253215737, step_size 0.9081871445175079, test_acc: 0.5187\n",
            "Epoch 2103, BestLoss: 0.04838137639618622, Temperature 0.00014001795003384986, step_size 0.9080963258030562, test_acc: 0.5176\n",
            "Epoch 2104, BestLoss: 0.04838137639618622, Temperature 0.00013301705253215737, step_size 0.9080055161704759, test_acc: 0.5176\n",
            "Epoch 2105, BestLoss: 0.04825443315589172, Temperature 0.00014001795003384986, step_size 0.9080055161704759, test_acc: 0.5192\n",
            "Epoch 2106, BestLoss: 0.048148190021384686, Temperature 0.00013301705253215737, step_size 0.9079147156188588, test_acc: 0.5199\n",
            "Epoch 2107, BestLoss: 0.04812324721660716, Temperature 0.0001263661999055495, step_size 0.907823924147297, test_acc: 0.5209\n",
            "Epoch 2108, BestLoss: 0.048077708297636725, Temperature 0.000120047889910272, step_size 0.9077331417548823, test_acc: 0.5222\n",
            "Epoch 2109, BestLoss: 0.04830326123511541, Temperature 0.0001140454954147584, step_size 0.9076423684407068, test_acc: 0.5196\n",
            "Epoch 2110, BestLoss: 0.0482995787476967, Temperature 0.00010834322064402047, step_size 0.9075516042038627, test_acc: 0.5191\n",
            "Epoch 2111, BestLoss: 0.04842182606313094, Temperature 0.0001140454954147584, step_size 0.9079147156188588, test_acc: 0.5181\n",
            "Epoch 2112, BestLoss: 0.04842182606313094, Temperature 0.00010834322064402047, step_size 0.907823924147297, test_acc: 0.5181\n",
            "Epoch 2113, BestLoss: 0.04839277526528841, Temperature 0.0001140454954147584, step_size 0.907823924147297, test_acc: 0.5185\n",
            "Epoch 2114, BestLoss: 0.04837036153338778, Temperature 0.00010834322064402047, step_size 0.9077331417548823, test_acc: 0.5189\n",
            "Epoch 2115, BestLoss: 0.04837036153338778, Temperature 0.00010292605961181944, step_size 0.9076423684407068, test_acc: 0.5189\n",
            "Epoch 2116, BestLoss: 0.04826317747800039, Temperature 0.00010834322064402047, step_size 0.9077331417548823, test_acc: 0.518\n",
            "Epoch 2117, BestLoss: 0.048292031191838884, Temperature 0.00010292605961181944, step_size 0.9076423684407068, test_acc: 0.5196\n",
            "Epoch 2118, BestLoss: 0.048294634282342305, Temperature 9.777975663122846e-05, step_size 0.9075516042038627, test_acc: 0.5203\n",
            "Epoch 2119, BestLoss: 0.04840474155521329, Temperature 0.00010292605961181944, step_size 0.9076423684407068, test_acc: 0.5188\n",
            "Epoch 2120, BestLoss: 0.04840474155521329, Temperature 9.777975663122846e-05, step_size 0.9075516042038627, test_acc: 0.5188\n",
            "Epoch 2121, BestLoss: 0.04840474155521329, Temperature 0.00010292605961181944, step_size 0.9075516042038627, test_acc: 0.5188\n",
            "Epoch 2122, BestLoss: 0.04840474155521329, Temperature 0.00010834322064402047, step_size 0.9074608490434424, test_acc: 0.5188\n",
            "Epoch 2123, BestLoss: 0.048671482811785065, Temperature 0.0001140454954147584, step_size 0.907370102958538, test_acc: 0.5147\n",
            "Epoch 2124, BestLoss: 0.048635924397459715, Temperature 0.00010834322064402047, step_size 0.9072793659482422, test_acc: 0.5158\n",
            "Epoch 2125, BestLoss: 0.048635924397459715, Temperature 0.00010292605961181944, step_size 0.9071886380116474, test_acc: 0.5158\n",
            "Epoch 2126, BestLoss: 0.04859104670739797, Temperature 0.00010834322064402047, step_size 0.9072793659482422, test_acc: 0.5179\n",
            "Epoch 2127, BestLoss: 0.04858626295953668, Temperature 0.00010292605961181944, step_size 0.9071886380116474, test_acc: 0.5155\n",
            "Epoch 2128, BestLoss: 0.04858626295953668, Temperature 0.00010834322064402047, step_size 0.9071886380116474, test_acc: 0.5155\n",
            "Epoch 2129, BestLoss: 0.048559218069819776, Temperature 0.0001140454954147584, step_size 0.9070979191478462, test_acc: 0.5152\n",
            "Epoch 2130, BestLoss: 0.048559218069819776, Temperature 0.00010834322064402047, step_size 0.9070072093559315, test_acc: 0.5152\n",
            "Epoch 2131, BestLoss: 0.04848981930459345, Temperature 0.0001140454954147584, step_size 0.9070072093559315, test_acc: 0.517\n",
            "Epoch 2132, BestLoss: 0.04848981930459345, Temperature 0.00010834322064402047, step_size 0.906916508634996, test_acc: 0.517\n",
            "Epoch 2133, BestLoss: 0.04840084565679775, Temperature 0.0001140454954147584, step_size 0.906916508634996, test_acc: 0.5187\n",
            "Epoch 2134, BestLoss: 0.04830667012682097, Temperature 0.00010834322064402047, step_size 0.9068258169841324, test_acc: 0.5197\n",
            "Epoch 2135, BestLoss: 0.04830667012682097, Temperature 0.00010292605961181944, step_size 0.906735134402434, test_acc: 0.5197\n",
            "Epoch 2136, BestLoss: 0.04841633406544897, Temperature 0.00010834322064402047, step_size 0.9068258169841324, test_acc: 0.5193\n",
            "Epoch 2137, BestLoss: 0.04841633406544897, Temperature 0.00010292605961181944, step_size 0.906735134402434, test_acc: 0.5193\n",
            "Epoch 2138, BestLoss: 0.04841633406544897, Temperature 0.00010834322064402047, step_size 0.906735134402434, test_acc: 0.5193\n",
            "Epoch 2139, BestLoss: 0.048279648308371455, Temperature 0.0001140454954147584, step_size 0.9066444608889938, test_acc: 0.5202\n",
            "Epoch 2140, BestLoss: 0.048342972263991806, Temperature 0.00010834322064402047, step_size 0.9065537964429049, test_acc: 0.5185\n",
            "Epoch 2141, BestLoss: 0.048342972263991806, Temperature 0.00010292605961181944, step_size 0.9064631410632606, test_acc: 0.5185\n",
            "Epoch 2142, BestLoss: 0.048342972263991806, Temperature 0.00010834322064402047, step_size 0.9065537964429049, test_acc: 0.5185\n",
            "Epoch 2143, BestLoss: 0.048342972263991806, Temperature 0.0001140454954147584, step_size 0.9064631410632606, test_acc: 0.5185\n",
            "Epoch 2144, BestLoss: 0.048342972263991806, Temperature 0.000120047889910272, step_size 0.9063724947491544, test_acc: 0.5185\n",
            "Epoch 2145, BestLoss: 0.048342972263991806, Temperature 0.0001263661999055495, step_size 0.9062818574996795, test_acc: 0.5185\n",
            "Epoch 2146, BestLoss: 0.048342972263991806, Temperature 0.00013301705253215737, step_size 0.9061912293139295, test_acc: 0.5185\n",
            "Epoch 2147, BestLoss: 0.048342972263991806, Temperature 0.00014001795003384986, step_size 0.9061006101909981, test_acc: 0.5185\n",
            "Epoch 2148, BestLoss: 0.048342972263991806, Temperature 0.00014738731582510513, step_size 0.906010000129979, test_acc: 0.5185\n",
            "Epoch 2149, BestLoss: 0.048342972263991806, Temperature 0.00015514454297379488, step_size 0.905919399129966, test_acc: 0.5185\n",
            "Epoch 2150, BestLoss: 0.048342972263991806, Temperature 0.00016331004523557357, step_size 0.905828807190053, test_acc: 0.5185\n",
            "Epoch 2151, BestLoss: 0.04826808370860429, Temperature 0.00017190531077428798, step_size 0.905738224309334, test_acc: 0.5183\n",
            "Epoch 2152, BestLoss: 0.048485630783565964, Temperature 0.00016331004523557357, step_size 0.9056476504869031, test_acc: 0.517\n",
            "Epoch 2153, BestLoss: 0.04846256536373271, Temperature 0.00015514454297379488, step_size 0.9055570857218544, test_acc: 0.5179\n",
            "Epoch 2154, BestLoss: 0.04838649242168011, Temperature 0.00014738731582510513, step_size 0.9054665300132823, test_acc: 0.518\n",
            "Epoch 2155, BestLoss: 0.04838649242168011, Temperature 0.00014001795003384986, step_size 0.9053759833602809, test_acc: 0.518\n",
            "Epoch 2156, BestLoss: 0.04840747816618954, Temperature 0.00014738731582510513, step_size 0.9056476504869031, test_acc: 0.519\n",
            "Epoch 2157, BestLoss: 0.04840747816618954, Temperature 0.00014001795003384986, step_size 0.9055570857218544, test_acc: 0.519\n",
            "Epoch 2158, BestLoss: 0.04840747816618954, Temperature 0.00014738731582510513, step_size 0.9055570857218544, test_acc: 0.519\n",
            "Epoch 2159, BestLoss: 0.048373754203760194, Temperature 0.00015514454297379488, step_size 0.9054665300132823, test_acc: 0.5196\n",
            "Epoch 2160, BestLoss: 0.048313699032206364, Temperature 0.00014738731582510513, step_size 0.9053759833602809, test_acc: 0.5198\n",
            "Epoch 2161, BestLoss: 0.048313699032206364, Temperature 0.00014001795003384986, step_size 0.9052854457619449, test_acc: 0.5198\n",
            "Epoch 2162, BestLoss: 0.048489765754405764, Temperature 0.00014738731582510513, step_size 0.9053759833602809, test_acc: 0.5178\n",
            "Epoch 2163, BestLoss: 0.04826098246484671, Temperature 0.00014001795003384986, step_size 0.9052854457619449, test_acc: 0.5214\n",
            "Epoch 2164, BestLoss: 0.0481680992546045, Temperature 0.00013301705253215737, step_size 0.9051949172173688, test_acc: 0.5222\n",
            "Epoch 2165, BestLoss: 0.04820445388237123, Temperature 0.0001263661999055495, step_size 0.9051043977256471, test_acc: 0.5201\n",
            "Epoch 2166, BestLoss: 0.04820445388237123, Temperature 0.000120047889910272, step_size 0.9050138872858745, test_acc: 0.5201\n",
            "Epoch 2167, BestLoss: 0.04826651546281958, Temperature 0.0001263661999055495, step_size 0.9052854457619449, test_acc: 0.5219\n",
            "Epoch 2168, BestLoss: 0.04824968008632595, Temperature 0.000120047889910272, step_size 0.9051949172173688, test_acc: 0.5227\n",
            "Epoch 2169, BestLoss: 0.04824968008632595, Temperature 0.0001140454954147584, step_size 0.9051043977256471, test_acc: 0.5227\n",
            "Epoch 2170, BestLoss: 0.04806678494864387, Temperature 0.000120047889910272, step_size 0.9051949172173688, test_acc: 0.5235\n",
            "Epoch 2171, BestLoss: 0.04806678494864387, Temperature 0.0001140454954147584, step_size 0.9051043977256471, test_acc: 0.5235\n",
            "Epoch 2172, BestLoss: 0.04803344621212431, Temperature 0.000120047889910272, step_size 0.9051043977256471, test_acc: 0.524\n",
            "Epoch 2173, BestLoss: 0.04797719124654578, Temperature 0.0001140454954147584, step_size 0.9050138872858745, test_acc: 0.5243\n",
            "Epoch 2174, BestLoss: 0.04811968542799576, Temperature 0.00010834322064402047, step_size 0.9049233858971459, test_acc: 0.5224\n",
            "Epoch 2175, BestLoss: 0.04811968542799576, Temperature 0.00010292605961181944, step_size 0.9048328935585562, test_acc: 0.5224\n",
            "Epoch 2176, BestLoss: 0.04811968542799576, Temperature 0.00010834322064402047, step_size 0.9050138872858745, test_acc: 0.5224\n",
            "Epoch 2177, BestLoss: 0.047964807608475615, Temperature 0.0001140454954147584, step_size 0.9049233858971459, test_acc: 0.5238\n",
            "Epoch 2178, BestLoss: 0.047836816538585805, Temperature 0.00010834322064402047, step_size 0.9048328935585562, test_acc: 0.5251\n",
            "Epoch 2179, BestLoss: 0.04783017648541861, Temperature 0.00010292605961181944, step_size 0.9047424102692004, test_acc: 0.5245\n",
            "Epoch 2180, BestLoss: 0.047766840733863815, Temperature 9.777975663122846e-05, step_size 0.9046519360281735, test_acc: 0.5258\n",
            "Epoch 2181, BestLoss: 0.04772315902600295, Temperature 9.289076879966704e-05, step_size 0.9045614708345707, test_acc: 0.5251\n",
            "Epoch 2182, BestLoss: 0.04772315902600295, Temperature 8.824623035968368e-05, step_size 0.9044710146874873, test_acc: 0.5251\n",
            "Epoch 2183, BestLoss: 0.04781246659777625, Temperature 9.289076879966704e-05, step_size 0.9048328935585562, test_acc: 0.5236\n",
            "Epoch 2184, BestLoss: 0.047877907706404335, Temperature 8.824623035968368e-05, step_size 0.9047424102692004, test_acc: 0.5228\n",
            "Epoch 2185, BestLoss: 0.04786009621554286, Temperature 8.383391884169949e-05, step_size 0.9046519360281735, test_acc: 0.5213\n",
            "Epoch 2186, BestLoss: 0.0477881220573041, Temperature 7.96422228996145e-05, step_size 0.9045614708345707, test_acc: 0.523\n",
            "Epoch 2187, BestLoss: 0.04779392011852441, Temperature 7.566011175463378e-05, step_size 0.9044710146874873, test_acc: 0.5246\n",
            "Epoch 2188, BestLoss: 0.04784142904475341, Temperature 7.187710616690208e-05, step_size 0.9043805675860185, test_acc: 0.5249\n",
            "Epoch 2189, BestLoss: 0.04779646223512416, Temperature 6.828325085855697e-05, step_size 0.9042901295292599, test_acc: 0.5251\n",
            "Epoch 2190, BestLoss: 0.04779646223512416, Temperature 6.486908831562912e-05, step_size 0.904199700516307, test_acc: 0.5251\n",
            "Epoch 2191, BestLoss: 0.047925403461106214, Temperature 6.828325085855697e-05, step_size 0.9047424102692004, test_acc: 0.525\n",
            "Epoch 2192, BestLoss: 0.04787312641281357, Temperature 6.486908831562912e-05, step_size 0.9046519360281735, test_acc: 0.528\n",
            "Epoch 2193, BestLoss: 0.047993144453927904, Temperature 6.162563389984766e-05, step_size 0.9045614708345707, test_acc: 0.5257\n",
            "Epoch 2194, BestLoss: 0.04796292539290201, Temperature 5.8544352204855274e-05, step_size 0.9044710146874873, test_acc: 0.5266\n",
            "Epoch 2195, BestLoss: 0.04796292539290201, Temperature 5.561713459461251e-05, step_size 0.9043805675860185, test_acc: 0.5266\n",
            "Epoch 2196, BestLoss: 0.047922681663523356, Temperature 5.8544352204855274e-05, step_size 0.9046519360281735, test_acc: 0.5255\n",
            "Epoch 2197, BestLoss: 0.047856599517815, Temperature 5.561713459461251e-05, step_size 0.9045614708345707, test_acc: 0.5246\n",
            "Epoch 2198, BestLoss: 0.047856599517815, Temperature 5.283627786488188e-05, step_size 0.9044710146874873, test_acc: 0.5246\n",
            "Epoch 2199, BestLoss: 0.047856599517815, Temperature 5.561713459461251e-05, step_size 0.9045614708345707, test_acc: 0.5246\n",
            "Epoch 2200, BestLoss: 0.047856599517815, Temperature 5.8544352204855274e-05, step_size 0.9044710146874873, test_acc: 0.5246\n",
            "Epoch 2201, BestLoss: 0.047831393420441445, Temperature 6.162563389984766e-05, step_size 0.9043805675860185, test_acc: 0.5275\n",
            "Epoch 2202, BestLoss: 0.047819300324151895, Temperature 5.8544352204855274e-05, step_size 0.9042901295292599, test_acc: 0.5262\n",
            "Epoch 2203, BestLoss: 0.04774274322049959, Temperature 5.561713459461251e-05, step_size 0.904199700516307, test_acc: 0.5276\n",
            "Epoch 2204, BestLoss: 0.04770655062063571, Temperature 5.283627786488188e-05, step_size 0.9041092805462554, test_acc: 0.5275\n",
            "Epoch 2205, BestLoss: 0.04768300155358253, Temperature 5.019446397163778e-05, step_size 0.9040188696182008, test_acc: 0.5291\n",
            "Epoch 2206, BestLoss: 0.04759600682872872, Temperature 4.768474077305589e-05, step_size 0.9039284677312389, test_acc: 0.5309\n",
            "Epoch 2207, BestLoss: 0.04748247171101476, Temperature 4.53005037344031e-05, step_size 0.9038380748844658, test_acc: 0.5289\n",
            "Epoch 2208, BestLoss: 0.047494849496330524, Temperature 4.303547854768294e-05, step_size 0.9037476910769774, test_acc: 0.5279\n",
            "Epoch 2209, BestLoss: 0.047494849496330524, Temperature 4.0883704620298796e-05, step_size 0.9036573163078697, test_acc: 0.5279\n",
            "Epoch 2210, BestLoss: 0.047429927220507206, Temperature 4.303547854768294e-05, step_size 0.9042901295292599, test_acc: 0.5276\n",
            "Epoch 2211, BestLoss: 0.04739517572342007, Temperature 4.0883704620298796e-05, step_size 0.904199700516307, test_acc: 0.5301\n",
            "Epoch 2212, BestLoss: 0.04739517572342007, Temperature 3.883951938928385e-05, step_size 0.9041092805462554, test_acc: 0.5301\n",
            "Epoch 2213, BestLoss: 0.04739517572342007, Temperature 4.0883704620298796e-05, step_size 0.904199700516307, test_acc: 0.5301\n",
            "Epoch 2214, BestLoss: 0.04739517572342007, Temperature 4.303547854768294e-05, step_size 0.9041092805462554, test_acc: 0.5301\n",
            "Epoch 2215, BestLoss: 0.04739517572342007, Temperature 4.53005037344031e-05, step_size 0.9040188696182008, test_acc: 0.5301\n",
            "Epoch 2216, BestLoss: 0.04739517572342007, Temperature 4.768474077305589e-05, step_size 0.9039284677312389, test_acc: 0.5301\n",
            "Epoch 2217, BestLoss: 0.04734553607881399, Temperature 5.019446397163778e-05, step_size 0.9038380748844658, test_acc: 0.5298\n",
            "Epoch 2218, BestLoss: 0.04730600863055399, Temperature 4.768474077305589e-05, step_size 0.9037476910769774, test_acc: 0.5295\n",
            "Epoch 2219, BestLoss: 0.047346564610109644, Temperature 4.53005037344031e-05, step_size 0.9036573163078697, test_acc: 0.5304\n",
            "Epoch 2220, BestLoss: 0.047346564610109644, Temperature 4.303547854768294e-05, step_size 0.9035669505762389, test_acc: 0.5304\n",
            "Epoch 2221, BestLoss: 0.047346564610109644, Temperature 4.53005037344031e-05, step_size 0.9037476910769774, test_acc: 0.5304\n",
            "Epoch 2222, BestLoss: 0.04721661727761526, Temperature 4.768474077305589e-05, step_size 0.9036573163078697, test_acc: 0.5316\n",
            "Epoch 2223, BestLoss: 0.047239724736104785, Temperature 4.53005037344031e-05, step_size 0.9035669505762389, test_acc: 0.5329\n",
            "Epoch 2224, BestLoss: 0.047239724736104785, Temperature 4.303547854768294e-05, step_size 0.9034765938811813, test_acc: 0.5329\n",
            "Epoch 2225, BestLoss: 0.04721324284717014, Temperature 4.53005037344031e-05, step_size 0.9035669505762389, test_acc: 0.5322\n",
            "Epoch 2226, BestLoss: 0.04723236533442159, Temperature 4.303547854768294e-05, step_size 0.9034765938811813, test_acc: 0.5325\n",
            "Epoch 2227, BestLoss: 0.04705880366260097, Temperature 4.0883704620298796e-05, step_size 0.9033862462217932, test_acc: 0.5316\n",
            "Epoch 2228, BestLoss: 0.04705880366260097, Temperature 3.883951938928385e-05, step_size 0.903295907597171, test_acc: 0.5316\n",
            "Epoch 2229, BestLoss: 0.04705880366260097, Temperature 4.0883704620298796e-05, step_size 0.9034765938811813, test_acc: 0.5316\n",
            "Epoch 2230, BestLoss: 0.04689201834728528, Temperature 4.303547854768294e-05, step_size 0.9033862462217932, test_acc: 0.5341\n",
            "Epoch 2231, BestLoss: 0.04689201834728528, Temperature 4.0883704620298796e-05, step_size 0.903295907597171, test_acc: 0.5341\n",
            "Epoch 2232, BestLoss: 0.0468836738474942, Temperature 4.303547854768294e-05, step_size 0.903295907597171, test_acc: 0.5337\n",
            "Epoch 2233, BestLoss: 0.0468836738474942, Temperature 4.0883704620298796e-05, step_size 0.9032055780064113, test_acc: 0.5337\n",
            "Epoch 2234, BestLoss: 0.04693750776062274, Temperature 4.303547854768294e-05, step_size 0.9032055780064113, test_acc: 0.534\n",
            "Epoch 2235, BestLoss: 0.04693750776062274, Temperature 4.0883704620298796e-05, step_size 0.9031152574486107, test_acc: 0.534\n",
            "Epoch 2236, BestLoss: 0.04693750776062274, Temperature 4.303547854768294e-05, step_size 0.9031152574486107, test_acc: 0.534\n",
            "Epoch 2237, BestLoss: 0.04693750776062274, Temperature 4.53005037344031e-05, step_size 0.9030249459228658, test_acc: 0.534\n",
            "Epoch 2238, BestLoss: 0.04693750776062274, Temperature 4.768474077305589e-05, step_size 0.9029346434282735, test_acc: 0.534\n",
            "Epoch 2239, BestLoss: 0.046774285069961286, Temperature 5.019446397163778e-05, step_size 0.9028443499639306, test_acc: 0.5356\n",
            "Epoch 2240, BestLoss: 0.04677000358155806, Temperature 4.768474077305589e-05, step_size 0.9027540655289342, test_acc: 0.5355\n",
            "Epoch 2241, BestLoss: 0.04675639932432887, Temperature 4.53005037344031e-05, step_size 0.9026637901223813, test_acc: 0.5344\n",
            "Epoch 2242, BestLoss: 0.04675639932432887, Temperature 4.303547854768294e-05, step_size 0.9025735237433691, test_acc: 0.5344\n",
            "Epoch 2243, BestLoss: 0.04672398658365751, Temperature 4.53005037344031e-05, step_size 0.9027540655289342, test_acc: 0.5347\n",
            "Epoch 2244, BestLoss: 0.046673121865181834, Temperature 4.303547854768294e-05, step_size 0.9026637901223813, test_acc: 0.5356\n",
            "Epoch 2245, BestLoss: 0.04669265021044937, Temperature 4.0883704620298796e-05, step_size 0.9025735237433691, test_acc: 0.5356\n",
            "Epoch 2246, BestLoss: 0.04669265021044937, Temperature 3.883951938928385e-05, step_size 0.9024832663909947, test_acc: 0.5356\n",
            "Epoch 2247, BestLoss: 0.046606284571605365, Temperature 4.0883704620298796e-05, step_size 0.9026637901223813, test_acc: 0.5353\n",
            "Epoch 2248, BestLoss: 0.04674496764846558, Temperature 3.883951938928385e-05, step_size 0.9025735237433691, test_acc: 0.5358\n",
            "Epoch 2249, BestLoss: 0.04666577552175408, Temperature 3.689754341981966e-05, step_size 0.9024832663909947, test_acc: 0.5362\n",
            "Epoch 2250, BestLoss: 0.046707571028606926, Temperature 3.505266624882867e-05, step_size 0.9023930180643557, test_acc: 0.5388\n",
            "Epoch 2251, BestLoss: 0.04666795548473215, Temperature 3.3300032936387236e-05, step_size 0.9023027787625493, test_acc: 0.5362\n",
            "Epoch 2252, BestLoss: 0.046669281700554434, Temperature 3.163503128956787e-05, step_size 0.902212548484673, test_acc: 0.5372\n",
            "Epoch 2253, BestLoss: 0.04667441796179832, Temperature 3.3300032936387236e-05, step_size 0.9025735237433691, test_acc: 0.5384\n",
            "Epoch 2254, BestLoss: 0.04667441796179832, Temperature 3.163503128956787e-05, step_size 0.9024832663909947, test_acc: 0.5384\n",
            "Epoch 2255, BestLoss: 0.04667441796179832, Temperature 3.3300032936387236e-05, step_size 0.9024832663909947, test_acc: 0.5384\n",
            "Epoch 2256, BestLoss: 0.046654372806673845, Temperature 3.505266624882867e-05, step_size 0.9023930180643557, test_acc: 0.5378\n",
            "Epoch 2257, BestLoss: 0.046654372806673845, Temperature 3.3300032936387236e-05, step_size 0.9023027787625493, test_acc: 0.5378\n",
            "Epoch 2258, BestLoss: 0.046654372806673845, Temperature 3.505266624882867e-05, step_size 0.9023027787625493, test_acc: 0.5378\n",
            "Epoch 2259, BestLoss: 0.046668021320411576, Temperature 3.689754341981966e-05, step_size 0.902212548484673, test_acc: 0.538\n",
            "Epoch 2260, BestLoss: 0.04675658017131723, Temperature 3.505266624882867e-05, step_size 0.9021223272298245, test_acc: 0.538\n",
            "Epoch 2261, BestLoss: 0.04675658017131723, Temperature 3.3300032936387236e-05, step_size 0.9020321149971016, test_acc: 0.538\n",
            "Epoch 2262, BestLoss: 0.04674545542142396, Temperature 3.505266624882867e-05, step_size 0.9021223272298245, test_acc: 0.537\n",
            "Epoch 2263, BestLoss: 0.04674545542142396, Temperature 3.3300032936387236e-05, step_size 0.9020321149971016, test_acc: 0.537\n",
            "Epoch 2264, BestLoss: 0.04674545542142396, Temperature 3.505266624882867e-05, step_size 0.9020321149971016, test_acc: 0.537\n",
            "Epoch 2265, BestLoss: 0.04674545542142396, Temperature 3.689754341981966e-05, step_size 0.9019419117856019, test_acc: 0.537\n",
            "Epoch 2266, BestLoss: 0.04674545542142396, Temperature 3.883951938928385e-05, step_size 0.9018517175944234, test_acc: 0.537\n",
            "Epoch 2267, BestLoss: 0.04674545542142396, Temperature 4.0883704620298796e-05, step_size 0.901761532422664, test_acc: 0.537\n",
            "Epoch 2268, BestLoss: 0.04674545542142396, Temperature 4.303547854768294e-05, step_size 0.9016713562694217, test_acc: 0.537\n",
            "Epoch 2269, BestLoss: 0.04674545542142396, Temperature 4.53005037344031e-05, step_size 0.9015811891337948, test_acc: 0.537\n",
            "Epoch 2270, BestLoss: 0.04674545542142396, Temperature 4.768474077305589e-05, step_size 0.9014910310148815, test_acc: 0.537\n",
            "Epoch 2271, BestLoss: 0.04674545542142396, Temperature 5.019446397163778e-05, step_size 0.90140088191178, test_acc: 0.537\n",
            "Epoch 2272, BestLoss: 0.04674545542142396, Temperature 5.283627786488188e-05, step_size 0.9013107418235888, test_acc: 0.537\n",
            "Epoch 2273, BestLoss: 0.04674545542142396, Temperature 5.561713459461251e-05, step_size 0.9012206107494065, test_acc: 0.537\n",
            "Epoch 2274, BestLoss: 0.04674545542142396, Temperature 5.8544352204855274e-05, step_size 0.9011304886883316, test_acc: 0.537\n",
            "Epoch 2275, BestLoss: 0.04674545542142396, Temperature 6.162563389984766e-05, step_size 0.9010403756394627, test_acc: 0.537\n",
            "Epoch 2276, BestLoss: 0.046705513054090354, Temperature 6.486908831562912e-05, step_size 0.9009502716018988, test_acc: 0.5375\n",
            "Epoch 2277, BestLoss: 0.04669456706338027, Temperature 6.162563389984766e-05, step_size 0.9008601765747386, test_acc: 0.5372\n",
            "Epoch 2278, BestLoss: 0.0466347489429079, Temperature 5.8544352204855274e-05, step_size 0.9007700905570811, test_acc: 0.5391\n",
            "Epoch 2279, BestLoss: 0.046646228069737054, Temperature 5.561713459461251e-05, step_size 0.9006800135480254, test_acc: 0.5383\n",
            "Epoch 2280, BestLoss: 0.04660597189110772, Temperature 5.283627786488188e-05, step_size 0.9005899455466706, test_acc: 0.5391\n",
            "Epoch 2281, BestLoss: 0.046596379741390616, Temperature 5.019446397163778e-05, step_size 0.900499886552116, test_acc: 0.5397\n",
            "Epoch 2282, BestLoss: 0.046596379741390616, Temperature 4.768474077305589e-05, step_size 0.9004098365634607, test_acc: 0.5397\n",
            "Epoch 2283, BestLoss: 0.046596379741390616, Temperature 5.019446397163778e-05, step_size 0.9008601765747386, test_acc: 0.5397\n",
            "Epoch 2284, BestLoss: 0.046596379741390616, Temperature 5.283627786488188e-05, step_size 0.9007700905570811, test_acc: 0.5397\n",
            "Epoch 2285, BestLoss: 0.04653835058129441, Temperature 5.561713459461251e-05, step_size 0.9006800135480254, test_acc: 0.5399\n",
            "Epoch 2286, BestLoss: 0.046495487341481914, Temperature 5.283627786488188e-05, step_size 0.9005899455466706, test_acc: 0.5398\n",
            "Epoch 2287, BestLoss: 0.046495487341481914, Temperature 5.019446397163778e-05, step_size 0.900499886552116, test_acc: 0.5398\n",
            "Epoch 2288, BestLoss: 0.046495487341481914, Temperature 5.283627786488188e-05, step_size 0.9005899455466706, test_acc: 0.5398\n",
            "Epoch 2289, BestLoss: 0.046495487341481914, Temperature 5.561713459461251e-05, step_size 0.900499886552116, test_acc: 0.5398\n",
            "Epoch 2290, BestLoss: 0.046495487341481914, Temperature 5.8544352204855274e-05, step_size 0.9004098365634607, test_acc: 0.5398\n",
            "Epoch 2291, BestLoss: 0.046495487341481914, Temperature 6.162563389984766e-05, step_size 0.9003197955798045, test_acc: 0.5398\n",
            "Epoch 2292, BestLoss: 0.04644132547071176, Temperature 6.486908831562912e-05, step_size 0.9002297636002465, test_acc: 0.5407\n",
            "Epoch 2293, BestLoss: 0.04644211263691918, Temperature 6.162563389984766e-05, step_size 0.9001397406238866, test_acc: 0.5391\n",
            "Epoch 2294, BestLoss: 0.04644211263691918, Temperature 6.486908831562912e-05, step_size 0.9001397406238866, test_acc: 0.5391\n",
            "Epoch 2295, BestLoss: 0.04648333195102239, Temperature 6.828325085855697e-05, step_size 0.9000497266498242, test_acc: 0.5376\n",
            "Epoch 2296, BestLoss: 0.04650767898925391, Temperature 6.486908831562912e-05, step_size 0.8999597216771592, test_acc: 0.5379\n",
            "Epoch 2297, BestLoss: 0.04650767898925391, Temperature 6.162563389984766e-05, step_size 0.8998697257049915, test_acc: 0.5379\n",
            "Epoch 2298, BestLoss: 0.04650767898925391, Temperature 6.486908831562912e-05, step_size 0.8999597216771592, test_acc: 0.5379\n",
            "Epoch 2299, BestLoss: 0.04650767898925391, Temperature 6.828325085855697e-05, step_size 0.8998697257049915, test_acc: 0.5379\n",
            "Epoch 2300, BestLoss: 0.04651098272084057, Temperature 7.187710616690208e-05, step_size 0.899779738732421, test_acc: 0.5383\n",
            "Epoch 2301, BestLoss: 0.046593541699440806, Temperature 7.566011175463378e-05, step_size 0.8996897607585478, test_acc: 0.5377\n",
            "Epoch 2302, BestLoss: 0.046593541699440806, Temperature 7.187710616690208e-05, step_size 0.899599791782472, test_acc: 0.5377\n",
            "Epoch 2303, BestLoss: 0.046568339064167436, Temperature 7.566011175463378e-05, step_size 0.899599791782472, test_acc: 0.5386\n",
            "Epoch 2304, BestLoss: 0.04660656159239281, Temperature 7.187710616690208e-05, step_size 0.8995098318032937, test_acc: 0.5379\n",
            "Epoch 2305, BestLoss: 0.04660656159239281, Temperature 6.828325085855697e-05, step_size 0.8994198808201134, test_acc: 0.5379\n",
            "Epoch 2306, BestLoss: 0.04663418337977608, Temperature 7.187710616690208e-05, step_size 0.8995098318032937, test_acc: 0.5379\n",
            "Epoch 2307, BestLoss: 0.04663418337977608, Temperature 6.828325085855697e-05, step_size 0.8994198808201134, test_acc: 0.5379\n",
            "Epoch 2308, BestLoss: 0.04663418337977608, Temperature 7.187710616690208e-05, step_size 0.8994198808201134, test_acc: 0.5379\n",
            "Epoch 2309, BestLoss: 0.04657273819315883, Temperature 7.566011175463378e-05, step_size 0.8993299388320314, test_acc: 0.5392\n",
            "Epoch 2310, BestLoss: 0.046664168921741425, Temperature 7.187710616690208e-05, step_size 0.8992400058381482, test_acc: 0.5391\n",
            "Epoch 2311, BestLoss: 0.046664168921741425, Temperature 6.828325085855697e-05, step_size 0.8991500818375644, test_acc: 0.5391\n",
            "Epoch 2312, BestLoss: 0.046664168921741425, Temperature 7.187710616690208e-05, step_size 0.8992400058381482, test_acc: 0.5391\n",
            "Epoch 2313, BestLoss: 0.04657932429981486, Temperature 7.566011175463378e-05, step_size 0.8991500818375644, test_acc: 0.5406\n",
            "Epoch 2314, BestLoss: 0.04655945854786488, Temperature 7.187710616690208e-05, step_size 0.8990601668293806, test_acc: 0.5396\n",
            "Epoch 2315, BestLoss: 0.04655945854786488, Temperature 6.828325085855697e-05, step_size 0.8989702608126977, test_acc: 0.5396\n",
            "Epoch 2316, BestLoss: 0.04655945854786488, Temperature 7.187710616690208e-05, step_size 0.8990601668293806, test_acc: 0.5396\n",
            "Epoch 2317, BestLoss: 0.04644472550332221, Temperature 7.566011175463378e-05, step_size 0.8989702608126977, test_acc: 0.5397\n",
            "Epoch 2318, BestLoss: 0.046479961451121356, Temperature 7.187710616690208e-05, step_size 0.8988803637866164, test_acc: 0.5398\n",
            "Epoch 2319, BestLoss: 0.046479961451121356, Temperature 6.828325085855697e-05, step_size 0.8987904757502377, test_acc: 0.5398\n",
            "Epoch 2320, BestLoss: 0.0464775310279744, Temperature 7.187710616690208e-05, step_size 0.8988803637866164, test_acc: 0.5387\n",
            "Epoch 2321, BestLoss: 0.0464775310279744, Temperature 7.566011175463378e-05, step_size 0.8987904757502377, test_acc: 0.5387\n",
            "Epoch 2322, BestLoss: 0.0464775310279744, Temperature 7.96422228996145e-05, step_size 0.8987005967026628, test_acc: 0.5387\n",
            "Epoch 2323, BestLoss: 0.0464775310279744, Temperature 8.383391884169949e-05, step_size 0.8986107266429926, test_acc: 0.5387\n",
            "Epoch 2324, BestLoss: 0.046571095380477115, Temperature 8.824623035968368e-05, step_size 0.8985208655703283, test_acc: 0.5381\n",
            "Epoch 2325, BestLoss: 0.046571095380477115, Temperature 8.383391884169949e-05, step_size 0.8984310134837713, test_acc: 0.5381\n",
            "Epoch 2326, BestLoss: 0.04662681103795752, Temperature 8.824623035968368e-05, step_size 0.8984310134837713, test_acc: 0.5373\n",
            "Epoch 2327, BestLoss: 0.04653886135445319, Temperature 8.383391884169949e-05, step_size 0.8983411703824229, test_acc: 0.5378\n",
            "Epoch 2328, BestLoss: 0.04653886135445319, Temperature 7.96422228996145e-05, step_size 0.8982513362653847, test_acc: 0.5378\n",
            "Epoch 2329, BestLoss: 0.04653886135445319, Temperature 8.383391884169949e-05, step_size 0.8983411703824229, test_acc: 0.5378\n",
            "Epoch 2330, BestLoss: 0.046641703120581406, Temperature 8.824623035968368e-05, step_size 0.8982513362653847, test_acc: 0.5387\n",
            "Epoch 2331, BestLoss: 0.046641703120581406, Temperature 8.383391884169949e-05, step_size 0.8981615111317581, test_acc: 0.5387\n",
            "Epoch 2332, BestLoss: 0.046641703120581406, Temperature 8.824623035968368e-05, step_size 0.8981615111317581, test_acc: 0.5387\n",
            "Epoch 2333, BestLoss: 0.04663004333562642, Temperature 9.289076879966704e-05, step_size 0.898071694980645, test_acc: 0.5375\n",
            "Epoch 2334, BestLoss: 0.046728330066107, Temperature 8.824623035968368e-05, step_size 0.897981887811147, test_acc: 0.5366\n",
            "Epoch 2335, BestLoss: 0.046780246724402834, Temperature 8.383391884169949e-05, step_size 0.8978920896223659, test_acc: 0.5361\n",
            "Epoch 2336, BestLoss: 0.046780246724402834, Temperature 7.96422228996145e-05, step_size 0.8978023004134037, test_acc: 0.5361\n",
            "Epoch 2337, BestLoss: 0.046780246724402834, Temperature 8.383391884169949e-05, step_size 0.897981887811147, test_acc: 0.5361\n",
            "Epoch 2338, BestLoss: 0.046780246724402834, Temperature 8.824623035968368e-05, step_size 0.8978920896223659, test_acc: 0.5361\n",
            "Epoch 2339, BestLoss: 0.046803052528004804, Temperature 9.289076879966704e-05, step_size 0.8978023004134037, test_acc: 0.5356\n",
            "Epoch 2340, BestLoss: 0.046803052528004804, Temperature 8.824623035968368e-05, step_size 0.8977125201833623, test_acc: 0.5356\n",
            "Epoch 2341, BestLoss: 0.04683869022246631, Temperature 9.289076879966704e-05, step_size 0.8977125201833623, test_acc: 0.5345\n",
            "Epoch 2342, BestLoss: 0.04683869022246631, Temperature 8.824623035968368e-05, step_size 0.897622748931344, test_acc: 0.5345\n",
            "Epoch 2343, BestLoss: 0.04683869022246631, Temperature 9.289076879966704e-05, step_size 0.897622748931344, test_acc: 0.5345\n",
            "Epoch 2344, BestLoss: 0.04688802765048628, Temperature 9.777975663122846e-05, step_size 0.8975329866564509, test_acc: 0.5352\n",
            "Epoch 2345, BestLoss: 0.04688802765048628, Temperature 9.289076879966704e-05, step_size 0.8974432333577852, test_acc: 0.5352\n",
            "Epoch 2346, BestLoss: 0.04686450271972177, Temperature 9.777975663122846e-05, step_size 0.8974432333577852, test_acc: 0.5339\n",
            "Epoch 2347, BestLoss: 0.04683019963865087, Temperature 9.289076879966704e-05, step_size 0.8973534890344494, test_acc: 0.5354\n",
            "Epoch 2348, BestLoss: 0.046816153816920676, Temperature 8.824623035968368e-05, step_size 0.897263753685546, test_acc: 0.5362\n",
            "Epoch 2349, BestLoss: 0.046833331079012976, Temperature 8.383391884169949e-05, step_size 0.8971740273101775, test_acc: 0.5354\n",
            "Epoch 2350, BestLoss: 0.046833331079012976, Temperature 7.96422228996145e-05, step_size 0.8970843099074465, test_acc: 0.5354\n",
            "Epoch 2351, BestLoss: 0.04678442979243014, Temperature 8.383391884169949e-05, step_size 0.8973534890344494, test_acc: 0.5356\n",
            "Epoch 2352, BestLoss: 0.04659939654342226, Temperature 7.96422228996145e-05, step_size 0.897263753685546, test_acc: 0.5386\n",
            "Epoch 2353, BestLoss: 0.04664954931970186, Temperature 7.566011175463378e-05, step_size 0.8971740273101775, test_acc: 0.5377\n",
            "Epoch 2354, BestLoss: 0.04664954931970186, Temperature 7.187710616690208e-05, step_size 0.8970843099074465, test_acc: 0.5377\n",
            "Epoch 2355, BestLoss: 0.04662155049604378, Temperature 7.566011175463378e-05, step_size 0.897263753685546, test_acc: 0.5364\n",
            "Epoch 2356, BestLoss: 0.04662155049604378, Temperature 7.187710616690208e-05, step_size 0.8971740273101775, test_acc: 0.5364\n",
            "Epoch 2357, BestLoss: 0.04662155049604378, Temperature 7.566011175463378e-05, step_size 0.8971740273101775, test_acc: 0.5364\n",
            "Epoch 2358, BestLoss: 0.04662155049604378, Temperature 7.96422228996145e-05, step_size 0.8970843099074465, test_acc: 0.5364\n",
            "Epoch 2359, BestLoss: 0.04662155049604378, Temperature 8.383391884169949e-05, step_size 0.8969946014764557, test_acc: 0.5364\n",
            "Epoch 2360, BestLoss: 0.04655082905070832, Temperature 8.824623035968368e-05, step_size 0.8969049020163081, test_acc: 0.5373\n",
            "Epoch 2361, BestLoss: 0.04655082905070832, Temperature 8.383391884169949e-05, step_size 0.8968152115261065, test_acc: 0.5373\n",
            "Epoch 2362, BestLoss: 0.04640750282697073, Temperature 8.824623035968368e-05, step_size 0.8968152115261065, test_acc: 0.5389\n",
            "Epoch 2363, BestLoss: 0.04636612267116039, Temperature 8.383391884169949e-05, step_size 0.8967255300049539, test_acc: 0.5393\n",
            "Epoch 2364, BestLoss: 0.04635005464735897, Temperature 7.96422228996145e-05, step_size 0.8966358574519534, test_acc: 0.54\n",
            "Epoch 2365, BestLoss: 0.04630950593169817, Temperature 7.566011175463378e-05, step_size 0.8965461938662083, test_acc: 0.5429\n",
            "Epoch 2366, BestLoss: 0.04630950593169817, Temperature 7.187710616690208e-05, step_size 0.8964565392468217, test_acc: 0.5429\n",
            "Epoch 2367, BestLoss: 0.04630634163451224, Temperature 7.566011175463378e-05, step_size 0.8967255300049539, test_acc: 0.5433\n",
            "Epoch 2368, BestLoss: 0.04630634163451224, Temperature 7.96422228996145e-05, step_size 0.8966358574519534, test_acc: 0.5433\n",
            "Epoch 2369, BestLoss: 0.04619983755036707, Temperature 8.383391884169949e-05, step_size 0.8965461938662083, test_acc: 0.5426\n",
            "Epoch 2370, BestLoss: 0.04619983755036707, Temperature 7.96422228996145e-05, step_size 0.8964565392468217, test_acc: 0.5426\n",
            "Epoch 2371, BestLoss: 0.046032992494645084, Temperature 8.383391884169949e-05, step_size 0.8964565392468217, test_acc: 0.5452\n",
            "Epoch 2372, BestLoss: 0.046032992494645084, Temperature 7.96422228996145e-05, step_size 0.896366893592897, test_acc: 0.5452\n",
            "Epoch 2373, BestLoss: 0.04606666624010729, Temperature 8.383391884169949e-05, step_size 0.896366893592897, test_acc: 0.5452\n",
            "Epoch 2374, BestLoss: 0.04624239086349532, Temperature 7.96422228996145e-05, step_size 0.8962772569035378, test_acc: 0.5421\n",
            "Epoch 2375, BestLoss: 0.04624239086349532, Temperature 7.566011175463378e-05, step_size 0.8961876291778474, test_acc: 0.5421\n",
            "Epoch 2376, BestLoss: 0.04624239086349532, Temperature 7.96422228996145e-05, step_size 0.8962772569035378, test_acc: 0.5421\n",
            "Epoch 2377, BestLoss: 0.04614657610062598, Temperature 8.383391884169949e-05, step_size 0.8961876291778474, test_acc: 0.5435\n",
            "Epoch 2378, BestLoss: 0.04614657610062598, Temperature 7.96422228996145e-05, step_size 0.8960980104149296, test_acc: 0.5435\n",
            "Epoch 2379, BestLoss: 0.046154795718408456, Temperature 8.383391884169949e-05, step_size 0.8960980104149296, test_acc: 0.5445\n",
            "Epoch 2380, BestLoss: 0.046154795718408456, Temperature 7.96422228996145e-05, step_size 0.8960084006138882, test_acc: 0.5445\n",
            "Epoch 2381, BestLoss: 0.046021545391179565, Temperature 8.383391884169949e-05, step_size 0.8960084006138882, test_acc: 0.5439\n",
            "Epoch 2382, BestLoss: 0.046021545391179565, Temperature 7.96422228996145e-05, step_size 0.8959187997738268, test_acc: 0.5439\n",
            "Epoch 2383, BestLoss: 0.046021545391179565, Temperature 8.383391884169949e-05, step_size 0.8959187997738268, test_acc: 0.5439\n",
            "Epoch 2384, BestLoss: 0.046100850206743524, Temperature 8.824623035968368e-05, step_size 0.8958292078938495, test_acc: 0.5437\n",
            "Epoch 2385, BestLoss: 0.04624104276369142, Temperature 8.383391884169949e-05, step_size 0.89573962497306, test_acc: 0.5414\n",
            "Epoch 2386, BestLoss: 0.04609276029526111, Temperature 7.96422228996145e-05, step_size 0.8956500510105627, test_acc: 0.5428\n",
            "Epoch 2387, BestLoss: 0.04603593705678155, Temperature 7.566011175463378e-05, step_size 0.8955604860054617, test_acc: 0.5431\n",
            "Epoch 2388, BestLoss: 0.04586409611137497, Temperature 7.187710616690208e-05, step_size 0.8954709299568612, test_acc: 0.5449\n",
            "Epoch 2389, BestLoss: 0.04586409611137497, Temperature 6.828325085855697e-05, step_size 0.8953813828638655, test_acc: 0.5449\n",
            "Epoch 2390, BestLoss: 0.0457062951297545, Temperature 7.187710616690208e-05, step_size 0.89573962497306, test_acc: 0.5452\n",
            "Epoch 2391, BestLoss: 0.0457062951297545, Temperature 6.828325085855697e-05, step_size 0.8956500510105627, test_acc: 0.5452\n",
            "Epoch 2392, BestLoss: 0.04571163842848675, Temperature 7.187710616690208e-05, step_size 0.8956500510105627, test_acc: 0.5469\n",
            "Epoch 2393, BestLoss: 0.04571163842848675, Temperature 6.828325085855697e-05, step_size 0.8955604860054617, test_acc: 0.5469\n",
            "Epoch 2394, BestLoss: 0.04571163842848675, Temperature 7.187710616690208e-05, step_size 0.8955604860054617, test_acc: 0.5469\n",
            "Epoch 2395, BestLoss: 0.04565159182480584, Temperature 7.566011175463378e-05, step_size 0.8954709299568612, test_acc: 0.5463\n",
            "Epoch 2396, BestLoss: 0.04565159182480584, Temperature 7.187710616690208e-05, step_size 0.8953813828638655, test_acc: 0.5463\n",
            "Epoch 2397, BestLoss: 0.04565159182480584, Temperature 7.566011175463378e-05, step_size 0.8953813828638655, test_acc: 0.5463\n",
            "Epoch 2398, BestLoss: 0.04565159182480584, Temperature 7.96422228996145e-05, step_size 0.8952918447255791, test_acc: 0.5463\n",
            "Epoch 2399, BestLoss: 0.04579101109457254, Temperature 8.383391884169949e-05, step_size 0.8952023155411065, test_acc: 0.5468\n",
            "Epoch 2400, BestLoss: 0.04591687308281022, Temperature 7.96422228996145e-05, step_size 0.8951127953095525, test_acc: 0.5454\n",
            "Epoch 2401, BestLoss: 0.04591687308281022, Temperature 7.566011175463378e-05, step_size 0.8950232840300215, test_acc: 0.5454\n",
            "Epoch 2402, BestLoss: 0.04595591725275694, Temperature 7.96422228996145e-05, step_size 0.8951127953095525, test_acc: 0.5465\n",
            "Epoch 2403, BestLoss: 0.04593395557722651, Temperature 7.566011175463378e-05, step_size 0.8950232840300215, test_acc: 0.5459\n",
            "Epoch 2404, BestLoss: 0.04593395557722651, Temperature 7.187710616690208e-05, step_size 0.8949337817016185, test_acc: 0.5459\n",
            "Epoch 2405, BestLoss: 0.04612960264662907, Temperature 7.566011175463378e-05, step_size 0.8950232840300215, test_acc: 0.5443\n",
            "Epoch 2406, BestLoss: 0.04610163237220633, Temperature 7.187710616690208e-05, step_size 0.8949337817016185, test_acc: 0.543\n",
            "Epoch 2407, BestLoss: 0.04610163237220633, Temperature 6.828325085855697e-05, step_size 0.8948442883234484, test_acc: 0.543\n",
            "Epoch 2408, BestLoss: 0.04604633049215722, Temperature 7.187710616690208e-05, step_size 0.8949337817016185, test_acc: 0.5442\n",
            "Epoch 2409, BestLoss: 0.04604633049215722, Temperature 6.828325085855697e-05, step_size 0.8948442883234484, test_acc: 0.5442\n",
            "Epoch 2410, BestLoss: 0.04604633049215722, Temperature 7.187710616690208e-05, step_size 0.8948442883234484, test_acc: 0.5442\n",
            "Epoch 2411, BestLoss: 0.046008833611238954, Temperature 7.566011175463378e-05, step_size 0.894754803894616, test_acc: 0.5448\n",
            "Epoch 2412, BestLoss: 0.046008833611238954, Temperature 7.187710616690208e-05, step_size 0.8946653284142266, test_acc: 0.5448\n",
            "Epoch 2413, BestLoss: 0.046008833611238954, Temperature 7.566011175463378e-05, step_size 0.8946653284142266, test_acc: 0.5448\n",
            "Epoch 2414, BestLoss: 0.046008833611238954, Temperature 7.96422228996145e-05, step_size 0.8945758618813853, test_acc: 0.5448\n",
            "Epoch 2415, BestLoss: 0.04607176653707749, Temperature 8.383391884169949e-05, step_size 0.8944864042951971, test_acc: 0.5436\n",
            "Epoch 2416, BestLoss: 0.04607176653707749, Temperature 7.96422228996145e-05, step_size 0.8943969556547676, test_acc: 0.5436\n",
            "Epoch 2417, BestLoss: 0.0461465087831926, Temperature 8.383391884169949e-05, step_size 0.8943969556547676, test_acc: 0.5439\n",
            "Epoch 2418, BestLoss: 0.04617999742418701, Temperature 7.96422228996145e-05, step_size 0.8943075159592021, test_acc: 0.5428\n",
            "Epoch 2419, BestLoss: 0.0461526722313902, Temperature 7.566011175463378e-05, step_size 0.8942180852076062, test_acc: 0.5423\n",
            "Epoch 2420, BestLoss: 0.0461526722313902, Temperature 7.187710616690208e-05, step_size 0.8941286633990854, test_acc: 0.5423\n",
            "Epoch 2421, BestLoss: 0.0461526722313902, Temperature 7.566011175463378e-05, step_size 0.8943075159592021, test_acc: 0.5423\n",
            "Epoch 2422, BestLoss: 0.0461526722313902, Temperature 7.96422228996145e-05, step_size 0.8942180852076062, test_acc: 0.5423\n",
            "Epoch 2423, BestLoss: 0.04615161502353332, Temperature 8.383391884169949e-05, step_size 0.8941286633990854, test_acc: 0.5434\n",
            "Epoch 2424, BestLoss: 0.04620102288297324, Temperature 8.824623035968368e-05, step_size 0.8940392505327455, test_acc: 0.5439\n",
            "Epoch 2425, BestLoss: 0.04620102288297324, Temperature 8.383391884169949e-05, step_size 0.8939498466076922, test_acc: 0.5439\n",
            "Epoch 2426, BestLoss: 0.04620102288297324, Temperature 8.824623035968368e-05, step_size 0.8939498466076922, test_acc: 0.5439\n",
            "Epoch 2427, BestLoss: 0.0463078951715895, Temperature 9.289076879966704e-05, step_size 0.8938604516230314, test_acc: 0.5438\n",
            "Epoch 2428, BestLoss: 0.04638383978536296, Temperature 8.824623035968368e-05, step_size 0.8937710655778691, test_acc: 0.5433\n",
            "Epoch 2429, BestLoss: 0.0463882881489558, Temperature 8.383391884169949e-05, step_size 0.8936816884713114, test_acc: 0.5421\n",
            "Epoch 2430, BestLoss: 0.0463882881489558, Temperature 7.96422228996145e-05, step_size 0.8935923203024643, test_acc: 0.5421\n",
            "Epoch 2431, BestLoss: 0.0463882881489558, Temperature 8.383391884169949e-05, step_size 0.8937710655778691, test_acc: 0.5421\n",
            "Epoch 2432, BestLoss: 0.0463882881489558, Temperature 8.824623035968368e-05, step_size 0.8936816884713114, test_acc: 0.5421\n",
            "Epoch 2433, BestLoss: 0.0465557418641096, Temperature 9.289076879966704e-05, step_size 0.8935923203024643, test_acc: 0.5392\n",
            "Epoch 2434, BestLoss: 0.04641666636322901, Temperature 8.824623035968368e-05, step_size 0.893502961070434, test_acc: 0.5398\n",
            "Epoch 2435, BestLoss: 0.04641666636322901, Temperature 8.383391884169949e-05, step_size 0.893413610774327, test_acc: 0.5398\n",
            "Epoch 2436, BestLoss: 0.04647159274359852, Temperature 8.824623035968368e-05, step_size 0.893502961070434, test_acc: 0.5383\n",
            "Epoch 2437, BestLoss: 0.04647159274359852, Temperature 8.383391884169949e-05, step_size 0.893413610774327, test_acc: 0.5383\n",
            "Epoch 2438, BestLoss: 0.04630301332835796, Temperature 8.824623035968368e-05, step_size 0.893413610774327, test_acc: 0.5388\n",
            "Epoch 2439, BestLoss: 0.04630301332835796, Temperature 8.383391884169949e-05, step_size 0.8933242694132496, test_acc: 0.5388\n",
            "Epoch 2440, BestLoss: 0.04628922496174164, Temperature 8.824623035968368e-05, step_size 0.8933242694132496, test_acc: 0.5386\n",
            "Epoch 2441, BestLoss: 0.04628922496174164, Temperature 8.383391884169949e-05, step_size 0.8932349369863083, test_acc: 0.5386\n",
            "Epoch 2442, BestLoss: 0.0464265906709974, Temperature 8.824623035968368e-05, step_size 0.8932349369863083, test_acc: 0.5373\n",
            "Epoch 2443, BestLoss: 0.0464265906709974, Temperature 8.383391884169949e-05, step_size 0.8931456134926097, test_acc: 0.5373\n",
            "Epoch 2444, BestLoss: 0.0464265906709974, Temperature 8.824623035968368e-05, step_size 0.8931456134926097, test_acc: 0.5373\n",
            "Epoch 2445, BestLoss: 0.046236478037852455, Temperature 9.289076879966704e-05, step_size 0.8930562989312605, test_acc: 0.5404\n",
            "Epoch 2446, BestLoss: 0.046236478037852455, Temperature 8.824623035968368e-05, step_size 0.8929669933013674, test_acc: 0.5404\n",
            "Epoch 2447, BestLoss: 0.046236478037852455, Temperature 9.289076879966704e-05, step_size 0.8929669933013674, test_acc: 0.5404\n",
            "Epoch 2448, BestLoss: 0.046236478037852455, Temperature 9.777975663122846e-05, step_size 0.8928776966020373, test_acc: 0.5404\n",
            "Epoch 2449, BestLoss: 0.04625878863933026, Temperature 0.00010292605961181944, step_size 0.8927884088323771, test_acc: 0.5404\n",
            "Epoch 2450, BestLoss: 0.04623293335106869, Temperature 9.777975663122846e-05, step_size 0.8926991299914938, test_acc: 0.54\n",
            "Epoch 2451, BestLoss: 0.04623293335106869, Temperature 9.289076879966704e-05, step_size 0.8926098600784946, test_acc: 0.54\n",
            "Epoch 2452, BestLoss: 0.04623293335106869, Temperature 9.777975663122846e-05, step_size 0.8926991299914938, test_acc: 0.54\n",
            "Epoch 2453, BestLoss: 0.04637937137456831, Temperature 0.00010292605961181944, step_size 0.8926098600784946, test_acc: 0.5398\n",
            "Epoch 2454, BestLoss: 0.04620623093357011, Temperature 9.777975663122846e-05, step_size 0.8925205990924868, test_acc: 0.5417\n",
            "Epoch 2455, BestLoss: 0.04620623093357011, Temperature 9.289076879966704e-05, step_size 0.8924313470325775, test_acc: 0.5417\n",
            "Epoch 2456, BestLoss: 0.04624434661344792, Temperature 9.777975663122846e-05, step_size 0.8925205990924868, test_acc: 0.5412\n",
            "Epoch 2457, BestLoss: 0.04609098529764971, Temperature 9.289076879966704e-05, step_size 0.8924313470325775, test_acc: 0.5429\n",
            "Epoch 2458, BestLoss: 0.04600224073076079, Temperature 8.824623035968368e-05, step_size 0.8923421038978743, test_acc: 0.5435\n",
            "Epoch 2459, BestLoss: 0.04600224073076079, Temperature 8.383391884169949e-05, step_size 0.8922528696874845, test_acc: 0.5435\n",
            "Epoch 2460, BestLoss: 0.04600224073076079, Temperature 8.824623035968368e-05, step_size 0.8924313470325775, test_acc: 0.5435\n",
            "Epoch 2461, BestLoss: 0.045852216778732933, Temperature 9.289076879966704e-05, step_size 0.8923421038978743, test_acc: 0.5447\n",
            "Epoch 2462, BestLoss: 0.045852216778732933, Temperature 8.824623035968368e-05, step_size 0.8922528696874845, test_acc: 0.5447\n",
            "Epoch 2463, BestLoss: 0.04577948135256897, Temperature 9.289076879966704e-05, step_size 0.8922528696874845, test_acc: 0.5451\n",
            "Epoch 2464, BestLoss: 0.04577948135256897, Temperature 8.824623035968368e-05, step_size 0.8921636444005158, test_acc: 0.5451\n",
            "Epoch 2465, BestLoss: 0.0455974685903401, Temperature 9.289076879966704e-05, step_size 0.8921636444005158, test_acc: 0.5459\n",
            "Epoch 2466, BestLoss: 0.0455974685903401, Temperature 8.824623035968368e-05, step_size 0.8920744280360757, test_acc: 0.5459\n",
            "Epoch 2467, BestLoss: 0.04563879327385811, Temperature 9.289076879966704e-05, step_size 0.8920744280360757, test_acc: 0.5475\n",
            "Epoch 2468, BestLoss: 0.04563879327385811, Temperature 8.824623035968368e-05, step_size 0.8919852205932721, test_acc: 0.5475\n",
            "Epoch 2469, BestLoss: 0.04563879327385811, Temperature 9.289076879966704e-05, step_size 0.8919852205932721, test_acc: 0.5475\n",
            "Epoch 2470, BestLoss: 0.04562019149934541, Temperature 9.777975663122846e-05, step_size 0.8918960220712128, test_acc: 0.5482\n",
            "Epoch 2471, BestLoss: 0.04562019149934541, Temperature 9.289076879966704e-05, step_size 0.8918068324690056, test_acc: 0.5482\n",
            "Epoch 2472, BestLoss: 0.04562019149934541, Temperature 9.777975663122846e-05, step_size 0.8918068324690056, test_acc: 0.5482\n",
            "Epoch 2473, BestLoss: 0.04566458550167997, Temperature 0.00010292605961181944, step_size 0.8917176517857587, test_acc: 0.548\n",
            "Epoch 2474, BestLoss: 0.04566458550167997, Temperature 9.777975663122846e-05, step_size 0.8916284800205801, test_acc: 0.548\n",
            "Epoch 2475, BestLoss: 0.04566458550167997, Temperature 0.00010292605961181944, step_size 0.8916284800205801, test_acc: 0.548\n",
            "Epoch 2476, BestLoss: 0.04566273998463955, Temperature 0.00010834322064402047, step_size 0.8915393171725781, test_acc: 0.5467\n",
            "Epoch 2477, BestLoss: 0.04566273998463955, Temperature 0.0001140454954147584, step_size 0.8914501632408608, test_acc: 0.5467\n",
            "Epoch 2478, BestLoss: 0.045632038722701045, Temperature 0.000120047889910272, step_size 0.8913610182245367, test_acc: 0.5461\n",
            "Epoch 2479, BestLoss: 0.04570163029324284, Temperature 0.0001140454954147584, step_size 0.8912718821227142, test_acc: 0.5459\n",
            "Epoch 2480, BestLoss: 0.045739579963339466, Temperature 0.00010834322064402047, step_size 0.8911827549345019, test_acc: 0.5461\n",
            "Epoch 2481, BestLoss: 0.045739579963339466, Temperature 0.00010292605961181944, step_size 0.8910936366590085, test_acc: 0.5461\n",
            "Epoch 2482, BestLoss: 0.0456445373781192, Temperature 0.00010834322064402047, step_size 0.8912718821227142, test_acc: 0.5458\n",
            "Epoch 2483, BestLoss: 0.04563650825026645, Temperature 0.00010292605961181944, step_size 0.8911827549345019, test_acc: 0.5473\n",
            "Epoch 2484, BestLoss: 0.04565686957860244, Temperature 9.777975663122846e-05, step_size 0.8910936366590085, test_acc: 0.5465\n",
            "Epoch 2485, BestLoss: 0.045666174003227984, Temperature 9.289076879966704e-05, step_size 0.8910045272953426, test_acc: 0.5456\n",
            "Epoch 2486, BestLoss: 0.045666174003227984, Temperature 8.824623035968368e-05, step_size 0.8909154268426132, test_acc: 0.5456\n",
            "Epoch 2487, BestLoss: 0.04567977430593899, Temperature 9.289076879966704e-05, step_size 0.8911827549345019, test_acc: 0.5466\n",
            "Epoch 2488, BestLoss: 0.04561200721788828, Temperature 8.824623035968368e-05, step_size 0.8910936366590085, test_acc: 0.5468\n",
            "Epoch 2489, BestLoss: 0.04561200721788828, Temperature 8.383391884169949e-05, step_size 0.8910045272953426, test_acc: 0.5468\n",
            "Epoch 2490, BestLoss: 0.04561200721788828, Temperature 8.824623035968368e-05, step_size 0.8910936366590085, test_acc: 0.5468\n",
            "Epoch 2491, BestLoss: 0.04561200721788828, Temperature 9.289076879966704e-05, step_size 0.8910045272953426, test_acc: 0.5468\n",
            "Epoch 2492, BestLoss: 0.04550996622740203, Temperature 9.777975663122846e-05, step_size 0.8909154268426132, test_acc: 0.5461\n",
            "Epoch 2493, BestLoss: 0.04556809879345428, Temperature 9.289076879966704e-05, step_size 0.8908263352999289, test_acc: 0.5468\n",
            "Epoch 2494, BestLoss: 0.04577140599892553, Temperature 8.824623035968368e-05, step_size 0.8907372526663989, test_acc: 0.5443\n",
            "Epoch 2495, BestLoss: 0.045699301563715426, Temperature 8.383391884169949e-05, step_size 0.8906481789411322, test_acc: 0.5439\n",
            "Epoch 2496, BestLoss: 0.045768040395149014, Temperature 7.96422228996145e-05, step_size 0.8905591141232382, test_acc: 0.5437\n",
            "Epoch 2497, BestLoss: 0.04580394332266621, Temperature 7.566011175463378e-05, step_size 0.8904700582118259, test_acc: 0.5418\n",
            "Epoch 2498, BestLoss: 0.045813000692120874, Temperature 7.187710616690208e-05, step_size 0.8903810112060048, test_acc: 0.5421\n",
            "Epoch 2499, BestLoss: 0.04574712050984652, Temperature 6.828325085855697e-05, step_size 0.8902919731048842, test_acc: 0.543\n",
            "Epoch 2500, BestLoss: 0.04574712050984652, Temperature 6.486908831562912e-05, step_size 0.8902029439075737, test_acc: 0.543\n",
            "Epoch 2501, BestLoss: 0.04584139157646836, Temperature 6.828325085855697e-05, step_size 0.8908263352999289, test_acc: 0.5405\n",
            "Epoch 2502, BestLoss: 0.04584139157646836, Temperature 6.486908831562912e-05, step_size 0.8907372526663989, test_acc: 0.5405\n",
            "Epoch 2503, BestLoss: 0.04584139157646836, Temperature 6.828325085855697e-05, step_size 0.8907372526663989, test_acc: 0.5405\n",
            "Epoch 2504, BestLoss: 0.04584139157646836, Temperature 7.187710616690208e-05, step_size 0.8906481789411322, test_acc: 0.5405\n",
            "Epoch 2505, BestLoss: 0.045815794987694815, Temperature 7.566011175463378e-05, step_size 0.8905591141232382, test_acc: 0.5425\n",
            "Epoch 2506, BestLoss: 0.04576833322384653, Temperature 7.187710616690208e-05, step_size 0.8904700582118259, test_acc: 0.5459\n",
            "Epoch 2507, BestLoss: 0.04576785136267732, Temperature 6.828325085855697e-05, step_size 0.8903810112060048, test_acc: 0.5447\n",
            "Epoch 2508, BestLoss: 0.04595859248782753, Temperature 7.187710616690208e-05, step_size 0.8904700582118259, test_acc: 0.5434\n",
            "Epoch 2509, BestLoss: 0.04595859248782753, Temperature 6.828325085855697e-05, step_size 0.8903810112060048, test_acc: 0.5434\n",
            "Epoch 2510, BestLoss: 0.045958931861022616, Temperature 7.187710616690208e-05, step_size 0.8903810112060048, test_acc: 0.5432\n",
            "Epoch 2511, BestLoss: 0.04599785000717985, Temperature 7.566011175463378e-05, step_size 0.8902919731048842, test_acc: 0.5415\n",
            "Epoch 2512, BestLoss: 0.04599785000717985, Temperature 7.187710616690208e-05, step_size 0.8902029439075737, test_acc: 0.5415\n",
            "Epoch 2513, BestLoss: 0.04599785000717985, Temperature 7.566011175463378e-05, step_size 0.8902029439075737, test_acc: 0.5415\n",
            "Epoch 2514, BestLoss: 0.04596632676687965, Temperature 7.96422228996145e-05, step_size 0.890113923613183, test_acc: 0.5422\n",
            "Epoch 2515, BestLoss: 0.04593421836160091, Temperature 7.566011175463378e-05, step_size 0.8900249122208217, test_acc: 0.5411\n",
            "Epoch 2516, BestLoss: 0.04593421836160091, Temperature 7.187710616690208e-05, step_size 0.8899359097295996, test_acc: 0.5411\n",
            "Epoch 2517, BestLoss: 0.04593421836160091, Temperature 7.566011175463378e-05, step_size 0.8900249122208217, test_acc: 0.5411\n",
            "Epoch 2518, BestLoss: 0.045916223970985194, Temperature 7.96422228996145e-05, step_size 0.8899359097295996, test_acc: 0.5427\n",
            "Epoch 2519, BestLoss: 0.045916223970985194, Temperature 7.566011175463378e-05, step_size 0.8898469161386267, test_acc: 0.5427\n",
            "Epoch 2520, BestLoss: 0.045916223970985194, Temperature 7.96422228996145e-05, step_size 0.8898469161386267, test_acc: 0.5427\n",
            "Epoch 2521, BestLoss: 0.04603315434544034, Temperature 8.383391884169949e-05, step_size 0.8897579314470128, test_acc: 0.5414\n",
            "Epoch 2522, BestLoss: 0.04603315434544034, Temperature 7.96422228996145e-05, step_size 0.889668955653868, test_acc: 0.5414\n",
            "Epoch 2523, BestLoss: 0.04603315434544034, Temperature 8.383391884169949e-05, step_size 0.889668955653868, test_acc: 0.5414\n",
            "Epoch 2524, BestLoss: 0.04603017859767374, Temperature 8.824623035968368e-05, step_size 0.8895799887583027, test_acc: 0.5416\n",
            "Epoch 2525, BestLoss: 0.04603017859767374, Temperature 9.289076879966704e-05, step_size 0.8894910307594268, test_acc: 0.5416\n",
            "Epoch 2526, BestLoss: 0.04606623822985846, Temperature 9.777975663122846e-05, step_size 0.8894020816563509, test_acc: 0.5411\n",
            "Epoch 2527, BestLoss: 0.04596415932194653, Temperature 9.289076879966704e-05, step_size 0.8893131414481853, test_acc: 0.5424\n",
            "Epoch 2528, BestLoss: 0.04596415932194653, Temperature 8.824623035968368e-05, step_size 0.8892242101340405, test_acc: 0.5424\n",
            "Epoch 2529, BestLoss: 0.04596415932194653, Temperature 9.289076879966704e-05, step_size 0.8893131414481853, test_acc: 0.5424\n",
            "Epoch 2530, BestLoss: 0.04596415932194653, Temperature 9.777975663122846e-05, step_size 0.8892242101340405, test_acc: 0.5424\n",
            "Epoch 2531, BestLoss: 0.04590159569874771, Temperature 0.00010292605961181944, step_size 0.8891352877130271, test_acc: 0.5424\n",
            "Epoch 2532, BestLoss: 0.04585738507593669, Temperature 9.777975663122846e-05, step_size 0.8890463741842558, test_acc: 0.5444\n",
            "Epoch 2533, BestLoss: 0.04571611417653438, Temperature 9.289076879966704e-05, step_size 0.8889574695468374, test_acc: 0.5456\n",
            "Epoch 2534, BestLoss: 0.04571611417653438, Temperature 8.824623035968368e-05, step_size 0.8888685737998827, test_acc: 0.5456\n",
            "Epoch 2535, BestLoss: 0.04571611417653438, Temperature 9.289076879966704e-05, step_size 0.8890463741842558, test_acc: 0.5456\n",
            "Epoch 2536, BestLoss: 0.04582613020559245, Temperature 9.777975663122846e-05, step_size 0.8889574695468374, test_acc: 0.5443\n",
            "Epoch 2537, BestLoss: 0.04582613020559245, Temperature 9.289076879966704e-05, step_size 0.8888685737998827, test_acc: 0.5443\n",
            "Epoch 2538, BestLoss: 0.04580627100388451, Temperature 9.777975663122846e-05, step_size 0.8888685737998827, test_acc: 0.5434\n",
            "Epoch 2539, BestLoss: 0.04580627100388451, Temperature 9.289076879966704e-05, step_size 0.8887796869425028, test_acc: 0.5434\n",
            "Epoch 2540, BestLoss: 0.04580627100388451, Temperature 9.777975663122846e-05, step_size 0.8887796869425028, test_acc: 0.5434\n",
            "Epoch 2541, BestLoss: 0.04580627100388451, Temperature 0.00010292605961181944, step_size 0.8886908089738085, test_acc: 0.5434\n",
            "Epoch 2542, BestLoss: 0.04580627100388451, Temperature 0.00010834322064402047, step_size 0.8886019398929111, test_acc: 0.5434\n",
            "Epoch 2543, BestLoss: 0.0459837814028093, Temperature 0.0001140454954147584, step_size 0.8885130796989219, test_acc: 0.5422\n",
            "Epoch 2544, BestLoss: 0.0459837814028093, Temperature 0.00010834322064402047, step_size 0.888424228390952, test_acc: 0.5422\n",
            "Epoch 2545, BestLoss: 0.0459837814028093, Temperature 0.0001140454954147584, step_size 0.888424228390952, test_acc: 0.5422\n",
            "Epoch 2546, BestLoss: 0.0459837814028093, Temperature 0.000120047889910272, step_size 0.8883353859681129, test_acc: 0.5422\n",
            "Epoch 2547, BestLoss: 0.04576499715942324, Temperature 0.0001263661999055495, step_size 0.8882465524295161, test_acc: 0.5458\n",
            "Epoch 2548, BestLoss: 0.045761536168278376, Temperature 0.000120047889910272, step_size 0.8881577277742732, test_acc: 0.5463\n",
            "Epoch 2549, BestLoss: 0.045761536168278376, Temperature 0.0001263661999055495, step_size 0.8881577277742732, test_acc: 0.5463\n",
            "Epoch 2550, BestLoss: 0.045761536168278376, Temperature 0.00013301705253215737, step_size 0.8880689120014957, test_acc: 0.5463\n",
            "Epoch 2551, BestLoss: 0.04583244953740951, Temperature 0.00014001795003384986, step_size 0.8879801051102956, test_acc: 0.5454\n",
            "Epoch 2552, BestLoss: 0.04573271269099706, Temperature 0.00013301705253215737, step_size 0.8878913070997846, test_acc: 0.5457\n",
            "Epoch 2553, BestLoss: 0.04573271269099706, Temperature 0.0001263661999055495, step_size 0.8878025179690746, test_acc: 0.5457\n",
            "Epoch 2554, BestLoss: 0.04585732743603553, Temperature 0.00013301705253215737, step_size 0.8878913070997846, test_acc: 0.5445\n",
            "Epoch 2555, BestLoss: 0.04585732743603553, Temperature 0.0001263661999055495, step_size 0.8878025179690746, test_acc: 0.5445\n",
            "Epoch 2556, BestLoss: 0.045856146073713716, Temperature 0.00013301705253215737, step_size 0.8878025179690746, test_acc: 0.544\n",
            "Epoch 2557, BestLoss: 0.04600107257616894, Temperature 0.00014001795003384986, step_size 0.8877137377172777, test_acc: 0.542\n",
            "Epoch 2558, BestLoss: 0.04600107257616894, Temperature 0.00013301705253215737, step_size 0.887624966343506, test_acc: 0.542\n",
            "Epoch 2559, BestLoss: 0.04599979497780606, Temperature 0.00014001795003384986, step_size 0.887624966343506, test_acc: 0.5411\n",
            "Epoch 2560, BestLoss: 0.04599979497780606, Temperature 0.00014738731582510513, step_size 0.8875362038468716, test_acc: 0.5411\n",
            "Epoch 2561, BestLoss: 0.04590812179838973, Temperature 0.00015514454297379488, step_size 0.887447450226487, test_acc: 0.5425\n",
            "Epoch 2562, BestLoss: 0.04599319875280284, Temperature 0.00014738731582510513, step_size 0.8873587054814643, test_acc: 0.542\n",
            "Epoch 2563, BestLoss: 0.046019615234474856, Temperature 0.00014001795003384986, step_size 0.8872699696109162, test_acc: 0.5409\n",
            "Epoch 2564, BestLoss: 0.04635453115880922, Temperature 0.00013301705253215737, step_size 0.8871812426139551, test_acc: 0.5377\n",
            "Epoch 2565, BestLoss: 0.04635453115880922, Temperature 0.0001263661999055495, step_size 0.8870925244896938, test_acc: 0.5377\n",
            "Epoch 2566, BestLoss: 0.04635453115880922, Temperature 0.00013301705253215737, step_size 0.8873587054814643, test_acc: 0.5377\n",
            "Epoch 2567, BestLoss: 0.04635453115880922, Temperature 0.00014001795003384986, step_size 0.8872699696109162, test_acc: 0.5377\n",
            "Epoch 2568, BestLoss: 0.04637272249921276, Temperature 0.00014738731582510513, step_size 0.8871812426139551, test_acc: 0.5377\n",
            "Epoch 2569, BestLoss: 0.04639504733125432, Temperature 0.00014001795003384986, step_size 0.8870925244896938, test_acc: 0.5368\n",
            "Epoch 2570, BestLoss: 0.04639504733125432, Temperature 0.00013301705253215737, step_size 0.8870038152372448, test_acc: 0.5368\n",
            "Epoch 2571, BestLoss: 0.04634984764360208, Temperature 0.00014001795003384986, step_size 0.8870925244896938, test_acc: 0.5373\n",
            "Epoch 2572, BestLoss: 0.04634984764360208, Temperature 0.00013301705253215737, step_size 0.8870038152372448, test_acc: 0.5373\n",
            "Epoch 2573, BestLoss: 0.04609753311797929, Temperature 0.00014001795003384986, step_size 0.8870038152372448, test_acc: 0.5409\n",
            "Epoch 2574, BestLoss: 0.04609753311797929, Temperature 0.00013301705253215737, step_size 0.886915114855721, test_acc: 0.5409\n",
            "Epoch 2575, BestLoss: 0.04609753311797929, Temperature 0.00014001795003384986, step_size 0.886915114855721, test_acc: 0.5409\n",
            "Epoch 2576, BestLoss: 0.04609753311797929, Temperature 0.00014738731582510513, step_size 0.8868264233442354, test_acc: 0.5409\n",
            "Epoch 2577, BestLoss: 0.04609753311797929, Temperature 0.00015514454297379488, step_size 0.886737740701901, test_acc: 0.5409\n",
            "Epoch 2578, BestLoss: 0.04611127686892104, Temperature 0.00016331004523557357, step_size 0.8866490669278309, test_acc: 0.5409\n",
            "Epoch 2579, BestLoss: 0.04611127686892104, Temperature 0.00015514454297379488, step_size 0.8865604020211381, test_acc: 0.5409\n",
            "Epoch 2580, BestLoss: 0.046127624949024275, Temperature 0.00016331004523557357, step_size 0.8865604020211381, test_acc: 0.5421\n",
            "Epoch 2581, BestLoss: 0.04615462503018054, Temperature 0.00015514454297379488, step_size 0.8864717459809359, test_acc: 0.54\n",
            "Epoch 2582, BestLoss: 0.04615462503018054, Temperature 0.00014738731582510513, step_size 0.8863830988063378, test_acc: 0.54\n",
            "Epoch 2583, BestLoss: 0.046114837856634595, Temperature 0.00015514454297379488, step_size 0.8864717459809359, test_acc: 0.5408\n",
            "Epoch 2584, BestLoss: 0.046156274246624364, Temperature 0.00014738731582510513, step_size 0.8863830988063378, test_acc: 0.5399\n",
            "Epoch 2585, BestLoss: 0.046106880676152866, Temperature 0.00014001795003384986, step_size 0.8862944604964572, test_acc: 0.5409\n",
            "Epoch 2586, BestLoss: 0.04625478688966304, Temperature 0.00013301705253215737, step_size 0.8862058310504076, test_acc: 0.5395\n",
            "Epoch 2587, BestLoss: 0.04625478688966304, Temperature 0.0001263661999055495, step_size 0.8861172104673026, test_acc: 0.5395\n",
            "Epoch 2588, BestLoss: 0.04625478688966304, Temperature 0.00013301705253215737, step_size 0.8863830988063378, test_acc: 0.5395\n",
            "Epoch 2589, BestLoss: 0.04634408145448398, Temperature 0.00014001795003384986, step_size 0.8862944604964572, test_acc: 0.5374\n",
            "Epoch 2590, BestLoss: 0.04634408145448398, Temperature 0.00013301705253215737, step_size 0.8862058310504076, test_acc: 0.5374\n",
            "Epoch 2591, BestLoss: 0.04634408145448398, Temperature 0.00014001795003384986, step_size 0.8862058310504076, test_acc: 0.5374\n",
            "Epoch 2592, BestLoss: 0.04634408145448398, Temperature 0.00014738731582510513, step_size 0.8861172104673026, test_acc: 0.5374\n",
            "Epoch 2593, BestLoss: 0.04652380851338765, Temperature 0.00015514454297379488, step_size 0.886028598746256, test_acc: 0.5347\n",
            "Epoch 2594, BestLoss: 0.04652380851338765, Temperature 0.00014738731582510513, step_size 0.8859399958863813, test_acc: 0.5347\n",
            "Epoch 2595, BestLoss: 0.04652380851338765, Temperature 0.00015514454297379488, step_size 0.8859399958863813, test_acc: 0.5347\n",
            "Epoch 2596, BestLoss: 0.04678630154625983, Temperature 0.00016331004523557357, step_size 0.8858514018867927, test_acc: 0.5317\n",
            "Epoch 2597, BestLoss: 0.04662551201006239, Temperature 0.00015514454297379488, step_size 0.885762816746604, test_acc: 0.5345\n",
            "Epoch 2598, BestLoss: 0.04662551201006239, Temperature 0.00014738731582510513, step_size 0.8856742404649293, test_acc: 0.5345\n",
            "Epoch 2599, BestLoss: 0.04662551201006239, Temperature 0.00015514454297379488, step_size 0.885762816746604, test_acc: 0.5345\n",
            "Epoch 2600, BestLoss: 0.04631331990854129, Temperature 0.00016331004523557357, step_size 0.8856742404649293, test_acc: 0.5385\n",
            "Epoch 2601, BestLoss: 0.04631331990854129, Temperature 0.00015514454297379488, step_size 0.8855856730408828, test_acc: 0.5385\n",
            "Epoch 2602, BestLoss: 0.04626019473968514, Temperature 0.00016331004523557357, step_size 0.8855856730408828, test_acc: 0.5401\n",
            "Epoch 2603, BestLoss: 0.046253813587704716, Temperature 0.00015514454297379488, step_size 0.8854971144735787, test_acc: 0.5412\n",
            "Epoch 2604, BestLoss: 0.04638508052508715, Temperature 0.00014738731582510513, step_size 0.8854085647621314, test_acc: 0.5402\n",
            "Epoch 2605, BestLoss: 0.04637119734679389, Temperature 0.00014001795003384986, step_size 0.8853200239056551, test_acc: 0.5399\n",
            "Epoch 2606, BestLoss: 0.04623099671718914, Temperature 0.00013301705253215737, step_size 0.8852314919032646, test_acc: 0.5407\n",
            "Epoch 2607, BestLoss: 0.04615640343664079, Temperature 0.0001263661999055495, step_size 0.8851429687540743, test_acc: 0.5414\n",
            "Epoch 2608, BestLoss: 0.04605375426873706, Temperature 0.000120047889910272, step_size 0.8850544544571989, test_acc: 0.54\n",
            "Epoch 2609, BestLoss: 0.04596563238379366, Temperature 0.0001140454954147584, step_size 0.8849659490117532, test_acc: 0.542\n",
            "Epoch 2610, BestLoss: 0.04596563238379366, Temperature 0.00010834322064402047, step_size 0.884877452416852, test_acc: 0.542\n",
            "Epoch 2611, BestLoss: 0.045917200623592266, Temperature 0.0001140454954147584, step_size 0.8854971144735787, test_acc: 0.5424\n",
            "Epoch 2612, BestLoss: 0.045935692378485556, Temperature 0.00010834322064402047, step_size 0.8854085647621314, test_acc: 0.5433\n",
            "Epoch 2613, BestLoss: 0.045944494182345044, Temperature 0.00010292605961181944, step_size 0.8853200239056551, test_acc: 0.5437\n",
            "Epoch 2614, BestLoss: 0.04591656957236664, Temperature 9.777975663122846e-05, step_size 0.8852314919032646, test_acc: 0.5442\n",
            "Epoch 2615, BestLoss: 0.04591656957236664, Temperature 9.289076879966704e-05, step_size 0.8851429687540743, test_acc: 0.5442\n",
            "Epoch 2616, BestLoss: 0.04591656957236664, Temperature 9.777975663122846e-05, step_size 0.8854085647621314, test_acc: 0.5442\n",
            "Epoch 2617, BestLoss: 0.04591656957236664, Temperature 0.00010292605961181944, step_size 0.8853200239056551, test_acc: 0.5442\n",
            "Epoch 2618, BestLoss: 0.04591656957236664, Temperature 0.00010834322064402047, step_size 0.8852314919032646, test_acc: 0.5442\n",
            "Epoch 2619, BestLoss: 0.045979897820060706, Temperature 0.0001140454954147584, step_size 0.8851429687540743, test_acc: 0.5437\n",
            "Epoch 2620, BestLoss: 0.04599314443943907, Temperature 0.00010834322064402047, step_size 0.8850544544571989, test_acc: 0.5433\n",
            "Epoch 2621, BestLoss: 0.046101366217098996, Temperature 0.00010292605961181944, step_size 0.8849659490117532, test_acc: 0.5436\n",
            "Epoch 2622, BestLoss: 0.046101366217098996, Temperature 9.777975663122846e-05, step_size 0.884877452416852, test_acc: 0.5436\n",
            "Epoch 2623, BestLoss: 0.046101366217098996, Temperature 0.00010292605961181944, step_size 0.8850544544571989, test_acc: 0.5436\n",
            "Epoch 2624, BestLoss: 0.04616461160998668, Temperature 0.00010834322064402047, step_size 0.8849659490117532, test_acc: 0.5418\n",
            "Epoch 2625, BestLoss: 0.04615245996887562, Temperature 0.00010292605961181944, step_size 0.884877452416852, test_acc: 0.5422\n",
            "Epoch 2626, BestLoss: 0.046054456694833094, Temperature 9.777975663122846e-05, step_size 0.8847889646716103, test_acc: 0.543\n",
            "Epoch 2627, BestLoss: 0.046004675001082455, Temperature 9.289076879966704e-05, step_size 0.8847004857751432, test_acc: 0.5445\n",
            "Epoch 2628, BestLoss: 0.046004675001082455, Temperature 8.824623035968368e-05, step_size 0.8846120157265657, test_acc: 0.5445\n",
            "Epoch 2629, BestLoss: 0.04602055772356508, Temperature 9.289076879966704e-05, step_size 0.884877452416852, test_acc: 0.5435\n",
            "Epoch 2630, BestLoss: 0.045999633632268236, Temperature 8.824623035968368e-05, step_size 0.8847889646716103, test_acc: 0.5426\n",
            "Epoch 2631, BestLoss: 0.04589974047235872, Temperature 8.383391884169949e-05, step_size 0.8847004857751432, test_acc: 0.5453\n",
            "Epoch 2632, BestLoss: 0.04589974047235872, Temperature 7.96422228996145e-05, step_size 0.8846120157265657, test_acc: 0.5453\n",
            "Epoch 2633, BestLoss: 0.045901779898947365, Temperature 8.383391884169949e-05, step_size 0.8847889646716103, test_acc: 0.5444\n",
            "Epoch 2634, BestLoss: 0.045739949015663126, Temperature 8.824623035968368e-05, step_size 0.8847004857751432, test_acc: 0.5456\n",
            "Epoch 2635, BestLoss: 0.04569498898810283, Temperature 8.383391884169949e-05, step_size 0.8846120157265657, test_acc: 0.5461\n",
            "Epoch 2636, BestLoss: 0.04563635514366711, Temperature 7.96422228996145e-05, step_size 0.884523554524993, test_acc: 0.5477\n",
            "Epoch 2637, BestLoss: 0.04557486769669106, Temperature 7.566011175463378e-05, step_size 0.8844351021695405, test_acc: 0.5472\n",
            "Epoch 2638, BestLoss: 0.04552369997507129, Temperature 7.187710616690208e-05, step_size 0.8843466586593235, test_acc: 0.5482\n",
            "Epoch 2639, BestLoss: 0.04552369997507129, Temperature 6.828325085855697e-05, step_size 0.8842582239934575, test_acc: 0.5482\n",
            "Epoch 2640, BestLoss: 0.04544325907494471, Temperature 7.187710616690208e-05, step_size 0.8846120157265657, test_acc: 0.5493\n",
            "Epoch 2641, BestLoss: 0.04544325907494471, Temperature 6.828325085855697e-05, step_size 0.884523554524993, test_acc: 0.5493\n",
            "Epoch 2642, BestLoss: 0.04542424381016667, Temperature 7.187710616690208e-05, step_size 0.884523554524993, test_acc: 0.5492\n",
            "Epoch 2643, BestLoss: 0.045447381343299564, Temperature 6.828325085855697e-05, step_size 0.8844351021695405, test_acc: 0.5498\n",
            "Epoch 2644, BestLoss: 0.045447381343299564, Temperature 6.486908831562912e-05, step_size 0.8843466586593235, test_acc: 0.5498\n",
            "Epoch 2645, BestLoss: 0.04549308037531639, Temperature 6.828325085855697e-05, step_size 0.8844351021695405, test_acc: 0.5479\n",
            "Epoch 2646, BestLoss: 0.0455211428607345, Temperature 6.486908831562912e-05, step_size 0.8843466586593235, test_acc: 0.5479\n",
            "Epoch 2647, BestLoss: 0.0455211428607345, Temperature 6.162563389984766e-05, step_size 0.8842582239934575, test_acc: 0.5479\n",
            "Epoch 2648, BestLoss: 0.045454794093298036, Temperature 6.486908831562912e-05, step_size 0.8843466586593235, test_acc: 0.549\n",
            "Epoch 2649, BestLoss: 0.045454794093298036, Temperature 6.162563389984766e-05, step_size 0.8842582239934575, test_acc: 0.549\n",
            "Epoch 2650, BestLoss: 0.045454794093298036, Temperature 6.486908831562912e-05, step_size 0.8842582239934575, test_acc: 0.549\n",
            "Epoch 2651, BestLoss: 0.045496658823172186, Temperature 6.828325085855697e-05, step_size 0.8841697981710582, test_acc: 0.5477\n",
            "Epoch 2652, BestLoss: 0.045496658823172186, Temperature 6.486908831562912e-05, step_size 0.8840813811912411, test_acc: 0.5477\n",
            "Epoch 2653, BestLoss: 0.045496658823172186, Temperature 6.828325085855697e-05, step_size 0.8840813811912411, test_acc: 0.5477\n",
            "Epoch 2654, BestLoss: 0.045496658823172186, Temperature 7.187710616690208e-05, step_size 0.883992973053122, test_acc: 0.5477\n",
            "Epoch 2655, BestLoss: 0.045496658823172186, Temperature 7.566011175463378e-05, step_size 0.8839045737558167, test_acc: 0.5477\n",
            "Epoch 2656, BestLoss: 0.04547122578953931, Temperature 7.96422228996145e-05, step_size 0.8838161832984411, test_acc: 0.5495\n",
            "Epoch 2657, BestLoss: 0.04538322898258929, Temperature 7.566011175463378e-05, step_size 0.8837278016801113, test_acc: 0.5494\n",
            "Epoch 2658, BestLoss: 0.0453383695950334, Temperature 7.187710616690208e-05, step_size 0.8836394288999433, test_acc: 0.5514\n",
            "Epoch 2659, BestLoss: 0.04533245479604976, Temperature 6.828325085855697e-05, step_size 0.8835510649570533, test_acc: 0.5504\n",
            "Epoch 2660, BestLoss: 0.04533245479604976, Temperature 6.486908831562912e-05, step_size 0.8834627098505575, test_acc: 0.5504\n",
            "Epoch 2661, BestLoss: 0.0453221890824916, Temperature 6.828325085855697e-05, step_size 0.8837278016801113, test_acc: 0.5503\n",
            "Epoch 2662, BestLoss: 0.04527293209422585, Temperature 6.486908831562912e-05, step_size 0.8836394288999433, test_acc: 0.55\n",
            "Epoch 2663, BestLoss: 0.04527293209422585, Temperature 6.162563389984766e-05, step_size 0.8835510649570533, test_acc: 0.55\n",
            "Epoch 2664, BestLoss: 0.04536828805128661, Temperature 6.486908831562912e-05, step_size 0.8836394288999433, test_acc: 0.5502\n",
            "Epoch 2665, BestLoss: 0.04536828805128661, Temperature 6.162563389984766e-05, step_size 0.8835510649570533, test_acc: 0.5502\n",
            "Epoch 2666, BestLoss: 0.04536828805128661, Temperature 6.486908831562912e-05, step_size 0.8835510649570533, test_acc: 0.5502\n",
            "Epoch 2667, BestLoss: 0.04536828805128661, Temperature 6.828325085855697e-05, step_size 0.8834627098505575, test_acc: 0.5502\n",
            "Epoch 2668, BestLoss: 0.04536828805128661, Temperature 7.187710616690208e-05, step_size 0.8833743635795724, test_acc: 0.5502\n",
            "Epoch 2669, BestLoss: 0.04547783481661353, Temperature 7.566011175463378e-05, step_size 0.8832860261432145, test_acc: 0.549\n",
            "Epoch 2670, BestLoss: 0.04545330990958485, Temperature 7.187710616690208e-05, step_size 0.8831976975406002, test_acc: 0.5488\n",
            "Epoch 2671, BestLoss: 0.0454551329868082, Temperature 6.828325085855697e-05, step_size 0.8831093777708461, test_acc: 0.5482\n",
            "Epoch 2672, BestLoss: 0.04537456163603357, Temperature 7.187710616690208e-05, step_size 0.8831976975406002, test_acc: 0.5492\n",
            "Epoch 2673, BestLoss: 0.04537456163603357, Temperature 6.828325085855697e-05, step_size 0.8831093777708461, test_acc: 0.5492\n",
            "Epoch 2674, BestLoss: 0.04537456163603357, Temperature 7.187710616690208e-05, step_size 0.8831093777708461, test_acc: 0.5492\n",
            "Epoch 2675, BestLoss: 0.045426120009727816, Temperature 7.566011175463378e-05, step_size 0.883021066833069, test_acc: 0.5489\n",
            "Epoch 2676, BestLoss: 0.0454831602761281, Temperature 7.187710616690208e-05, step_size 0.8829327647263857, test_acc: 0.5484\n",
            "Epoch 2677, BestLoss: 0.0454831602761281, Temperature 6.828325085855697e-05, step_size 0.8828444714499131, test_acc: 0.5484\n",
            "Epoch 2678, BestLoss: 0.04544564335960716, Temperature 7.187710616690208e-05, step_size 0.8829327647263857, test_acc: 0.5492\n",
            "Epoch 2679, BestLoss: 0.04554794311311481, Temperature 6.828325085855697e-05, step_size 0.8828444714499131, test_acc: 0.5468\n",
            "Epoch 2680, BestLoss: 0.04543782236723352, Temperature 6.486908831562912e-05, step_size 0.8827561870027681, test_acc: 0.5486\n",
            "Epoch 2681, BestLoss: 0.04548638537411351, Temperature 6.162563389984766e-05, step_size 0.8826679113840679, test_acc: 0.5492\n",
            "Epoch 2682, BestLoss: 0.04548638537411351, Temperature 5.8544352204855274e-05, step_size 0.8825796445929295, test_acc: 0.5492\n",
            "Epoch 2683, BestLoss: 0.045413966278839916, Temperature 6.162563389984766e-05, step_size 0.8828444714499131, test_acc: 0.5499\n",
            "Epoch 2684, BestLoss: 0.045413966278839916, Temperature 5.8544352204855274e-05, step_size 0.8827561870027681, test_acc: 0.5499\n",
            "Epoch 2685, BestLoss: 0.045413966278839916, Temperature 6.162563389984766e-05, step_size 0.8827561870027681, test_acc: 0.5499\n",
            "Epoch 2686, BestLoss: 0.045413966278839916, Temperature 6.486908831562912e-05, step_size 0.8826679113840679, test_acc: 0.5499\n",
            "Epoch 2687, BestLoss: 0.045413966278839916, Temperature 6.828325085855697e-05, step_size 0.8825796445929295, test_acc: 0.5499\n",
            "Epoch 2688, BestLoss: 0.04549984095146778, Temperature 7.187710616690208e-05, step_size 0.8824913866284702, test_acc: 0.5484\n",
            "Epoch 2689, BestLoss: 0.04540344217666209, Temperature 6.828325085855697e-05, step_size 0.8824031374898074, test_acc: 0.5475\n",
            "Epoch 2690, BestLoss: 0.04540344217666209, Temperature 6.486908831562912e-05, step_size 0.8823148971760584, test_acc: 0.5475\n",
            "Epoch 2691, BestLoss: 0.0454326691562651, Temperature 6.828325085855697e-05, step_size 0.8824031374898074, test_acc: 0.5467\n",
            "Epoch 2692, BestLoss: 0.0454326691562651, Temperature 6.486908831562912e-05, step_size 0.8823148971760584, test_acc: 0.5467\n",
            "Epoch 2693, BestLoss: 0.04543823444136097, Temperature 6.828325085855697e-05, step_size 0.8823148971760584, test_acc: 0.5493\n",
            "Epoch 2694, BestLoss: 0.04537451655818022, Temperature 6.486908831562912e-05, step_size 0.8822266656863408, test_acc: 0.547\n",
            "Epoch 2695, BestLoss: 0.04537451655818022, Temperature 6.162563389984766e-05, step_size 0.8821384430197722, test_acc: 0.547\n",
            "Epoch 2696, BestLoss: 0.04537451655818022, Temperature 6.486908831562912e-05, step_size 0.8822266656863408, test_acc: 0.547\n",
            "Epoch 2697, BestLoss: 0.04537451655818022, Temperature 6.828325085855697e-05, step_size 0.8821384430197722, test_acc: 0.547\n",
            "Epoch 2698, BestLoss: 0.04537451655818022, Temperature 7.187710616690208e-05, step_size 0.8820502291754702, test_acc: 0.547\n",
            "Epoch 2699, BestLoss: 0.04537451655818022, Temperature 7.566011175463378e-05, step_size 0.8819620241525526, test_acc: 0.547\n",
            "Epoch 2700, BestLoss: 0.04537451655818022, Temperature 7.96422228996145e-05, step_size 0.8818738279501374, test_acc: 0.547\n",
            "Epoch 2701, BestLoss: 0.04537451655818022, Temperature 8.383391884169949e-05, step_size 0.8817856405673423, test_acc: 0.547\n",
            "Epoch 2702, BestLoss: 0.04537451655818022, Temperature 8.824623035968368e-05, step_size 0.8816974620032856, test_acc: 0.547\n",
            "Epoch 2703, BestLoss: 0.04537451655818022, Temperature 9.289076879966704e-05, step_size 0.8816092922570853, test_acc: 0.547\n",
            "Epoch 2704, BestLoss: 0.04530593778149598, Temperature 9.777975663122846e-05, step_size 0.8815211313278596, test_acc: 0.5493\n",
            "Epoch 2705, BestLoss: 0.04534592559099849, Temperature 9.289076879966704e-05, step_size 0.8814329792147269, test_acc: 0.5488\n",
            "Epoch 2706, BestLoss: 0.04548880265395836, Temperature 8.824623035968368e-05, step_size 0.8813448359168053, test_acc: 0.5456\n",
            "Epoch 2707, BestLoss: 0.04548880265395836, Temperature 8.383391884169949e-05, step_size 0.8812567014332137, test_acc: 0.5456\n",
            "Epoch 2708, BestLoss: 0.04548880265395836, Temperature 8.824623035968368e-05, step_size 0.8814329792147269, test_acc: 0.5456\n",
            "Epoch 2709, BestLoss: 0.045597230279248516, Temperature 9.289076879966704e-05, step_size 0.8813448359168053, test_acc: 0.5449\n",
            "Epoch 2710, BestLoss: 0.045597230279248516, Temperature 8.824623035968368e-05, step_size 0.8812567014332137, test_acc: 0.5449\n",
            "Epoch 2711, BestLoss: 0.045597230279248516, Temperature 9.289076879966704e-05, step_size 0.8812567014332137, test_acc: 0.5449\n",
            "Epoch 2712, BestLoss: 0.04549139078387585, Temperature 9.777975663122846e-05, step_size 0.8811685757630704, test_acc: 0.548\n",
            "Epoch 2713, BestLoss: 0.045713232300146685, Temperature 9.289076879966704e-05, step_size 0.8810804589054941, test_acc: 0.544\n",
            "Epoch 2714, BestLoss: 0.045713232300146685, Temperature 8.824623035968368e-05, step_size 0.8809923508596036, test_acc: 0.544\n",
            "Epoch 2715, BestLoss: 0.045713232300146685, Temperature 9.289076879966704e-05, step_size 0.8810804589054941, test_acc: 0.544\n",
            "Epoch 2716, BestLoss: 0.04573827321242334, Temperature 9.777975663122846e-05, step_size 0.8809923508596036, test_acc: 0.5458\n",
            "Epoch 2717, BestLoss: 0.04573827321242334, Temperature 9.289076879966704e-05, step_size 0.8809042516245177, test_acc: 0.5458\n",
            "Epoch 2718, BestLoss: 0.04574831586964165, Temperature 9.777975663122846e-05, step_size 0.8809042516245177, test_acc: 0.5446\n",
            "Epoch 2719, BestLoss: 0.045702626534162384, Temperature 9.289076879966704e-05, step_size 0.8808161611993552, test_acc: 0.5442\n",
            "Epoch 2720, BestLoss: 0.045768078627545145, Temperature 8.824623035968368e-05, step_size 0.8807280795832353, test_acc: 0.5439\n",
            "Epoch 2721, BestLoss: 0.04579453807319207, Temperature 8.383391884169949e-05, step_size 0.880640006775277, test_acc: 0.5442\n",
            "Epoch 2722, BestLoss: 0.04579735277528471, Temperature 7.96422228996145e-05, step_size 0.8805519427745995, test_acc: 0.5441\n",
            "Epoch 2723, BestLoss: 0.045709092346535765, Temperature 8.383391884169949e-05, step_size 0.8808161611993552, test_acc: 0.5458\n",
            "Epoch 2724, BestLoss: 0.04569468190831111, Temperature 7.96422228996145e-05, step_size 0.8807280795832353, test_acc: 0.547\n",
            "Epoch 2725, BestLoss: 0.04569468190831111, Temperature 7.566011175463378e-05, step_size 0.880640006775277, test_acc: 0.547\n",
            "Epoch 2726, BestLoss: 0.04569468190831111, Temperature 7.96422228996145e-05, step_size 0.8807280795832353, test_acc: 0.547\n",
            "Epoch 2727, BestLoss: 0.045591632059668645, Temperature 8.383391884169949e-05, step_size 0.880640006775277, test_acc: 0.548\n",
            "Epoch 2728, BestLoss: 0.045591632059668645, Temperature 7.96422228996145e-05, step_size 0.8805519427745995, test_acc: 0.548\n",
            "Epoch 2729, BestLoss: 0.045591632059668645, Temperature 8.383391884169949e-05, step_size 0.8805519427745995, test_acc: 0.548\n",
            "Epoch 2730, BestLoss: 0.045591632059668645, Temperature 8.824623035968368e-05, step_size 0.880463887580322, test_acc: 0.548\n",
            "Epoch 2731, BestLoss: 0.045591632059668645, Temperature 9.289076879966704e-05, step_size 0.880375841191564, test_acc: 0.548\n",
            "Epoch 2732, BestLoss: 0.04554362151569226, Temperature 9.777975663122846e-05, step_size 0.8802878036074449, test_acc: 0.5498\n",
            "Epoch 2733, BestLoss: 0.04549887322413785, Temperature 9.289076879966704e-05, step_size 0.8801997748270841, test_acc: 0.5493\n",
            "Epoch 2734, BestLoss: 0.04549887322413785, Temperature 8.824623035968368e-05, step_size 0.8801117548496015, test_acc: 0.5493\n",
            "Epoch 2735, BestLoss: 0.045489854191321684, Temperature 9.289076879966704e-05, step_size 0.8801997748270841, test_acc: 0.5511\n",
            "Epoch 2736, BestLoss: 0.04550761765947476, Temperature 8.824623035968368e-05, step_size 0.8801117548496015, test_acc: 0.5499\n",
            "Epoch 2737, BestLoss: 0.045687859250986076, Temperature 8.383391884169949e-05, step_size 0.8800237436741165, test_acc: 0.5478\n",
            "Epoch 2738, BestLoss: 0.045822637489986995, Temperature 7.96422228996145e-05, step_size 0.879935741299749, test_acc: 0.5453\n",
            "Epoch 2739, BestLoss: 0.04586844644651941, Temperature 7.566011175463378e-05, step_size 0.8798477477256191, test_acc: 0.5459\n",
            "Epoch 2740, BestLoss: 0.046065035575508444, Temperature 7.187710616690208e-05, step_size 0.8797597629508466, test_acc: 0.5438\n",
            "Epoch 2741, BestLoss: 0.046123178383507345, Temperature 6.828325085855697e-05, step_size 0.8796717869745515, test_acc: 0.5418\n",
            "Epoch 2742, BestLoss: 0.04621936581050302, Temperature 6.486908831562912e-05, step_size 0.8795838197958541, test_acc: 0.5419\n",
            "Epoch 2743, BestLoss: 0.04621936581050302, Temperature 6.162563389984766e-05, step_size 0.8794958614138745, test_acc: 0.5419\n",
            "Epoch 2744, BestLoss: 0.04621936581050302, Temperature 6.486908831562912e-05, step_size 0.8801117548496015, test_acc: 0.5419\n",
            "Epoch 2745, BestLoss: 0.04612059457915095, Temperature 6.828325085855697e-05, step_size 0.8800237436741165, test_acc: 0.5435\n",
            "Epoch 2746, BestLoss: 0.04619105444097621, Temperature 6.486908831562912e-05, step_size 0.879935741299749, test_acc: 0.5441\n",
            "Epoch 2747, BestLoss: 0.04617666517049471, Temperature 6.162563389984766e-05, step_size 0.8798477477256191, test_acc: 0.5441\n",
            "Epoch 2748, BestLoss: 0.04617666517049471, Temperature 5.8544352204855274e-05, step_size 0.8797597629508466, test_acc: 0.5441\n",
            "Epoch 2749, BestLoss: 0.04616661852045682, Temperature 6.162563389984766e-05, step_size 0.879935741299749, test_acc: 0.5439\n",
            "Epoch 2750, BestLoss: 0.04615343499661051, Temperature 5.8544352204855274e-05, step_size 0.8798477477256191, test_acc: 0.5427\n",
            "Epoch 2751, BestLoss: 0.04615343499661051, Temperature 5.561713459461251e-05, step_size 0.8797597629508466, test_acc: 0.5427\n",
            "Epoch 2752, BestLoss: 0.04615343499661051, Temperature 5.8544352204855274e-05, step_size 0.8798477477256191, test_acc: 0.5427\n",
            "Epoch 2753, BestLoss: 0.04615343499661051, Temperature 6.162563389984766e-05, step_size 0.8797597629508466, test_acc: 0.5427\n",
            "Epoch 2754, BestLoss: 0.04617998938090688, Temperature 6.486908831562912e-05, step_size 0.8796717869745515, test_acc: 0.5421\n",
            "Epoch 2755, BestLoss: 0.046176265174104225, Temperature 6.162563389984766e-05, step_size 0.8795838197958541, test_acc: 0.5418\n",
            "Epoch 2756, BestLoss: 0.046129793707529725, Temperature 5.8544352204855274e-05, step_size 0.8794958614138745, test_acc: 0.5433\n",
            "Epoch 2757, BestLoss: 0.046129793707529725, Temperature 5.561713459461251e-05, step_size 0.8794079118277331, test_acc: 0.5433\n",
            "Epoch 2758, BestLoss: 0.046204101896791014, Temperature 5.8544352204855274e-05, step_size 0.8795838197958541, test_acc: 0.5425\n",
            "Epoch 2759, BestLoss: 0.046204101896791014, Temperature 5.561713459461251e-05, step_size 0.8794958614138745, test_acc: 0.5425\n",
            "Epoch 2760, BestLoss: 0.046204101896791014, Temperature 5.8544352204855274e-05, step_size 0.8794958614138745, test_acc: 0.5425\n",
            "Epoch 2761, BestLoss: 0.04606566527461788, Temperature 6.162563389984766e-05, step_size 0.8794079118277331, test_acc: 0.5423\n",
            "Epoch 2762, BestLoss: 0.04606566527461788, Temperature 5.8544352204855274e-05, step_size 0.8793199710365504, test_acc: 0.5423\n",
            "Epoch 2763, BestLoss: 0.046085295838827756, Temperature 6.162563389984766e-05, step_size 0.8793199710365504, test_acc: 0.5419\n",
            "Epoch 2764, BestLoss: 0.04610804525171632, Temperature 5.8544352204855274e-05, step_size 0.8792320390394467, test_acc: 0.5429\n",
            "Epoch 2765, BestLoss: 0.04614788624370864, Temperature 5.561713459461251e-05, step_size 0.8791441158355427, test_acc: 0.5435\n",
            "Epoch 2766, BestLoss: 0.04614788624370864, Temperature 5.283627786488188e-05, step_size 0.8790562014239592, test_acc: 0.5435\n",
            "Epoch 2767, BestLoss: 0.04614788624370864, Temperature 5.561713459461251e-05, step_size 0.8792320390394467, test_acc: 0.5435\n",
            "Epoch 2768, BestLoss: 0.04609980442957376, Temperature 5.8544352204855274e-05, step_size 0.8791441158355427, test_acc: 0.5424\n",
            "Epoch 2769, BestLoss: 0.04609980442957376, Temperature 5.561713459461251e-05, step_size 0.8790562014239592, test_acc: 0.5424\n",
            "Epoch 2770, BestLoss: 0.04609980442957376, Temperature 5.8544352204855274e-05, step_size 0.8790562014239592, test_acc: 0.5424\n",
            "Epoch 2771, BestLoss: 0.04612118464632435, Temperature 6.162563389984766e-05, step_size 0.8789682958038169, test_acc: 0.5417\n",
            "Epoch 2772, BestLoss: 0.04612118464632435, Temperature 5.8544352204855274e-05, step_size 0.8788803989742365, test_acc: 0.5417\n",
            "Epoch 2773, BestLoss: 0.04609406357362059, Temperature 6.162563389984766e-05, step_size 0.8788803989742365, test_acc: 0.5428\n",
            "Epoch 2774, BestLoss: 0.0461766299499655, Temperature 5.8544352204855274e-05, step_size 0.8787925109343391, test_acc: 0.5432\n",
            "Epoch 2775, BestLoss: 0.04613649284871052, Temperature 5.561713459461251e-05, step_size 0.8787046316832456, test_acc: 0.5435\n",
            "Epoch 2776, BestLoss: 0.04613649284871052, Temperature 5.283627786488188e-05, step_size 0.8786167612200774, test_acc: 0.5435\n",
            "Epoch 2777, BestLoss: 0.04613649284871052, Temperature 5.561713459461251e-05, step_size 0.8787925109343391, test_acc: 0.5435\n",
            "Epoch 2778, BestLoss: 0.04607316854750603, Temperature 5.8544352204855274e-05, step_size 0.8787046316832456, test_acc: 0.5434\n",
            "Epoch 2779, BestLoss: 0.04607316854750603, Temperature 5.561713459461251e-05, step_size 0.8786167612200774, test_acc: 0.5434\n",
            "Epoch 2780, BestLoss: 0.04607316854750603, Temperature 5.8544352204855274e-05, step_size 0.8786167612200774, test_acc: 0.5434\n",
            "Epoch 2781, BestLoss: 0.04607316854750603, Temperature 6.162563389984766e-05, step_size 0.8785288995439554, test_acc: 0.5434\n",
            "Epoch 2782, BestLoss: 0.04609952558814641, Temperature 6.486908831562912e-05, step_size 0.878441046654001, test_acc: 0.5435\n",
            "Epoch 2783, BestLoss: 0.04618463799832356, Temperature 6.162563389984766e-05, step_size 0.8783532025493357, test_acc: 0.5426\n",
            "Epoch 2784, BestLoss: 0.04618463799832356, Temperature 5.8544352204855274e-05, step_size 0.8782653672290808, test_acc: 0.5426\n",
            "Epoch 2785, BestLoss: 0.04618463799832356, Temperature 6.162563389984766e-05, step_size 0.8783532025493357, test_acc: 0.5426\n",
            "Epoch 2786, BestLoss: 0.04617418357304512, Temperature 6.486908831562912e-05, step_size 0.8782653672290808, test_acc: 0.5446\n",
            "Epoch 2787, BestLoss: 0.046131002894580136, Temperature 6.162563389984766e-05, step_size 0.8781775406923579, test_acc: 0.5441\n",
            "Epoch 2788, BestLoss: 0.04622339035187488, Temperature 5.8544352204855274e-05, step_size 0.8780897229382887, test_acc: 0.5419\n",
            "Epoch 2789, BestLoss: 0.04622339035187488, Temperature 5.561713459461251e-05, step_size 0.8780019139659949, test_acc: 0.5419\n",
            "Epoch 2790, BestLoss: 0.04612929389910835, Temperature 5.8544352204855274e-05, step_size 0.8781775406923579, test_acc: 0.5424\n",
            "Epoch 2791, BestLoss: 0.04612929389910835, Temperature 5.561713459461251e-05, step_size 0.8780897229382887, test_acc: 0.5424\n",
            "Epoch 2792, BestLoss: 0.0461891955468458, Temperature 5.8544352204855274e-05, step_size 0.8780897229382887, test_acc: 0.5424\n",
            "Epoch 2793, BestLoss: 0.0461891955468458, Temperature 5.561713459461251e-05, step_size 0.8780019139659949, test_acc: 0.5424\n",
            "Epoch 2794, BestLoss: 0.046146590018646565, Temperature 5.8544352204855274e-05, step_size 0.8780019139659949, test_acc: 0.5419\n",
            "Epoch 2795, BestLoss: 0.046146590018646565, Temperature 5.561713459461251e-05, step_size 0.8779141137745984, test_acc: 0.5419\n",
            "Epoch 2796, BestLoss: 0.046146590018646565, Temperature 5.8544352204855274e-05, step_size 0.8779141137745984, test_acc: 0.5419\n",
            "Epoch 2797, BestLoss: 0.046146590018646565, Temperature 6.162563389984766e-05, step_size 0.8778263223632209, test_acc: 0.5419\n",
            "Epoch 2798, BestLoss: 0.04629482219133421, Temperature 6.486908831562912e-05, step_size 0.8777385397309846, test_acc: 0.5407\n",
            "Epoch 2799, BestLoss: 0.04629482219133421, Temperature 6.162563389984766e-05, step_size 0.8776507658770115, test_acc: 0.5407\n",
            "Epoch 2800, BestLoss: 0.04629482219133421, Temperature 6.486908831562912e-05, step_size 0.8776507658770115, test_acc: 0.5407\n",
            "Epoch 2801, BestLoss: 0.04629482219133421, Temperature 6.828325085855697e-05, step_size 0.8775630008004238, test_acc: 0.5407\n",
            "Epoch 2802, BestLoss: 0.04629482219133421, Temperature 7.187710616690208e-05, step_size 0.8774752445003438, test_acc: 0.5407\n",
            "Epoch 2803, BestLoss: 0.04629482219133421, Temperature 7.566011175463378e-05, step_size 0.8773874969758937, test_acc: 0.5407\n",
            "Epoch 2804, BestLoss: 0.04629482219133421, Temperature 7.96422228996145e-05, step_size 0.8772997582261961, test_acc: 0.5407\n",
            "Epoch 2805, BestLoss: 0.04629482219133421, Temperature 8.383391884169949e-05, step_size 0.8772120282503735, test_acc: 0.5407\n",
            "Epoch 2806, BestLoss: 0.046207912329654814, Temperature 8.824623035968368e-05, step_size 0.8771243070475484, test_acc: 0.5414\n",
            "Epoch 2807, BestLoss: 0.046207912329654814, Temperature 8.383391884169949e-05, step_size 0.8770365946168437, test_acc: 0.5414\n",
            "Epoch 2808, BestLoss: 0.046207912329654814, Temperature 8.824623035968368e-05, step_size 0.8770365946168437, test_acc: 0.5414\n",
            "Epoch 2809, BestLoss: 0.04624329836891486, Temperature 9.289076879966704e-05, step_size 0.876948890957382, test_acc: 0.5416\n",
            "Epoch 2810, BestLoss: 0.04627658276981847, Temperature 8.824623035968368e-05, step_size 0.8768611960682863, test_acc: 0.5415\n",
            "Epoch 2811, BestLoss: 0.04627658276981847, Temperature 8.383391884169949e-05, step_size 0.8767735099486794, test_acc: 0.5415\n",
            "Epoch 2812, BestLoss: 0.0463583226341199, Temperature 8.824623035968368e-05, step_size 0.8768611960682863, test_acc: 0.5408\n",
            "Epoch 2813, BestLoss: 0.046279178233516315, Temperature 8.383391884169949e-05, step_size 0.8767735099486794, test_acc: 0.5408\n",
            "Epoch 2814, BestLoss: 0.046279178233516315, Temperature 7.96422228996145e-05, step_size 0.8766858325976845, test_acc: 0.5408\n",
            "Epoch 2815, BestLoss: 0.046538091766470835, Temperature 8.383391884169949e-05, step_size 0.8767735099486794, test_acc: 0.5405\n",
            "Epoch 2816, BestLoss: 0.046538091766470835, Temperature 7.96422228996145e-05, step_size 0.8766858325976845, test_acc: 0.5405\n",
            "Epoch 2817, BestLoss: 0.046538091766470835, Temperature 8.383391884169949e-05, step_size 0.8766858325976845, test_acc: 0.5405\n",
            "Epoch 2818, BestLoss: 0.046538091766470835, Temperature 8.824623035968368e-05, step_size 0.8765981640144248, test_acc: 0.5405\n",
            "Epoch 2819, BestLoss: 0.04638160680277933, Temperature 9.289076879966704e-05, step_size 0.8765105041980233, test_acc: 0.5407\n",
            "Epoch 2820, BestLoss: 0.04638160680277933, Temperature 8.824623035968368e-05, step_size 0.8764228531476036, test_acc: 0.5407\n",
            "Epoch 2821, BestLoss: 0.04643698910327965, Temperature 9.289076879966704e-05, step_size 0.8764228531476036, test_acc: 0.5398\n",
            "Epoch 2822, BestLoss: 0.046199392872222036, Temperature 8.824623035968368e-05, step_size 0.8763352108622888, test_acc: 0.5421\n",
            "Epoch 2823, BestLoss: 0.046199392872222036, Temperature 8.383391884169949e-05, step_size 0.8762475773412026, test_acc: 0.5421\n",
            "Epoch 2824, BestLoss: 0.04622774334588548, Temperature 8.824623035968368e-05, step_size 0.8763352108622888, test_acc: 0.5403\n",
            "Epoch 2825, BestLoss: 0.04622774334588548, Temperature 8.383391884169949e-05, step_size 0.8762475773412026, test_acc: 0.5403\n",
            "Epoch 2826, BestLoss: 0.04603327548887018, Temperature 8.824623035968368e-05, step_size 0.8762475773412026, test_acc: 0.5431\n",
            "Epoch 2827, BestLoss: 0.04603327548887018, Temperature 8.383391884169949e-05, step_size 0.8761599525834685, test_acc: 0.5431\n",
            "Epoch 2828, BestLoss: 0.04603327548887018, Temperature 8.824623035968368e-05, step_size 0.8761599525834685, test_acc: 0.5431\n",
            "Epoch 2829, BestLoss: 0.04603327548887018, Temperature 9.289076879966704e-05, step_size 0.8760723365882102, test_acc: 0.5431\n",
            "Epoch 2830, BestLoss: 0.04603789030737581, Temperature 9.777975663122846e-05, step_size 0.8759847293545513, test_acc: 0.5425\n",
            "Epoch 2831, BestLoss: 0.04603789030737581, Temperature 9.289076879966704e-05, step_size 0.8758971308816158, test_acc: 0.5425\n",
            "Epoch 2832, BestLoss: 0.04605750567552249, Temperature 9.777975663122846e-05, step_size 0.8758971308816158, test_acc: 0.5422\n",
            "Epoch 2833, BestLoss: 0.04606945185419846, Temperature 9.289076879966704e-05, step_size 0.8758095411685276, test_acc: 0.5425\n",
            "Epoch 2834, BestLoss: 0.04614400576984387, Temperature 8.824623035968368e-05, step_size 0.8757219602144107, test_acc: 0.543\n",
            "Epoch 2835, BestLoss: 0.04613809542491989, Temperature 8.383391884169949e-05, step_size 0.8756343880183893, test_acc: 0.5421\n",
            "Epoch 2836, BestLoss: 0.04598292498544598, Temperature 7.96422228996145e-05, step_size 0.8755468245795875, test_acc: 0.5435\n",
            "Epoch 2837, BestLoss: 0.04595519942681806, Temperature 7.566011175463378e-05, step_size 0.8754592698971296, test_acc: 0.5458\n",
            "Epoch 2838, BestLoss: 0.04615483946264623, Temperature 7.187710616690208e-05, step_size 0.87537172397014, test_acc: 0.5427\n",
            "Epoch 2839, BestLoss: 0.04610185595617198, Temperature 6.828325085855697e-05, step_size 0.875284186797743, test_acc: 0.5435\n",
            "Epoch 2840, BestLoss: 0.04610185595617198, Temperature 6.486908831562912e-05, step_size 0.8751966583790632, test_acc: 0.5435\n",
            "Epoch 2841, BestLoss: 0.04605480728191672, Temperature 6.828325085855697e-05, step_size 0.8758095411685276, test_acc: 0.5419\n",
            "Epoch 2842, BestLoss: 0.046186038025636596, Temperature 6.486908831562912e-05, step_size 0.8757219602144107, test_acc: 0.5434\n",
            "Epoch 2843, BestLoss: 0.046186038025636596, Temperature 6.162563389984766e-05, step_size 0.8756343880183893, test_acc: 0.5434\n",
            "Epoch 2844, BestLoss: 0.046186038025636596, Temperature 6.486908831562912e-05, step_size 0.8757219602144107, test_acc: 0.5434\n",
            "Epoch 2845, BestLoss: 0.04616446562674215, Temperature 6.828325085855697e-05, step_size 0.8756343880183893, test_acc: 0.5434\n",
            "Epoch 2846, BestLoss: 0.04611999133276615, Temperature 6.486908831562912e-05, step_size 0.8755468245795875, test_acc: 0.5442\n",
            "Epoch 2847, BestLoss: 0.04611999133276615, Temperature 6.162563389984766e-05, step_size 0.8754592698971296, test_acc: 0.5442\n",
            "Epoch 2848, BestLoss: 0.04611999133276615, Temperature 6.486908831562912e-05, step_size 0.8755468245795875, test_acc: 0.5442\n",
            "Epoch 2849, BestLoss: 0.0461645830234516, Temperature 6.828325085855697e-05, step_size 0.8754592698971296, test_acc: 0.5433\n",
            "Epoch 2850, BestLoss: 0.04622827904042315, Temperature 6.486908831562912e-05, step_size 0.87537172397014, test_acc: 0.5434\n",
            "Epoch 2851, BestLoss: 0.04622827904042315, Temperature 6.162563389984766e-05, step_size 0.875284186797743, test_acc: 0.5434\n",
            "Epoch 2852, BestLoss: 0.046226554712124585, Temperature 6.486908831562912e-05, step_size 0.87537172397014, test_acc: 0.5447\n",
            "Epoch 2853, BestLoss: 0.046226554712124585, Temperature 6.828325085855697e-05, step_size 0.875284186797743, test_acc: 0.5447\n",
            "Epoch 2854, BestLoss: 0.046226554712124585, Temperature 7.187710616690208e-05, step_size 0.8751966583790632, test_acc: 0.5447\n",
            "Epoch 2855, BestLoss: 0.04621305557756186, Temperature 7.566011175463378e-05, step_size 0.8751091387132254, test_acc: 0.5449\n",
            "Epoch 2856, BestLoss: 0.04623079358232102, Temperature 7.187710616690208e-05, step_size 0.8750216277993541, test_acc: 0.5433\n",
            "Epoch 2857, BestLoss: 0.04623079358232102, Temperature 6.828325085855697e-05, step_size 0.8749341256365741, test_acc: 0.5433\n",
            "Epoch 2858, BestLoss: 0.04616771177088614, Temperature 7.187710616690208e-05, step_size 0.8750216277993541, test_acc: 0.5448\n",
            "Epoch 2859, BestLoss: 0.04616771177088614, Temperature 6.828325085855697e-05, step_size 0.8749341256365741, test_acc: 0.5448\n",
            "Epoch 2860, BestLoss: 0.04616771177088614, Temperature 7.187710616690208e-05, step_size 0.8749341256365741, test_acc: 0.5448\n",
            "Epoch 2861, BestLoss: 0.04616771177088614, Temperature 7.566011175463378e-05, step_size 0.8748466322240105, test_acc: 0.5448\n",
            "Epoch 2862, BestLoss: 0.04612427386162583, Temperature 7.96422228996145e-05, step_size 0.8747591475607881, test_acc: 0.5437\n",
            "Epoch 2863, BestLoss: 0.04610080661148504, Temperature 7.566011175463378e-05, step_size 0.874671671646032, test_acc: 0.545\n",
            "Epoch 2864, BestLoss: 0.04605790523124435, Temperature 7.187710616690208e-05, step_size 0.8745842044788674, test_acc: 0.5469\n",
            "Epoch 2865, BestLoss: 0.04602267998009411, Temperature 6.828325085855697e-05, step_size 0.8744967460584195, test_acc: 0.5464\n",
            "Epoch 2866, BestLoss: 0.04603489686528582, Temperature 6.486908831562912e-05, step_size 0.8744092963838137, test_acc: 0.5459\n",
            "Epoch 2867, BestLoss: 0.04603489686528582, Temperature 6.162563389984766e-05, step_size 0.8743218554541753, test_acc: 0.5459\n",
            "Epoch 2868, BestLoss: 0.04603489686528582, Temperature 6.486908831562912e-05, step_size 0.874671671646032, test_acc: 0.5459\n",
            "Epoch 2869, BestLoss: 0.04608312214526763, Temperature 6.828325085855697e-05, step_size 0.8745842044788674, test_acc: 0.5479\n",
            "Epoch 2870, BestLoss: 0.04608312214526763, Temperature 6.486908831562912e-05, step_size 0.8744967460584195, test_acc: 0.5479\n",
            "Epoch 2871, BestLoss: 0.04608312214526763, Temperature 6.828325085855697e-05, step_size 0.8744967460584195, test_acc: 0.5479\n",
            "Epoch 2872, BestLoss: 0.04608312214526763, Temperature 7.187710616690208e-05, step_size 0.8744092963838137, test_acc: 0.5479\n",
            "Epoch 2873, BestLoss: 0.04608312214526763, Temperature 7.566011175463378e-05, step_size 0.8743218554541753, test_acc: 0.5479\n",
            "Epoch 2874, BestLoss: 0.046150141182611286, Temperature 7.96422228996145e-05, step_size 0.8742344232686299, test_acc: 0.5466\n",
            "Epoch 2875, BestLoss: 0.046150141182611286, Temperature 7.566011175463378e-05, step_size 0.8741469998263031, test_acc: 0.5466\n",
            "Epoch 2876, BestLoss: 0.046021480759454655, Temperature 7.96422228996145e-05, step_size 0.8741469998263031, test_acc: 0.5483\n",
            "Epoch 2877, BestLoss: 0.04598965725662756, Temperature 7.566011175463378e-05, step_size 0.8740595851263204, test_acc: 0.5476\n",
            "Epoch 2878, BestLoss: 0.0460149202147505, Temperature 7.187710616690208e-05, step_size 0.8739721791678078, test_acc: 0.5482\n",
            "Epoch 2879, BestLoss: 0.0460149202147505, Temperature 6.828325085855697e-05, step_size 0.873884781949891, test_acc: 0.5482\n",
            "Epoch 2880, BestLoss: 0.04599392576750108, Temperature 7.187710616690208e-05, step_size 0.8740595851263204, test_acc: 0.5492\n",
            "Epoch 2881, BestLoss: 0.04599916040941731, Temperature 6.828325085855697e-05, step_size 0.8739721791678078, test_acc: 0.5495\n",
            "Epoch 2882, BestLoss: 0.046123350637873976, Temperature 6.486908831562912e-05, step_size 0.873884781949891, test_acc: 0.5476\n",
            "Epoch 2883, BestLoss: 0.04613636983735102, Temperature 6.162563389984766e-05, step_size 0.873797393471696, test_acc: 0.5479\n",
            "Epoch 2884, BestLoss: 0.04613636983735102, Temperature 5.8544352204855274e-05, step_size 0.8737100137323489, test_acc: 0.5479\n",
            "Epoch 2885, BestLoss: 0.046086268019224934, Temperature 6.162563389984766e-05, step_size 0.8739721791678078, test_acc: 0.5481\n",
            "Epoch 2886, BestLoss: 0.04617380032113746, Temperature 5.8544352204855274e-05, step_size 0.873884781949891, test_acc: 0.5463\n",
            "Epoch 2887, BestLoss: 0.04617380032113746, Temperature 5.561713459461251e-05, step_size 0.873797393471696, test_acc: 0.5463\n",
            "Epoch 2888, BestLoss: 0.04617380032113746, Temperature 5.8544352204855274e-05, step_size 0.873884781949891, test_acc: 0.5463\n",
            "Epoch 2889, BestLoss: 0.04609911082290833, Temperature 6.162563389984766e-05, step_size 0.873797393471696, test_acc: 0.5467\n",
            "Epoch 2890, BestLoss: 0.04610767608615805, Temperature 5.8544352204855274e-05, step_size 0.8737100137323489, test_acc: 0.5476\n",
            "Epoch 2891, BestLoss: 0.0461732154216221, Temperature 5.561713459461251e-05, step_size 0.8736226427309757, test_acc: 0.5454\n",
            "Epoch 2892, BestLoss: 0.046093150012834185, Temperature 5.283627786488188e-05, step_size 0.8735352804667026, test_acc: 0.5466\n",
            "Epoch 2893, BestLoss: 0.046093150012834185, Temperature 5.019446397163778e-05, step_size 0.8734479269386559, test_acc: 0.5466\n",
            "Epoch 2894, BestLoss: 0.04610614736997145, Temperature 5.283627786488188e-05, step_size 0.8737100137323489, test_acc: 0.5473\n",
            "Epoch 2895, BestLoss: 0.04610614736997145, Temperature 5.019446397163778e-05, step_size 0.8736226427309757, test_acc: 0.5473\n",
            "Epoch 2896, BestLoss: 0.04616191787888963, Temperature 5.283627786488188e-05, step_size 0.8736226427309757, test_acc: 0.5465\n",
            "Epoch 2897, BestLoss: 0.04616191787888963, Temperature 5.019446397163778e-05, step_size 0.8735352804667026, test_acc: 0.5465\n",
            "Epoch 2898, BestLoss: 0.04625902546402332, Temperature 5.283627786488188e-05, step_size 0.8735352804667026, test_acc: 0.5452\n",
            "Epoch 2899, BestLoss: 0.04625902546402332, Temperature 5.019446397163778e-05, step_size 0.8734479269386559, test_acc: 0.5452\n",
            "Epoch 2900, BestLoss: 0.04620841577802228, Temperature 5.283627786488188e-05, step_size 0.8734479269386559, test_acc: 0.5459\n",
            "Epoch 2901, BestLoss: 0.04620841577802228, Temperature 5.019446397163778e-05, step_size 0.873360582145962, test_acc: 0.5459\n",
            "Epoch 2902, BestLoss: 0.04620841577802228, Temperature 5.283627786488188e-05, step_size 0.873360582145962, test_acc: 0.5459\n",
            "Epoch 2903, BestLoss: 0.04620841577802228, Temperature 5.561713459461251e-05, step_size 0.8732732460877475, test_acc: 0.5459\n",
            "Epoch 2904, BestLoss: 0.04620841577802228, Temperature 5.8544352204855274e-05, step_size 0.8731859187631387, test_acc: 0.5459\n",
            "Epoch 2905, BestLoss: 0.046269775404362654, Temperature 6.162563389984766e-05, step_size 0.8730986001712624, test_acc: 0.5432\n",
            "Epoch 2906, BestLoss: 0.046269775404362654, Temperature 5.8544352204855274e-05, step_size 0.8730112903112452, test_acc: 0.5432\n",
            "Epoch 2907, BestLoss: 0.046269775404362654, Temperature 6.162563389984766e-05, step_size 0.8730112903112452, test_acc: 0.5432\n",
            "Epoch 2908, BestLoss: 0.046269775404362654, Temperature 6.486908831562912e-05, step_size 0.8729239891822141, test_acc: 0.5432\n",
            "Epoch 2909, BestLoss: 0.04635720612006583, Temperature 6.828325085855697e-05, step_size 0.8728366967832959, test_acc: 0.5436\n",
            "Epoch 2910, BestLoss: 0.04635216348183165, Temperature 6.486908831562912e-05, step_size 0.8727494131136175, test_acc: 0.5429\n",
            "Epoch 2911, BestLoss: 0.04620675950555935, Temperature 6.162563389984766e-05, step_size 0.8726621381723062, test_acc: 0.5459\n",
            "Epoch 2912, BestLoss: 0.04617164337861489, Temperature 5.8544352204855274e-05, step_size 0.8725748719584889, test_acc: 0.5447\n",
            "Epoch 2913, BestLoss: 0.04617164337861489, Temperature 5.561713459461251e-05, step_size 0.8724876144712931, test_acc: 0.5447\n",
            "Epoch 2914, BestLoss: 0.046069629212445, Temperature 5.8544352204855274e-05, step_size 0.8727494131136175, test_acc: 0.5446\n",
            "Epoch 2915, BestLoss: 0.046069629212445, Temperature 5.561713459461251e-05, step_size 0.8726621381723062, test_acc: 0.5446\n",
            "Epoch 2916, BestLoss: 0.04606464099338616, Temperature 5.8544352204855274e-05, step_size 0.8726621381723062, test_acc: 0.5443\n",
            "Epoch 2917, BestLoss: 0.046037871145279574, Temperature 5.561713459461251e-05, step_size 0.8725748719584889, test_acc: 0.5461\n",
            "Epoch 2918, BestLoss: 0.0460280028793268, Temperature 5.283627786488188e-05, step_size 0.8724876144712931, test_acc: 0.5455\n",
            "Epoch 2919, BestLoss: 0.04605086673819502, Temperature 5.019446397163778e-05, step_size 0.8724003657098459, test_acc: 0.5463\n",
            "Epoch 2920, BestLoss: 0.04605086673819502, Temperature 4.768474077305589e-05, step_size 0.8723131256732749, test_acc: 0.5463\n",
            "Epoch 2921, BestLoss: 0.04605160624857908, Temperature 5.019446397163778e-05, step_size 0.8725748719584889, test_acc: 0.5465\n",
            "Epoch 2922, BestLoss: 0.04605160624857908, Temperature 5.283627786488188e-05, step_size 0.8724876144712931, test_acc: 0.5465\n",
            "Epoch 2923, BestLoss: 0.04605160624857908, Temperature 5.561713459461251e-05, step_size 0.8724003657098459, test_acc: 0.5465\n",
            "Epoch 2924, BestLoss: 0.04604970045915283, Temperature 5.8544352204855274e-05, step_size 0.8723131256732749, test_acc: 0.5467\n",
            "Epoch 2925, BestLoss: 0.04604970045915283, Temperature 6.162563389984766e-05, step_size 0.8722258943607076, test_acc: 0.5467\n",
            "Epoch 2926, BestLoss: 0.04606635887217857, Temperature 6.486908831562912e-05, step_size 0.8721386717712716, test_acc: 0.5468\n",
            "Epoch 2927, BestLoss: 0.04606635887217857, Temperature 6.162563389984766e-05, step_size 0.8720514579040944, test_acc: 0.5468\n",
            "Epoch 2928, BestLoss: 0.04600452601633008, Temperature 6.486908831562912e-05, step_size 0.8720514579040944, test_acc: 0.5483\n",
            "Epoch 2929, BestLoss: 0.04600452601633008, Temperature 6.162563389984766e-05, step_size 0.871964252758304, test_acc: 0.5483\n",
            "Epoch 2930, BestLoss: 0.04596780554192745, Temperature 6.486908831562912e-05, step_size 0.871964252758304, test_acc: 0.549\n",
            "Epoch 2931, BestLoss: 0.04596166630984392, Temperature 6.162563389984766e-05, step_size 0.8718770563330283, test_acc: 0.5491\n",
            "Epoch 2932, BestLoss: 0.04597651703714681, Temperature 5.8544352204855274e-05, step_size 0.8717898686273949, test_acc: 0.5478\n",
            "Epoch 2933, BestLoss: 0.045887570433808235, Temperature 5.561713459461251e-05, step_size 0.8717026896405322, test_acc: 0.5479\n",
            "Epoch 2934, BestLoss: 0.04583301750476663, Temperature 5.283627786488188e-05, step_size 0.8716155193715681, test_acc: 0.5489\n",
            "Epoch 2935, BestLoss: 0.04583301750476663, Temperature 5.019446397163778e-05, step_size 0.871528357819631, test_acc: 0.5489\n",
            "Epoch 2936, BestLoss: 0.04583301750476663, Temperature 5.283627786488188e-05, step_size 0.8718770563330283, test_acc: 0.5489\n",
            "Epoch 2937, BestLoss: 0.04580303856514626, Temperature 5.561713459461251e-05, step_size 0.8717898686273949, test_acc: 0.5496\n",
            "Epoch 2938, BestLoss: 0.045779339610233866, Temperature 5.283627786488188e-05, step_size 0.8717026896405322, test_acc: 0.5508\n",
            "Epoch 2939, BestLoss: 0.045779339610233866, Temperature 5.019446397163778e-05, step_size 0.8716155193715681, test_acc: 0.5508\n",
            "Epoch 2940, BestLoss: 0.045779339610233866, Temperature 5.283627786488188e-05, step_size 0.8717026896405322, test_acc: 0.5508\n",
            "Epoch 2941, BestLoss: 0.045779339610233866, Temperature 5.561713459461251e-05, step_size 0.8716155193715681, test_acc: 0.5508\n",
            "Epoch 2942, BestLoss: 0.045779339610233866, Temperature 5.8544352204855274e-05, step_size 0.871528357819631, test_acc: 0.5508\n",
            "Epoch 2943, BestLoss: 0.04580268135792477, Temperature 6.162563389984766e-05, step_size 0.871441204983849, test_acc: 0.5504\n",
            "Epoch 2944, BestLoss: 0.04580268135792477, Temperature 5.8544352204855274e-05, step_size 0.8713540608633507, test_acc: 0.5504\n",
            "Epoch 2945, BestLoss: 0.04580268135792477, Temperature 6.162563389984766e-05, step_size 0.8713540608633507, test_acc: 0.5504\n",
            "Epoch 2946, BestLoss: 0.0457416602836882, Temperature 6.486908831562912e-05, step_size 0.8712669254572644, test_acc: 0.5493\n",
            "Epoch 2947, BestLoss: 0.0457416602836882, Temperature 6.162563389984766e-05, step_size 0.8711797987647186, test_acc: 0.5493\n",
            "Epoch 2948, BestLoss: 0.0457416602836882, Temperature 6.486908831562912e-05, step_size 0.8711797987647186, test_acc: 0.5493\n",
            "Epoch 2949, BestLoss: 0.045759934415369206, Temperature 6.828325085855697e-05, step_size 0.8710926807848421, test_acc: 0.5503\n",
            "Epoch 2950, BestLoss: 0.04582247007152811, Temperature 6.486908831562912e-05, step_size 0.8710055715167637, test_acc: 0.5506\n",
            "Epoch 2951, BestLoss: 0.04582247007152811, Temperature 6.162563389984766e-05, step_size 0.8709184709596121, test_acc: 0.5506\n",
            "Epoch 2952, BestLoss: 0.04584322865957762, Temperature 6.486908831562912e-05, step_size 0.8710055715167637, test_acc: 0.5501\n",
            "Epoch 2953, BestLoss: 0.04584322865957762, Temperature 6.162563389984766e-05, step_size 0.8709184709596121, test_acc: 0.5501\n",
            "Epoch 2954, BestLoss: 0.04584322865957762, Temperature 6.486908831562912e-05, step_size 0.8709184709596121, test_acc: 0.5501\n",
            "Epoch 2955, BestLoss: 0.04590281113973216, Temperature 6.828325085855697e-05, step_size 0.8708313791125161, test_acc: 0.5493\n",
            "Epoch 2956, BestLoss: 0.04593472759671229, Temperature 6.486908831562912e-05, step_size 0.8707442959746048, test_acc: 0.5491\n",
            "Epoch 2957, BestLoss: 0.04593472759671229, Temperature 6.162563389984766e-05, step_size 0.8706572215450074, test_acc: 0.5491\n",
            "Epoch 2958, BestLoss: 0.045978314851213946, Temperature 6.486908831562912e-05, step_size 0.8707442959746048, test_acc: 0.5485\n",
            "Epoch 2959, BestLoss: 0.04600665693581162, Temperature 6.162563389984766e-05, step_size 0.8706572215450074, test_acc: 0.548\n",
            "Epoch 2960, BestLoss: 0.04600665693581162, Temperature 5.8544352204855274e-05, step_size 0.8705701558228529, test_acc: 0.548\n",
            "Epoch 2961, BestLoss: 0.04600665693581162, Temperature 6.162563389984766e-05, step_size 0.8706572215450074, test_acc: 0.548\n",
            "Epoch 2962, BestLoss: 0.04600665693581162, Temperature 6.486908831562912e-05, step_size 0.8705701558228529, test_acc: 0.548\n",
            "Epoch 2963, BestLoss: 0.04600665693581162, Temperature 6.828325085855697e-05, step_size 0.8704830988072706, test_acc: 0.548\n",
            "Epoch 2964, BestLoss: 0.046193058490186616, Temperature 7.187710616690208e-05, step_size 0.8703960504973899, test_acc: 0.5467\n",
            "Epoch 2965, BestLoss: 0.04611992493903021, Temperature 6.828325085855697e-05, step_size 0.8703090108923401, test_acc: 0.5476\n",
            "Epoch 2966, BestLoss: 0.04611468583838097, Temperature 6.486908831562912e-05, step_size 0.870221979991251, test_acc: 0.548\n",
            "Epoch 2967, BestLoss: 0.046186297402980796, Temperature 6.162563389984766e-05, step_size 0.8701349577932518, test_acc: 0.5479\n",
            "Epoch 2968, BestLoss: 0.04613287334037732, Temperature 5.8544352204855274e-05, step_size 0.8700479442974725, test_acc: 0.5485\n",
            "Epoch 2969, BestLoss: 0.04613287334037732, Temperature 5.561713459461251e-05, step_size 0.8699609395030428, test_acc: 0.5485\n",
            "Epoch 2970, BestLoss: 0.04613287334037732, Temperature 5.8544352204855274e-05, step_size 0.8703090108923401, test_acc: 0.5485\n",
            "Epoch 2971, BestLoss: 0.046150946298606166, Temperature 6.162563389984766e-05, step_size 0.870221979991251, test_acc: 0.5484\n",
            "Epoch 2972, BestLoss: 0.04618124939914404, Temperature 5.8544352204855274e-05, step_size 0.8701349577932518, test_acc: 0.5462\n",
            "Epoch 2973, BestLoss: 0.04618124939914404, Temperature 5.561713459461251e-05, step_size 0.8700479442974725, test_acc: 0.5462\n",
            "Epoch 2974, BestLoss: 0.04618124939914404, Temperature 5.8544352204855274e-05, step_size 0.8701349577932518, test_acc: 0.5462\n",
            "Epoch 2975, BestLoss: 0.04617142739251342, Temperature 6.162563389984766e-05, step_size 0.8700479442974725, test_acc: 0.5471\n",
            "Epoch 2976, BestLoss: 0.04617142739251342, Temperature 5.8544352204855274e-05, step_size 0.8699609395030428, test_acc: 0.5471\n",
            "Epoch 2977, BestLoss: 0.04617142739251342, Temperature 6.162563389984766e-05, step_size 0.8699609395030428, test_acc: 0.5471\n",
            "Epoch 2978, BestLoss: 0.04617142739251342, Temperature 6.486908831562912e-05, step_size 0.8698739434090925, test_acc: 0.5471\n",
            "Epoch 2979, BestLoss: 0.04617871045955696, Temperature 6.828325085855697e-05, step_size 0.8697869560147516, test_acc: 0.5473\n",
            "Epoch 2980, BestLoss: 0.04603646017225662, Temperature 6.486908831562912e-05, step_size 0.8696999773191502, test_acc: 0.5483\n",
            "Epoch 2981, BestLoss: 0.04603646017225662, Temperature 6.162563389984766e-05, step_size 0.8696130073214182, test_acc: 0.5483\n",
            "Epoch 2982, BestLoss: 0.04603646017225662, Temperature 6.486908831562912e-05, step_size 0.8696999773191502, test_acc: 0.5483\n",
            "Epoch 2983, BestLoss: 0.04603646017225662, Temperature 6.828325085855697e-05, step_size 0.8696130073214182, test_acc: 0.5483\n",
            "Epoch 2984, BestLoss: 0.04603646017225662, Temperature 7.187710616690208e-05, step_size 0.8695260460206861, test_acc: 0.5483\n",
            "Epoch 2985, BestLoss: 0.046119656668886365, Temperature 7.566011175463378e-05, step_size 0.869439093416084, test_acc: 0.5474\n",
            "Epoch 2986, BestLoss: 0.046119656668886365, Temperature 7.187710616690208e-05, step_size 0.8693521495067424, test_acc: 0.5474\n",
            "Epoch 2987, BestLoss: 0.046084984955501396, Temperature 7.566011175463378e-05, step_size 0.8693521495067424, test_acc: 0.5474\n",
            "Epoch 2988, BestLoss: 0.04607786896107636, Temperature 7.187710616690208e-05, step_size 0.8692652142917918, test_acc: 0.5471\n",
            "Epoch 2989, BestLoss: 0.04612379846650302, Temperature 6.828325085855697e-05, step_size 0.8691782877703627, test_acc: 0.5475\n",
            "Epoch 2990, BestLoss: 0.04607133976716998, Temperature 6.486908831562912e-05, step_size 0.8690913699415856, test_acc: 0.548\n",
            "Epoch 2991, BestLoss: 0.04617654914389474, Temperature 6.162563389984766e-05, step_size 0.8690044608045915, test_acc: 0.5471\n",
            "Epoch 2992, BestLoss: 0.04610839927343435, Temperature 5.8544352204855274e-05, step_size 0.8689175603585111, test_acc: 0.5472\n",
            "Epoch 2993, BestLoss: 0.04605272876225019, Temperature 5.561713459461251e-05, step_size 0.8688306686024753, test_acc: 0.5487\n",
            "Epoch 2994, BestLoss: 0.04605272876225019, Temperature 5.283627786488188e-05, step_size 0.868743785535615, test_acc: 0.5487\n",
            "Epoch 2995, BestLoss: 0.046076297480754196, Temperature 5.561713459461251e-05, step_size 0.8692652142917918, test_acc: 0.548\n",
            "Epoch 2996, BestLoss: 0.046076297480754196, Temperature 5.283627786488188e-05, step_size 0.8691782877703627, test_acc: 0.548\n",
            "Epoch 2997, BestLoss: 0.04595587337808148, Temperature 5.561713459461251e-05, step_size 0.8691782877703627, test_acc: 0.5497\n",
            "Epoch 2998, BestLoss: 0.04595587337808148, Temperature 5.283627786488188e-05, step_size 0.8690913699415856, test_acc: 0.5497\n",
            "Epoch 2999, BestLoss: 0.04595587337808148, Temperature 5.561713459461251e-05, step_size 0.8690913699415856, test_acc: 0.5497\n",
            "Epoch 3000, BestLoss: 0.04595587337808148, Temperature 5.8544352204855274e-05, step_size 0.8690044608045915, test_acc: 0.5497\n",
            "Epoch 3001, BestLoss: 0.04594986053053645, Temperature 6.162563389984766e-05, step_size 0.8689175603585111, test_acc: 0.5495\n",
            "Epoch 3002, BestLoss: 0.04594986053053645, Temperature 5.8544352204855274e-05, step_size 0.8688306686024753, test_acc: 0.5495\n",
            "Epoch 3003, BestLoss: 0.04594986053053645, Temperature 6.162563389984766e-05, step_size 0.8688306686024753, test_acc: 0.5495\n",
            "Epoch 3004, BestLoss: 0.04594986053053645, Temperature 6.486908831562912e-05, step_size 0.868743785535615, test_acc: 0.5495\n",
            "Epoch 3005, BestLoss: 0.04600771782969332, Temperature 6.828325085855697e-05, step_size 0.8686569111570615, test_acc: 0.5494\n",
            "Epoch 3006, BestLoss: 0.045979716571915644, Temperature 6.486908831562912e-05, step_size 0.8685700454659457, test_acc: 0.5487\n",
            "Epoch 3007, BestLoss: 0.045979716571915644, Temperature 6.162563389984766e-05, step_size 0.8684831884613992, test_acc: 0.5487\n",
            "Epoch 3008, BestLoss: 0.045969794592180244, Temperature 6.486908831562912e-05, step_size 0.8685700454659457, test_acc: 0.5474\n",
            "Epoch 3009, BestLoss: 0.045969794592180244, Temperature 6.162563389984766e-05, step_size 0.8684831884613992, test_acc: 0.5474\n",
            "Epoch 3010, BestLoss: 0.045969794592180244, Temperature 6.486908831562912e-05, step_size 0.8684831884613992, test_acc: 0.5474\n",
            "Epoch 3011, BestLoss: 0.04602284083816128, Temperature 6.828325085855697e-05, step_size 0.8683963401425531, test_acc: 0.5481\n",
            "Epoch 3012, BestLoss: 0.04602284083816128, Temperature 6.486908831562912e-05, step_size 0.8683095005085388, test_acc: 0.5481\n",
            "Epoch 3013, BestLoss: 0.04602284083816128, Temperature 6.828325085855697e-05, step_size 0.8683095005085388, test_acc: 0.5481\n",
            "Epoch 3014, BestLoss: 0.04602284083816128, Temperature 7.187710616690208e-05, step_size 0.868222669558488, test_acc: 0.5481\n",
            "Epoch 3015, BestLoss: 0.04607853513865947, Temperature 7.566011175463378e-05, step_size 0.8681358472915321, test_acc: 0.5474\n",
            "Epoch 3016, BestLoss: 0.04612165081726135, Temperature 7.187710616690208e-05, step_size 0.868049033706803, test_acc: 0.5471\n",
            "Epoch 3017, BestLoss: 0.04612165081726135, Temperature 6.828325085855697e-05, step_size 0.8679622288034323, test_acc: 0.5471\n",
            "Epoch 3018, BestLoss: 0.04612165081726135, Temperature 7.187710616690208e-05, step_size 0.868049033706803, test_acc: 0.5471\n",
            "Epoch 3019, BestLoss: 0.046091504705386595, Temperature 7.566011175463378e-05, step_size 0.8679622288034323, test_acc: 0.5463\n",
            "Epoch 3020, BestLoss: 0.04596445942531537, Temperature 7.187710616690208e-05, step_size 0.867875432580552, test_acc: 0.5468\n",
            "Epoch 3021, BestLoss: 0.046002568154970176, Temperature 6.828325085855697e-05, step_size 0.8677886450372939, test_acc: 0.5469\n",
            "Epoch 3022, BestLoss: 0.0459766432321732, Temperature 6.486908831562912e-05, step_size 0.8677018661727902, test_acc: 0.5467\n",
            "Epoch 3023, BestLoss: 0.04602512558046254, Temperature 6.162563389984766e-05, step_size 0.8676150959861729, test_acc: 0.5461\n",
            "Epoch 3024, BestLoss: 0.045973045774660375, Temperature 5.8544352204855274e-05, step_size 0.8675283344765743, test_acc: 0.547\n",
            "Epoch 3025, BestLoss: 0.045973045774660375, Temperature 5.561713459461251e-05, step_size 0.8674415816431267, test_acc: 0.547\n",
            "Epoch 3026, BestLoss: 0.045973045774660375, Temperature 5.8544352204855274e-05, step_size 0.867875432580552, test_acc: 0.547\n",
            "Epoch 3027, BestLoss: 0.04596728286067034, Temperature 6.162563389984766e-05, step_size 0.8677886450372939, test_acc: 0.5476\n",
            "Epoch 3028, BestLoss: 0.04596728286067034, Temperature 5.8544352204855274e-05, step_size 0.8677018661727902, test_acc: 0.5476\n",
            "Epoch 3029, BestLoss: 0.04596728286067034, Temperature 6.162563389984766e-05, step_size 0.8677018661727902, test_acc: 0.5476\n",
            "Epoch 3030, BestLoss: 0.04596728286067034, Temperature 6.486908831562912e-05, step_size 0.8676150959861729, test_acc: 0.5476\n",
            "Epoch 3031, BestLoss: 0.04605048079254262, Temperature 6.828325085855697e-05, step_size 0.8675283344765743, test_acc: 0.547\n",
            "Epoch 3032, BestLoss: 0.04610632979669656, Temperature 6.486908831562912e-05, step_size 0.8674415816431267, test_acc: 0.5449\n",
            "Epoch 3033, BestLoss: 0.04617798648023846, Temperature 6.162563389984766e-05, step_size 0.8673548374849623, test_acc: 0.5443\n",
            "Epoch 3034, BestLoss: 0.04617798648023846, Temperature 5.8544352204855274e-05, step_size 0.8672681020012138, test_acc: 0.5443\n",
            "Epoch 3035, BestLoss: 0.046163264955923856, Temperature 6.162563389984766e-05, step_size 0.8674415816431267, test_acc: 0.5443\n",
            "Epoch 3036, BestLoss: 0.046207700086466054, Temperature 5.8544352204855274e-05, step_size 0.8673548374849623, test_acc: 0.5435\n",
            "Epoch 3037, BestLoss: 0.046207700086466054, Temperature 5.561713459461251e-05, step_size 0.8672681020012138, test_acc: 0.5435\n",
            "Epoch 3038, BestLoss: 0.0462397878638714, Temperature 5.8544352204855274e-05, step_size 0.8673548374849623, test_acc: 0.5443\n",
            "Epoch 3039, BestLoss: 0.046251573532990954, Temperature 5.561713459461251e-05, step_size 0.8672681020012138, test_acc: 0.5442\n",
            "Epoch 3040, BestLoss: 0.046251573532990954, Temperature 5.283627786488188e-05, step_size 0.8671813751910137, test_acc: 0.5442\n",
            "Epoch 3041, BestLoss: 0.046251573532990954, Temperature 5.561713459461251e-05, step_size 0.8672681020012138, test_acc: 0.5442\n",
            "Epoch 3042, BestLoss: 0.046177019689471216, Temperature 5.8544352204855274e-05, step_size 0.8671813751910137, test_acc: 0.5435\n",
            "Epoch 3043, BestLoss: 0.046177019689471216, Temperature 5.561713459461251e-05, step_size 0.8670946570534946, test_acc: 0.5435\n",
            "Epoch 3044, BestLoss: 0.046218212411006654, Temperature 5.8544352204855274e-05, step_size 0.8670946570534946, test_acc: 0.5423\n",
            "Epoch 3045, BestLoss: 0.046218212411006654, Temperature 5.561713459461251e-05, step_size 0.8670079475877893, test_acc: 0.5423\n",
            "Epoch 3046, BestLoss: 0.0463326033250186, Temperature 5.8544352204855274e-05, step_size 0.8670079475877893, test_acc: 0.5418\n",
            "Epoch 3047, BestLoss: 0.0463326033250186, Temperature 5.561713459461251e-05, step_size 0.8669212467930305, test_acc: 0.5418\n",
            "Epoch 3048, BestLoss: 0.046402866679128914, Temperature 5.8544352204855274e-05, step_size 0.8669212467930305, test_acc: 0.5404\n",
            "Epoch 3049, BestLoss: 0.046469011564694074, Temperature 5.561713459461251e-05, step_size 0.8668345546683512, test_acc: 0.5403\n",
            "Epoch 3050, BestLoss: 0.046469011564694074, Temperature 5.283627786488188e-05, step_size 0.8667478712128844, test_acc: 0.5403\n",
            "Epoch 3051, BestLoss: 0.0462847593712545, Temperature 5.561713459461251e-05, step_size 0.8668345546683512, test_acc: 0.5422\n",
            "Epoch 3052, BestLoss: 0.0462847593712545, Temperature 5.283627786488188e-05, step_size 0.8667478712128844, test_acc: 0.5422\n",
            "Epoch 3053, BestLoss: 0.0462847593712545, Temperature 5.561713459461251e-05, step_size 0.8667478712128844, test_acc: 0.5422\n",
            "Epoch 3054, BestLoss: 0.0462847593712545, Temperature 5.8544352204855274e-05, step_size 0.8666611964257631, test_acc: 0.5422\n",
            "Epoch 3055, BestLoss: 0.046266592004553735, Temperature 6.162563389984766e-05, step_size 0.8665745303061205, test_acc: 0.5403\n",
            "Epoch 3056, BestLoss: 0.046266592004553735, Temperature 5.8544352204855274e-05, step_size 0.8664878728530899, test_acc: 0.5403\n",
            "Epoch 3057, BestLoss: 0.046289447267336366, Temperature 6.162563389984766e-05, step_size 0.8664878728530899, test_acc: 0.5422\n",
            "Epoch 3058, BestLoss: 0.04608528965382418, Temperature 5.8544352204855274e-05, step_size 0.8664012240658047, test_acc: 0.5437\n",
            "Epoch 3059, BestLoss: 0.04607844345998694, Temperature 5.561713459461251e-05, step_size 0.8663145839433981, test_acc: 0.5439\n",
            "Epoch 3060, BestLoss: 0.04605697582997848, Temperature 5.283627786488188e-05, step_size 0.8662279524850037, test_acc: 0.5429\n",
            "Epoch 3061, BestLoss: 0.046140310104789264, Temperature 5.019446397163778e-05, step_size 0.8661413296897552, test_acc: 0.5433\n",
            "Epoch 3062, BestLoss: 0.04596471352457356, Temperature 4.768474077305589e-05, step_size 0.8660547155567863, test_acc: 0.5455\n",
            "Epoch 3063, BestLoss: 0.045818653272573576, Temperature 4.53005037344031e-05, step_size 0.8659681100852306, test_acc: 0.5478\n",
            "Epoch 3064, BestLoss: 0.045818653272573576, Temperature 4.303547854768294e-05, step_size 0.865881513274222, test_acc: 0.5478\n",
            "Epoch 3065, BestLoss: 0.04582603463654945, Temperature 4.53005037344031e-05, step_size 0.8664012240658047, test_acc: 0.5468\n",
            "Epoch 3066, BestLoss: 0.04582603463654945, Temperature 4.303547854768294e-05, step_size 0.8663145839433981, test_acc: 0.5468\n",
            "Epoch 3067, BestLoss: 0.04582603463654945, Temperature 4.53005037344031e-05, step_size 0.8663145839433981, test_acc: 0.5468\n",
            "Epoch 3068, BestLoss: 0.045831851435054985, Temperature 4.768474077305589e-05, step_size 0.8662279524850037, test_acc: 0.546\n",
            "Epoch 3069, BestLoss: 0.045831851435054985, Temperature 4.53005037344031e-05, step_size 0.8661413296897552, test_acc: 0.546\n",
            "Epoch 3070, BestLoss: 0.045831851435054985, Temperature 4.768474077305589e-05, step_size 0.8661413296897552, test_acc: 0.546\n",
            "Epoch 3071, BestLoss: 0.04573607713963988, Temperature 5.019446397163778e-05, step_size 0.8660547155567863, test_acc: 0.5455\n",
            "Epoch 3072, BestLoss: 0.04573607713963988, Temperature 4.768474077305589e-05, step_size 0.8659681100852306, test_acc: 0.5455\n",
            "Epoch 3073, BestLoss: 0.04573607713963988, Temperature 5.019446397163778e-05, step_size 0.8659681100852306, test_acc: 0.5455\n",
            "Epoch 3074, BestLoss: 0.04573607713963988, Temperature 5.283627786488188e-05, step_size 0.865881513274222, test_acc: 0.5455\n",
            "Epoch 3075, BestLoss: 0.045646725949534055, Temperature 5.561713459461251e-05, step_size 0.8657949251228946, test_acc: 0.5463\n",
            "Epoch 3076, BestLoss: 0.0456544825007201, Temperature 5.283627786488188e-05, step_size 0.8657083456303823, test_acc: 0.5462\n",
            "Epoch 3077, BestLoss: 0.0456544825007201, Temperature 5.019446397163778e-05, step_size 0.8656217747958194, test_acc: 0.5462\n",
            "Epoch 3078, BestLoss: 0.0456544825007201, Temperature 5.283627786488188e-05, step_size 0.8657083456303823, test_acc: 0.5462\n",
            "Epoch 3079, BestLoss: 0.045648352572259, Temperature 5.561713459461251e-05, step_size 0.8656217747958194, test_acc: 0.5448\n",
            "Epoch 3080, BestLoss: 0.045648352572259, Temperature 5.283627786488188e-05, step_size 0.8655352126183398, test_acc: 0.5448\n",
            "Epoch 3081, BestLoss: 0.04571488642796295, Temperature 5.561713459461251e-05, step_size 0.8655352126183398, test_acc: 0.545\n",
            "Epoch 3082, BestLoss: 0.04569721495108655, Temperature 5.283627786488188e-05, step_size 0.8654486590970779, test_acc: 0.5452\n",
            "Epoch 3083, BestLoss: 0.04572445571457699, Temperature 5.019446397163778e-05, step_size 0.8653621142311683, test_acc: 0.5455\n",
            "Epoch 3084, BestLoss: 0.04572445571457699, Temperature 4.768474077305589e-05, step_size 0.8652755780197452, test_acc: 0.5455\n",
            "Epoch 3085, BestLoss: 0.04579650118546247, Temperature 5.019446397163778e-05, step_size 0.8654486590970779, test_acc: 0.5445\n",
            "Epoch 3086, BestLoss: 0.04579650118546247, Temperature 4.768474077305589e-05, step_size 0.8653621142311683, test_acc: 0.5445\n",
            "Epoch 3087, BestLoss: 0.04574972580284363, Temperature 5.019446397163778e-05, step_size 0.8653621142311683, test_acc: 0.5467\n",
            "Epoch 3088, BestLoss: 0.04561831620196098, Temperature 4.768474077305589e-05, step_size 0.8652755780197452, test_acc: 0.548\n",
            "Epoch 3089, BestLoss: 0.04568477231398695, Temperature 4.53005037344031e-05, step_size 0.8651890504619433, test_acc: 0.548\n",
            "Epoch 3090, BestLoss: 0.04568477231398695, Temperature 4.303547854768294e-05, step_size 0.8651025315568971, test_acc: 0.548\n",
            "Epoch 3091, BestLoss: 0.045583004451600836, Temperature 4.53005037344031e-05, step_size 0.8652755780197452, test_acc: 0.5479\n",
            "Epoch 3092, BestLoss: 0.045583004451600836, Temperature 4.303547854768294e-05, step_size 0.8651890504619433, test_acc: 0.5479\n",
            "Epoch 3093, BestLoss: 0.045583004451600836, Temperature 4.53005037344031e-05, step_size 0.8651890504619433, test_acc: 0.5479\n",
            "Epoch 3094, BestLoss: 0.045583004451600836, Temperature 4.768474077305589e-05, step_size 0.8651025315568971, test_acc: 0.5479\n",
            "Epoch 3095, BestLoss: 0.045583004451600836, Temperature 5.019446397163778e-05, step_size 0.8650160213037414, test_acc: 0.5479\n",
            "Epoch 3096, BestLoss: 0.045583004451600836, Temperature 5.283627786488188e-05, step_size 0.864929519701611, test_acc: 0.5479\n",
            "Epoch 3097, BestLoss: 0.04557166436009623, Temperature 5.561713459461251e-05, step_size 0.8648430267496409, test_acc: 0.5474\n",
            "Epoch 3098, BestLoss: 0.04555455897813704, Temperature 5.283627786488188e-05, step_size 0.8647565424469659, test_acc: 0.5489\n",
            "Epoch 3099, BestLoss: 0.045416229366195146, Temperature 5.019446397163778e-05, step_size 0.8646700667927212, test_acc: 0.5508\n",
            "Epoch 3100, BestLoss: 0.045416229366195146, Temperature 4.768474077305589e-05, step_size 0.8645835997860419, test_acc: 0.5508\n",
            "Epoch 3101, BestLoss: 0.045416229366195146, Temperature 5.019446397163778e-05, step_size 0.8647565424469659, test_acc: 0.5508\n",
            "Epoch 3102, BestLoss: 0.045416229366195146, Temperature 5.283627786488188e-05, step_size 0.8646700667927212, test_acc: 0.5508\n",
            "Epoch 3103, BestLoss: 0.045378297655825066, Temperature 5.561713459461251e-05, step_size 0.8645835997860419, test_acc: 0.5525\n",
            "Epoch 3104, BestLoss: 0.045378297655825066, Temperature 5.283627786488188e-05, step_size 0.8644971414260634, test_acc: 0.5525\n",
            "Epoch 3105, BestLoss: 0.045378297655825066, Temperature 5.561713459461251e-05, step_size 0.8644971414260634, test_acc: 0.5525\n",
            "Epoch 3106, BestLoss: 0.045378297655825066, Temperature 5.8544352204855274e-05, step_size 0.8644106917119208, test_acc: 0.5525\n",
            "Epoch 3107, BestLoss: 0.04533158555404828, Temperature 6.162563389984766e-05, step_size 0.8643242506427495, test_acc: 0.5526\n",
            "Epoch 3108, BestLoss: 0.04533475087837412, Temperature 5.8544352204855274e-05, step_size 0.8642378182176853, test_acc: 0.5527\n",
            "Epoch 3109, BestLoss: 0.04535123243535378, Temperature 5.561713459461251e-05, step_size 0.8641513944358635, test_acc: 0.5534\n",
            "Epoch 3110, BestLoss: 0.0453916497295013, Temperature 5.283627786488188e-05, step_size 0.8640649792964199, test_acc: 0.5515\n",
            "Epoch 3111, BestLoss: 0.04533659273056547, Temperature 5.019446397163778e-05, step_size 0.8639785727984902, test_acc: 0.5519\n",
            "Epoch 3112, BestLoss: 0.04533453740341776, Temperature 4.768474077305589e-05, step_size 0.8638921749412104, test_acc: 0.5526\n",
            "Epoch 3113, BestLoss: 0.04532495150778641, Temperature 5.019446397163778e-05, step_size 0.8642378182176853, test_acc: 0.5525\n",
            "Epoch 3114, BestLoss: 0.045197664434654616, Temperature 4.768474077305589e-05, step_size 0.8641513944358635, test_acc: 0.5534\n",
            "Epoch 3115, BestLoss: 0.04523350960600153, Temperature 4.53005037344031e-05, step_size 0.8640649792964199, test_acc: 0.5536\n",
            "Epoch 3116, BestLoss: 0.04523350960600153, Temperature 4.303547854768294e-05, step_size 0.8639785727984902, test_acc: 0.5536\n",
            "Epoch 3117, BestLoss: 0.04523350960600153, Temperature 4.53005037344031e-05, step_size 0.8641513944358635, test_acc: 0.5536\n",
            "Epoch 3118, BestLoss: 0.04523350960600153, Temperature 4.768474077305589e-05, step_size 0.8640649792964199, test_acc: 0.5536\n",
            "Epoch 3119, BestLoss: 0.04523350960600153, Temperature 5.019446397163778e-05, step_size 0.8639785727984902, test_acc: 0.5536\n",
            "Epoch 3120, BestLoss: 0.045184811902350956, Temperature 5.283627786488188e-05, step_size 0.8638921749412104, test_acc: 0.5522\n",
            "Epoch 3121, BestLoss: 0.045215039970183314, Temperature 5.019446397163778e-05, step_size 0.8638057857237162, test_acc: 0.5527\n",
            "Epoch 3122, BestLoss: 0.04518977476603818, Temperature 4.768474077305589e-05, step_size 0.8637194051451439, test_acc: 0.554\n",
            "Epoch 3123, BestLoss: 0.04518977476603818, Temperature 4.53005037344031e-05, step_size 0.8636330332046294, test_acc: 0.554\n",
            "Epoch 3124, BestLoss: 0.045253993769048866, Temperature 4.768474077305589e-05, step_size 0.8638057857237162, test_acc: 0.5519\n",
            "Epoch 3125, BestLoss: 0.045253993769048866, Temperature 4.53005037344031e-05, step_size 0.8637194051451439, test_acc: 0.5519\n",
            "Epoch 3126, BestLoss: 0.045257929845498646, Temperature 4.768474077305589e-05, step_size 0.8637194051451439, test_acc: 0.5527\n",
            "Epoch 3127, BestLoss: 0.045263038565877954, Temperature 4.53005037344031e-05, step_size 0.8636330332046294, test_acc: 0.5525\n",
            "Epoch 3128, BestLoss: 0.04525183650476456, Temperature 4.303547854768294e-05, step_size 0.8635466699013089, test_acc: 0.5529\n",
            "Epoch 3129, BestLoss: 0.04525183650476456, Temperature 4.0883704620298796e-05, step_size 0.8634603152343188, test_acc: 0.5529\n",
            "Epoch 3130, BestLoss: 0.04525183650476456, Temperature 4.303547854768294e-05, step_size 0.8636330332046294, test_acc: 0.5529\n",
            "Epoch 3131, BestLoss: 0.04525183650476456, Temperature 4.53005037344031e-05, step_size 0.8635466699013089, test_acc: 0.5529\n",
            "Epoch 3132, BestLoss: 0.045204807081451276, Temperature 4.768474077305589e-05, step_size 0.8634603152343188, test_acc: 0.5534\n",
            "Epoch 3133, BestLoss: 0.045204784439682524, Temperature 4.53005037344031e-05, step_size 0.8633739692027953, test_acc: 0.5535\n",
            "Epoch 3134, BestLoss: 0.045204784439682524, Temperature 4.768474077305589e-05, step_size 0.8633739692027953, test_acc: 0.5535\n",
            "Epoch 3135, BestLoss: 0.045204784439682524, Temperature 5.019446397163778e-05, step_size 0.863287631805875, test_acc: 0.5535\n",
            "Epoch 3136, BestLoss: 0.045204784439682524, Temperature 5.283627786488188e-05, step_size 0.8632013030426944, test_acc: 0.5535\n",
            "Epoch 3137, BestLoss: 0.045204784439682524, Temperature 5.561713459461251e-05, step_size 0.8631149829123901, test_acc: 0.5535\n",
            "Epoch 3138, BestLoss: 0.045204784439682524, Temperature 5.8544352204855274e-05, step_size 0.8630286714140989, test_acc: 0.5535\n",
            "Epoch 3139, BestLoss: 0.04526831773759622, Temperature 6.162563389984766e-05, step_size 0.8629423685469575, test_acc: 0.5535\n",
            "Epoch 3140, BestLoss: 0.04526831773759622, Temperature 5.8544352204855274e-05, step_size 0.8628560743101028, test_acc: 0.5535\n",
            "Epoch 3141, BestLoss: 0.04526831773759622, Temperature 6.162563389984766e-05, step_size 0.8628560743101028, test_acc: 0.5535\n",
            "Epoch 3142, BestLoss: 0.04526831773759622, Temperature 6.486908831562912e-05, step_size 0.8627697887026718, test_acc: 0.5535\n",
            "Epoch 3143, BestLoss: 0.04531685783679137, Temperature 6.828325085855697e-05, step_size 0.8626835117238016, test_acc: 0.553\n",
            "Epoch 3144, BestLoss: 0.04531685783679137, Temperature 6.486908831562912e-05, step_size 0.8625972433726292, test_acc: 0.553\n",
            "Epoch 3145, BestLoss: 0.04531685783679137, Temperature 6.828325085855697e-05, step_size 0.8625972433726292, test_acc: 0.553\n",
            "Epoch 3146, BestLoss: 0.045292824526368645, Temperature 7.187710616690208e-05, step_size 0.8625109836482919, test_acc: 0.5532\n",
            "Epoch 3147, BestLoss: 0.04528302682923334, Temperature 6.828325085855697e-05, step_size 0.8624247325499271, test_acc: 0.554\n",
            "Epoch 3148, BestLoss: 0.045258324237702034, Temperature 6.486908831562912e-05, step_size 0.8623384900766722, test_acc: 0.5532\n",
            "Epoch 3149, BestLoss: 0.045258324237702034, Temperature 6.162563389984766e-05, step_size 0.8622522562276645, test_acc: 0.5532\n",
            "Epoch 3150, BestLoss: 0.045258324237702034, Temperature 6.486908831562912e-05, step_size 0.8624247325499271, test_acc: 0.5532\n",
            "Epoch 3151, BestLoss: 0.045258324237702034, Temperature 6.828325085855697e-05, step_size 0.8623384900766722, test_acc: 0.5532\n",
            "Epoch 3152, BestLoss: 0.04525249962796815, Temperature 7.187710616690208e-05, step_size 0.8622522562276645, test_acc: 0.5528\n",
            "Epoch 3153, BestLoss: 0.04525249962796815, Temperature 6.828325085855697e-05, step_size 0.8621660310020418, test_acc: 0.5528\n",
            "Epoch 3154, BestLoss: 0.04528668227998358, Temperature 7.187710616690208e-05, step_size 0.8621660310020418, test_acc: 0.553\n",
            "Epoch 3155, BestLoss: 0.04538447046707068, Temperature 6.828325085855697e-05, step_size 0.8620798143989417, test_acc: 0.5521\n",
            "Epoch 3156, BestLoss: 0.04529324695141789, Temperature 6.486908831562912e-05, step_size 0.8619936064175018, test_acc: 0.5534\n",
            "Epoch 3157, BestLoss: 0.04529324695141789, Temperature 6.162563389984766e-05, step_size 0.8619074070568601, test_acc: 0.5534\n",
            "Epoch 3158, BestLoss: 0.04536856146723684, Temperature 6.486908831562912e-05, step_size 0.8620798143989417, test_acc: 0.553\n",
            "Epoch 3159, BestLoss: 0.04535944385286288, Temperature 6.162563389984766e-05, step_size 0.8619936064175018, test_acc: 0.5533\n",
            "Epoch 3160, BestLoss: 0.045406665852067624, Temperature 5.8544352204855274e-05, step_size 0.8619074070568601, test_acc: 0.5523\n",
            "Epoch 3161, BestLoss: 0.04537867226520009, Temperature 5.561713459461251e-05, step_size 0.8618212163161544, test_acc: 0.5521\n",
            "Epoch 3162, BestLoss: 0.04537867226520009, Temperature 5.283627786488188e-05, step_size 0.8617350341945228, test_acc: 0.5521\n",
            "Epoch 3163, BestLoss: 0.04537867226520009, Temperature 5.561713459461251e-05, step_size 0.8619936064175018, test_acc: 0.5521\n",
            "Epoch 3164, BestLoss: 0.04537867226520009, Temperature 5.8544352204855274e-05, step_size 0.8619074070568601, test_acc: 0.5521\n",
            "Epoch 3165, BestLoss: 0.04537867226520009, Temperature 6.162563389984766e-05, step_size 0.8618212163161544, test_acc: 0.5521\n",
            "Epoch 3166, BestLoss: 0.045357590196671904, Temperature 6.486908831562912e-05, step_size 0.8617350341945228, test_acc: 0.5519\n",
            "Epoch 3167, BestLoss: 0.045357590196671904, Temperature 6.162563389984766e-05, step_size 0.8616488606911034, test_acc: 0.5519\n",
            "Epoch 3168, BestLoss: 0.045357590196671904, Temperature 6.486908831562912e-05, step_size 0.8616488606911034, test_acc: 0.5519\n",
            "Epoch 3169, BestLoss: 0.04530173289519325, Temperature 6.828325085855697e-05, step_size 0.8615626958050343, test_acc: 0.5536\n",
            "Epoch 3170, BestLoss: 0.04530173289519325, Temperature 6.486908831562912e-05, step_size 0.8614765395354538, test_acc: 0.5536\n",
            "Epoch 3171, BestLoss: 0.04530173289519325, Temperature 6.828325085855697e-05, step_size 0.8614765395354538, test_acc: 0.5536\n",
            "Epoch 3172, BestLoss: 0.04530173289519325, Temperature 7.187710616690208e-05, step_size 0.8613903918815002, test_acc: 0.5536\n",
            "Epoch 3173, BestLoss: 0.04530173289519325, Temperature 7.566011175463378e-05, step_size 0.861304252842312, test_acc: 0.5536\n",
            "Epoch 3174, BestLoss: 0.04527096514797197, Temperature 7.96422228996145e-05, step_size 0.8612181224170278, test_acc: 0.5528\n",
            "Epoch 3175, BestLoss: 0.04529827668221079, Temperature 7.566011175463378e-05, step_size 0.8611320006047861, test_acc: 0.5532\n",
            "Epoch 3176, BestLoss: 0.04520869106559767, Temperature 7.187710616690208e-05, step_size 0.8610458874047257, test_acc: 0.5558\n",
            "Epoch 3177, BestLoss: 0.04520869106559767, Temperature 6.828325085855697e-05, step_size 0.8609597828159852, test_acc: 0.5558\n",
            "Epoch 3178, BestLoss: 0.04520869106559767, Temperature 7.187710616690208e-05, step_size 0.8611320006047861, test_acc: 0.5558\n",
            "Epoch 3179, BestLoss: 0.04519747744164319, Temperature 7.566011175463378e-05, step_size 0.8610458874047257, test_acc: 0.555\n",
            "Epoch 3180, BestLoss: 0.045172428479185366, Temperature 7.187710616690208e-05, step_size 0.8609597828159852, test_acc: 0.5544\n",
            "Epoch 3181, BestLoss: 0.04512823573572937, Temperature 6.828325085855697e-05, step_size 0.8608736868377036, test_acc: 0.5546\n",
            "Epoch 3182, BestLoss: 0.04512823573572937, Temperature 6.486908831562912e-05, step_size 0.8607875994690198, test_acc: 0.5546\n",
            "Epoch 3183, BestLoss: 0.04512823573572937, Temperature 6.828325085855697e-05, step_size 0.8609597828159852, test_acc: 0.5546\n",
            "Epoch 3184, BestLoss: 0.04512823573572937, Temperature 7.187710616690208e-05, step_size 0.8608736868377036, test_acc: 0.5546\n",
            "Epoch 3185, BestLoss: 0.04512823573572937, Temperature 7.566011175463378e-05, step_size 0.8607875994690198, test_acc: 0.5546\n",
            "Epoch 3186, BestLoss: 0.04512823573572937, Temperature 7.96422228996145e-05, step_size 0.8607015207090729, test_acc: 0.5546\n",
            "Epoch 3187, BestLoss: 0.04508792370492283, Temperature 8.383391884169949e-05, step_size 0.8606154505570021, test_acc: 0.5551\n",
            "Epoch 3188, BestLoss: 0.04508456862777942, Temperature 7.96422228996145e-05, step_size 0.8605293890119464, test_acc: 0.5562\n",
            "Epoch 3189, BestLoss: 0.04508456862777942, Temperature 8.383391884169949e-05, step_size 0.8605293890119464, test_acc: 0.5562\n",
            "Epoch 3190, BestLoss: 0.04516928965291747, Temperature 8.824623035968368e-05, step_size 0.8604433360730452, test_acc: 0.5556\n",
            "Epoch 3191, BestLoss: 0.045205817396023244, Temperature 8.383391884169949e-05, step_size 0.860357291739438, test_acc: 0.5558\n",
            "Epoch 3192, BestLoss: 0.04512651904212894, Temperature 7.96422228996145e-05, step_size 0.860271256010264, test_acc: 0.5536\n",
            "Epoch 3193, BestLoss: 0.04512651904212894, Temperature 7.566011175463378e-05, step_size 0.860185228884663, test_acc: 0.5536\n",
            "Epoch 3194, BestLoss: 0.04512651904212894, Temperature 7.96422228996145e-05, step_size 0.860357291739438, test_acc: 0.5536\n",
            "Epoch 3195, BestLoss: 0.045116665091336626, Temperature 8.383391884169949e-05, step_size 0.860271256010264, test_acc: 0.5551\n",
            "Epoch 3196, BestLoss: 0.04514818365988749, Temperature 7.96422228996145e-05, step_size 0.860185228884663, test_acc: 0.5539\n",
            "Epoch 3197, BestLoss: 0.04514818365988749, Temperature 7.566011175463378e-05, step_size 0.8600992103617745, test_acc: 0.5539\n",
            "Epoch 3198, BestLoss: 0.04513314628817368, Temperature 7.96422228996145e-05, step_size 0.860185228884663, test_acc: 0.5537\n",
            "Epoch 3199, BestLoss: 0.04512730959646062, Temperature 7.566011175463378e-05, step_size 0.8600992103617745, test_acc: 0.5534\n",
            "Epoch 3200, BestLoss: 0.045086866166846366, Temperature 7.187710616690208e-05, step_size 0.8600132004407384, test_acc: 0.5531\n",
            "Epoch 3201, BestLoss: 0.04507636185310847, Temperature 6.828325085855697e-05, step_size 0.8599271991206943, test_acc: 0.5526\n",
            "Epoch 3202, BestLoss: 0.04513595039143939, Temperature 6.486908831562912e-05, step_size 0.8598412064007822, test_acc: 0.5524\n",
            "Epoch 3203, BestLoss: 0.04513595039143939, Temperature 6.162563389984766e-05, step_size 0.8597552222801421, test_acc: 0.5524\n",
            "Epoch 3204, BestLoss: 0.045064577937733795, Temperature 6.486908831562912e-05, step_size 0.8600992103617745, test_acc: 0.5528\n",
            "Epoch 3205, BestLoss: 0.045063094537796146, Temperature 6.162563389984766e-05, step_size 0.8600132004407384, test_acc: 0.5527\n",
            "Epoch 3206, BestLoss: 0.045063094537796146, Temperature 6.486908831562912e-05, step_size 0.8600132004407384, test_acc: 0.5527\n",
            "Epoch 3207, BestLoss: 0.0451603944610589, Temperature 6.828325085855697e-05, step_size 0.8599271991206943, test_acc: 0.5536\n",
            "Epoch 3208, BestLoss: 0.045086331959227656, Temperature 6.486908831562912e-05, step_size 0.8598412064007822, test_acc: 0.5543\n",
            "Epoch 3209, BestLoss: 0.045086331959227656, Temperature 6.162563389984766e-05, step_size 0.8597552222801421, test_acc: 0.5543\n",
            "Epoch 3210, BestLoss: 0.0451148782054424, Temperature 6.486908831562912e-05, step_size 0.8598412064007822, test_acc: 0.5545\n",
            "Epoch 3211, BestLoss: 0.0450762956523726, Temperature 6.162563389984766e-05, step_size 0.8597552222801421, test_acc: 0.5536\n",
            "Epoch 3212, BestLoss: 0.044969747607373683, Temperature 5.8544352204855274e-05, step_size 0.8596692467579141, test_acc: 0.5557\n",
            "Epoch 3213, BestLoss: 0.04501349150668716, Temperature 5.561713459461251e-05, step_size 0.8595832798332383, test_acc: 0.556\n",
            "Epoch 3214, BestLoss: 0.04501349150668716, Temperature 5.283627786488188e-05, step_size 0.859497321505255, test_acc: 0.556\n",
            "Epoch 3215, BestLoss: 0.04501349150668716, Temperature 5.561713459461251e-05, step_size 0.8597552222801421, test_acc: 0.556\n",
            "Epoch 3216, BestLoss: 0.04501349150668716, Temperature 5.8544352204855274e-05, step_size 0.8596692467579141, test_acc: 0.556\n",
            "Epoch 3217, BestLoss: 0.04498081401530086, Temperature 6.162563389984766e-05, step_size 0.8595832798332383, test_acc: 0.5558\n",
            "Epoch 3218, BestLoss: 0.04498332221161848, Temperature 5.8544352204855274e-05, step_size 0.859497321505255, test_acc: 0.5547\n",
            "Epoch 3219, BestLoss: 0.04487788195575366, Temperature 6.162563389984766e-05, step_size 0.859497321505255, test_acc: 0.5571\n",
            "Epoch 3220, BestLoss: 0.044829179050122014, Temperature 5.8544352204855274e-05, step_size 0.8594113717731046, test_acc: 0.5575\n",
            "Epoch 3221, BestLoss: 0.044829179050122014, Temperature 5.561713459461251e-05, step_size 0.8593254306359273, test_acc: 0.5575\n",
            "Epoch 3222, BestLoss: 0.044857567741885526, Temperature 5.8544352204855274e-05, step_size 0.8594113717731046, test_acc: 0.555\n",
            "Epoch 3223, BestLoss: 0.04484651576326611, Temperature 5.561713459461251e-05, step_size 0.8593254306359273, test_acc: 0.5567\n",
            "Epoch 3224, BestLoss: 0.04484651576326611, Temperature 5.283627786488188e-05, step_size 0.8592394980928637, test_acc: 0.5567\n",
            "Epoch 3225, BestLoss: 0.04479556967044159, Temperature 5.561713459461251e-05, step_size 0.8593254306359273, test_acc: 0.5597\n",
            "Epoch 3226, BestLoss: 0.044913230233692654, Temperature 5.283627786488188e-05, step_size 0.8592394980928637, test_acc: 0.5573\n",
            "Epoch 3227, BestLoss: 0.04479252379300459, Temperature 5.019446397163778e-05, step_size 0.8591535741430544, test_acc: 0.5587\n",
            "Epoch 3228, BestLoss: 0.04479252379300459, Temperature 4.768474077305589e-05, step_size 0.8590676587856401, test_acc: 0.5587\n",
            "Epoch 3229, BestLoss: 0.04479252379300459, Temperature 5.019446397163778e-05, step_size 0.8592394980928637, test_acc: 0.5587\n",
            "Epoch 3230, BestLoss: 0.044873185779568066, Temperature 5.283627786488188e-05, step_size 0.8591535741430544, test_acc: 0.5557\n",
            "Epoch 3231, BestLoss: 0.0447908387761885, Temperature 5.019446397163778e-05, step_size 0.8590676587856401, test_acc: 0.5571\n",
            "Epoch 3232, BestLoss: 0.0447908387761885, Temperature 4.768474077305589e-05, step_size 0.8589817520197615, test_acc: 0.5571\n",
            "Epoch 3233, BestLoss: 0.04479162078360435, Temperature 5.019446397163778e-05, step_size 0.8590676587856401, test_acc: 0.5574\n",
            "Epoch 3234, BestLoss: 0.04475650455323475, Temperature 5.283627786488188e-05, step_size 0.8589817520197615, test_acc: 0.5582\n",
            "Epoch 3235, BestLoss: 0.04475650455323475, Temperature 5.019446397163778e-05, step_size 0.8588958538445595, test_acc: 0.5582\n",
            "Epoch 3236, BestLoss: 0.04475650455323475, Temperature 5.283627786488188e-05, step_size 0.8588958538445595, test_acc: 0.5582\n",
            "Epoch 3237, BestLoss: 0.04478982560565944, Temperature 5.561713459461251e-05, step_size 0.858809964259175, test_acc: 0.5564\n",
            "Epoch 3238, BestLoss: 0.04484230235294509, Temperature 5.283627786488188e-05, step_size 0.8587240832627491, test_acc: 0.5577\n",
            "Epoch 3239, BestLoss: 0.04484230235294509, Temperature 5.019446397163778e-05, step_size 0.8586382108544228, test_acc: 0.5577\n",
            "Epoch 3240, BestLoss: 0.04479166519815268, Temperature 5.283627786488188e-05, step_size 0.8587240832627491, test_acc: 0.5576\n",
            "Epoch 3241, BestLoss: 0.04475164432196787, Temperature 5.019446397163778e-05, step_size 0.8586382108544228, test_acc: 0.56\n",
            "Epoch 3242, BestLoss: 0.04468599459640035, Temperature 4.768474077305589e-05, step_size 0.8585523470333374, test_acc: 0.5589\n",
            "Epoch 3243, BestLoss: 0.044680950339921484, Temperature 4.53005037344031e-05, step_size 0.8584664917986341, test_acc: 0.56\n",
            "Epoch 3244, BestLoss: 0.044680950339921484, Temperature 4.303547854768294e-05, step_size 0.8583806451494542, test_acc: 0.56\n",
            "Epoch 3245, BestLoss: 0.044621248917671656, Temperature 4.53005037344031e-05, step_size 0.8586382108544228, test_acc: 0.5605\n",
            "Epoch 3246, BestLoss: 0.044621248917671656, Temperature 4.303547854768294e-05, step_size 0.8585523470333374, test_acc: 0.5605\n",
            "Epoch 3247, BestLoss: 0.04455820068950183, Temperature 4.53005037344031e-05, step_size 0.8585523470333374, test_acc: 0.5592\n",
            "Epoch 3248, BestLoss: 0.044680961977951544, Temperature 4.303547854768294e-05, step_size 0.8584664917986341, test_acc: 0.5585\n",
            "Epoch 3249, BestLoss: 0.044622984376210734, Temperature 4.0883704620298796e-05, step_size 0.8583806451494542, test_acc: 0.5597\n",
            "Epoch 3250, BestLoss: 0.044622984376210734, Temperature 3.883951938928385e-05, step_size 0.8582948070849393, test_acc: 0.5597\n",
            "Epoch 3251, BestLoss: 0.0446152012094322, Temperature 4.0883704620298796e-05, step_size 0.8584664917986341, test_acc: 0.5589\n",
            "Epoch 3252, BestLoss: 0.0446152012094322, Temperature 3.883951938928385e-05, step_size 0.8583806451494542, test_acc: 0.5589\n",
            "Epoch 3253, BestLoss: 0.0446152012094322, Temperature 4.0883704620298796e-05, step_size 0.8583806451494542, test_acc: 0.5589\n",
            "Epoch 3254, BestLoss: 0.044609993820426935, Temperature 4.303547854768294e-05, step_size 0.8582948070849393, test_acc: 0.5605\n",
            "Epoch 3255, BestLoss: 0.044651493608302895, Temperature 4.0883704620298796e-05, step_size 0.8582089776042309, test_acc: 0.5596\n",
            "Epoch 3256, BestLoss: 0.04463973166097258, Temperature 3.883951938928385e-05, step_size 0.8581231567064704, test_acc: 0.5596\n",
            "Epoch 3257, BestLoss: 0.04463973166097258, Temperature 3.689754341981966e-05, step_size 0.8580373443907998, test_acc: 0.5596\n",
            "Epoch 3258, BestLoss: 0.0445607736962669, Temperature 3.883951938928385e-05, step_size 0.8582089776042309, test_acc: 0.5603\n",
            "Epoch 3259, BestLoss: 0.0445607736962669, Temperature 3.689754341981966e-05, step_size 0.8581231567064704, test_acc: 0.5603\n",
            "Epoch 3260, BestLoss: 0.0445607736962669, Temperature 3.883951938928385e-05, step_size 0.8581231567064704, test_acc: 0.5603\n",
            "Epoch 3261, BestLoss: 0.044424509673345276, Temperature 4.0883704620298796e-05, step_size 0.8580373443907998, test_acc: 0.5618\n",
            "Epoch 3262, BestLoss: 0.04428958404074461, Temperature 3.883951938928385e-05, step_size 0.8579515406563607, test_acc: 0.5636\n",
            "Epoch 3263, BestLoss: 0.044268103948359214, Temperature 3.689754341981966e-05, step_size 0.8578657455022951, test_acc: 0.5639\n",
            "Epoch 3264, BestLoss: 0.04419492826524075, Temperature 3.505266624882867e-05, step_size 0.8577799589277448, test_acc: 0.5646\n",
            "Epoch 3265, BestLoss: 0.04419492826524075, Temperature 3.3300032936387236e-05, step_size 0.8576941809318521, test_acc: 0.5646\n",
            "Epoch 3266, BestLoss: 0.04419492826524075, Temperature 3.505266624882867e-05, step_size 0.8579515406563607, test_acc: 0.5646\n",
            "Epoch 3267, BestLoss: 0.04427298999512699, Temperature 3.689754341981966e-05, step_size 0.8578657455022951, test_acc: 0.5627\n",
            "Epoch 3268, BestLoss: 0.04427298999512699, Temperature 3.505266624882867e-05, step_size 0.8577799589277448, test_acc: 0.5627\n",
            "Epoch 3269, BestLoss: 0.044259580042800506, Temperature 3.689754341981966e-05, step_size 0.8577799589277448, test_acc: 0.5635\n",
            "Epoch 3270, BestLoss: 0.04419169447239241, Temperature 3.505266624882867e-05, step_size 0.8576941809318521, test_acc: 0.5642\n",
            "Epoch 3271, BestLoss: 0.044249435273310433, Temperature 3.3300032936387236e-05, step_size 0.857608411513759, test_acc: 0.5633\n",
            "Epoch 3272, BestLoss: 0.044249435273310433, Temperature 3.163503128956787e-05, step_size 0.8575226506726076, test_acc: 0.5633\n",
            "Epoch 3273, BestLoss: 0.044262699911128675, Temperature 3.3300032936387236e-05, step_size 0.8576941809318521, test_acc: 0.5637\n",
            "Epoch 3274, BestLoss: 0.04425589644171565, Temperature 3.163503128956787e-05, step_size 0.857608411513759, test_acc: 0.5624\n",
            "Epoch 3275, BestLoss: 0.04426048612455133, Temperature 3.0053279725089478e-05, step_size 0.8575226506726076, test_acc: 0.563\n",
            "Epoch 3276, BestLoss: 0.04426048612455133, Temperature 2.8550615738835003e-05, step_size 0.8574368984075403, test_acc: 0.563\n",
            "Epoch 3277, BestLoss: 0.044286104308465545, Temperature 3.0053279725089478e-05, step_size 0.857608411513759, test_acc: 0.5627\n",
            "Epoch 3278, BestLoss: 0.04428162305931985, Temperature 2.8550615738835003e-05, step_size 0.8575226506726076, test_acc: 0.5626\n",
            "Epoch 3279, BestLoss: 0.04428162305931985, Temperature 2.7123084951893252e-05, step_size 0.8574368984075403, test_acc: 0.5626\n",
            "Epoch 3280, BestLoss: 0.04428162305931985, Temperature 2.8550615738835003e-05, step_size 0.8575226506726076, test_acc: 0.5626\n",
            "Epoch 3281, BestLoss: 0.04423618419271981, Temperature 3.0053279725089478e-05, step_size 0.8574368984075403, test_acc: 0.5627\n",
            "Epoch 3282, BestLoss: 0.044191739509798184, Temperature 2.8550615738835003e-05, step_size 0.8573511547176996, test_acc: 0.5643\n",
            "Epoch 3283, BestLoss: 0.044191739509798184, Temperature 2.7123084951893252e-05, step_size 0.8572654196022279, test_acc: 0.5643\n",
            "Epoch 3284, BestLoss: 0.044191739509798184, Temperature 2.8550615738835003e-05, step_size 0.8573511547176996, test_acc: 0.5643\n",
            "Epoch 3285, BestLoss: 0.044191739509798184, Temperature 3.0053279725089478e-05, step_size 0.8572654196022279, test_acc: 0.5643\n",
            "Epoch 3286, BestLoss: 0.044191739509798184, Temperature 3.163503128956787e-05, step_size 0.8571796930602676, test_acc: 0.5643\n",
            "Epoch 3287, BestLoss: 0.044191739509798184, Temperature 3.3300032936387236e-05, step_size 0.8570939750909616, test_acc: 0.5643\n",
            "Epoch 3288, BestLoss: 0.04413664384551704, Temperature 3.505266624882867e-05, step_size 0.8570082656934526, test_acc: 0.5638\n",
            "Epoch 3289, BestLoss: 0.04405628110185174, Temperature 3.3300032936387236e-05, step_size 0.8569225648668832, test_acc: 0.566\n",
            "Epoch 3290, BestLoss: 0.04406491981646864, Temperature 3.163503128956787e-05, step_size 0.8568368726103965, test_acc: 0.5672\n",
            "Epoch 3291, BestLoss: 0.04406491981646864, Temperature 3.0053279725089478e-05, step_size 0.8567511889231355, test_acc: 0.5672\n",
            "Epoch 3292, BestLoss: 0.04406491981646864, Temperature 3.163503128956787e-05, step_size 0.8569225648668832, test_acc: 0.5672\n",
            "Epoch 3293, BestLoss: 0.04406491981646864, Temperature 3.3300032936387236e-05, step_size 0.8568368726103965, test_acc: 0.5672\n",
            "Epoch 3294, BestLoss: 0.04406491981646864, Temperature 3.505266624882867e-05, step_size 0.8567511889231355, test_acc: 0.5672\n",
            "Epoch 3295, BestLoss: 0.04406491981646864, Temperature 3.689754341981966e-05, step_size 0.8566655138042432, test_acc: 0.5672\n",
            "Epoch 3296, BestLoss: 0.04397491993634859, Temperature 3.883951938928385e-05, step_size 0.8565798472528627, test_acc: 0.5679\n",
            "Epoch 3297, BestLoss: 0.04397491993634859, Temperature 3.689754341981966e-05, step_size 0.8564941892681375, test_acc: 0.5679\n",
            "Epoch 3298, BestLoss: 0.043899976711340424, Temperature 3.883951938928385e-05, step_size 0.8564941892681375, test_acc: 0.569\n",
            "Epoch 3299, BestLoss: 0.04388644161448102, Temperature 3.689754341981966e-05, step_size 0.8564085398492106, test_acc: 0.5677\n",
            "Epoch 3300, BestLoss: 0.04388644161448102, Temperature 3.505266624882867e-05, step_size 0.8563228989952257, test_acc: 0.5677\n",
            "Epoch 3301, BestLoss: 0.04388644161448102, Temperature 3.689754341981966e-05, step_size 0.8564085398492106, test_acc: 0.5677\n",
            "Epoch 3302, BestLoss: 0.04388426407126539, Temperature 3.883951938928385e-05, step_size 0.8563228989952257, test_acc: 0.569\n",
            "Epoch 3303, BestLoss: 0.04388426407126539, Temperature 3.689754341981966e-05, step_size 0.8562372667053262, test_acc: 0.569\n",
            "Epoch 3304, BestLoss: 0.043902856577349124, Temperature 3.883951938928385e-05, step_size 0.8562372667053262, test_acc: 0.5679\n",
            "Epoch 3305, BestLoss: 0.04386005565321443, Temperature 3.689754341981966e-05, step_size 0.8561516429786556, test_acc: 0.568\n",
            "Epoch 3306, BestLoss: 0.04386005565321443, Temperature 3.505266624882867e-05, step_size 0.8560660278143578, test_acc: 0.568\n",
            "Epoch 3307, BestLoss: 0.04386823099330276, Temperature 3.689754341981966e-05, step_size 0.8561516429786556, test_acc: 0.5682\n",
            "Epoch 3308, BestLoss: 0.04381150800860994, Temperature 3.505266624882867e-05, step_size 0.8560660278143578, test_acc: 0.5678\n",
            "Epoch 3309, BestLoss: 0.04381150800860994, Temperature 3.3300032936387236e-05, step_size 0.8559804212115764, test_acc: 0.5678\n",
            "Epoch 3310, BestLoss: 0.04381150800860994, Temperature 3.505266624882867e-05, step_size 0.8560660278143578, test_acc: 0.5678\n",
            "Epoch 3311, BestLoss: 0.04381150800860994, Temperature 3.689754341981966e-05, step_size 0.8559804212115764, test_acc: 0.5678\n",
            "Epoch 3312, BestLoss: 0.04381150800860994, Temperature 3.883951938928385e-05, step_size 0.8558948231694552, test_acc: 0.5678\n",
            "Epoch 3313, BestLoss: 0.04388055559607801, Temperature 4.0883704620298796e-05, step_size 0.8558092336871382, test_acc: 0.5685\n",
            "Epoch 3314, BestLoss: 0.0438400993450048, Temperature 3.883951938928385e-05, step_size 0.8557236527637695, test_acc: 0.5689\n",
            "Epoch 3315, BestLoss: 0.0438400993450048, Temperature 3.689754341981966e-05, step_size 0.8556380803984931, test_acc: 0.5689\n",
            "Epoch 3316, BestLoss: 0.0438400993450048, Temperature 3.883951938928385e-05, step_size 0.8557236527637695, test_acc: 0.5689\n",
            "Epoch 3317, BestLoss: 0.0438400993450048, Temperature 4.0883704620298796e-05, step_size 0.8556380803984931, test_acc: 0.5689\n",
            "Epoch 3318, BestLoss: 0.04380326673254844, Temperature 4.303547854768294e-05, step_size 0.8555525165904533, test_acc: 0.5691\n",
            "Epoch 3319, BestLoss: 0.04380326673254844, Temperature 4.0883704620298796e-05, step_size 0.8554669613387943, test_acc: 0.5691\n",
            "Epoch 3320, BestLoss: 0.04380326673254844, Temperature 4.303547854768294e-05, step_size 0.8554669613387943, test_acc: 0.5691\n",
            "Epoch 3321, BestLoss: 0.043768946593113395, Temperature 4.53005037344031e-05, step_size 0.8553814146426604, test_acc: 0.5694\n",
            "Epoch 3322, BestLoss: 0.04359299682134698, Temperature 4.303547854768294e-05, step_size 0.8552958765011961, test_acc: 0.5692\n",
            "Epoch 3323, BestLoss: 0.04359299682134698, Temperature 4.0883704620298796e-05, step_size 0.855210346913546, test_acc: 0.5692\n",
            "Epoch 3324, BestLoss: 0.04359299682134698, Temperature 4.303547854768294e-05, step_size 0.8552958765011961, test_acc: 0.5692\n",
            "Epoch 3325, BestLoss: 0.04359299682134698, Temperature 4.53005037344031e-05, step_size 0.855210346913546, test_acc: 0.5692\n",
            "Epoch 3326, BestLoss: 0.04359299682134698, Temperature 4.768474077305589e-05, step_size 0.8551248258788546, test_acc: 0.5692\n",
            "Epoch 3327, BestLoss: 0.04359299682134698, Temperature 5.019446397163778e-05, step_size 0.8550393133962667, test_acc: 0.5692\n",
            "Epoch 3328, BestLoss: 0.04359299682134698, Temperature 5.283627786488188e-05, step_size 0.854953809464927, test_acc: 0.5692\n",
            "Epoch 3329, BestLoss: 0.04359299682134698, Temperature 5.561713459461251e-05, step_size 0.8548683140839806, test_acc: 0.5692\n",
            "Epoch 3330, BestLoss: 0.04359299682134698, Temperature 5.8544352204855274e-05, step_size 0.8547828272525722, test_acc: 0.5692\n",
            "Epoch 3331, BestLoss: 0.04359299682134698, Temperature 6.162563389984766e-05, step_size 0.854697348969847, test_acc: 0.5692\n",
            "Epoch 3332, BestLoss: 0.0437031123953958, Temperature 6.486908831562912e-05, step_size 0.85461187923495, test_acc: 0.568\n",
            "Epoch 3333, BestLoss: 0.0437031123953958, Temperature 6.162563389984766e-05, step_size 0.8545264180470264, test_acc: 0.568\n",
            "Epoch 3334, BestLoss: 0.0437031123953958, Temperature 6.486908831562912e-05, step_size 0.8545264180470264, test_acc: 0.568\n",
            "Epoch 3335, BestLoss: 0.04368796861905692, Temperature 6.828325085855697e-05, step_size 0.8544409654052217, test_acc: 0.5669\n",
            "Epoch 3336, BestLoss: 0.04375441627095695, Temperature 6.486908831562912e-05, step_size 0.8543555213086812, test_acc: 0.5655\n",
            "Epoch 3337, BestLoss: 0.04375441627095695, Temperature 6.162563389984766e-05, step_size 0.8542700857565504, test_acc: 0.5655\n",
            "Epoch 3338, BestLoss: 0.04374996246734862, Temperature 6.486908831562912e-05, step_size 0.8543555213086812, test_acc: 0.5666\n",
            "Epoch 3339, BestLoss: 0.04374996246734862, Temperature 6.162563389984766e-05, step_size 0.8542700857565504, test_acc: 0.5666\n",
            "Epoch 3340, BestLoss: 0.04374996246734862, Temperature 6.486908831562912e-05, step_size 0.8542700857565504, test_acc: 0.5666\n",
            "Epoch 3341, BestLoss: 0.043639584631828925, Temperature 6.828325085855697e-05, step_size 0.8541846587479748, test_acc: 0.5693\n",
            "Epoch 3342, BestLoss: 0.043639584631828925, Temperature 6.486908831562912e-05, step_size 0.8540992402820999, test_acc: 0.5693\n",
            "Epoch 3343, BestLoss: 0.043639584631828925, Temperature 6.828325085855697e-05, step_size 0.8540992402820999, test_acc: 0.5693\n",
            "Epoch 3344, BestLoss: 0.04361302623919137, Temperature 7.187710616690208e-05, step_size 0.8540138303580718, test_acc: 0.5709\n",
            "Epoch 3345, BestLoss: 0.04361302623919137, Temperature 6.828325085855697e-05, step_size 0.853928428975036, test_acc: 0.5709\n",
            "Epoch 3346, BestLoss: 0.043600932374472226, Temperature 7.187710616690208e-05, step_size 0.853928428975036, test_acc: 0.5705\n",
            "Epoch 3347, BestLoss: 0.043526156880052076, Temperature 6.828325085855697e-05, step_size 0.8538430361321384, test_acc: 0.5707\n",
            "Epoch 3348, BestLoss: 0.043457287178678805, Temperature 6.486908831562912e-05, step_size 0.8537576518285253, test_acc: 0.5725\n",
            "Epoch 3349, BestLoss: 0.043457287178678805, Temperature 6.162563389984766e-05, step_size 0.8536722760633424, test_acc: 0.5725\n",
            "Epoch 3350, BestLoss: 0.043457287178678805, Temperature 6.486908831562912e-05, step_size 0.8538430361321384, test_acc: 0.5725\n",
            "Epoch 3351, BestLoss: 0.04350881581045568, Temperature 6.828325085855697e-05, step_size 0.8537576518285253, test_acc: 0.5706\n",
            "Epoch 3352, BestLoss: 0.04353929992165668, Temperature 6.486908831562912e-05, step_size 0.8536722760633424, test_acc: 0.5726\n",
            "Epoch 3353, BestLoss: 0.04353999674889631, Temperature 6.162563389984766e-05, step_size 0.8535869088357361, test_acc: 0.5733\n",
            "Epoch 3354, BestLoss: 0.04353999674889631, Temperature 6.486908831562912e-05, step_size 0.8536722760633424, test_acc: 0.5733\n",
            "Epoch 3355, BestLoss: 0.043426228686738774, Temperature 6.828325085855697e-05, step_size 0.8535869088357361, test_acc: 0.5727\n",
            "Epoch 3356, BestLoss: 0.043426228686738774, Temperature 6.486908831562912e-05, step_size 0.8535015501448525, test_acc: 0.5727\n",
            "Epoch 3357, BestLoss: 0.043426228686738774, Temperature 6.828325085855697e-05, step_size 0.8535015501448525, test_acc: 0.5727\n",
            "Epoch 3358, BestLoss: 0.043426228686738774, Temperature 7.187710616690208e-05, step_size 0.8534161999898381, test_acc: 0.5727\n",
            "Epoch 3359, BestLoss: 0.043426228686738774, Temperature 7.566011175463378e-05, step_size 0.8533308583698391, test_acc: 0.5727\n",
            "Epoch 3360, BestLoss: 0.043426228686738774, Temperature 7.96422228996145e-05, step_size 0.8532455252840021, test_acc: 0.5727\n",
            "Epoch 3361, BestLoss: 0.043426228686738774, Temperature 8.383391884169949e-05, step_size 0.8531602007314737, test_acc: 0.5727\n",
            "Epoch 3362, BestLoss: 0.043426228686738774, Temperature 8.824623035968368e-05, step_size 0.8530748847114006, test_acc: 0.5727\n",
            "Epoch 3363, BestLoss: 0.04353672727029636, Temperature 9.289076879966704e-05, step_size 0.8529895772229295, test_acc: 0.5712\n",
            "Epoch 3364, BestLoss: 0.04353672727029636, Temperature 8.824623035968368e-05, step_size 0.8529042782652072, test_acc: 0.5712\n",
            "Epoch 3365, BestLoss: 0.04353672727029636, Temperature 9.289076879966704e-05, step_size 0.8529042782652072, test_acc: 0.5712\n",
            "Epoch 3366, BestLoss: 0.04358817079372237, Temperature 9.777975663122846e-05, step_size 0.8528189878373807, test_acc: 0.5704\n",
            "Epoch 3367, BestLoss: 0.043661425041441194, Temperature 9.289076879966704e-05, step_size 0.852733705938597, test_acc: 0.5691\n",
            "Epoch 3368, BestLoss: 0.043661425041441194, Temperature 8.824623035968368e-05, step_size 0.8526484325680032, test_acc: 0.5691\n",
            "Epoch 3369, BestLoss: 0.043667304639257165, Temperature 9.289076879966704e-05, step_size 0.852733705938597, test_acc: 0.5708\n",
            "Epoch 3370, BestLoss: 0.04353225058009795, Temperature 8.824623035968368e-05, step_size 0.8526484325680032, test_acc: 0.5707\n",
            "Epoch 3371, BestLoss: 0.04357929329502467, Temperature 8.383391884169949e-05, step_size 0.8525631677247464, test_acc: 0.5705\n",
            "Epoch 3372, BestLoss: 0.04357929329502467, Temperature 7.96422228996145e-05, step_size 0.8524779114079739, test_acc: 0.5705\n",
            "Epoch 3373, BestLoss: 0.04357929329502467, Temperature 8.383391884169949e-05, step_size 0.8526484325680032, test_acc: 0.5705\n",
            "Epoch 3374, BestLoss: 0.04357929329502467, Temperature 8.824623035968368e-05, step_size 0.8525631677247464, test_acc: 0.5705\n",
            "Epoch 3375, BestLoss: 0.04351946464539373, Temperature 9.289076879966704e-05, step_size 0.8524779114079739, test_acc: 0.5717\n",
            "Epoch 3376, BestLoss: 0.04366139873629004, Temperature 8.824623035968368e-05, step_size 0.8523926636168331, test_acc: 0.5708\n",
            "Epoch 3377, BestLoss: 0.043971662600957785, Temperature 8.383391884169949e-05, step_size 0.8523074243504714, test_acc: 0.5686\n",
            "Epoch 3378, BestLoss: 0.04402801746457906, Temperature 7.96422228996145e-05, step_size 0.8522221936080363, test_acc: 0.5656\n",
            "Epoch 3379, BestLoss: 0.043852781332530115, Temperature 7.566011175463378e-05, step_size 0.8521369713886755, test_acc: 0.5679\n",
            "Epoch 3380, BestLoss: 0.04374619306700358, Temperature 7.187710616690208e-05, step_size 0.8520517576915366, test_acc: 0.5681\n",
            "Epoch 3381, BestLoss: 0.04374619306700358, Temperature 6.828325085855697e-05, step_size 0.8519665525157675, test_acc: 0.5681\n",
            "Epoch 3382, BestLoss: 0.04372390228912535, Temperature 7.187710616690208e-05, step_size 0.8523926636168331, test_acc: 0.5696\n",
            "Epoch 3383, BestLoss: 0.04372390228912535, Temperature 6.828325085855697e-05, step_size 0.8523074243504714, test_acc: 0.5696\n",
            "Epoch 3384, BestLoss: 0.04372390228912535, Temperature 7.187710616690208e-05, step_size 0.8523074243504714, test_acc: 0.5696\n",
            "Epoch 3385, BestLoss: 0.043704853827557746, Temperature 7.566011175463378e-05, step_size 0.8522221936080363, test_acc: 0.5703\n",
            "Epoch 3386, BestLoss: 0.043704853827557746, Temperature 7.187710616690208e-05, step_size 0.8521369713886755, test_acc: 0.5703\n",
            "Epoch 3387, BestLoss: 0.04384991792662687, Temperature 7.566011175463378e-05, step_size 0.8521369713886755, test_acc: 0.5709\n",
            "Epoch 3388, BestLoss: 0.043786701997885855, Temperature 7.187710616690208e-05, step_size 0.8520517576915366, test_acc: 0.5715\n",
            "Epoch 3389, BestLoss: 0.043818318331649724, Temperature 6.828325085855697e-05, step_size 0.8519665525157675, test_acc: 0.5709\n",
            "Epoch 3390, BestLoss: 0.04386142483607656, Temperature 6.486908831562912e-05, step_size 0.8518813558605159, test_acc: 0.5692\n",
            "Epoch 3391, BestLoss: 0.04386142483607656, Temperature 6.162563389984766e-05, step_size 0.8517961677249299, test_acc: 0.5692\n",
            "Epoch 3392, BestLoss: 0.043792773025151756, Temperature 6.486908831562912e-05, step_size 0.8520517576915366, test_acc: 0.5699\n",
            "Epoch 3393, BestLoss: 0.043792773025151756, Temperature 6.162563389984766e-05, step_size 0.8519665525157675, test_acc: 0.5699\n",
            "Epoch 3394, BestLoss: 0.043868273147442946, Temperature 6.486908831562912e-05, step_size 0.8519665525157675, test_acc: 0.5689\n",
            "Epoch 3395, BestLoss: 0.043868273147442946, Temperature 6.162563389984766e-05, step_size 0.8518813558605159, test_acc: 0.5689\n",
            "Epoch 3396, BestLoss: 0.044057997696609785, Temperature 6.486908831562912e-05, step_size 0.8518813558605159, test_acc: 0.5679\n",
            "Epoch 3397, BestLoss: 0.044057997696609785, Temperature 6.162563389984766e-05, step_size 0.8517961677249299, test_acc: 0.5679\n",
            "Epoch 3398, BestLoss: 0.044057997696609785, Temperature 6.486908831562912e-05, step_size 0.8517961677249299, test_acc: 0.5679\n",
            "Epoch 3399, BestLoss: 0.044057997696609785, Temperature 6.828325085855697e-05, step_size 0.8517109881081575, test_acc: 0.5679\n",
            "Epoch 3400, BestLoss: 0.044057997696609785, Temperature 7.187710616690208e-05, step_size 0.8516258170093467, test_acc: 0.5679\n",
            "Epoch 3401, BestLoss: 0.044057997696609785, Temperature 7.566011175463378e-05, step_size 0.8515406544276458, test_acc: 0.5679\n",
            "Epoch 3402, BestLoss: 0.04392794956988188, Temperature 7.96422228996145e-05, step_size 0.8514555003622031, test_acc: 0.5694\n",
            "Epoch 3403, BestLoss: 0.04388966691601174, Temperature 7.566011175463378e-05, step_size 0.8513703548121668, test_acc: 0.5696\n",
            "Epoch 3404, BestLoss: 0.04388966691601174, Temperature 7.187710616690208e-05, step_size 0.8512852177766856, test_acc: 0.5696\n",
            "Epoch 3405, BestLoss: 0.04388966691601174, Temperature 7.566011175463378e-05, step_size 0.8513703548121668, test_acc: 0.5696\n",
            "Epoch 3406, BestLoss: 0.043806412849258625, Temperature 7.96422228996145e-05, step_size 0.8512852177766856, test_acc: 0.5708\n",
            "Epoch 3407, BestLoss: 0.043806412849258625, Temperature 7.566011175463378e-05, step_size 0.851200089254908, test_acc: 0.5708\n",
            "Epoch 3408, BestLoss: 0.04372987783365364, Temperature 7.96422228996145e-05, step_size 0.851200089254908, test_acc: 0.572\n",
            "Epoch 3409, BestLoss: 0.043755014604582344, Temperature 7.566011175463378e-05, step_size 0.8511149692459825, test_acc: 0.5719\n",
            "Epoch 3410, BestLoss: 0.043755014604582344, Temperature 7.187710616690208e-05, step_size 0.8510298577490579, test_acc: 0.5719\n",
            "Epoch 3411, BestLoss: 0.043755014604582344, Temperature 7.566011175463378e-05, step_size 0.8511149692459825, test_acc: 0.5719\n",
            "Epoch 3412, BestLoss: 0.043755014604582344, Temperature 7.96422228996145e-05, step_size 0.8510298577490579, test_acc: 0.5719\n",
            "Epoch 3413, BestLoss: 0.043755014604582344, Temperature 8.383391884169949e-05, step_size 0.850944754763283, test_acc: 0.5719\n",
            "Epoch 3414, BestLoss: 0.04381163009676275, Temperature 8.824623035968368e-05, step_size 0.8508596602878067, test_acc: 0.5707\n",
            "Epoch 3415, BestLoss: 0.04377395606158193, Temperature 8.383391884169949e-05, step_size 0.8507745743217779, test_acc: 0.571\n",
            "Epoch 3416, BestLoss: 0.04377395606158193, Temperature 7.96422228996145e-05, step_size 0.8506894968643458, test_acc: 0.571\n",
            "Epoch 3417, BestLoss: 0.043806606993736445, Temperature 8.383391884169949e-05, step_size 0.8507745743217779, test_acc: 0.5705\n",
            "Epoch 3418, BestLoss: 0.04382407118919092, Temperature 7.96422228996145e-05, step_size 0.8506894968643458, test_acc: 0.5706\n",
            "Epoch 3419, BestLoss: 0.04382407118919092, Temperature 7.566011175463378e-05, step_size 0.8506044279146594, test_acc: 0.5706\n",
            "Epoch 3420, BestLoss: 0.04382407118919092, Temperature 7.96422228996145e-05, step_size 0.8506894968643458, test_acc: 0.5706\n",
            "Epoch 3421, BestLoss: 0.04382407118919092, Temperature 8.383391884169949e-05, step_size 0.8506044279146594, test_acc: 0.5706\n",
            "Epoch 3422, BestLoss: 0.04382407118919092, Temperature 8.824623035968368e-05, step_size 0.850519367471868, test_acc: 0.5706\n",
            "Epoch 3423, BestLoss: 0.04382407118919092, Temperature 9.289076879966704e-05, step_size 0.8504343155351208, test_acc: 0.5706\n",
            "Epoch 3424, BestLoss: 0.043728819518544744, Temperature 9.777975663122846e-05, step_size 0.8503492721035674, test_acc: 0.5715\n",
            "Epoch 3425, BestLoss: 0.043728819518544744, Temperature 9.289076879966704e-05, step_size 0.850264237176357, test_acc: 0.5715\n",
            "Epoch 3426, BestLoss: 0.04366519946864566, Temperature 9.777975663122846e-05, step_size 0.850264237176357, test_acc: 0.5702\n",
            "Epoch 3427, BestLoss: 0.04367544166633424, Temperature 9.289076879966704e-05, step_size 0.8501792107526394, test_acc: 0.5707\n",
            "Epoch 3428, BestLoss: 0.04381056862034494, Temperature 8.824623035968368e-05, step_size 0.8500941928315641, test_acc: 0.5704\n",
            "Epoch 3429, BestLoss: 0.04373833334213397, Temperature 8.383391884169949e-05, step_size 0.8500091834122809, test_acc: 0.5719\n",
            "Epoch 3430, BestLoss: 0.043779885345307766, Temperature 7.96422228996145e-05, step_size 0.8499241824939398, test_acc: 0.5709\n",
            "Epoch 3431, BestLoss: 0.04377964178014442, Temperature 7.566011175463378e-05, step_size 0.8498391900756904, test_acc: 0.5712\n",
            "Epoch 3432, BestLoss: 0.04377964178014442, Temperature 7.96422228996145e-05, step_size 0.8501792107526394, test_acc: 0.5712\n",
            "Epoch 3433, BestLoss: 0.04374594015134825, Temperature 8.383391884169949e-05, step_size 0.8500941928315641, test_acc: 0.5702\n",
            "Epoch 3434, BestLoss: 0.04376310845131583, Temperature 7.96422228996145e-05, step_size 0.8500091834122809, test_acc: 0.5694\n",
            "Epoch 3435, BestLoss: 0.04377428390042669, Temperature 7.566011175463378e-05, step_size 0.8499241824939398, test_acc: 0.5695\n",
            "Epoch 3436, BestLoss: 0.043729970878720305, Temperature 7.187710616690208e-05, step_size 0.8498391900756904, test_acc: 0.5694\n",
            "Epoch 3437, BestLoss: 0.04364127493439162, Temperature 6.828325085855697e-05, step_size 0.8497542061566828, test_acc: 0.5696\n",
            "Epoch 3438, BestLoss: 0.04364127493439162, Temperature 6.486908831562912e-05, step_size 0.8496692307360671, test_acc: 0.5696\n",
            "Epoch 3439, BestLoss: 0.04356418596215698, Temperature 6.828325085855697e-05, step_size 0.8500091834122809, test_acc: 0.5702\n",
            "Epoch 3440, BestLoss: 0.04355861229915874, Temperature 6.486908831562912e-05, step_size 0.8499241824939398, test_acc: 0.5693\n",
            "Epoch 3441, BestLoss: 0.04355861229915874, Temperature 6.162563389984766e-05, step_size 0.8498391900756904, test_acc: 0.5693\n",
            "Epoch 3442, BestLoss: 0.04355861229915874, Temperature 6.486908831562912e-05, step_size 0.8499241824939398, test_acc: 0.5693\n",
            "Epoch 3443, BestLoss: 0.04355861229915874, Temperature 6.828325085855697e-05, step_size 0.8498391900756904, test_acc: 0.5693\n",
            "Epoch 3444, BestLoss: 0.0435283164612498, Temperature 7.187710616690208e-05, step_size 0.8497542061566828, test_acc: 0.5705\n",
            "Epoch 3445, BestLoss: 0.043625281139842424, Temperature 6.828325085855697e-05, step_size 0.8496692307360671, test_acc: 0.57\n",
            "Epoch 3446, BestLoss: 0.043569920286207646, Temperature 6.486908831562912e-05, step_size 0.8495842638129936, test_acc: 0.5685\n",
            "Epoch 3447, BestLoss: 0.04349665083449094, Temperature 6.162563389984766e-05, step_size 0.8494993053866122, test_acc: 0.5717\n",
            "Epoch 3448, BestLoss: 0.043390197804377334, Temperature 5.8544352204855274e-05, step_size 0.8494143554560736, test_acc: 0.572\n",
            "Epoch 3449, BestLoss: 0.043390197804377334, Temperature 5.561713459461251e-05, step_size 0.849329414020528, test_acc: 0.572\n",
            "Epoch 3450, BestLoss: 0.043390197804377334, Temperature 5.8544352204855274e-05, step_size 0.8496692307360671, test_acc: 0.572\n",
            "Epoch 3451, BestLoss: 0.043390197804377334, Temperature 6.162563389984766e-05, step_size 0.8495842638129936, test_acc: 0.572\n",
            "Epoch 3452, BestLoss: 0.043390197804377334, Temperature 6.486908831562912e-05, step_size 0.8494993053866122, test_acc: 0.572\n",
            "Epoch 3453, BestLoss: 0.04332791514811122, Temperature 6.828325085855697e-05, step_size 0.8494143554560736, test_acc: 0.5732\n",
            "Epoch 3454, BestLoss: 0.043315385871972686, Temperature 6.486908831562912e-05, step_size 0.849329414020528, test_acc: 0.5739\n",
            "Epoch 3455, BestLoss: 0.043223073794420044, Temperature 6.162563389984766e-05, step_size 0.849244481079126, test_acc: 0.5737\n",
            "Epoch 3456, BestLoss: 0.043167540577017986, Temperature 5.8544352204855274e-05, step_size 0.849159556631018, test_acc: 0.5735\n",
            "Epoch 3457, BestLoss: 0.043089902648172904, Temperature 5.561713459461251e-05, step_size 0.849074640675355, test_acc: 0.5746\n",
            "Epoch 3458, BestLoss: 0.04306436928148789, Temperature 5.283627786488188e-05, step_size 0.8489897332112875, test_acc: 0.5754\n",
            "Epoch 3459, BestLoss: 0.04307303821945055, Temperature 5.019446397163778e-05, step_size 0.8489048342379664, test_acc: 0.573\n",
            "Epoch 3460, BestLoss: 0.04307303821945055, Temperature 4.768474077305589e-05, step_size 0.8488199437545426, test_acc: 0.573\n",
            "Epoch 3461, BestLoss: 0.04304270591299147, Temperature 5.019446397163778e-05, step_size 0.849329414020528, test_acc: 0.5717\n",
            "Epoch 3462, BestLoss: 0.04304270591299147, Temperature 4.768474077305589e-05, step_size 0.849244481079126, test_acc: 0.5717\n",
            "Epoch 3463, BestLoss: 0.04305458311997016, Temperature 5.019446397163778e-05, step_size 0.849244481079126, test_acc: 0.5736\n",
            "Epoch 3464, BestLoss: 0.04305458311997016, Temperature 4.768474077305589e-05, step_size 0.849159556631018, test_acc: 0.5736\n",
            "Epoch 3465, BestLoss: 0.04316999886573625, Temperature 5.019446397163778e-05, step_size 0.849159556631018, test_acc: 0.572\n",
            "Epoch 3466, BestLoss: 0.04316999886573625, Temperature 4.768474077305589e-05, step_size 0.849074640675355, test_acc: 0.572\n",
            "Epoch 3467, BestLoss: 0.04316999886573625, Temperature 5.019446397163778e-05, step_size 0.849074640675355, test_acc: 0.572\n",
            "Epoch 3468, BestLoss: 0.04316999886573625, Temperature 5.283627786488188e-05, step_size 0.8489897332112875, test_acc: 0.572\n",
            "Epoch 3469, BestLoss: 0.04314997983394453, Temperature 5.561713459461251e-05, step_size 0.8489048342379664, test_acc: 0.5715\n",
            "Epoch 3470, BestLoss: 0.04313614569626677, Temperature 5.283627786488188e-05, step_size 0.8488199437545426, test_acc: 0.5724\n",
            "Epoch 3471, BestLoss: 0.043131439467571385, Temperature 5.019446397163778e-05, step_size 0.8487350617601672, test_acc: 0.574\n",
            "Epoch 3472, BestLoss: 0.04313075822393104, Temperature 4.768474077305589e-05, step_size 0.8486501882539912, test_acc: 0.5734\n",
            "Epoch 3473, BestLoss: 0.04313159074694612, Temperature 5.019446397163778e-05, step_size 0.8488199437545426, test_acc: 0.5734\n",
            "Epoch 3474, BestLoss: 0.04313159074694612, Temperature 5.283627786488188e-05, step_size 0.8487350617601672, test_acc: 0.5734\n",
            "Epoch 3475, BestLoss: 0.04310126765333833, Temperature 5.561713459461251e-05, step_size 0.8486501882539912, test_acc: 0.5738\n",
            "Epoch 3476, BestLoss: 0.04310126765333833, Temperature 5.283627786488188e-05, step_size 0.8485653232351658, test_acc: 0.5738\n",
            "Epoch 3477, BestLoss: 0.04310126765333833, Temperature 5.561713459461251e-05, step_size 0.8485653232351658, test_acc: 0.5738\n",
            "Epoch 3478, BestLoss: 0.04310126765333833, Temperature 5.8544352204855274e-05, step_size 0.8484804667028423, test_acc: 0.5738\n",
            "Epoch 3479, BestLoss: 0.04305823641648465, Temperature 6.162563389984766e-05, step_size 0.848395618656172, test_acc: 0.5725\n",
            "Epoch 3480, BestLoss: 0.04305823641648465, Temperature 5.8544352204855274e-05, step_size 0.8483107790943064, test_acc: 0.5725\n",
            "Epoch 3481, BestLoss: 0.04305823641648465, Temperature 6.162563389984766e-05, step_size 0.8483107790943064, test_acc: 0.5725\n",
            "Epoch 3482, BestLoss: 0.04305823641648465, Temperature 6.486908831562912e-05, step_size 0.848225948016397, test_acc: 0.5725\n",
            "Epoch 3483, BestLoss: 0.04305823641648465, Temperature 6.828325085855697e-05, step_size 0.8481411254215954, test_acc: 0.5725\n",
            "Epoch 3484, BestLoss: 0.04305823641648465, Temperature 7.187710616690208e-05, step_size 0.8480563113090532, test_acc: 0.5725\n",
            "Epoch 3485, BestLoss: 0.04308130222904114, Temperature 7.566011175463378e-05, step_size 0.8479715056779223, test_acc: 0.5729\n",
            "Epoch 3486, BestLoss: 0.04302440943724523, Temperature 7.187710616690208e-05, step_size 0.8478867085273546, test_acc: 0.5732\n",
            "Epoch 3487, BestLoss: 0.043035681979917265, Temperature 6.828325085855697e-05, step_size 0.8478019198565019, test_acc: 0.5739\n",
            "Epoch 3488, BestLoss: 0.04285490233573968, Temperature 6.486908831562912e-05, step_size 0.8477171396645162, test_acc: 0.5754\n",
            "Epoch 3489, BestLoss: 0.04285490233573968, Temperature 6.162563389984766e-05, step_size 0.8476323679505497, test_acc: 0.5754\n",
            "Epoch 3490, BestLoss: 0.04285490233573968, Temperature 6.486908831562912e-05, step_size 0.8478867085273546, test_acc: 0.5754\n",
            "Epoch 3491, BestLoss: 0.04285490233573968, Temperature 6.828325085855697e-05, step_size 0.8478019198565019, test_acc: 0.5754\n",
            "Epoch 3492, BestLoss: 0.04285490233573968, Temperature 7.187710616690208e-05, step_size 0.8477171396645162, test_acc: 0.5754\n",
            "Epoch 3493, BestLoss: 0.0429863898194728, Temperature 7.566011175463378e-05, step_size 0.8476323679505497, test_acc: 0.574\n",
            "Epoch 3494, BestLoss: 0.0429863898194728, Temperature 7.187710616690208e-05, step_size 0.8475476047137547, test_acc: 0.574\n",
            "Epoch 3495, BestLoss: 0.0429529230289344, Temperature 7.566011175463378e-05, step_size 0.8475476047137547, test_acc: 0.5758\n",
            "Epoch 3496, BestLoss: 0.0429480326982906, Temperature 7.187710616690208e-05, step_size 0.8474628499532834, test_acc: 0.5772\n",
            "Epoch 3497, BestLoss: 0.04298310846934511, Temperature 6.828325085855697e-05, step_size 0.847378103668288, test_acc: 0.5768\n",
            "Epoch 3498, BestLoss: 0.04298310846934511, Temperature 6.486908831562912e-05, step_size 0.8472933658579213, test_acc: 0.5768\n",
            "Epoch 3499, BestLoss: 0.04298310846934511, Temperature 6.828325085855697e-05, step_size 0.8474628499532834, test_acc: 0.5768\n",
            "Epoch 3500, BestLoss: 0.0428465994326904, Temperature 7.187710616690208e-05, step_size 0.847378103668288, test_acc: 0.5768\n",
            "Epoch 3501, BestLoss: 0.04282223510132201, Temperature 6.828325085855697e-05, step_size 0.8472933658579213, test_acc: 0.5769\n",
            "Epoch 3502, BestLoss: 0.04279577708397853, Temperature 6.486908831562912e-05, step_size 0.8472086365213355, test_acc: 0.5776\n",
            "Epoch 3503, BestLoss: 0.04279577708397853, Temperature 6.162563389984766e-05, step_size 0.8471239156576834, test_acc: 0.5776\n",
            "Epoch 3504, BestLoss: 0.04279577708397853, Temperature 6.486908831562912e-05, step_size 0.8472933658579213, test_acc: 0.5776\n",
            "Epoch 3505, BestLoss: 0.042811635201836507, Temperature 6.828325085855697e-05, step_size 0.8472086365213355, test_acc: 0.5766\n"
          ]
        }
      ],
      "source": [
        "# MNIST\n",
        "nl.set_random_key(4)\n",
        "layers = [\n",
        "    nl.SADense(784, 128),\n",
        "    nl.ReLU(),\n",
        "    nl.SADense(128, 10),\n",
        "    nl.Softmax(),\n",
        "]\n",
        "\n",
        "net = nl.NeuralNet(layers)\n",
        "optimizer = SimulatedAnnealingOptimizer(net, learning_rate = 1, loss=nl.MeanSquaredError())\n",
        "\n",
        "optimizer.fit((cx_train, cy_train), (cx_test, cy_test), epochs=10000, batch_size=60000, sample_per_batch=1, initial_temp=1.0, cooling_rate=0.95, verbose=True)\n",
        "# Infer on cx_test, cy_test\n",
        "predictions = net.forward(cx_test)\n",
        "preds = jnp.array(nl.antiCategorical(predictions))\n",
        "expected = jnp.array(nl.antiCategorical(cy_test))\n",
        "\n",
        "print(f'Accuracy: {sklearn.metrics.accuracy_score(expected.get(), preds.get())}')\n",
        "print(f'Confusion Matrix: {sklearn.metrics.confusion_matrix(expected.get(), preds.get())}')\n",
        "print(f'Classification Report: {sklearn.metrics.classification_report(expected.get(), preds.get())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihnJ0B6oDT7X"
      },
      "source": [
        "# Extreme Learning Machines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "1VGWIuDRDbW8"
      },
      "outputs": [],
      "source": [
        "# Extreme Learning Machines\n",
        "class ELM_Optimizer(nl.Optimizer):\n",
        "    def __init__(self, model, learning_rate, loss):\n",
        "        super().__init__(model, loss)\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "    def train_step(self, x_batch, y_batch, alpha=0):\n",
        "        predictions = self.model.forward(x_batch)\n",
        "        loss_value = self.loss.forward(predictions, y_batch)\n",
        "\n",
        "        # Smooth out y_batch\n",
        "        y_batch = jnp.where(y_batch > 0.5, 0.9, 0.1)\n",
        "        expected = y_batch\n",
        "        for layer in reversed(self.model.get_layers()):\n",
        "            if isinstance(layer, nl.Dense):\n",
        "                x_inv = jnp.linalg.pinv(layer.last_inputs)\n",
        "                weight_approx = jnp.dot(x_inv, expected)\n",
        "                layer.weights = layer.weights * alpha + weight_approx * (1 - alpha)\n",
        "                # layer.weights = weight_approx\n",
        "                # expected = layer.last_inputs\n",
        "                expected = layer.inverse(expected)\n",
        "            else:\n",
        "                expected = layer.inverse(expected)\n",
        "        return loss_value\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hplic86C31-r",
        "outputId": "8f789b3b-06d0-4908-af3c-94c309b11d33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.16489561130438207, test_acc: 1.0\n",
            "Epoch 1, Loss: 0.14321428571428574, test_acc: 1.0\n",
            "Epoch 2, Loss: 0.1432142857142857, test_acc: 1.0\n",
            "Epoch 3, Loss: 0.1432142857142857, test_acc: 1.0\n",
            "Epoch 4, Loss: 0.1432142857142857, test_acc: 1.0\n",
            "Epoch 5, Loss: 0.14321428571428574, test_acc: 1.0\n",
            "Epoch 6, Loss: 0.1432142857142857, test_acc: 1.0\n",
            "Epoch 7, Loss: 0.1432142857142857, test_acc: 1.0\n",
            "Epoch 8, Loss: 0.1432142857142857, test_acc: 1.0\n",
            "Epoch 9, Loss: 0.1432142857142857, test_acc: 1.0\n",
            "expected [[0]\n",
            " [1]\n",
            " [1]\n",
            " [0]\n",
            " [1]\n",
            " [0]\n",
            " [0]]\n",
            "preds [[0.   ]\n",
            " [0.05 ]\n",
            " [0.475]\n",
            " [0.525]\n",
            " [0.475]\n",
            " [0.   ]\n",
            " [0.525]]\n"
          ]
        }
      ],
      "source": [
        "# XOR\n",
        "nl.set_random_key(4)\n",
        "layers = [\n",
        "    nl.Dense(2, 3, False),\n",
        "    nl.LeakyReLU(),\n",
        "    nl.Dense(3, 1, False),\n",
        "    nl.LeakyReLU(),\n",
        "]\n",
        "\n",
        "net = nl.NeuralNet(layers)\n",
        "optimizer = ELM_Optimizer(net, learning_rate = 0.1, loss=nl.MeanSquaredError())\n",
        "\n",
        "optimizer.fit((xor_x_train, xor_y_train), (xor_x_train, xor_y_train), epochs=10, batch_size=60000, verbose=True)\n",
        "# Infer on cx_test, cy_test\n",
        "preds = net(xor_x_train)\n",
        "expected = xor_y_train\n",
        "\n",
        "print(\"expected\", expected)\n",
        "print(\"preds\", preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFjPB4kq30EY",
        "outputId": "63096f35-71c1-421f-ce48-d72d52847f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0, Loss: 0.10928068989420225, test_acc: 0.8509\n",
            "Accuracy: 0.8509\n",
            "Confusion Matrix: [[ 936    0    3    3    2    9   17    1    7    2]\n",
            " [   0 1108    2    2    1    1    5    1   14    1]\n",
            " [  18   59  805   29   15    0   38   24   39    5]\n",
            " [   5   19   24  875    1   19    9   20   24   14]\n",
            " [   0   24    8    4  866    5    9    2   14   50]\n",
            " [  20   15    6   77   16  632   22   14   66   24]\n",
            " [  19   10   10    0   19   21  870    0    9    0]\n",
            " [   5   40   18    6   22    1    1  868    5   62]\n",
            " [  16   56    9   32   26   47   15   11  736   26]\n",
            " [  19   11    3   15   69    0    1   67   11  813]]\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       980\n",
            "           1       0.83      0.98      0.89      1135\n",
            "           2       0.91      0.78      0.84      1032\n",
            "           3       0.84      0.87      0.85      1010\n",
            "           4       0.84      0.88      0.86       982\n",
            "           5       0.86      0.71      0.78       892\n",
            "           6       0.88      0.91      0.89       958\n",
            "           7       0.86      0.84      0.85      1028\n",
            "           8       0.80      0.76      0.78       974\n",
            "           9       0.82      0.81      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# MNIST\n",
        "nl.set_random_key(4)\n",
        "layers = [\n",
        "    nl.Dense(784, 128, False),\n",
        "    # LeakyReLU(),\n",
        "    # Linear(),\n",
        "    # Dense(128, 128, False),\n",
        "    # LeakyReLU(),\n",
        "    # Dense(128, 10, False),\n",
        "    # Sigmoid(),\n",
        "]\n",
        "\n",
        "net = nl.NeuralNet(layers)\n",
        "optimizer = ELM_Optimizer(net, learning_rate = 0.01, loss=nl.MeanSquaredError())\n",
        "\n",
        "optimizer.fit((cx_train, cy_train), (cx_test, cy_test), epochs=1, batch_size=60000, verbose=True)\n",
        "# Infer on cx_test, cy_test\n",
        "predictions = net.forward(cx_test)\n",
        "preds = jnp.array(nl.antiCategorical(predictions))\n",
        "expected = jnp.array(nl.antiCategorical(cy_test))\n",
        "\n",
        "print(f'Accuracy: {sklearn.metrics.accuracy_score(expected.get(), preds.get())}')\n",
        "print(f'Confusion Matrix: {sklearn.metrics.confusion_matrix(expected.get(), preds.get())}')\n",
        "print(f'Classification Report: {sklearn.metrics.classification_report(expected.get(), preds.get())}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "2f5L3HXfD3ku"
      },
      "outputs": [],
      "source": [
        "# Given matrices\n",
        "a = cy_train[:30000]\n",
        "b = cx_train[:30000]\n",
        "c = cy_train[30000:]\n",
        "d = cx_train[30000:]\n",
        "\n",
        "# Randomly initialize x and y\n",
        "x = jnp.random.rand(b.shape[1], c.shape[1])\n",
        "y = jnp.random.rand(a.shape[0], c.shape[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uybi_KwYC0dr",
        "outputId": "8abeaa53-c080-4551-8c48-683efe7fdeaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.8534\n",
            "Confusion Matrix: [[ 942    0    2    2    1    7   15    2    7    2]\n",
            " [   0 1107    2    2    1    1    5    2   15    0]\n",
            " [  17   56  809   28   16    0   42   21   39    4]\n",
            " [   4   15   26  887    2   14    9   21   21   11]\n",
            " [   0   23    6    3  872    5   10    2   13   48]\n",
            " [  20   17    2   84   19  624   22   13   69   22]\n",
            " [  17    9   10    0   21   20  872    0    9    0]\n",
            " [   5   38   18    8   20    0    1  877    3   58]\n",
            " [  17   54    9   32   27   42   15   12  743   23]\n",
            " [  18   10    2   15   72    1    1   76   13  801]]\n",
            "Classification Report:               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93       980\n",
            "           1       0.83      0.98      0.90      1135\n",
            "           2       0.91      0.78      0.84      1032\n",
            "           3       0.84      0.88      0.86      1010\n",
            "           4       0.83      0.89      0.86       982\n",
            "           5       0.87      0.70      0.78       892\n",
            "           6       0.88      0.91      0.89       958\n",
            "           7       0.85      0.85      0.85      1028\n",
            "           8       0.80      0.76      0.78       974\n",
            "           9       0.83      0.79      0.81      1009\n",
            "\n",
            "    accuracy                           0.85     10000\n",
            "   macro avg       0.85      0.85      0.85     10000\n",
            "weighted avg       0.85      0.85      0.85     10000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Calculate intermediate variables\n",
        "# z1 = jnp.dot(b, x)\n",
        "# z2 = jnp.dot(d, x)\n",
        "z1 = b\n",
        "z2 = d\n",
        "\n",
        "# Form stacked matrices\n",
        "A = jnp.vstack((a, c))\n",
        "Z = jnp.vstack((z1, z2))\n",
        "\n",
        "# Compute pseudoinverse and solve for y\n",
        "Z_pseudo_inv = jnp.linalg.pinv(Z)\n",
        "y = jnp.dot(Z_pseudo_inv, A)\n",
        "\n",
        "# Substitute back to solve for x\n",
        "# B = jnp.vstack((b, d))\n",
        "# Z_prime = jnp.vstack((jnp.dot(b, x), jnp.dot(d, x)))\n",
        "# B_pseudo_inv = jnp.linalg.pinv(B)\n",
        "# x = jnp.dot(B_pseudo_inv, Z_prime)\n",
        "\n",
        "# output = jnp.dot(cx_test, x)\n",
        "output = jnp.dot(cx_test, y)\n",
        "\n",
        "preds = jnp.array(nl.antiCategorical(output))\n",
        "expected = jnp.array(nl.antiCategorical(cy_test))\n",
        "\n",
        "print(f'Accuracy: {sklearn.metrics.accuracy_score(expected.get(), preds.get())}')\n",
        "print(f'Confusion Matrix: {sklearn.metrics.confusion_matrix(expected.get(), preds.get())}')\n",
        "print(f'Classification Report: {sklearn.metrics.classification_report(expected.get(), preds.get())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkzlISnxmDe2"
      },
      "source": [
        "# ELM + Simulated Annealing Hybrid"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "0tWEJtvmmHUH"
      },
      "outputs": [],
      "source": [
        "# Extreme Learning Machines Hybrid\n",
        "class ELM_SA_Optimizer(SimulatedAnnealingOptimizer):\n",
        "    def __init__(self, model, learning_rate, loss):\n",
        "        super().__init__(model, learning_rate, loss)\n",
        "\n",
        "    def train_step(self, x_batch, y_batch, alpha=0.8):\n",
        "        predictions = self.model.forward(x_batch)\n",
        "        # loss_value = self.loss.forward(predictions, y_batch)\n",
        "\n",
        "        # Smooth out y_batch\n",
        "        y_batch = jnp.where(y_batch > 0.5, 0.9, 0.1)\n",
        "        expected = y_batch\n",
        "        for layer in reversed(self.model.get_layers()):\n",
        "            if isinstance(layer, Dense):\n",
        "                x_inv = jnp.linalg.pinv(layer.last_inputs)\n",
        "                weight_approx = jnp.dot(x_inv, expected)\n",
        "                layer.weights = layer.weights * alpha + weight_approx * (1 - alpha)\n",
        "                # layer.weights = weight_approx\n",
        "                # expected = layer.last_inputs\n",
        "                expected = layer.inverse(expected)\n",
        "            else:\n",
        "                expected = layer.inverse(expected)\n",
        "\n",
        "        loss_value = super().train_step(x_batch, y_batch)\n",
        "        return loss_value\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CqA2JSPShvah"
      },
      "source": [
        "# K-BFGS Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_g0rlkJ5MPZ"
      },
      "outputs": [],
      "source": [
        "class Layer:\n",
        "    def forward(self, inputs):\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        raise NotImplementedError\n",
        "\n",
        "class Dense(Layer):\n",
        "    def __init__(self, n_input, n_output):\n",
        "        self.weights = jnp.random.randn(n_input, n_output) * jnp.sqrt(2.0 / n_input)\n",
        "        self.biases = jnp.zeros((1, n_output))\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        self.inputs = inputs\n",
        "        self.output = jnp.dot(inputs, self.weights) + self.biases\n",
        "        return self.output\n",
        "\n",
        "    def set_weights_biases(self, weights, biases):\n",
        "        self.weights = weights\n",
        "        self.biases = biases\n",
        "\n",
        "    def get_params(self):\n",
        "        return jnp.concatenate([self.weights.flatten(), self.biases.flatten()])\n",
        "\n",
        "    def set_params(self, params):\n",
        "        weight_size = self.weights.size\n",
        "        self.weights = params[:weight_size].reshape(self.weights.shape)\n",
        "        self.biases = params[weight_size:].reshape(self.biases.shape)\n",
        "\n",
        "class Sigmoid:\n",
        "    @staticmethod\n",
        "    def forward(x):\n",
        "        return 1 / (1 + jnp.exp(-x))\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(x):\n",
        "        sigmoid = Sigmoid.forward(x)\n",
        "        return sigmoid * (1 - sigmoid)\n",
        "\n",
        "class ReLU:\n",
        "    @staticmethod\n",
        "    def forward(x):\n",
        "        return jnp.maximum(0, x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(x):\n",
        "        return jnp.where(x > 0, 1, 0)\n",
        "\n",
        "class Softmax:\n",
        "    @staticmethod\n",
        "    def forward(x):\n",
        "        exp_x = jnp.exp(x - jnp.max(x, axis=1, keepdims=True))\n",
        "        return exp_x / jnp.sum(exp_x, axis=1, keepdims=True)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(x):\n",
        "        pass\n",
        "\n",
        "class MeanSquaredError:\n",
        "    @staticmethod\n",
        "    def forward(predictions, targets):\n",
        "        return jnp.mean((predictions - targets)**2)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(predictions, targets):\n",
        "        return 2 * (predictions - targets) / predictions.size\n",
        "\n",
        "class NeuralNet:\n",
        "    def __init__(self, layers, loss):\n",
        "        self.layers = layers\n",
        "        self.loss = loss\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        for layer in self.layers:\n",
        "            inputs = layer.forward(inputs)\n",
        "        return inputs\n",
        "\n",
        "    def get_params(self):\n",
        "        \"\"\"Returns all layer parameters as a single flattened array.\"\"\"\n",
        "        params = jnp.concatenate([layer.get_params() for layer in self.layers if isinstance(layer, Dense)])\n",
        "        return params\n",
        "\n",
        "    def set_params(self, params):\n",
        "        \"\"\"Sets all layer parameters from a single flattened array.\"\"\"\n",
        "        start_idx = 0\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, Dense):\n",
        "                layer_params_size = layer.get_params().size\n",
        "                layer.set_params(params[start_idx:start_idx + layer_params_size])\n",
        "                start_idx += layer_params_size\n",
        "\n",
        "    def loss_and_grad(self, params, x_train, y_train):\n",
        "        \"\"\"Calculates loss and gradient based on provided parameters.\"\"\"\n",
        "        self.set_params(params)\n",
        "        predictions = self.forward(x_train)\n",
        "\n",
        "        loss_value = self.loss.forward(predictions, y_train)\n",
        "        grad_loss = self.loss.backward(predictions, y_train)\n",
        "\n",
        "        grad_params = []\n",
        "        for layer in self.layers:\n",
        "            if isinstance(layer, Dense):\n",
        "                grad_weights = jnp.dot(layer.inputs.T, grad_loss)\n",
        "                grad_biases = jnp.sum(grad_loss, axis=0, keepdims=True)\n",
        "\n",
        "                grad_params.append(grad_weights.flatten())\n",
        "                grad_params.append(grad_biases.flatten())\n",
        "\n",
        "                grad_loss = jnp.dot(grad_loss, layer.weights.T)\n",
        "\n",
        "        grad_params = jnp.concatenate(grad_params)\n",
        "        return loss_value, grad_params\n",
        "\n",
        "    def k_bfgs(self, x_train, y_train, epochs=1, verbose=True):\n",
        "        \"\"\"Trains the model using the K-BFGS algorithm.\"\"\"\n",
        "        params = self.get_params()\n",
        "\n",
        "        # Initialize memory for Hessian approximation\n",
        "        s_list, y_list = [], []\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            loss_value, grad_params = self.loss_and_grad(params, x_train, y_train)\n",
        "\n",
        "            # Form Hessian approximation from s and y lists\n",
        "            H = jnp.eye(len(params))\n",
        "\n",
        "            for s, y in zip(s_list, y_list):\n",
        "                rho = 1 / jnp.dot(y, s)\n",
        "                V = H - rho * jnp.outer(jnp.dot(H, s), y)\n",
        "                H = V + rho * jnp.outer(s, s)\n",
        "\n",
        "            # Compute search direction\n",
        "            direction = -jnp.dot(H, grad_params)\n",
        "\n",
        "            # Line search to find suitable step size\n",
        "            step_size = 1.0\n",
        "\n",
        "            def line_search_loss(step):\n",
        "                new_params = params + step * direction\n",
        "                new_loss, _ = self.loss_and_grad(new_params, x_train, y_train)\n",
        "                return new_loss\n",
        "\n",
        "            # Try step size reductions until loss decreases\n",
        "            while line_search_loss(step_size) >= loss_value:\n",
        "                step_size *= 0.5\n",
        "                if step_size < 1e-10:\n",
        "                    break\n",
        "\n",
        "            new_params = params + step_size * direction\n",
        "\n",
        "            # Update s and y lists\n",
        "            s = new_params - params\n",
        "            new_loss, new_grad_params = self.loss_and_grad(new_params, x_train, y_train)\n",
        "            y = new_grad_params - grad_params\n",
        "\n",
        "            if len(s_list) >= 10:  # Limit to 10 recent updates\n",
        "                s_list.pop(0)\n",
        "                y_list.pop(0)\n",
        "\n",
        "            s_list.append(s)\n",
        "            y_list.append(y)\n",
        "\n",
        "            params = new_params\n",
        "\n",
        "            if verbose:\n",
        "                print(f'Epoch {epoch}, Loss: {loss_value}')\n",
        "\n",
        "        self.set_params(params)\n",
        "\n",
        "def antiCategorical(arr):\n",
        "    return jnp.argmax(arr, axis=1)\n",
        "\n",
        "def main():\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    y_train_c = jnp.array(to_categorical(y_train))\n",
        "    y_test_c = jnp.array(to_categorical(y_test))\n",
        "\n",
        "    x_train = jnp.array(x_train.reshape(-1, 784) / 255.)\n",
        "    x_test = jnp.array(x_test.reshape(-1, 784) / 255.)\n",
        "\n",
        "    layers = [\n",
        "        Dense(784, 128),\n",
        "        ReLU(),\n",
        "        Dense(128, 10),\n",
        "        Softmax(),\n",
        "    ]\n",
        "\n",
        "    nn = NeuralNet(layers, loss=MeanSquaredError())\n",
        "\n",
        "    nn.k_bfgs(x_train, y_train_c, epochs=10, verbose=True)\n",
        "\n",
        "    predictions = nn.forward(x_test)\n",
        "\n",
        "    preds = antiCategorical(predictions)\n",
        "    expected = antiCategorical(y_test_c)\n",
        "\n",
        "    print(f'Accuracy: {sklearn.metrics.accuracy_score(expected, preds)}')\n",
        "    print(f'Confusion Matrix: {sklearn.metrics.confusion_matrix(expected, preds)}')\n",
        "    print(f'Classification Report: {sklearn.metrics.classification_report(expected, preds)}')\n",
        "\n",
        "main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "walR85hABMuW"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "LkT5n07Hc0et",
        "outputId": "3a626ecb-159e-4bec-bb5f-c11172af16d7"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "only integer scalar arrays can be converted to a scalar index",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-28f4c2d15334>\u001b[0m in \u001b[0;36m<cell line: 142>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-28f4c2d15334>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;31m# Train the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;31m# Evaluate on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-28f4c2d15334>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X_train, y_train, epochs)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-28f4c2d15334>\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# Initialize neuron activations with input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneurons\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_neurons\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Propagate for multiple passes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Data Preprocessing\n",
        "def preprocess_data():\n",
        "\n",
        "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    y_train_c = jnp.array(to_categorical(y_train))\n",
        "    y_test_c = jnp.array(to_categorical(y_test))\n",
        "\n",
        "    x_train = jnp.array(x_train.reshape(-1, 784) / 255.)\n",
        "    x_test = jnp.array(x_test.reshape(-1, 784) / 255.)\n",
        "\n",
        "    # Split into training and testing sets\n",
        "    return x_train, x_test, y_train_c, y_test_c\n",
        "\n",
        "# Utility functions\n",
        "def relu(x):\n",
        "    return jnp.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return jnp.where(x > 0, 1, 0)\n",
        "\n",
        "# Mesh Neural Network Class\n",
        "class MeshNeuralNetwork:\n",
        "    def __init__(self, num_neurons, input_size, output_size, num_passes=3, learning_rate=0.001):\n",
        "        self.num_neurons = num_neurons\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "        self.num_passes = num_passes\n",
        "        self.learning_rate = learning_rate\n",
        "\n",
        "        # Initialize neurons\n",
        "        self.neurons = [None] * num_neurons\n",
        "        self.connections = jnp.random.choice(\n",
        "            jnp.arange(num_neurons),\n",
        "            size=(num_neurons, num_neurons),\n",
        "            replace=True\n",
        "        )\n",
        "\n",
        "        # Initialize weights and biases randomly\n",
        "        self.weights = jnp.random.randn(num_neurons, num_neurons)\n",
        "        self.biases = jnp.random.randn(num_neurons)\n",
        "\n",
        "        # Select random input/output neurons\n",
        "        self.input_neurons = jnp.random.choice(jnp.arange(num_neurons), size=input_size, replace=False)\n",
        "        self.output_neurons = jnp.random.choice(jnp.arange(num_neurons), size=output_size, replace=False)\n",
        "\n",
        "    def forward_pass(self, X):\n",
        "        # Initialize neuron activations with input data\n",
        "        self.neurons[self.input_neurons] = X\n",
        "\n",
        "        # Propagate for multiple passes\n",
        "        for _ in range(self.num_passes):\n",
        "            for i in range(self.num_neurons):\n",
        "                # Update each neuron activation based on connections\n",
        "                inputs = self.weights[i, self.connections[i]]\n",
        "                activation_input = jnp.dot(inputs, self.neurons[self.connections[i]]) + self.biases[i]\n",
        "                self.neurons[i] = relu(activation_input)\n",
        "\n",
        "        # Output activations\n",
        "        return self.neurons[self.output_neurons]\n",
        "\n",
        "    def backward_pass(self, X, y_true, y_pred):\n",
        "        # Loss gradient (Cross-Entropy Loss derivative)\n",
        "        loss_grad = y_pred - y_true\n",
        "\n",
        "        # Backpropagate through output neurons first\n",
        "        for i in self.output_neurons:\n",
        "            # Compute gradients w.r.t weights and biases\n",
        "            neuron_output = self.neurons[i]\n",
        "            relu_grad = relu_derivative(neuron_output)\n",
        "            grad_w = jnp.outer(loss_grad[i], self.neurons[self.connections[i]]) * relu_grad\n",
        "            grad_b = loss_grad[i] * relu_grad\n",
        "\n",
        "            # Update weights and biases\n",
        "            self.weights[i, self.connections[i]] -= self.learning_rate * grad_w\n",
        "            self.biases[i] -= self.learning_rate * grad_b\n",
        "\n",
        "        # Backpropagate further into the network\n",
        "        for i in reversed(range(self.num_neurons)):\n",
        "            if i in self.output_neurons:\n",
        "                continue\n",
        "\n",
        "            neuron_output = self.neurons[i]\n",
        "            relu_grad = relu_derivative(neuron_output)\n",
        "            grad_w = jnp.outer(loss_grad[i], self.neurons[self.connections[i]]) * relu_grad\n",
        "            grad_b = loss_grad[i] * relu_grad\n",
        "\n",
        "            self.weights[i, self.connections[i]] -= self.learning_rate * grad_w\n",
        "            self.biases[i] -= self.learning_rate * grad_b\n",
        "\n",
        "    def fit(self, X_train, y_train, epochs):\n",
        "        for epoch in range(epochs):\n",
        "            for X_batch, y_batch in zip(X_train, y_train):\n",
        "                y_pred = self.forward_pass(X_batch)\n",
        "                self.backward_pass(X_batch, y_batch, y_pred)\n",
        "\n",
        "            # Output training metrics\n",
        "            train_loss, train_accuracy = self.evaluate(X_train, y_train)\n",
        "            print(f\"Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "    def evaluate(self, X, y):\n",
        "        correct_predictions = 0\n",
        "        total_loss = 0\n",
        "\n",
        "        for X_sample, y_true in zip(X, y):\n",
        "            y_pred = self.forward_pass(X_sample)\n",
        "\n",
        "            # Compute loss\n",
        "            loss = jnp.mean(-y_true * jnp.log(y_pred) - (1 - y_true) * jnp.log(1 - y_pred))\n",
        "            total_loss += loss\n",
        "\n",
        "            # Compute accuracy\n",
        "            correct_predictions += jnp.argmax(y_pred) == jnp.argmax(y_true)\n",
        "\n",
        "        return total_loss / len(X), correct_predictions / len(X)\n",
        "\n",
        "# Main Training Loop\n",
        "def main():\n",
        "    X_train, X_test, y_train, y_test = preprocess_data()\n",
        "\n",
        "    # Convert to arrays for easier manipulation\n",
        "    X_train, X_test = jnp.array(X_train), jnp.array(X_test)\n",
        "    y_train, y_test = jnp.array(y_train), jnp.array(y_test)\n",
        "\n",
        "    # Initialize network with a suitable number of neurons, input size, and output size\n",
        "    input_size, output_size = X_train.shape[1], y_train.shape[1]\n",
        "    num_neurons = 2000  # Example number\n",
        "    network = MeshNeuralNetwork(num_neurons=num_neurons, input_size=input_size, output_size=output_size, num_passes=3)\n",
        "\n",
        "    # Train the network\n",
        "    network.fit(X_train, y_train, epochs=10)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    test_loss, test_accuracy = network.evaluate(X_test, y_test)\n",
        "    print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tunb6mihc5us"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pARZuRAtDgY0",
        "XXIwFDrQ_dBr"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
